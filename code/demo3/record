2017:03:02 23:33:47	reading and processing the text file
2017:03:02 23:33:58	flatmap a list of sentence list to a list of sentence.
2017:03:02 23:37:06	reading and processing the text file
2017:03:02 23:37:17	flatmap a list of sentence list to a list of sentence.
2017:03:02 23:37:35	mapping from index to word.
2017:03:02 23:37:35	mapping from word to index.
2017:03:02 23:39:30	reading and processing the text file
2017:03:02 23:39:30	preprocess the dataset.
2017:03:02 23:39:36	build a vocabulary.
2017:03:02 23:39:36	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:39:53	...mapping from index to word.
2017:03:02 23:39:53	...mapping from word to index.
2017:03:02 23:39:53	...map word to index.
2017:03:02 23:41:00	reading and processing the text file.
2017:03:02 23:41:00	preprocess the dataset.
2017:03:02 23:41:05	build a vocabulary.
2017:03:02 23:41:05	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:41:23	...mapping from index to word.
2017:03:02 23:41:23	...mapping from word to index.
2017:03:02 23:41:23	...map word to index.
2017:03:02 23:41:27	reading and processing the text file.
2017:03:02 23:41:27	preprocess the dataset.
2017:03:02 23:41:31	build a vocabulary.
2017:03:02 23:41:31	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:41:51	reading and processing the text file.
2017:03:02 23:41:51	preprocess the dataset.
2017:03:02 23:41:55	build a vocabulary.
2017:03:02 23:41:55	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:42:30	reading and processing the text file.
2017:03:02 23:42:30	preprocess the dataset.
2017:03:02 23:42:34	build a vocabulary.
2017:03:02 23:42:34	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:42:35	...mapping from index to word.
2017:03:02 23:42:35	...mapping from word to index.
2017:03:02 23:42:35	...map word to index.
2017:03:02 23:43:05	reading and processing the text file.
2017:03:02 23:43:05	preprocess the dataset.
2017:03:02 23:43:09	build a vocabulary.
2017:03:02 23:43:09	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:43:10	...mapping from index to word.
2017:03:02 23:43:10	...mapping from word to index.
2017:03:02 23:43:10	...map word to index.
2017:03:02 23:43:37	reading and processing the text file.
2017:03:02 23:43:37	preprocess the dataset.
2017:03:02 23:43:42	build a vocabulary.
2017:03:02 23:43:42	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:43:43	...mapping from index to word.
2017:03:02 23:43:43	...mapping from word to index.
2017:03:02 23:43:43	...map word to index.
2017:03:02 23:44:45	reading and processing the text file.
2017:03:02 23:44:45	preprocess the dataset.
2017:03:02 23:44:49	build a vocabulary.
2017:03:02 23:44:49	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:44:50	...mapping from index to word.
2017:03:02 23:44:50	...mapping from word to index.
2017:03:02 23:44:50	...map word to index.
2017:03:02 23:45:10	reading and processing the text file.
2017:03:02 23:45:10	preprocess the dataset.
2017:03:02 23:45:14	build a vocabulary.
2017:03:02 23:45:14	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:45:15	...mapping from index to word.
2017:03:02 23:45:15	...mapping from word to index.
2017:03:02 23:45:15	...map word to index.
2017:03:02 23:45:37	reading and processing the text file.
2017:03:02 23:45:37	preprocess the dataset.
2017:03:02 23:45:41	build a vocabulary.
2017:03:02 23:45:41	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:45:42	...mapping from index to word.
2017:03:02 23:45:42	...mapping from word to index.
2017:03:02 23:45:43	...map word to index.
2017:03:02 23:47:16	reading and processing the text file.
2017:03:02 23:47:16	preprocess the dataset.
2017:03:02 23:47:20	build a vocabulary.
2017:03:02 23:47:20	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:47:22	...mapping from index to word.
2017:03:02 23:47:22	...mapping from word to index.
2017:03:02 23:47:22	...map word to index.
2017:03:02 23:48:16	reading and processing the text file.
2017:03:02 23:48:16	preprocess the dataset.
2017:03:02 23:48:20	build a vocabulary.
2017:03:02 23:48:20	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:48:21	...mapping from index to word.
2017:03:02 23:48:22	...mapping from word to index.
2017:03:02 23:48:22	...map word to index.
2017:03:02 23:48:50	reading and processing the text file.
2017:03:02 23:48:50	preprocess the dataset.
2017:03:02 23:48:54	build a vocabulary.
2017:03:02 23:48:54	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:48:56	...mapping from index to word.
2017:03:02 23:48:56	...mapping from word to index.
2017:03:02 23:48:56	...map word to index.
2017:03:02 23:50:52	reading and processing the text file.
2017:03:02 23:50:52	preprocess the dataset.
2017:03:02 23:50:56	build a vocabulary.
2017:03:02 23:50:56	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:50:58	...mapping from index to word.
2017:03:02 23:50:58	...mapping from word to index.
2017:03:02 23:50:58	...map word to index.
2017:03:02 23:51:12	reading and processing the text file.
2017:03:02 23:51:12	preprocess the dataset.
2017:03:02 23:51:17	build a vocabulary.
2017:03:02 23:51:17	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:51:18	...mapping from index to word.
2017:03:02 23:51:18	...mapping from word to index.
2017:03:02 23:51:18	...map word to index.
2017:03:02 23:51:53	reading and processing the text file.
2017:03:02 23:51:53	preprocess the dataset.
2017:03:02 23:52:06	reading and processing the text file.
2017:03:02 23:52:06	preprocess the dataset.
2017:03:02 23:52:16	reading and processing the text file.
2017:03:02 23:52:16	preprocess the dataset.
2017:03:02 23:52:22	build a vocabulary.
2017:03:02 23:52:22	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:52:23	...mapping from index to word.
2017:03:02 23:52:23	...mapping from word to index.
2017:03:02 23:52:23	...map word to index.
2017:03:02 23:53:08	reading and processing the text file.
2017:03:02 23:53:08	preprocess the dataset.
2017:03:02 23:53:16	build a vocabulary.
2017:03:02 23:53:16	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:53:18	...mapping from index to word.
2017:03:02 23:53:18	...mapping from word to index.
2017:03:02 23:53:18	...map word to index.
2017:03:02 23:53:33	reading and processing the text file.
2017:03:02 23:53:33	preprocess the dataset.
2017:03:02 23:53:41	build a vocabulary.
2017:03:02 23:53:41	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:53:42	...mapping from index to word.
2017:03:02 23:53:42	...mapping from word to index.
2017:03:02 23:53:42	...map word to index.
2017:03:02 23:54:31	reading and processing the text file.
2017:03:02 23:54:31	preprocess the dataset.
2017:03:02 23:54:39	build a vocabulary.
2017:03:02 23:54:39	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:54:40	...mapping from index to word.
2017:03:02 23:54:40	...mapping from word to index.
2017:03:02 23:54:40	...map word to index.
2017:03:02 23:56:49	reading and processing the text file.
2017:03:02 23:56:49	preprocess the dataset.
2017:03:02 23:56:58	build a vocabulary.
2017:03:02 23:56:58	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:56:59	...mapping from index to word.
2017:03:02 23:56:59	...mapping from word to index.
2017:03:02 23:56:59	...map word to index.
2017:03:02 23:57:37	reading and processing the text file.
2017:03:02 23:57:37	preprocess the dataset.
2017:03:02 23:57:45	build a vocabulary.
2017:03:02 23:57:45	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:57:47	...mapping from index to word.
2017:03:02 23:57:47	...mapping from word to index.
2017:03:02 23:57:47	...map word to index.
2017:03:02 23:58:10	reading and processing the text file.
2017:03:02 23:58:10	preprocess the dataset.
2017:03:02 23:58:23	reading and processing the text file.
2017:03:02 23:58:23	preprocess the dataset.
2017:03:02 23:58:32	reading and processing the text file.
2017:03:02 23:58:32	preprocess the dataset.
2017:03:02 23:58:41	build a vocabulary.
2017:03:02 23:58:41	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:58:42	...mapping from index to word.
2017:03:02 23:58:42	...mapping from word to index.
2017:03:02 23:58:42	...map word to index.
2017:03:02 23:58:56	reading and processing the text file.
2017:03:02 23:58:56	preprocess the dataset.
2017:03:02 23:59:05	build a vocabulary.
2017:03:02 23:59:05	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:59:07	...mapping from index to word.
2017:03:02 23:59:07	...mapping from word to index.
2017:03:02 23:59:07	...map word to index.
2017:03:02 23:59:41	reading and processing the text file.
2017:03:02 23:59:41	preprocess the dataset.
2017:03:02 23:59:51	build a vocabulary.
2017:03:02 23:59:51	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:59:52	...mapping from index to word.
2017:03:02 23:59:53	...mapping from word to index.
2017:03:02 23:59:53	...map word to index.
2017:03:03 00:00:30	reading and processing the text file.
2017:03:03 00:00:30	preprocess the dataset.
2017:03:03 00:00:41	build a vocabulary.
2017:03:03 00:00:41	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:00:43	...mapping from index to word.
2017:03:03 00:00:43	...mapping from word to index.
2017:03:03 00:00:43	...map word to index.
2017:03:03 00:01:13	reading and processing the text file.
2017:03:03 00:01:13	preprocess the dataset.
2017:03:03 00:01:25	build a vocabulary.
2017:03:03 00:01:25	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:01:26	...mapping from index to word.
2017:03:03 00:01:26	...mapping from word to index.
2017:03:03 00:01:26	...map word to index.
2017:03:03 00:02:08	reading and processing the text file.
2017:03:03 00:02:08	preprocess the dataset.
2017:03:03 00:02:19	build a vocabulary.
2017:03:03 00:02:19	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:02:20	...mapping from index to word.
2017:03:03 00:02:20	...mapping from word to index.
2017:03:03 00:02:21	...map word to index.
2017:03:03 00:03:35	reading and processing the text file.
2017:03:03 00:03:35	preprocess the dataset.
2017:03:03 00:03:40	build a vocabulary.
2017:03:03 00:03:40	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:03:41	...mapping from index to word.
2017:03:03 00:03:41	...mapping from word to index.
2017:03:03 00:03:41	...map word to index.
2017:03:03 00:05:19	reading and processing the text file.
2017:03:03 00:05:19	preprocess the dataset.
2017:03:03 00:05:35	reading and processing the text file.
2017:03:03 00:05:35	preprocess the dataset.
2017:03:03 00:05:51	reading and processing the text file.
2017:03:03 00:05:51	preprocess the dataset.
2017:03:03 00:05:57	build a vocabulary.
2017:03:03 00:05:57	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:05:58	...mapping from index to word.
2017:03:03 00:05:58	...mapping from word to index.
2017:03:03 00:05:58	...map word to index.
2017:03:03 00:06:30	reading and processing the text file.
2017:03:03 00:06:30	preprocess the dataset.
2017:03:03 00:06:35	build a vocabulary.
2017:03:03 00:06:35	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:06:36	...mapping from index to word.
2017:03:03 00:06:36	...mapping from word to index.
2017:03:03 00:06:36	...map word to index.
2017:03:03 00:08:22	reading and processing the text file.
2017:03:03 00:08:22	preprocess the dataset.
2017:03:03 00:08:28	build a vocabulary.
2017:03:03 00:08:28	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:08:29	...mapping from index to word.
2017:03:03 00:08:29	...mapping from word to index.
2017:03:03 00:08:29	...map word to index.
2017:03:03 00:08:50	reading and processing the text file.
2017:03:03 00:08:50	preprocess the dataset.
2017:03:03 00:08:56	build a vocabulary.
2017:03:03 00:08:56	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:08:57	...mapping from index to word.
2017:03:03 00:08:57	...mapping from word to index.
2017:03:03 00:08:57	...map word to index.
2017:03:03 00:09:04	reading and processing the text file.
2017:03:03 00:09:04	preprocess the dataset.
2017:03:03 00:09:09	build a vocabulary.
2017:03:03 00:09:09	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:09:11	...mapping from index to word.
2017:03:03 00:09:11	...mapping from word to index.
2017:03:03 00:09:11	...map word to index.
2017:03:03 00:09:33	reading and processing the text file.
2017:03:03 00:09:33	preprocess the dataset.
2017:03:03 00:09:38	build a vocabulary.
2017:03:03 00:09:38	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:09:39	...mapping from index to word.
2017:03:03 00:09:39	...mapping from word to index.
2017:03:03 00:09:40	...map word to index.
2017:03:03 00:10:48	reading and processing the text file.
2017:03:03 00:10:48	preprocess the dataset.
2017:03:03 00:10:54	build a vocabulary.
2017:03:03 00:10:54	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:10:54	...mapping from index to word.
2017:03:03 00:10:54	...mapping from word to index.
2017:03:03 00:10:54	...map word to index.
2017:03:03 00:12:17	reading and processing the text file.
2017:03:03 00:12:17	preprocess the dataset.
2017:03:03 00:12:24	build a vocabulary.
2017:03:03 00:12:24	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:12:25	...mapping from index to word.
2017:03:03 00:12:25	...mapping from word to index.
2017:03:03 00:12:25	...map word to index.
2017:03:03 00:12:56	reading and processing the text file.
2017:03:03 00:12:56	preprocess the dataset.
2017:03:03 00:13:02	build a vocabulary.
2017:03:03 00:13:02	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:13:03	...mapping from index to word.
2017:03:03 00:13:03	...mapping from word to index.
2017:03:03 00:13:03	...map word to index.
2017:03:03 00:13:26	reading and processing the text file.
2017:03:03 00:13:26	preprocess the dataset.
2017:03:03 00:14:05	reading and processing the text file.
2017:03:03 00:14:05	preprocess the dataset.
2017:03:03 00:14:08	build a vocabulary.
2017:03:03 00:14:08	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:14:08	...mapping from index to word.
2017:03:03 00:14:08	...mapping from word to index.
2017:03:03 00:14:08	...map word to index.
2017:03:03 00:14:31	reading and processing the text file.
2017:03:03 00:14:31	preprocess the dataset.
2017:03:03 00:14:33	build a vocabulary.
2017:03:03 00:14:33	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:14:33	...mapping from index to word.
2017:03:03 00:14:33	...mapping from word to index.
2017:03:03 00:14:33	...map word to index.
2017:03:03 00:16:29	reading and processing the text file.
2017:03:03 00:16:29	preprocess the dataset.
2017:03:03 00:16:35	build a vocabulary.
2017:03:03 00:16:35	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:16:36	...mapping from index to word.
2017:03:03 00:16:36	...mapping from word to index.
2017:03:03 00:16:36	...map word to index.
2017:03:03 00:21:05	reading and processing the text file.
2017:03:03 00:21:05	preprocess the dataset.
2017:03:03 00:21:11	build a vocabulary.
2017:03:03 00:21:11	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:21:12	...mapping from index to word.
2017:03:03 00:21:12	...mapping from word to index.
2017:03:03 00:21:12	...map word to index.
2017:03:03 00:21:38	reading and processing the text file.
2017:03:03 00:21:38	preprocess the dataset.
2017:03:03 00:21:44	build a vocabulary.
2017:03:03 00:21:44	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:21:46	...mapping from index to word.
2017:03:03 00:21:46	...mapping from word to index.
2017:03:03 00:21:46	...map word to index.
2017:03:03 09:53:37	loading preprocessed files.
2017:03:03 09:54:07	loading preprocessed files.
2017:03:03 09:54:56	loading preprocessed files.
2017:03:03 09:55:36	loading preprocessed files.
2017:03:03 09:59:26	reading and processing the text file.
2017:03:03 09:59:26	preprocess the dataset.
2017:03:03 09:59:34	build a vocabulary.
2017:03:03 09:59:34	...flatmap a list of sentence list to a list of sentence.
2017:03:03 09:59:39	...mapping from index to word.
2017:03:03 09:59:39	...mapping from word to index.
2017:03:03 09:59:39	...map word to index.
2017:03:03 10:02:52	reading and processing the text file.
2017:03:03 10:02:52	preprocess the dataset.
2017:03:03 10:02:58	build a vocabulary.
2017:03:03 10:02:58	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:03:02	...mapping from index to word.
2017:03:03 10:03:02	...mapping from word to index.
2017:03:03 10:03:02	...map word to index.
2017:03:03 10:07:36	reading and processing the text file.
2017:03:03 10:07:36	preprocess the dataset.
2017:03:03 10:07:41	build a vocabulary.
2017:03:03 10:07:41	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:07:45	...mapping from index to word.
2017:03:03 10:07:45	...mapping from word to index.
2017:03:03 10:07:45	...map word to index.
2017:03:03 10:10:24	reading and processing the text file.
2017:03:03 10:10:24	preprocess the dataset.
2017:03:03 10:10:30	build a vocabulary.
2017:03:03 10:10:30	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:10:34	...mapping from index to word.
2017:03:03 10:10:34	...mapping from word to index.
2017:03:03 10:10:34	...map word to index.
2017:03:03 10:12:18	reading and processing the text file.
2017:03:03 10:12:18	preprocess the dataset.
2017:03:03 10:12:24	build a vocabulary.
2017:03:03 10:12:24	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:12:29	...mapping from index to word.
2017:03:03 10:12:29	...mapping from word to index.
2017:03:03 10:12:29	...map word to index.
2017:03:03 10:13:56	reading and processing the text file.
2017:03:03 10:13:56	preprocess the dataset.
2017:03:03 10:14:04	build a vocabulary.
2017:03:03 10:14:04	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:14:09	...mapping from index to word.
2017:03:03 10:14:09	...mapping from word to index.
2017:03:03 10:14:09	...map word to index.
2017:03:03 10:15:59	reading and processing the text file.
2017:03:03 10:15:59	preprocess the dataset.
2017:03:03 10:16:06	build a vocabulary.
2017:03:03 10:16:06	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:16:11	...mapping from index to word.
2017:03:03 10:16:11	...mapping from word to index.
2017:03:03 10:16:11	...map word to index.
2017:03:03 11:05:37	reading and processing the text file.
2017:03:03 11:05:37	preprocess the dataset.
2017:03:03 11:05:45	build a vocabulary.
2017:03:03 11:05:45	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:05:50	...mapping from index to word.
2017:03:03 11:05:50	...mapping from word to index.
2017:03:03 11:05:50	...map word to index.
2017:03:03 11:06:51	the vocabulary size is 40
2017:03:03 11:09:54	reading and processing the text file.
2017:03:03 11:09:54	preprocess the dataset.
2017:03:03 11:10:01	build a vocabulary.
2017:03:03 11:10:01	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:10:05	...mapping from index to word.
2017:03:03 11:10:05	...mapping from word to index.
2017:03:03 11:10:05	...map word to index.
2017:03:03 11:11:37	reading and processing the text file.
2017:03:03 11:11:37	preprocess the dataset.
2017:03:03 11:11:43	build a vocabulary.
2017:03:03 11:11:43	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:11:44	...mapping from index to word.
2017:03:03 11:11:44	...mapping from word to index.
2017:03:03 11:11:44	...map word to index.
2017:03:03 11:12:05	reading and processing the text file.
2017:03:03 11:12:05	preprocess the dataset.
2017:03:03 11:12:10	build a vocabulary.
2017:03:03 11:12:10	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:12:11	...mapping from index to word.
2017:03:03 11:12:11	...mapping from word to index.
2017:03:03 11:12:11	...map word to index.
2017:03:03 11:12:58	reading and processing the text file.
2017:03:03 11:12:58	preprocess the dataset.
2017:03:03 11:13:05	build a vocabulary.
2017:03:03 11:13:05	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:13:06	...mapping from index to word.
2017:03:03 11:13:06	...mapping from word to index.
2017:03:03 11:13:06	...map word to index.
2017:03:03 11:13:23	reading and processing the text file.
2017:03:03 11:13:23	preprocess the dataset.
2017:03:03 11:13:30	build a vocabulary.
2017:03:03 11:13:30	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:13:31	...mapping from index to word.
2017:03:03 11:13:32	...mapping from word to index.
2017:03:03 11:13:32	...map word to index.
2017:03:03 11:14:41	the vocabulary size is 29264
2017:03:03 13:49:46	loading preprocessed files.
2017:03:03 13:50:37	the vocabulary size is 29264.
2017:03:03 14:02:25	loading preprocessed files.
2017:03:03 14:07:19	reading and processing the text file.
2017:03:03 14:07:19	preprocess the dataset.
2017:03:03 14:07:24	build a vocabulary.
2017:03:03 14:07:24	...flatmap a list of sentence list to a list of sentence.
2017:03:03 14:07:25	...mapping from index to word.
2017:03:03 14:07:26	...mapping from word to index.
2017:03:03 14:07:26	...map word to index.
2017:03:03 14:13:54	reading and processing the text file.
2017:03:03 14:13:54	preprocess the dataset.
2017:03:03 14:14:00	build a vocabulary.
2017:03:03 14:14:00	...flatmap a list of sentence list to a list of sentence.
2017:03:03 14:14:02	...mapping from index to word.
2017:03:03 14:14:02	...mapping from word to index.
2017:03:03 14:14:02	...map word to index.
2017:03:03 14:15:07	the vocabulary size is 29264.
2017:03:03 14:25:50	reading and processing the text file.
2017:03:03 14:25:50	preprocess the dataset.
2017:03:03 14:26:25	reading and processing the text file.
2017:03:03 14:26:25	preprocess the dataset.
2017:03:03 14:33:12	reading and processing the text file.
2017:03:03 14:33:12	preprocess the dataset and extract the valid content.
2017:03:03 14:34:33	reading and processing the text file.
2017:03:03 14:34:33	preprocess the dataset and extract the valid content.
2017:03:03 14:34:33	init data from the raw dataset.
2017:03:03 14:36:19	reading and processing the text file.
2017:03:03 14:36:19	preprocess the dataset and extract the valid content.
2017:03:03 14:36:19	init data from the raw dataset.
2017:03:03 14:36:44	...Parse the emails into a list email objects
2017:03:03 14:38:10	...Get fields from parsed email objects
2017:03:03 14:38:31	...Parse content from emails
2017:03:03 14:38:34	...Split multiple email addresses
2017:03:03 14:38:41	...Extract the root of 'file' as 'user'
2017:03:03 14:38:42	extract content from email data frame.
2017:03:03 14:39:14	reading and processing the text file.
2017:03:03 14:39:14	preprocess the dataset and extract the valid content.
2017:03:03 14:39:49	reading and processing the text file.
2017:03:03 14:39:49	preprocess the dataset and extract the valid content.
2017:03:03 14:40:00	reading and processing the text file.
2017:03:03 14:40:00	preprocess the dataset and extract the valid content.
2017:03:03 14:40:00	init data from the raw dataset.
2017:03:03 14:40:24	...Parse the emails into a list email objects
2017:03:03 14:41:44	...Get fields from parsed email objects
2017:03:03 14:42:03	...Parse content from emails
2017:03:03 14:42:05	...Split multiple email addresses
2017:03:03 14:42:10	...Extract the root of 'file' as 'user'
2017:03:03 14:42:11	extract content from email data frame.
2017:03:03 14:45:37	reading and processing the text file.
2017:03:03 14:45:37	preprocess the dataset and extract the valid content.
2017:03:03 14:45:37	init data from the raw dataset.
2017:03:03 14:46:01	...Parse the emails into a list email objects
2017:03:03 14:47:22	...Get fields from parsed email objects
2017:03:03 14:47:42	...Parse content from emails
2017:03:03 14:47:44	...Split multiple email addresses
2017:03:03 14:47:49	...Extract the root of 'file' as 'user'
2017:03:03 14:47:50	extract content from email data frame.
2017:03:03 14:49:06	reading and processing the text file.
2017:03:03 14:49:06	preprocess the dataset and extract the valid content.
2017:03:03 14:49:47	reading and processing the text file.
2017:03:03 14:49:47	preprocess the dataset and extract the valid content.
2017:03:03 14:49:47	init data from the raw dataset.
2017:03:03 14:50:11	...Parse the emails into a list email objects
2017:03:03 14:51:34	...Get fields from parsed email objects
2017:03:03 14:51:54	...Parse content from emails
2017:03:03 14:51:57	...Split multiple email addresses
2017:03:03 14:52:01	...Extract the root of 'file' as 'user'
2017:03:03 14:52:03	extract content from email data frame.
2017:03:03 15:07:09	reading and processing the text file.
2017:03:03 15:07:09	preprocess the dataset and extract the valid content.
2017:03:03 15:07:09	init data from the raw dataset.
2017:03:03 15:08:27	reading and processing the text file.
2017:03:03 15:08:27	preprocess the dataset and extract the valid content.
2017:03:03 15:08:27	init data from the raw dataset.
2017:03:03 15:09:43	reading and processing the text file.
2017:03:03 15:09:43	preprocess the dataset and extract the valid content.
2017:03:03 15:10:11	reading and processing the text file.
2017:03:03 15:10:11	preprocess the dataset and extract the valid content.
2017:03:03 15:10:11	init data from the raw dataset.
2017:03:03 15:10:43	reading and processing the text file.
2017:03:03 15:10:43	preprocess the dataset and extract the valid content.
2017:03:03 15:11:59	reading and processing the text file.
2017:03:03 15:11:59	preprocess the dataset and extract the valid content.
2017:03:03 15:11:59	init data from the raw dataset.
2017:03:03 15:13:17	reading and processing the text file.
2017:03:03 15:13:17	preprocess the dataset and extract the valid content.
2017:03:03 15:13:29	reading and processing the text file.
2017:03:03 15:13:29	preprocess the dataset and extract the valid content.
2017:03:03 15:13:29	init data from the raw dataset.
2017:03:03 15:14:56	reading and processing the text file.
2017:03:03 15:14:56	preprocess the dataset and extract the valid content.
2017:03:03 15:15:05	reading and processing the text file.
2017:03:03 15:15:05	preprocess the dataset and extract the valid content.
2017:03:03 15:15:05	init data from the raw dataset.
2017:03:03 15:16:57	reading and processing the text file.
2017:03:03 15:16:57	preprocess the dataset and extract the valid content.
2017:03:03 15:17:07	reading and processing the text file.
2017:03:03 15:17:07	preprocess the dataset and extract the valid content.
2017:03:03 15:17:07	init data from the raw dataset.
2017:03:03 15:17:22	reading and processing the text file.
2017:03:03 15:17:22	preprocess the dataset and extract the valid content.
2017:03:03 15:17:30	reading and processing the text file.
2017:03:03 15:17:30	preprocess the dataset and extract the valid content.
2017:03:03 15:17:30	init data from the raw dataset.
2017:03:03 15:19:05	reading and processing the text file.
2017:03:03 15:19:05	preprocess the dataset and extract the valid content.
2017:03:03 15:19:13	reading and processing the text file.
2017:03:03 15:19:13	preprocess the dataset and extract the valid content.
2017:03:03 15:19:13	init data from the raw dataset.
2017:03:03 15:19:54	reading and processing the text file.
2017:03:03 15:19:54	preprocess the dataset and extract the valid content.
2017:03:03 15:19:54	init data from the raw dataset.
2017:03:03 15:22:10	reading and processing the text file.
2017:03:03 15:22:10	preprocess the dataset and extract the valid content.
2017:03:03 15:22:10	...load data.
2017:03:03 15:22:10	...clean data.
2017:03:03 15:22:20	reading and processing the text file.
2017:03:03 15:22:20	preprocess the dataset and extract the valid content.
2017:03:03 15:22:20	...load data.
2017:03:03 15:22:20	...clean data.
2017:03:03 15:22:39	reading and processing the text file.
2017:03:03 15:22:39	preprocess the dataset and extract the valid content.
2017:03:03 15:22:39	...load data.
2017:03:03 15:22:39	...clean data.
2017:03:03 15:23:45	reading and processing the text file.
2017:03:03 15:23:45	preprocess the dataset and extract the valid content.
2017:03:03 15:23:45	...load data.
2017:03:03 15:23:45	...clean data.
2017:03:03 15:24:59	reading and processing the text file.
2017:03:03 15:24:59	preprocess the dataset and extract the valid content.
2017:03:03 15:24:59	...load data.
2017:03:03 15:24:59	...clean data.
2017:03:03 15:25:10	reading and processing the text file.
2017:03:03 15:25:10	preprocess the dataset and extract the valid content.
2017:03:03 15:25:10	...load data.
2017:03:03 15:25:10	...clean data.
2017:03:03 15:25:26	reading and processing the text file.
2017:03:03 15:25:26	preprocess the dataset and extract the valid content.
2017:03:03 15:25:26	...load data.
2017:03:03 15:25:26	...clean data.
2017:03:03 15:25:49	reading and processing the text file.
2017:03:03 15:25:49	preprocess the dataset and extract the valid content.
2017:03:03 15:25:49	...load data.
2017:03:03 15:25:49	...clean data.
2017:03:03 15:26:41	reading and processing the text file.
2017:03:03 15:26:41	preprocess the dataset and extract the valid content.
2017:03:03 15:26:41	...load data.
2017:03:03 15:26:41	...clean data.
2017:03:03 15:27:15	reading and processing the text file.
2017:03:03 15:27:15	preprocess the dataset and extract the valid content.
2017:03:03 15:27:15	...load data.
2017:03:03 15:27:15	...clean data.
2017:03:03 15:27:39	reading and processing the text file.
2017:03:03 15:27:39	preprocess the dataset and extract the valid content.
2017:03:03 15:27:39	...load data.
2017:03:03 15:27:39	...clean data.
2017:03:03 15:29:06	reading and processing the text file.
2017:03:03 15:29:06	preprocess the dataset and extract the valid content.
2017:03:03 15:29:06	...load data.
2017:03:03 15:29:06	...clean data.
2017:03:03 15:30:18	reading and processing the text file.
2017:03:03 15:30:18	preprocess the dataset and extract the valid content.
2017:03:03 15:30:18	...load data.
2017:03:03 15:30:18	...clean data.
2017:03:03 15:33:23	reading and processing the text file.
2017:03:03 15:33:23	preprocess the dataset and extract the valid content.
2017:03:03 15:33:23	...load data.
2017:03:03 15:33:23	...clean data.
2017:03:03 15:34:20	reading and processing the text file.
2017:03:03 15:34:20	preprocess the dataset and extract the valid content.
2017:03:03 15:34:20	...load data.
2017:03:03 15:34:20	...clean data.
2017:03:03 15:34:25	reading and processing the text file.
2017:03:03 15:34:25	preprocess the dataset and extract the valid content.
2017:03:03 15:34:25	...load data.
2017:03:03 15:34:25	...clean data.
2017:03:03 15:35:45	reading and processing the text file.
2017:03:03 15:35:45	preprocess the dataset and extract the valid content.
2017:03:03 15:35:45	...load data.
2017:03:03 15:35:45	...clean data.
2017:03:03 15:36:06	reading and processing the text file.
2017:03:03 15:36:06	preprocess the dataset and extract the valid content.
2017:03:03 15:36:06	...load data.
2017:03:03 15:36:06	...clean data.
2017:03:03 15:36:20	reading and processing the text file.
2017:03:03 15:36:20	preprocess the dataset and extract the valid content.
2017:03:03 15:36:20	...load data.
2017:03:03 15:36:20	...clean data.
2017:03:03 15:36:37	reading and processing the text file.
2017:03:03 15:36:37	preprocess the dataset and extract the valid content.
2017:03:03 15:36:37	...load data.
2017:03:03 15:36:37	...clean data.
2017:03:03 15:37:12	reading and processing the text file.
2017:03:03 15:37:12	preprocess the dataset and extract the valid content.
2017:03:03 15:37:12	...load data.
2017:03:03 15:37:12	...clean data.
2017:03:03 15:37:28	reading and processing the text file.
2017:03:03 15:37:28	preprocess the dataset and extract the valid content.
2017:03:03 15:37:28	...load data.
2017:03:03 15:37:28	...clean data.
2017:03:03 15:38:08	reading and processing the text file.
2017:03:03 15:38:08	preprocess the dataset and extract the valid content.
2017:03:03 15:38:08	...load data.
2017:03:03 15:38:08	...clean data.
2017:03:03 15:38:39	reading and processing the text file.
2017:03:03 15:38:39	preprocess the dataset and extract the valid content.
2017:03:03 15:38:39	...load data.
2017:03:03 15:38:39	...clean data.
2017:03:03 15:38:54	reading and processing the text file.
2017:03:03 15:38:54	preprocess the dataset and extract the valid content.
2017:03:03 15:38:54	...load data.
2017:03:03 15:38:54	...clean data.
2017:03:03 15:39:09	reading and processing the text file.
2017:03:03 15:39:09	preprocess the dataset and extract the valid content.
2017:03:03 15:39:09	...load data.
2017:03:03 15:39:09	...clean data.
2017:03:03 15:39:32	reading and processing the text file.
2017:03:03 15:39:32	preprocess the dataset and extract the valid content.
2017:03:03 15:39:32	...load data.
2017:03:03 15:39:32	...clean data.
2017:03:03 15:40:03	reading and processing the text file.
2017:03:03 15:40:03	preprocess the dataset and extract the valid content.
2017:03:03 15:40:03	...load data.
2017:03:03 15:40:03	...clean data.
2017:03:03 15:41:35	reading and processing the text file.
2017:03:03 15:41:35	preprocess the dataset and extract the valid content.
2017:03:03 15:41:35	...load data.
2017:03:03 15:41:35	...clean data.
2017:03:03 15:41:54	reading and processing the text file.
2017:03:03 15:41:54	preprocess the dataset and extract the valid content.
2017:03:03 15:41:54	...load data.
2017:03:03 15:41:54	...clean data.
2017:03:03 15:42:16	reading and processing the text file.
2017:03:03 15:42:16	preprocess the dataset and extract the valid content.
2017:03:03 15:42:16	...load data.
2017:03:03 15:42:16	...clean data.
2017:03:03 15:42:51	reading and processing the text file.
2017:03:03 15:42:51	preprocess the dataset and extract the valid content.
2017:03:03 15:42:51	...load data.
2017:03:03 15:42:51	...clean data.
2017:03:03 15:44:22	reading and processing the text file.
2017:03:03 15:44:22	preprocess the dataset and extract the valid content.
2017:03:03 15:44:22	...load data.
2017:03:03 15:44:22	...clean data.
2017:03:03 15:44:45	reading and processing the text file.
2017:03:03 15:44:45	preprocess the dataset and extract the valid content.
2017:03:03 15:44:45	...load data.
2017:03:03 15:44:45	...clean data.
2017:03:03 15:45:46	reading and processing the text file.
2017:03:03 15:45:46	preprocess the dataset and extract the valid content.
2017:03:03 15:45:46	...load data.
2017:03:03 15:45:46	...clean data.
2017:03:03 15:45:53	reading and processing the text file.
2017:03:03 15:45:53	preprocess the dataset and extract the valid content.
2017:03:03 15:45:53	...load data.
2017:03:03 15:45:53	...clean data.
2017:03:03 15:46:54	reading and processing the text file.
2017:03:03 15:46:54	preprocess the dataset and extract the valid content.
2017:03:03 15:46:54	...load data.
2017:03:03 15:46:54	...clean data.
2017:03:03 15:47:38	reading and processing the text file.
2017:03:03 15:47:38	preprocess the dataset and extract the valid content.
2017:03:03 15:47:38	...load data.
2017:03:03 15:47:38	...clean data.
2017:03:03 15:47:54	reading and processing the text file.
2017:03:03 15:47:54	preprocess the dataset and extract the valid content.
2017:03:03 15:47:54	...load data.
2017:03:03 15:47:54	...clean data.
2017:03:03 15:48:02	reading and processing the text file.
2017:03:03 15:48:02	preprocess the dataset and extract the valid content.
2017:03:03 15:48:02	...load data.
2017:03:03 15:48:02	...clean data.
2017:03:03 15:48:59	reading and processing the text file.
2017:03:03 15:48:59	preprocess the dataset and extract the valid content.
2017:03:03 15:48:59	...load data.
2017:03:03 15:48:59	...clean data.
2017:03:03 15:50:26	reading and processing the text file.
2017:03:03 15:50:26	preprocess the dataset and extract the valid content.
2017:03:03 15:50:26	...load data.
2017:03:03 15:50:26	...clean data.
2017:03:03 15:51:11	reading and processing the text file.
2017:03:03 15:51:11	preprocess the dataset and extract the valid content.
2017:03:03 15:51:11	...load data.
2017:03:03 15:51:11	...clean data.
2017:03:03 15:51:12	build a vocabulary.
2017:03:03 15:51:12	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:51:14	...mapping from index to word.
2017:03:03 15:51:14	...mapping from word to index.
2017:03:03 15:51:14	...map word to index.
2017:03:03 15:51:14	the vocabulary size is 62.
2017:03:03 15:51:52	reading and processing the text file.
2017:03:03 15:51:52	preprocess the dataset and extract the valid content.
2017:03:03 15:51:52	...load data.
2017:03:03 15:51:52	...clean data.
2017:03:03 15:51:53	build a vocabulary.
2017:03:03 15:51:53	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:51:54	...mapping from index to word.
2017:03:03 15:51:54	...mapping from word to index.
2017:03:03 15:51:54	...map word to index.
2017:03:03 15:51:54	the vocabulary size is 62.
2017:03:03 15:53:14	reading and processing the text file.
2017:03:03 15:53:14	preprocess the dataset and extract the valid content.
2017:03:03 15:53:14	...load data.
2017:03:03 15:53:14	...clean data.
2017:03:03 15:54:32	reading and processing the text file.
2017:03:03 15:54:32	preprocess the dataset and extract the valid content.
2017:03:03 15:54:32	...load data.
2017:03:03 15:54:32	...clean data.
2017:03:03 15:54:33	build a vocabulary.
2017:03:03 15:54:33	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:54:33	...mapping from index to word.
2017:03:03 15:54:33	...mapping from word to index.
2017:03:03 15:54:33	...map word to index.
2017:03:03 15:54:33	the vocabulary size is 34472.
2017:03:03 15:56:56	reading and processing the text file.
2017:03:03 15:56:56	preprocess the dataset.
2017:03:03 15:57:01	build a vocabulary.
2017:03:03 15:57:01	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:57:02	...mapping from index to word.
2017:03:03 15:57:02	...mapping from word to index.
2017:03:03 15:57:02	...map word to index.
2017:03:03 15:57:12	reading and processing the text file.
2017:03:03 15:57:12	preprocess the dataset.
2017:03:03 15:57:17	build a vocabulary.
2017:03:03 15:57:17	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:57:18	...mapping from index to word.
2017:03:03 15:57:18	...mapping from word to index.
2017:03:03 15:57:18	...map word to index.
2017:03:03 15:58:10	the vocabulary size is 29265.
2017:03:03 16:00:13	reading and processing the text file.
2017:03:03 16:00:13	preprocess the dataset and extract the valid content.
2017:03:03 16:00:13	...load data.
2017:03:03 16:00:13	...clean data.
2017:03:03 16:00:13	build a vocabulary.
2017:03:03 16:00:13	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:00:14	...mapping from index to word.
2017:03:03 16:00:14	...mapping from word to index.
2017:03:03 16:00:14	...map word to index.
2017:03:03 16:00:29	the vocabulary size is 34472.
2017:03:03 16:01:22	use DataLoaderBBC to init data.
2017:03:03 16:01:22	reading and processing the text file.
2017:03:03 16:01:22	preprocess the dataset and extract the valid content.
2017:03:03 16:01:22	...load data.
2017:03:03 16:01:22	...clean data.
2017:03:03 16:01:23	build a vocabulary.
2017:03:03 16:01:23	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:01:23	...mapping from index to word.
2017:03:03 16:01:24	...mapping from word to index.
2017:03:03 16:01:24	...map word to index.
2017:03:03 16:01:42	use DataLoaderBBC to init data.
2017:03:03 16:01:42	reading and processing the text file.
2017:03:03 16:01:42	preprocess the dataset and extract the valid content.
2017:03:03 16:01:42	...load data.
2017:03:03 16:01:42	...clean data.
2017:03:03 16:01:43	build a vocabulary.
2017:03:03 16:01:43	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:01:43	...mapping from index to word.
2017:03:03 16:01:43	...mapping from word to index.
2017:03:03 16:01:43	...map word to index.
2017:03:03 16:02:00	the vocabulary size is 34472.
2017:03:03 16:02:11	use DataLoaderBBC to init data.
2017:03:03 16:02:11	reading and processing the text file.
2017:03:03 16:02:11	preprocess the dataset and extract the valid content.
2017:03:03 16:02:11	...load data.
2017:03:03 16:02:11	...clean data.
2017:03:03 16:02:12	build a vocabulary.
2017:03:03 16:02:12	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:02:12	...mapping from index to word.
2017:03:03 16:02:12	...mapping from word to index.
2017:03:03 16:02:12	...map word to index.
2017:03:03 16:02:27	the vocabulary size is 34472.
2017:03:03 16:02:46	use DataLoaderChildrenStory to init data.
2017:03:03 16:02:46	reading and processing the text file.
2017:03:03 16:02:46	preprocess the dataset.
2017:03:03 16:02:51	build a vocabulary.
2017:03:03 16:02:51	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:02:52	...mapping from index to word.
2017:03:03 16:02:52	...mapping from word to index.
2017:03:03 16:02:52	...map word to index.
2017:03:03 16:03:37	the vocabulary size is 29265.
2017:03:03 16:04:12	use DataLoaderChildrenStory to init data.
2017:03:03 16:04:12	reading and processing the text file.
2017:03:03 16:04:12	preprocess the dataset.
2017:03:03 16:04:17	build a vocabulary.
2017:03:03 16:04:17	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:04:18	...mapping from index to word.
2017:03:03 16:04:18	...mapping from word to index.
2017:03:03 16:04:18	...map word to index.
2017:03:03 16:05:10	the vocabulary size is 29265.
2017:03:03 16:07:22	use DataLoaderChildrenStory to init data.
2017:03:03 16:07:22	reading and processing the text file.
2017:03:03 16:07:22	preprocess the dataset.
2017:03:03 16:07:27	build a vocabulary.
2017:03:03 16:07:27	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:07:28	...mapping from index to word.
2017:03:03 16:07:29	...mapping from word to index.
2017:03:03 16:07:29	...map word to index.
2017:03:03 16:08:29	the vocabulary size is 29265.
2017:03:03 16:08:47	use DataLoaderBBC to init data.
2017:03:03 16:08:47	reading and processing the text file.
2017:03:03 16:08:47	preprocess the dataset and extract the valid content.
2017:03:03 16:08:47	...load data.
2017:03:03 16:08:47	...clean data.
2017:03:03 16:08:48	build a vocabulary.
2017:03:03 16:08:48	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:08:48	...mapping from index to word.
2017:03:03 16:08:49	...mapping from word to index.
2017:03:03 16:08:49	...map word to index.
2017:03:03 16:09:18	the vocabulary size is 34472.
2017:03:03 16:11:02	use DataLoaderBBC to init data.
2017:03:03 16:11:02	reading and processing the text file.
2017:03:03 16:11:02	preprocess the dataset and extract the valid content.
2017:03:03 16:11:02	...load data.
2017:03:03 16:11:02	...clean data.
2017:03:03 16:11:03	build a vocabulary.
2017:03:03 16:11:03	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:11:03	...mapping from index to word.
2017:03:03 16:11:04	...mapping from word to index.
2017:03:03 16:11:04	...map word to index.
2017:03:03 16:11:27	the vocabulary size is 34472.
2017:03:03 16:12:52	use DataLoaderBBC to init data.
2017:03:03 16:12:52	reading and processing the text file.
2017:03:03 16:12:52	preprocess the dataset and extract the valid content.
2017:03:03 16:12:52	...load data.
2017:03:03 16:12:52	...clean data.
2017:03:03 16:12:53	build a vocabulary.
2017:03:03 16:12:53	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:12:53	...mapping from index to word.
2017:03:03 16:12:53	...mapping from word to index.
2017:03:03 16:12:53	...map word to index.
2017:03:03 16:13:09	the vocabulary size is 34472.
2017:03:03 16:13:44	use DataLoaderChildrenStory to init data.
2017:03:03 16:13:44	reading and processing the text file.
2017:03:03 16:13:44	preprocess the dataset.
2017:03:03 16:13:49	build a vocabulary.
2017:03:03 16:13:49	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:13:50	...mapping from index to word.
2017:03:03 16:13:51	...mapping from word to index.
2017:03:03 16:13:51	...map word to index.
2017:03:03 16:14:50	the vocabulary size is 29265.
2017:03:03 16:16:20	use DataLoaderEnron to init data.
2017:03:03 16:16:20	reading and processing the text file.
2017:03:03 16:16:20	preprocess the dataset and extract the valid content.
2017:03:03 16:17:33	use DataLoaderChildrenStory to init data.
2017:03:03 16:17:33	reading and processing the text file.
2017:03:03 16:17:33	preprocess the dataset.
2017:03:03 16:17:38	build a vocabulary.
2017:03:03 16:17:38	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:17:39	...mapping from index to word.
2017:03:03 16:17:39	...mapping from word to index.
2017:03:03 16:17:39	...map word to index.
2017:03:03 16:18:39	the vocabulary size is 29265.
2017:03:03 16:19:50	use DataLoaderBBC to init data.
2017:03:03 16:19:50	reading and processing the text file.
2017:03:03 16:19:50	preprocess the dataset and extract the valid content.
2017:03:03 16:19:50	...load data.
2017:03:03 16:19:50	...clean data.
2017:03:03 16:19:51	build a vocabulary.
2017:03:03 16:19:51	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:19:52	...mapping from index to word.
2017:03:03 16:19:52	...mapping from word to index.
2017:03:03 16:19:52	...map word to index.
2017:03:03 16:20:10	the vocabulary size is 34472.
2017:03:03 16:20:45	use DataLoaderEnron to init data.
2017:03:03 16:20:45	reading and processing the text file.
2017:03:03 16:20:45	preprocess the dataset and extract the valid content.
2017:03:03 16:20:45	init data from the raw dataset.
2017:03:03 16:21:07	...Parse the emails into a list email objects
2017:03:03 16:22:40	...Get fields from parsed email objects
2017:03:03 16:23:00	...Parse content from emails
2017:03:03 16:23:03	...Split multiple email addresses
2017:03:03 16:23:07	...Extract the root of 'file' as 'user'
2017:03:03 16:23:09	extract content from email data frame.
2017:03:03 16:29:27	use DataLoaderEnron to init data.
2017:03:03 16:29:27	reading and processing the text file.
2017:03:03 16:29:27	preprocess the dataset and extract the valid content.
2017:03:03 16:29:27	...load data.
2017:03:03 16:29:27	load context for further preprocessing.
2017:03:03 16:29:34	...clean data.
2017:03:03 16:31:00	use DataLoaderEnron to init data.
2017:03:03 16:31:00	reading and processing the text file.
2017:03:03 16:31:00	preprocess the dataset and extract the valid content.
2017:03:03 16:31:00	...load data.
2017:03:03 16:31:00	......load context for further preprocessing.
2017:03:03 16:31:01	...clean data.
2017:03:03 16:32:10	use DataLoaderEnron to init data.
2017:03:03 16:32:10	reading and processing the text file.
2017:03:03 16:32:10	preprocess the dataset and extract the valid content.
2017:03:03 16:32:10	...load data.
2017:03:03 16:32:10	......load context for further preprocessing.
2017:03:03 16:32:10	...clean data.
2017:03:03 16:32:47	use DataLoaderEnron to init data.
2017:03:03 16:32:47	reading and processing the text file.
2017:03:03 16:32:47	preprocess the dataset and extract the valid content.
2017:03:03 16:32:47	...load data.
2017:03:03 16:32:47	......load context for further preprocessing.
2017:03:03 16:32:48	...clean data.
2017:03:03 16:33:54	use DataLoaderEnron to init data.
2017:03:03 16:33:54	reading and processing the text file.
2017:03:03 16:33:54	preprocess the dataset and extract the valid content.
2017:03:03 16:33:54	...load data.
2017:03:03 16:33:54	......load context for further preprocessing.
2017:03:03 16:33:55	...clean data.
2017:03:03 16:36:11	use DataLoaderEnron to init data.
2017:03:03 16:36:11	reading and processing the text file.
2017:03:03 16:36:11	preprocess the dataset and extract the valid content.
2017:03:03 16:36:11	...load data.
2017:03:03 16:36:11	......load context for further preprocessing.
2017:03:03 16:36:12	...clean data.
2017:03:03 16:36:23	use DataLoaderEnron to init data.
2017:03:03 16:36:23	reading and processing the text file.
2017:03:03 16:36:23	preprocess the dataset and extract the valid content.
2017:03:03 16:36:23	...load data.
2017:03:03 16:36:23	......load context for further preprocessing.
2017:03:03 16:36:23	...clean data.
2017:03:03 16:36:40	use DataLoaderEnron to init data.
2017:03:03 16:36:40	reading and processing the text file.
2017:03:03 16:36:40	preprocess the dataset and extract the valid content.
2017:03:03 16:36:40	...load data.
2017:03:03 16:36:40	......load context for further preprocessing.
2017:03:03 16:36:40	...clean data.
2017:03:03 16:56:39	use DataLoaderWikiText to init data.
2017:03:03 16:56:39	reading and processing the text file.
2017:03:03 16:56:39	preprocess the dataset.
2017:03:03 16:57:35	use DataLoaderWikiText to init data.
2017:03:03 16:57:35	reading and processing the text file.
2017:03:03 16:57:35	preprocess the dataset.
2017:03:03 16:59:38	use DataLoaderWikiText to init data.
2017:03:03 16:59:38	reading and processing the text file.
2017:03:03 16:59:38	preprocess the dataset.
2017:03:03 16:59:49	use DataLoaderWikiText to init data.
2017:03:03 16:59:49	reading and processing the text file.
2017:03:03 16:59:49	preprocess the dataset.
2017:03:03 17:00:23	use DataLoaderWikiText to init data.
2017:03:03 17:00:23	reading and processing the text file.
2017:03:03 17:00:23	preprocess the dataset.
2017:03:03 17:00:45	use DataLoaderWikiText to init data.
2017:03:03 17:00:45	reading and processing the text file.
2017:03:03 17:00:45	preprocess the dataset.
2017:03:03 17:01:47	use DataLoaderWikiText to init data.
2017:03:03 17:01:47	reading and processing the text file.
2017:03:03 17:01:47	preprocess the dataset.
2017:03:03 17:02:32	use DataLoaderWikiText to init data.
2017:03:03 17:02:32	reading and processing the text file.
2017:03:03 17:02:32	preprocess the dataset.
2017:03:03 17:02:58	use DataLoaderWikiText to init data.
2017:03:03 17:02:58	reading and processing the text file.
2017:03:03 17:02:58	preprocess the dataset.
2017:03:03 17:03:07	use DataLoaderWikiText to init data.
2017:03:03 17:03:07	reading and processing the text file.
2017:03:03 17:03:07	preprocess the dataset.
2017:03:03 17:03:44	use DataLoaderWikiText to init data.
2017:03:03 17:03:44	reading and processing the text file.
2017:03:03 17:03:44	preprocess the dataset.
2017:03:03 17:04:12	use DataLoaderWikiText to init data.
2017:03:03 17:04:12	reading and processing the text file.
2017:03:03 17:04:12	preprocess the dataset.
2017:03:03 17:04:54	use DataLoaderWikiText to init data.
2017:03:03 17:04:54	reading and processing the text file.
2017:03:03 17:04:54	preprocess the dataset.
2017:03:03 17:05:22	use DataLoaderWikiText to init data.
2017:03:03 17:05:22	reading and processing the text file.
2017:03:03 17:05:22	preprocess the dataset.
2017:03:03 17:05:52	use DataLoaderWikiText to init data.
2017:03:03 17:05:52	reading and processing the text file.
2017:03:03 17:05:52	preprocess the dataset.
2017:03:03 17:06:04	use DataLoaderWikiText to init data.
2017:03:03 17:06:04	reading and processing the text file.
2017:03:03 17:06:04	preprocess the dataset.
2017:03:03 17:06:50	use DataLoaderWikiText to init data.
2017:03:03 17:06:50	reading and processing the text file.
2017:03:03 17:06:50	preprocess the dataset.
2017:03:03 17:07:21	use DataLoaderWikiText to init data.
2017:03:03 17:07:21	reading and processing the text file.
2017:03:03 17:07:21	preprocess the dataset.
2017:03:03 17:08:02	use DataLoaderWikiText to init data.
2017:03:03 17:08:02	reading and processing the text file.
2017:03:03 17:08:02	preprocess the dataset.
2017:03:03 17:08:12	use DataLoaderWikiText to init data.
2017:03:03 17:08:12	reading and processing the text file.
2017:03:03 17:08:12	preprocess the dataset.
2017:03:03 17:09:02	use DataLoaderWikiText to init data.
2017:03:03 17:09:02	reading and processing the text file.
2017:03:03 17:09:02	preprocess the dataset.
2017:03:03 17:09:38	use DataLoaderWikiText to init data.
2017:03:03 17:09:38	reading and processing the text file.
2017:03:03 17:09:38	preprocess the dataset.
2017:03:03 17:10:05	use DataLoaderWikiText to init data.
2017:03:03 17:10:05	reading and processing the text file.
2017:03:03 17:10:05	preprocess the dataset.
2017:03:03 17:11:04	use DataLoaderWikiText to init data.
2017:03:03 17:11:04	reading and processing the text file.
2017:03:03 17:11:04	preprocess the dataset.
2017:03:03 17:11:20	use DataLoaderWikiText to init data.
2017:03:03 17:11:20	reading and processing the text file.
2017:03:03 17:11:20	preprocess the dataset.
2017:03:03 17:12:25	use DataLoaderWikiText to init data.
2017:03:03 17:12:25	reading and processing the text file.
2017:03:03 17:12:25	preprocess the dataset.
2017:03:03 17:12:56	use DataLoaderWikiText to init data.
2017:03:03 17:12:56	reading and processing the text file.
2017:03:03 17:12:56	preprocess the dataset.
2017:03:03 17:13:31	use DataLoaderWikiText to init data.
2017:03:03 17:13:31	reading and processing the text file.
2017:03:03 17:13:31	preprocess the dataset.
2017:03:03 17:14:54	use DataLoaderWikiText to init data.
2017:03:03 17:14:54	reading and processing the text file.
2017:03:03 17:14:54	preprocess the dataset.
2017:03:03 17:14:55	build a vocabulary.
2017:03:03 17:14:55	...flatmap a list of sentence list to a list of sentence.
2017:03:03 17:14:56	...mapping from index to word.
2017:03:03 17:14:56	...mapping from word to index.
2017:03:03 17:14:56	...map word to index.
2017:03:03 17:16:45	use DataLoaderWikiText to init data.
2017:03:03 17:16:45	loading preprocessed files.
2017:03:03 17:17:24	use DataLoaderWikiText to init data.
2017:03:03 17:17:24	loading preprocessed files.
2017:03:03 17:18:52	use DataLoaderWikiText to init data.
2017:03:03 17:18:52	reading and processing the text file.
2017:03:03 17:18:52	preprocess the dataset.
2017:03:03 17:18:53	build a vocabulary.
2017:03:03 17:18:53	...flatmap a list of sentence list to a list of sentence.
2017:03:03 17:18:54	...mapping from index to word.
2017:03:03 17:18:54	...mapping from word to index.
2017:03:03 17:18:54	...map word to index.
2017:03:03 17:19:34	the vocabulary size is 34093.
2017:03:03 21:13:39	use DataLoaderChildrenStory to init data.
2017:03:03 21:13:39	reading and processing the text file.
2017:03:03 21:13:39	preprocess the dataset.
2017:03:03 21:14:03	use DataLoaderChildrenStory to init data.
2017:03:03 21:14:03	reading and processing the text file.
2017:03:03 21:14:03	preprocess the dataset.
2017:03:03 21:14:08	build a vocabulary.
2017:03:03 21:14:08	...flatmap a list of sentence list to a list of sentence.
2017:03:03 21:14:09	...mapping from index to word.
2017:03:03 21:14:09	...mapping from word to index.
2017:03:03 21:14:09	...map word to index.
2017:03:03 21:15:25	use DataLoaderChildrenStory to init data.
2017:03:03 21:15:25	loading preprocessed files.
2017:03:03 21:16:37	use DataLoaderChildrenStory to init data.
2017:03:03 21:16:37	loading preprocessed files.
2017:03:03 21:17:24	use DataLoaderChildrenStory to init data.
2017:03:03 21:17:24	reading and processing the text file.
2017:03:03 21:17:24	preprocess the dataset.
2017:03:03 21:17:29	build a vocabulary.
2017:03:03 21:17:29	...flatmap a list of sentence list to a list of sentence.
2017:03:03 21:17:30	...mapping from index to word.
2017:03:03 21:17:30	...mapping from word to index.
2017:03:03 21:17:30	...map word to index.
2017:03:03 21:18:28	the vocabulary size is 29265.
2017:03:03 21:19:27	use DataLoaderChildrenStory to init data.
2017:03:03 21:19:27	loading preprocessed files.
2017:03:03 21:20:15	the vocabulary size is 29265.
2017:03:07 14:51:41	use DataLoaderChildrenStory to init data.
2017:03:07 14:51:41	reading and processing the text file.
2017:03:07 14:51:41	preprocess the dataset.
2017:03:07 14:51:46	build a vocabulary.
2017:03:07 14:51:46	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:53:08	use DataLoaderChildrenStory to init data.
2017:03:07 14:53:08	reading and processing the text file.
2017:03:07 14:53:08	preprocess the dataset.
2017:03:07 14:53:13	build a vocabulary.
2017:03:07 14:53:13	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:53:20	use DataLoaderChildrenStory to init data.
2017:03:07 14:53:20	reading and processing the text file.
2017:03:07 14:53:20	preprocess the dataset.
2017:03:07 14:53:24	build a vocabulary.
2017:03:07 14:53:24	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:53:29	use DataLoaderChildrenStory to init data.
2017:03:07 14:53:29	reading and processing the text file.
2017:03:07 14:53:29	preprocess the dataset.
2017:03:07 14:53:33	build a vocabulary.
2017:03:07 14:53:33	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:54:06	use DataLoaderChildrenStory to init data.
2017:03:07 14:54:06	reading and processing the text file.
2017:03:07 14:54:06	preprocess the dataset.
2017:03:07 14:54:10	build a vocabulary.
2017:03:07 14:54:10	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:01:50	use DataLoaderChildrenStory to init data.
2017:03:07 15:01:50	reading and processing the text file.
2017:03:07 15:01:50	preprocess the dataset.
2017:03:07 15:17:53	use DataLoaderChildrenStory to init data.
2017:03:07 15:17:53	reading and processing the text file.
2017:03:07 15:17:53	preprocess the dataset.
2017:03:07 15:17:59	build a vocabulary.
2017:03:07 15:17:59	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:18:00	...mapping from index to word.
2017:03:07 15:18:00	...mapping from word to index.
2017:03:07 15:18:00	...map word to index.
2017:03:07 15:19:37	use DataLoaderChildrenStory to init data.
2017:03:07 15:19:37	reading and processing the text file.
2017:03:07 15:19:37	preprocess the dataset.
2017:03:07 15:19:42	build a vocabulary.
2017:03:07 15:19:42	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:19:42	...mapping from index to word.
2017:03:07 15:19:42	...mapping from word to index.
2017:03:07 15:19:42	...map word to index.
2017:03:07 15:22:54	use DataLoaderChildrenStory to init data.
2017:03:07 15:22:54	reading and processing the text file.
2017:03:07 15:22:54	preprocess the dataset.
2017:03:07 15:22:58	build a vocabulary.
2017:03:07 15:22:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:22:59	...mapping from index to word.
2017:03:07 15:22:59	...mapping from word to index.
2017:03:07 15:22:59	...map word to index.
2017:03:07 15:23:33	use DataLoaderChildrenStory to init data.
2017:03:07 15:23:33	reading and processing the text file.
2017:03:07 15:23:33	preprocess the dataset.
2017:03:07 15:23:38	build a vocabulary.
2017:03:07 15:23:38	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:23:38	...mapping from index to word.
2017:03:07 15:23:38	...mapping from word to index.
2017:03:07 15:23:38	...map word to index.
2017:03:07 15:23:52	use DataLoaderChildrenStory to init data.
2017:03:07 15:23:52	reading and processing the text file.
2017:03:07 15:23:52	preprocess the dataset.
2017:03:07 15:23:56	build a vocabulary.
2017:03:07 15:23:56	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:23:56	...mapping from index to word.
2017:03:07 15:23:56	...mapping from word to index.
2017:03:07 15:23:56	...map word to index.
2017:03:07 15:24:21	use DataLoaderChildrenStory to init data.
2017:03:07 15:24:21	reading and processing the text file.
2017:03:07 15:24:21	preprocess the dataset.
2017:03:07 15:24:25	build a vocabulary.
2017:03:07 15:24:25	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:24:25	...mapping from index to word.
2017:03:07 15:24:25	...mapping from word to index.
2017:03:07 15:24:25	...map word to index.
2017:03:07 15:25:28	use DataLoaderChildrenStory to init data.
2017:03:07 15:25:28	reading and processing the text file.
2017:03:07 15:25:28	preprocess the dataset.
2017:03:07 15:25:32	build a vocabulary.
2017:03:07 15:25:32	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:25:32	...mapping from index to word.
2017:03:07 15:25:32	...mapping from word to index.
2017:03:07 15:25:32	...map word to index.
2017:03:07 15:27:23	use DataLoaderChildrenStory to init data.
2017:03:07 15:27:23	reading and processing the text file.
2017:03:07 15:27:23	preprocess the dataset.
2017:03:07 15:27:27	build a vocabulary.
2017:03:07 15:27:27	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:28:29	use DataLoaderChildrenStory to init data.
2017:03:07 15:28:29	reading and processing the text file.
2017:03:07 15:28:29	preprocess the dataset.
2017:03:07 15:28:32	build a vocabulary.
2017:03:07 15:28:32	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:28:32	...mapping from index to word.
2017:03:07 15:28:32	...mapping from word to index.
2017:03:07 15:28:32	...map word to index.
2017:03:07 15:28:49	use DataLoaderChildrenStory to init data.
2017:03:07 15:28:49	reading and processing the text file.
2017:03:07 15:28:49	preprocess the dataset.
2017:03:07 15:28:53	build a vocabulary.
2017:03:07 15:28:53	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:28:53	...mapping from index to word.
2017:03:07 15:28:53	...mapping from word to index.
2017:03:07 15:28:53	...map word to index.
2017:03:07 15:30:54	use DataLoaderChildrenStory to init data.
2017:03:07 15:30:54	reading and processing the text file.
2017:03:07 15:30:54	preprocess the dataset.
2017:03:07 15:30:58	build a vocabulary.
2017:03:07 15:30:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:30:58	...mapping from index to word.
2017:03:07 15:30:58	...mapping from word to index.
2017:03:07 15:30:58	...map word to index.
2017:03:07 15:33:58	use DataLoaderChildrenStory to init data.
2017:03:07 15:33:58	reading and processing the text file.
2017:03:07 15:33:58	preprocess the dataset.
2017:03:07 15:34:03	build a vocabulary.
2017:03:07 15:34:03	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:34:04	...mapping from index to word.
2017:03:07 15:34:04	...mapping from word to index.
2017:03:07 15:34:04	...map word to index.
2017:03:07 15:34:32	use DataLoaderChildrenStory to init data.
2017:03:07 15:34:32	reading and processing the text file.
2017:03:07 15:34:32	preprocess the dataset.
2017:03:07 15:34:37	build a vocabulary.
2017:03:07 15:34:37	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:34:37	...mapping from index to word.
2017:03:07 15:34:37	...mapping from word to index.
2017:03:07 15:34:37	...map word to index.
2017:03:07 15:36:09	use DataLoaderChildrenStory to init data.
2017:03:07 15:36:09	reading and processing the text file.
2017:03:07 15:36:09	preprocess the dataset.
2017:03:07 15:36:16	build a vocabulary.
2017:03:07 15:36:16	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:36:16	...mapping from index to word.
2017:03:07 15:36:16	...mapping from word to index.
2017:03:07 15:36:16	...map word to index.
2017:03:07 15:37:14	use DataLoaderChildrenStory to init data.
2017:03:07 15:37:14	reading and processing the text file.
2017:03:07 15:37:14	preprocess the dataset.
2017:03:07 15:37:20	build a vocabulary.
2017:03:07 15:37:20	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:37:21	...mapping from index to word.
2017:03:07 15:37:21	...mapping from word to index.
2017:03:07 15:37:21	...map word to index.
2017:03:07 15:37:33	use DataLoaderChildrenStory to init data.
2017:03:07 15:37:33	reading and processing the text file.
2017:03:07 15:37:33	preprocess the dataset.
2017:03:07 15:37:39	build a vocabulary.
2017:03:07 15:37:39	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:37:39	...mapping from index to word.
2017:03:07 15:37:39	...mapping from word to index.
2017:03:07 15:37:39	...map word to index.
2017:03:07 15:37:55	use DataLoaderChildrenStory to init data.
2017:03:07 15:37:55	reading and processing the text file.
2017:03:07 15:37:55	preprocess the dataset.
2017:03:07 15:38:01	build a vocabulary.
2017:03:07 15:38:01	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:38:01	...mapping from index to word.
2017:03:07 15:38:01	...mapping from word to index.
2017:03:07 15:38:01	...map word to index.
2017:03:07 15:43:08	use DataLoaderChildrenStory to init data.
2017:03:07 15:43:08	reading and processing the text file.
2017:03:07 15:43:08	preprocess the dataset.
2017:03:07 15:43:14	...mask and pad the sentence.
2017:03:07 15:43:14	build a vocabulary.
2017:03:07 15:43:14	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:43:14	...mapping from index to word.
2017:03:07 15:43:14	...mapping from word to index.
2017:03:07 15:43:14	...map word to index.
2017:03:07 15:44:44	use DataLoaderChildrenStory to init data.
2017:03:07 15:44:44	reading and processing the text file.
2017:03:07 15:44:44	preprocess the dataset.
2017:03:07 15:44:50	...mask and pad the sentence.
2017:03:07 15:44:50	build a vocabulary.
2017:03:07 15:44:50	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:44:50	...mapping from index to word.
2017:03:07 15:44:50	...mapping from word to index.
2017:03:07 15:44:50	...map word to index.
2017:03:07 15:54:01	use DataLoaderChildrenStory to init data.
2017:03:07 15:54:01	reading and processing the text file.
2017:03:07 15:54:01	preprocess the dataset.
2017:03:07 15:54:12	...mask and pad the sentence.
2017:03:07 15:55:33	use DataLoaderChildrenStory to init data.
2017:03:07 15:55:33	reading and processing the text file.
2017:03:07 15:55:33	preprocess the dataset.
2017:03:07 15:55:38	...mask and pad the sentence.
2017:03:07 15:55:38	build a vocabulary.
2017:03:07 15:55:38	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:55:39	...mapping from index to word.
2017:03:07 15:55:39	...mapping from word to index.
2017:03:07 15:55:39	...map word to index.
2017:03:07 15:55:53	use DataLoaderChildrenStory to init data.
2017:03:07 15:55:53	reading and processing the text file.
2017:03:07 15:55:53	preprocess the dataset.
2017:03:07 15:55:58	...mask and pad the sentence.
2017:03:07 15:55:58	build a vocabulary.
2017:03:07 15:55:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:55:58	...mapping from index to word.
2017:03:07 15:55:58	...mapping from word to index.
2017:03:07 15:55:58	...map word to index.
2017:03:07 15:56:05	use DataLoaderChildrenStory to init data.
2017:03:07 15:56:05	reading and processing the text file.
2017:03:07 15:56:05	preprocess the dataset.
2017:03:07 15:56:12	...mask and pad the sentence.
2017:03:07 15:56:12	build a vocabulary.
2017:03:07 15:56:12	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:56:12	...mapping from index to word.
2017:03:07 15:56:12	...mapping from word to index.
2017:03:07 15:56:12	...map word to index.
2017:03:07 15:56:27	use DataLoaderChildrenStory to init data.
2017:03:07 15:56:27	reading and processing the text file.
2017:03:07 15:56:27	preprocess the dataset.
2017:03:07 15:56:32	...mask and pad the sentence.
2017:03:07 15:56:32	build a vocabulary.
2017:03:07 15:56:32	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:56:32	...mapping from index to word.
2017:03:07 15:56:32	...mapping from word to index.
2017:03:07 15:56:32	...map word to index.
2017:03:07 15:58:30	use DataLoaderChildrenStory to init data.
2017:03:07 15:58:31	reading and processing the text file.
2017:03:07 15:58:31	preprocess the dataset.
2017:03:07 15:58:37	...mask and pad the sentence.
2017:03:07 15:58:56	use DataLoaderChildrenStory to init data.
2017:03:07 15:58:56	reading and processing the text file.
2017:03:07 15:58:56	preprocess the dataset.
2017:03:07 15:59:00	...mask and pad the sentence.
2017:03:07 15:59:00	......max len:19, median len:9.0, min len:2
2017:03:07 15:59:00	build a vocabulary.
2017:03:07 15:59:00	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:59:00	...mapping from index to word.
2017:03:07 15:59:00	...mapping from word to index.
2017:03:07 15:59:00	...map word to index.
2017:03:07 15:59:18	use DataLoaderChildrenStory to init data.
2017:03:07 15:59:18	reading and processing the text file.
2017:03:07 15:59:18	preprocess the dataset.
2017:03:07 15:59:24	...mask and pad the sentence.
2017:03:07 15:59:24	......max len:19, median len:9.0, min len:2
2017:03:07 15:59:24	build a vocabulary.
2017:03:07 15:59:24	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:59:24	...mapping from index to word.
2017:03:07 15:59:24	...mapping from word to index.
2017:03:07 15:59:24	...map word to index.
2017:03:07 16:00:30	use DataLoaderChildrenStory to init data.
2017:03:07 16:00:30	reading and processing the text file.
2017:03:07 16:00:30	preprocess the dataset.
2017:03:07 16:00:34	...mask and pad the sentence.
2017:03:07 16:00:35	......max len:19, median len:9.0, min len:2
2017:03:07 16:00:35	build a vocabulary.
2017:03:07 16:00:35	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:00:35	...mapping from index to word.
2017:03:07 16:00:35	...mapping from word to index.
2017:03:07 16:00:35	...map word to index.
2017:03:07 16:06:24	use DataLoaderChildrenStory to init data.
2017:03:07 16:06:24	reading and processing the text file.
2017:03:07 16:06:24	preprocess the dataset.
2017:03:07 16:06:30	...mask and pad the sentence.
2017:03:07 16:06:30	......max len:18, median len:8.0, min len:1
2017:03:07 16:06:31	build a vocabulary.
2017:03:07 16:06:31	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:06:31	...mapping from index to word.
2017:03:07 16:06:31	...mapping from word to index.
2017:03:07 16:06:31	...map word to index.
2017:03:07 16:07:35	use DataLoaderChildrenStory to init data.
2017:03:07 16:07:35	reading and processing the text file.
2017:03:07 16:07:35	preprocess the dataset.
2017:03:07 16:07:42	...mask and pad the sentence.
2017:03:07 16:07:42	......max len:18, median len:8.0, min len:1
2017:03:07 16:07:42	build a vocabulary.
2017:03:07 16:07:42	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:07:42	...mapping from index to word.
2017:03:07 16:07:43	...mapping from word to index.
2017:03:07 16:07:43	...map word to index.
2017:03:07 16:14:26	use DataLoaderChildrenStory to init data.
2017:03:07 16:14:26	reading and processing the text file.
2017:03:07 16:14:26	preprocess the dataset.
2017:03:07 16:14:37	...mask and pad the sentence.
2017:03:07 16:14:37	......max len:18, median len:8.0, min len:1
2017:03:07 16:14:37	build a vocabulary.
2017:03:07 16:14:37	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:14:38	...mapping from index to word.
2017:03:07 16:14:38	...mapping from word to index.
2017:03:07 16:14:38	...map word to index.
2017:03:07 16:17:17	use DataLoaderChildrenStory to init data.
2017:03:07 16:17:17	reading and processing the text file.
2017:03:07 16:17:17	preprocess the dataset.
2017:03:07 16:17:26	...mask and pad the sentence.
2017:03:07 16:17:26	......max len:18, median len:8.0, min len:1
2017:03:07 16:17:27	build a vocabulary.
2017:03:07 16:17:27	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:17:27	...mapping from index to word.
2017:03:07 16:17:28	...mapping from word to index.
2017:03:07 16:17:28	...map word to index.
2017:03:07 16:25:58	use DataLoaderChildrenStory to init data.
2017:03:07 16:25:58	reading and processing the text file.
2017:03:07 16:25:58	preprocess the dataset.
2017:03:07 16:26:06	...mask and pad the sentence.
2017:03:07 16:26:06	......max len:18, median len:8.0, min len:1
2017:03:07 16:26:06	build a vocabulary.
2017:03:07 16:26:06	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:26:07	...mapping from index to word.
2017:03:07 16:26:07	...mapping from word to index.
2017:03:07 16:26:07	...map word to index.
2017:03:07 16:26:08	...some data statistics.
2017:03:07 16:26:08	...save processed data to file.
2017:03:07 16:26:10	the sample size is 78290, the vocab size is 17612
2017:03:07 20:34:49	use DataLoaderChildrenStory to init data.
2017:03:07 20:34:49	reading and processing the text file.
2017:03:07 20:34:49	preprocess the dataset.
2017:03:07 20:34:59	...mask and pad the sentence.
2017:03:07 20:34:59	......max len:19, median len:9.0, min len:2
2017:03:07 20:35:00	build a vocabulary.
2017:03:07 20:35:00	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:35:01	...mapping from index to word.
2017:03:07 20:35:01	...mapping from word to index.
2017:03:07 20:35:01	...map word to index.
2017:03:07 20:35:02	...some data statistics.
2017:03:07 20:35:02	...save processed data to file.
2017:03:07 20:35:05	the sample size is 95182, the vocab size is 18626
2017:03:07 20:36:30	use DataLoaderChildrenStory to init data.
2017:03:07 20:36:30	reading and processing the text file.
2017:03:07 20:36:30	preprocess the dataset.
2017:03:07 20:36:34	...mask and pad the sentence.
2017:03:07 20:36:34	......max len:19, median len:8.0, min len:2
2017:03:07 20:36:35	build a vocabulary.
2017:03:07 20:36:35	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:36:35	...mapping from index to word.
2017:03:07 20:36:36	...mapping from word to index.
2017:03:07 20:36:36	...map word to index.
2017:03:07 20:36:37	...some data statistics.
2017:03:07 20:36:37	...save processed data to file.
2017:03:07 20:36:40	the sample size is 95080, the vocab size is 22861
2017:03:07 20:37:14	use DataLoaderChildrenStory to init data.
2017:03:07 20:37:14	reading and processing the text file.
2017:03:07 20:37:14	preprocess the dataset.
2017:03:07 20:37:18	...mask and pad the sentence.
2017:03:07 20:37:18	......max len:19, median len:8.0, min len:2
2017:03:07 20:37:19	build a vocabulary.
2017:03:07 20:37:19	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:37:20	...mapping from index to word.
2017:03:07 20:37:20	...mapping from word to index.
2017:03:07 20:37:20	...map word to index.
2017:03:07 20:37:20	...some data statistics.
2017:03:07 20:37:20	...save processed data to file.
2017:03:07 20:37:24	the sample size is 95080, the vocab size is 22861
2017:03:07 20:37:27	use DataLoaderChildrenStory to init data.
2017:03:07 20:37:27	reading and processing the text file.
2017:03:07 20:37:27	preprocess the dataset.
2017:03:07 20:37:37	...mask and pad the sentence.
2017:03:07 20:37:37	......max len:19, median len:9.0, min len:2
2017:03:07 20:37:38	build a vocabulary.
2017:03:07 20:37:38	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:37:39	...mapping from index to word.
2017:03:07 20:37:39	...mapping from word to index.
2017:03:07 20:37:39	...map word to index.
2017:03:07 20:37:40	...some data statistics.
2017:03:07 20:37:40	...save processed data to file.
2017:03:07 20:37:43	the sample size is 95182, the vocab size is 18626
2017:03:07 20:38:48	use DataLoaderChildrenStory to init data.
2017:03:07 20:38:48	reading and processing the text file.
2017:03:07 20:38:48	preprocess the dataset.
2017:03:07 20:38:58	...mask and pad the sentence.
2017:03:07 20:38:58	......max len:19, median len:9.0, min len:2
2017:03:07 20:38:58	build a vocabulary.
2017:03:07 20:38:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:38:59	...mapping from index to word.
2017:03:07 20:38:59	...mapping from word to index.
2017:03:07 20:38:59	...map word to index.
2017:03:07 20:39:00	...some data statistics.
2017:03:07 20:39:00	...save processed data to file.
2017:03:07 20:39:03	the sample size is 95182, the vocab size is 18626
2017:03:07 20:40:34	use DataLoaderChildrenStory to init data.
2017:03:07 20:40:34	reading and processing the text file.
2017:03:07 20:40:34	preprocess the dataset.
2017:03:07 20:40:44	...mask and pad the sentence.
2017:03:07 20:40:44	......max len:19, median len:9.0, min len:2
2017:03:07 20:40:44	build a vocabulary.
2017:03:07 20:40:44	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:40:45	...mapping from index to word.
2017:03:07 20:40:45	...mapping from word to index.
2017:03:07 20:40:45	...map word to index.
2017:03:07 20:40:46	...some data statistics.
2017:03:07 20:40:46	...save processed data to file.
2017:03:07 20:40:49	the sample size is 95182, the vocab size is 18626
2017:03:07 20:42:08	use DataLoaderChildrenStory to init data.
2017:03:07 20:42:08	reading and processing the text file.
2017:03:07 20:42:08	preprocess the dataset.
2017:03:07 20:42:17	...mask and pad the sentence.
2017:03:07 20:42:17	......max len:19, median len:9.0, min len:2
2017:03:07 20:42:18	build a vocabulary.
2017:03:07 20:42:18	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:42:19	...mapping from index to word.
2017:03:07 20:42:19	...mapping from word to index.
2017:03:07 20:42:19	...map word to index.
2017:03:07 20:42:19	...some data statistics.
2017:03:07 20:42:19	...save processed data to file.
2017:03:07 20:42:22	the sample size is 95182, the vocab size is 18626
2017:03:07 21:52:40	use DataLoaderChildrenStory to init data.
2017:03:07 21:52:40	reading and processing the text file.
2017:03:07 21:52:40	preprocess the dataset.
2017:03:07 21:52:48	...mask and pad the sentence.
2017:03:07 21:52:48	......max len:19, median len:9.0, min len:2
2017:03:07 21:52:48	build a vocabulary.
2017:03:07 21:52:48	...flatmap a list of sentence list to a list of sentence.
2017:03:07 21:52:49	...mapping from index to word.
2017:03:07 21:52:49	...mapping from word to index.
2017:03:07 21:52:49	...map word to index.
2017:03:07 21:52:50	...some data statistics.
2017:03:07 21:52:50	...save processed data to file.
2017:03:07 21:52:53	the sample size is 95182, the vocab size is 18627
2017:03:07 21:56:38	use DataLoaderChildrenStory to init data.
2017:03:07 21:56:38	loading preprocessed files.
2017:03:07 21:56:43	the sample size is 95182, the vocab size is 18627
2017:03:07 21:57:30	use DataLoaderChildrenStory to init data.
2017:03:07 21:57:30	loading preprocessed files.
2017:03:07 21:57:36	the sample size is 95182, the vocab size is 18627
2017:03:07 21:58:33	use DataLoaderChildrenStory to init data.
2017:03:07 21:58:33	loading preprocessed files.
2017:03:07 21:58:38	the sample size is 95182, the vocab size is 18627
2017:03:07 22:08:37	use DataLoaderChildrenStory to init data.
2017:03:07 22:08:37	loading preprocessed files.
2017:03:07 22:08:42	the sample size is 95182, the vocab size is 18627
2017:03:07 22:19:08	use DataLoaderChildrenStory to init data.
2017:03:07 22:19:08	loading preprocessed files.
2017:03:07 22:19:13	the sample size is 95182, the vocab size is 18627
2017:03:07 22:21:11	use DataLoaderChildrenStory to init data.
2017:03:07 22:21:11	loading preprocessed files.
2017:03:07 22:21:16	the sample size is 95182, the vocab size is 18627
2017:03:07 22:25:46	use DataLoaderChildrenStory to init data.
2017:03:07 22:25:46	loading preprocessed files.
2017:03:07 22:25:50	the sample size is 95182, the vocab size is 18627
2017:03:07 22:27:14	use DataLoaderChildrenStory to init data.
2017:03:07 22:27:14	loading preprocessed files.
2017:03:07 22:27:18	the sample size is 95182, the vocab size is 18627
2017:03:07 22:27:40	use DataLoaderChildrenStory to init data.
2017:03:07 22:27:40	loading preprocessed files.
2017:03:07 22:27:44	the sample size is 95182, the vocab size is 18627
2017:03:07 23:24:29	use DataLoaderChildrenStory to init data.
2017:03:07 23:24:29	loading preprocessed files.
2017:03:07 23:24:33	the sample size is 95182, the vocab size is 18627
2017:03:07 23:26:00	use DataLoaderChildrenStory to init data.
2017:03:07 23:26:00	loading preprocessed files.
2017:03:07 23:26:04	the sample size is 95182, the vocab size is 18627
2017:03:07 23:49:16	use DataLoaderChildrenStory to init data.
2017:03:07 23:49:16	loading preprocessed files.
2017:03:08 23:42:48	use DataLoaderChildrenStory to init data.
2017:03:08 23:42:48	loading preprocessed files.
2017:03:08 23:42:52	the sample size is 95182, the vocab size is 18627
2017:03:08 23:44:30	use DataLoaderChildrenStory to init data.
2017:03:08 23:44:30	reading and processing the text file.
2017:03:08 23:44:30	preprocess the dataset.
2017:03:08 23:44:35	...mask and pad the sentence.
2017:03:08 23:44:35	......max len:19, median len:9.0, min len:2
2017:03:08 23:44:35	build a vocabulary.
2017:03:08 23:44:35	...flatmap a list of sentence list to a list of sentence.
2017:03:08 23:44:36	...mapping from index to word.
2017:03:08 23:44:36	...mapping from word to index.
2017:03:08 23:44:36	...map word to index.
2017:03:08 23:44:37	...some data statistics.
2017:03:08 23:44:37	...save processed data to file.
2017:03:08 23:44:40	the sample size is 95182, the vocab size is 18628
2017:03:08 23:45:20	use DataLoaderChildrenStory to init data.
2017:03:08 23:45:20	loading preprocessed files.
2017:03:08 23:45:27	the sample size is 95182, the vocab size is 18628
2017:03:08 23:46:58	use DataLoaderChildrenStory to init data.
2017:03:08 23:46:58	loading preprocessed files.
2017:03:08 23:47:04	the sample size is 95182, the vocab size is 18628
2017:03:08 23:47:16	use DataLoaderChildrenStory to init data.
2017:03:08 23:47:16	loading preprocessed files.
2017:03:08 23:47:23	the sample size is 95182, the vocab size is 18628
2017:03:08 23:48:11	use DataLoaderChildrenStory to init data.
2017:03:08 23:48:11	loading preprocessed files.
2017:03:08 23:48:18	the sample size is 95182, the vocab size is 18628
2017:03:08 23:48:45	use DataLoaderChildrenStory to init data.
2017:03:08 23:48:45	loading preprocessed files.
2017:03:08 23:48:51	the sample size is 95182, the vocab size is 18628
2017:03:08 23:49:08	use DataLoaderChildrenStory to init data.
2017:03:08 23:49:08	loading preprocessed files.
2017:03:08 23:49:14	the sample size is 95182, the vocab size is 18628
2017:03:08 23:49:36	use DataLoaderChildrenStory to init data.
2017:03:08 23:49:36	loading preprocessed files.
2017:03:08 23:49:43	the sample size is 95182, the vocab size is 18628
2017:03:08 23:49:58	use DataLoaderChildrenStory to init data.
2017:03:08 23:49:58	loading preprocessed files.
2017:03:08 23:50:05	the sample size is 95182, the vocab size is 18628
2017:03:08 23:52:24	use DataLoaderChildrenStory to init data.
2017:03:08 23:52:24	loading preprocessed files.
2017:03:08 23:52:31	the sample size is 95182, the vocab size is 18628
2017:03:08 23:53:22	use DataLoaderChildrenStory to init data.
2017:03:08 23:53:22	loading preprocessed files.
2017:03:08 23:53:28	the sample size is 95182, the vocab size is 18628
2017:03:08 23:55:43	use DataLoaderChildrenStory to init data.
2017:03:08 23:55:43	loading preprocessed files.
2017:03:08 23:55:49	the sample size is 95182, the vocab size is 18628
2017:03:08 23:56:43	use DataLoaderChildrenStory to init data.
2017:03:08 23:56:43	loading preprocessed files.
2017:03:08 23:56:49	the sample size is 95182, the vocab size is 18628
2017:03:08 23:57:17	use DataLoaderChildrenStory to init data.
2017:03:08 23:57:17	loading preprocessed files.
2017:03:08 23:57:24	the sample size is 95182, the vocab size is 18628
2017:03:08 23:58:38	use DataLoaderChildrenStory to init data.
2017:03:08 23:58:38	loading preprocessed files.
2017:03:08 23:58:45	the sample size is 95182, the vocab size is 18628
2017:03:09 00:00:36	use DataLoaderChildrenStory to init data.
2017:03:09 00:00:36	loading preprocessed files.
2017:03:09 00:00:42	the sample size is 95182, the vocab size is 18628
2017:03:09 00:01:10	use DataLoaderChildrenStory to init data.
2017:03:09 00:01:10	loading preprocessed files.
2017:03:09 00:01:17	the sample size is 95182, the vocab size is 18628
2017:03:09 00:02:37	use DataLoaderChildrenStory to init data.
2017:03:09 00:02:37	loading preprocessed files.
2017:03:09 00:02:44	the sample size is 95182, the vocab size is 18628
2017:03:09 00:03:02	use DataLoaderChildrenStory to init data.
2017:03:09 00:03:02	loading preprocessed files.
2017:03:09 00:03:09	the sample size is 95182, the vocab size is 18628
2017:03:09 00:06:41	use DataLoaderChildrenStory to init data.
2017:03:09 00:06:41	loading preprocessed files.
2017:03:09 00:06:48	the sample size is 95182, the vocab size is 18628
2017:03:09 00:07:02	use DataLoaderChildrenStory to init data.
2017:03:09 00:07:02	loading preprocessed files.
2017:03:09 00:07:09	the sample size is 95182, the vocab size is 18628
2017:03:09 00:07:44	use DataLoaderChildrenStory to init data.
2017:03:09 00:07:44	loading preprocessed files.
2017:03:09 00:07:50	the sample size is 95182, the vocab size is 18628
2017:03:09 00:08:29	use DataLoaderChildrenStory to init data.
2017:03:09 00:08:29	loading preprocessed files.
2017:03:09 00:08:36	the sample size is 95182, the vocab size is 18628
2017:03:09 00:09:51	use DataLoaderChildrenStory to init data.
2017:03:09 00:09:51	loading preprocessed files.
2017:03:09 00:09:57	the sample size is 95182, the vocab size is 18628
2017:03:09 00:10:31	use DataLoaderChildrenStory to init data.
2017:03:09 00:10:31	loading preprocessed files.
2017:03:09 00:10:38	the sample size is 95182, the vocab size is 18628
2017:03:09 00:11:37	use DataLoaderChildrenStory to init data.
2017:03:09 00:11:37	loading preprocessed files.
2017:03:09 00:11:43	the sample size is 95182, the vocab size is 18628
2017:03:09 00:13:27	use DataLoaderChildrenStory to init data.
2017:03:09 00:13:27	loading preprocessed files.
2017:03:09 00:13:34	the sample size is 95182, the vocab size is 18628
2017:03:09 00:14:10	use DataLoaderChildrenStory to init data.
2017:03:09 00:14:10	loading preprocessed files.
2017:03:09 00:14:16	the sample size is 95182, the vocab size is 18628
2017:03:09 00:19:02	use DataLoaderChildrenStory to init data.
2017:03:09 00:19:02	loading preprocessed files.
2017:03:09 00:19:09	the sample size is 95182, the vocab size is 18628
2017:03:09 00:20:20	use DataLoaderChildrenStory to init data.
2017:03:09 00:20:20	loading preprocessed files.
2017:03:09 00:20:27	the sample size is 95182, the vocab size is 18628
2017:03:09 00:21:09	use DataLoaderChildrenStory to init data.
2017:03:09 00:21:09	loading preprocessed files.
2017:03:09 00:21:15	the sample size is 95182, the vocab size is 18628
2017:03:09 00:23:13	use DataLoaderChildrenStory to init data.
2017:03:09 00:23:13	loading preprocessed files.
2017:03:09 00:23:19	the sample size is 95182, the vocab size is 18628
2017:03:09 00:23:46	use DataLoaderChildrenStory to init data.
2017:03:09 00:23:46	loading preprocessed files.
2017:03:09 00:23:53	the sample size is 95182, the vocab size is 18628
2017:03:09 00:25:09	use DataLoaderChildrenStory to init data.
2017:03:09 00:25:09	loading preprocessed files.
2017:03:09 00:25:16	the sample size is 95182, the vocab size is 18628
2017:03:09 00:25:55	use DataLoaderChildrenStory to init data.
2017:03:09 00:25:55	loading preprocessed files.
2017:03:09 00:26:01	the sample size is 95182, the vocab size is 18628
2017:03:09 00:27:10	use DataLoaderChildrenStory to init data.
2017:03:09 00:27:10	loading preprocessed files.
2017:03:09 00:27:16	the sample size is 95182, the vocab size is 18628
2017:03:09 00:28:00	use DataLoaderChildrenStory to init data.
2017:03:09 00:28:00	loading preprocessed files.
2017:03:09 00:28:06	the sample size is 95182, the vocab size is 18628
2017:03:09 15:36:56	use DataLoaderChildrenStory to init data.
2017:03:09 15:36:56	reading and processing the text file.
2017:03:09 15:36:56	preprocess the dataset.
2017:03:09 15:37:01	...mask and pad the sentence.
2017:03:09 15:37:01	......max len:19, median len:9.0, min len:2
2017:03:09 15:37:02	build a vocabulary.
2017:03:09 15:37:02	...flatmap a list of sentence list to a list of sentence.
2017:03:09 15:37:03	...mapping from index to word.
2017:03:09 15:37:03	...mapping from word to index.
2017:03:09 15:37:03	...map word to index.
2017:03:09 15:37:03	...some data statistics.
2017:03:09 15:37:03	...save processed data to file.
2017:03:09 15:37:07	the sample size is 95182, the vocab size is 18628
2017:03:09 15:39:15	use DataLoaderChildrenStory to init data.
2017:03:09 15:39:15	loading preprocessed files.
2017:03:09 15:39:23	the sample size is 95182, the vocab size is 18628
2017:03:09 15:40:58	use DataLoaderChildrenStory to init data.
2017:03:09 15:40:58	loading preprocessed files.
2017:03:09 15:41:05	the sample size is 95182, the vocab size is 18628
2017:03:09 16:23:00	use DataLoaderChildrenStory to init data.
2017:03:09 16:23:00	loading preprocessed files.
2017:03:09 16:23:07	the sample size is 95182, the vocab size is 18628
2017:03:09 16:23:10	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076590

2017:03:09 16:24:52	use DataLoaderChildrenStory to init data.
2017:03:09 16:24:52	loading preprocessed files.
2017:03:09 16:24:59	the sample size is 95182, the vocab size is 18628
2017:03:09 16:25:03	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076703

2017:03:09 16:25:33	use DataLoaderChildrenStory to init data.
2017:03:09 16:25:33	loading preprocessed files.
2017:03:09 16:25:40	the sample size is 95182, the vocab size is 18628
2017:03:09 16:25:43	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076743

2017:03:09 16:26:13	use DataLoaderChildrenStory to init data.
2017:03:09 16:26:13	loading preprocessed files.
2017:03:09 16:26:20	the sample size is 95182, the vocab size is 18628
2017:03:09 16:26:23	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076783

2017:03:09 17:02:45	use DataLoaderChildrenStory to init data.
2017:03:09 17:02:45	loading preprocessed files.
2017:03:09 17:02:54	the sample size is 95182, the vocab size is 18628
2017:03:09 17:02:57	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489078977

2017:03:09 17:03:25	use DataLoaderChildrenStory to init data.
2017:03:09 17:03:25	loading preprocessed files.
2017:03:09 17:03:32	the sample size is 95182, the vocab size is 18628
2017:03:09 17:03:35	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489079015

2017:03:09 17:04:17	use DataLoaderChildrenStory to init data.
2017:03:09 17:04:17	loading preprocessed files.
2017:03:09 17:04:24	the sample size is 95182, the vocab size is 18628
2017:03:09 17:04:28	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489079067

2017:03:09 18:32:49	use DataLoaderChildrenStory to init data.
2017:03:09 18:32:49	loading preprocessed files.
2017:03:09 18:32:56	the sample size is 95182, the vocab size is 18628
2017:03:09 18:32:59	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489084379

2017:03:09 19:43:35	use DataLoaderChildrenStory to init data.
2017:03:09 19:43:35	loading preprocessed files.
2017:03:09 19:43:42	the sample size is 95182, the vocab size is 18628
2017:03:09 19:43:46	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489088626

2017:03:09 19:53:00	use DataLoaderChildrenStory to init data.
2017:03:09 19:53:00	loading preprocessed files.
2017:03:09 19:53:10	the sample size is 95182, the vocab size is 18628
2017:03:09 19:53:53	use DataLoaderChildrenStory to init data.
2017:03:09 19:53:53	loading preprocessed files.
2017:03:09 19:53:59	the sample size is 95182, the vocab size is 18628
2017:03:09 19:55:09	use DataLoaderChildrenStory to init data.
2017:03:09 19:55:09	loading preprocessed files.
2017:03:09 19:55:17	the sample size is 95182, the vocab size is 18628
2017:03:09 19:55:26	use DataLoaderChildrenStory to init data.
2017:03:09 19:55:26	loading preprocessed files.
2017:03:09 19:55:33	the sample size is 95182, the vocab size is 18628
2017:03:09 19:55:36	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089336

2017:03:09 19:56:35	use DataLoaderChildrenStory to init data.
2017:03:09 19:56:35	loading preprocessed files.
2017:03:09 19:56:41	the sample size is 95182, the vocab size is 18628
2017:03:09 19:56:44	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089404

2017:03:09 19:58:36	use DataLoaderChildrenStory to init data.
2017:03:09 19:58:36	loading preprocessed files.
2017:03:09 19:58:44	the sample size is 95182, the vocab size is 18628
2017:03:09 19:58:47	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089527

2017:03:09 19:59:32	use DataLoaderChildrenStory to init data.
2017:03:09 19:59:32	loading preprocessed files.
2017:03:09 19:59:39	the sample size is 95182, the vocab size is 18628
2017:03:09 19:59:42	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089582

2017:03:09 20:00:30	use DataLoaderChildrenStory to init data.
2017:03:09 20:00:30	loading preprocessed files.
2017:03:09 20:00:37	the sample size is 95182, the vocab size is 18628
2017:03:09 20:00:40	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089640

2017:03:09 20:02:00	use DataLoaderChildrenStory to init data.
2017:03:09 20:02:00	loading preprocessed files.
2017:03:09 20:02:07	the sample size is 95182, the vocab size is 18628
2017:03:09 20:02:36	use DataLoaderChildrenStory to init data.
2017:03:09 20:02:36	loading preprocessed files.
2017:03:09 20:02:43	the sample size is 95182, the vocab size is 18628
2017:03:09 20:02:47	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089767

2017:03:09 20:03:45	use DataLoaderChildrenStory to init data.
2017:03:09 20:03:45	loading preprocessed files.
2017:03:09 20:03:54	the sample size is 95182, the vocab size is 18628
2017:03:09 20:03:57	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089837

2017:03:09 20:04:38	use DataLoaderChildrenStory to init data.
2017:03:09 20:04:38	loading preprocessed files.
2017:03:09 20:04:44	the sample size is 95182, the vocab size is 18628
2017:03:09 20:05:17	use DataLoaderChildrenStory to init data.
2017:03:09 20:05:17	loading preprocessed files.
2017:03:09 20:05:24	the sample size is 95182, the vocab size is 18628
2017:03:09 20:06:13	use DataLoaderChildrenStory to init data.
2017:03:09 20:06:13	loading preprocessed files.
2017:03:09 20:06:20	the sample size is 95182, the vocab size is 18628
2017:03:09 20:06:43	use DataLoaderChildrenStory to init data.
2017:03:09 20:06:43	loading preprocessed files.
2017:03:09 20:06:49	the sample size is 95182, the vocab size is 18628
2017:03:09 20:08:02	use DataLoaderChildrenStory to init data.
2017:03:09 20:08:02	loading preprocessed files.
2017:03:09 20:08:09	the sample size is 95182, the vocab size is 18628
2017:03:09 20:08:17	use DataLoaderChildrenStory to init data.
2017:03:09 20:08:17	loading preprocessed files.
2017:03:09 20:08:23	the sample size is 95182, the vocab size is 18628
2017:03:09 20:08:26	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090106

2017:03:09 20:11:05	use DataLoaderChildrenStory to init data.
2017:03:09 20:11:05	loading preprocessed files.
2017:03:09 20:11:13	the sample size is 95182, the vocab size is 18628
2017:03:09 20:11:46	use DataLoaderChildrenStory to init data.
2017:03:09 20:11:46	loading preprocessed files.
2017:03:09 20:11:53	the sample size is 95182, the vocab size is 18628
2017:03:09 20:11:56	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090316

2017:03:09 20:13:00	use DataLoaderChildrenStory to init data.
2017:03:09 20:13:00	loading preprocessed files.
2017:03:09 20:13:08	the sample size is 95182, the vocab size is 18628
2017:03:09 20:13:12	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090391

2017:03:09 20:21:58	use DataLoaderChildrenStory to init data.
2017:03:09 20:21:58	reading and processing the text file.
2017:03:09 20:21:58	preprocess the dataset.
2017:03:09 20:22:03	...mask and pad the sentence.
2017:03:09 20:22:03	......max len:20, median len:10.0, min len:3
2017:03:09 20:22:04	build a vocabulary.
2017:03:09 20:22:04	...flatmap a list of sentence list to a list of sentence.
2017:03:09 20:22:05	...mapping from index to word.
2017:03:09 20:22:05	...mapping from word to index.
2017:03:09 20:22:05	...map word to index.
2017:03:09 20:22:07	...some data statistics.
2017:03:09 20:22:07	...save processed data to file.
2017:03:09 20:22:12	the sample size is 97314, the vocab size is 18739
2017:03:09 20:22:15	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090935

2017:03:09 20:27:28	use DataLoaderChildrenStory to init data.
2017:03:09 20:27:28	loading preprocessed files.
2017:03:09 20:27:41	the sample size is 97314, the vocab size is 18739
2017:03:09 20:27:44	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489091264

2017:03:10 10:05:00	use DataLoaderChildrenStory to init data.
2017:03:10 10:05:00	loading preprocessed files.
2017:03:10 10:05:08	the sample size is 97314, the vocab size is 18739
2017:03:10 10:09:00	use DataLoaderChildrenStory to init data.
2017:03:10 10:09:00	loading preprocessed files.
2017:03:10 10:09:08	the sample size is 97314, the vocab size is 18739
2017:03:10 10:17:11	use DataLoaderChildrenStory to init data.
2017:03:10 10:17:11	loading preprocessed files.
2017:03:10 10:17:19	the sample size is 97314, the vocab size is 18739
2017:03:10 10:22:41	use DataLoaderChildrenStory to init data.
2017:03:10 10:22:41	loading preprocessed files.
2017:03:10 10:22:49	the sample size is 97314, the vocab size is 18739
2017:03:10 10:23:06	use DataLoaderChildrenStory to init data.
2017:03:10 10:23:06	loading preprocessed files.
2017:03:10 10:23:13	the sample size is 97314, the vocab size is 18739
2017:03:10 12:52:55	use DataLoaderChildrenStory to init data.
2017:03:10 12:52:55	loading preprocessed files.
2017:03:10 12:53:03	the sample size is 97314, the vocab size is 18739
2017:03:10 12:53:37	use DataLoaderChildrenStory to init data.
2017:03:10 12:53:37	loading preprocessed files.
2017:03:10 12:53:43	the sample size is 97314, the vocab size is 18739
2017:03:10 13:24:25	use DataLoaderChildrenStory to init data.
2017:03:10 13:24:25	loading preprocessed files.
2017:03:10 13:24:33	the sample size is 97314, the vocab size is 18739
2017:03:10 13:25:03	use DataLoaderChildrenStory to init data.
2017:03:10 13:25:03	loading preprocessed files.
2017:03:10 13:25:12	the sample size is 97314, the vocab size is 18739
2017:03:10 13:27:03	use DataLoaderChildrenStory to init data.
2017:03:10 13:27:03	loading preprocessed files.
2017:03:10 13:27:11	the sample size is 97314, the vocab size is 18739
2017:03:10 13:30:02	use DataLoaderChildrenStory to init data.
2017:03:10 13:30:02	loading preprocessed files.
2017:03:10 13:30:10	the sample size is 97314, the vocab size is 18739
2017:03:10 13:31:53	use DataLoaderChildrenStory to init data.
2017:03:10 13:31:53	loading preprocessed files.
2017:03:10 13:32:01	the sample size is 97314, the vocab size is 18739
2017:03:10 14:04:41	use DataLoaderChildrenStory to init data.
2017:03:10 14:04:41	loading preprocessed files.
2017:03:10 14:04:48	the sample size is 97314, the vocab size is 18739
2017:03:10 14:06:44	use DataLoaderChildrenStory to init data.
2017:03:10 14:06:44	loading preprocessed files.
2017:03:10 14:06:51	the sample size is 97314, the vocab size is 18739
2017:03:10 14:08:09	use DataLoaderChildrenStory to init data.
2017:03:10 14:08:09	loading preprocessed files.
2017:03:10 14:08:17	the sample size is 97314, the vocab size is 18739
2017:03:10 14:09:06	use DataLoaderChildrenStory to init data.
2017:03:10 14:09:06	loading preprocessed files.
2017:03:10 14:09:14	the sample size is 97314, the vocab size is 18739
2017:03:10 14:16:31	use DataLoaderChildrenStory to init data.
2017:03:10 14:16:31	loading preprocessed files.
2017:03:10 14:16:39	the sample size is 97314, the vocab size is 18739
2017:03:10 14:18:23	use DataLoaderChildrenStory to init data.
2017:03:10 14:18:23	loading preprocessed files.
2017:03:10 14:18:30	the sample size is 97314, the vocab size is 18739
2017:03:10 14:21:17	use DataLoaderChildrenStory to init data.
2017:03:10 14:21:17	loading preprocessed files.
2017:03:10 14:21:24	the sample size is 97314, the vocab size is 18739
2017:03:10 14:21:46	use DataLoaderChildrenStory to init data.
2017:03:10 14:21:46	loading preprocessed files.
2017:03:10 14:21:55	the sample size is 97314, the vocab size is 18739
2017:03:10 14:22:01	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489155721

2017:03:10 14:22:03	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489155721

2017:03:10 14:22:05	------ do the pretrain ------ 

2017:03:10 14:24:47	use DataLoaderChildrenStory to init data.
2017:03:10 14:24:47	loading preprocessed files.
2017:03:10 14:24:55	the sample size is 97314, the vocab size is 18739
2017:03:10 14:25:01	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489155901

2017:03:10 14:25:05	------ do the pretrain ------ 

2017:03:10 15:18:57	use DataLoaderChildrenStory to init data.
2017:03:10 15:18:57	loading preprocessed files.
2017:03:10 15:19:05	the sample size is 97314, the vocab size is 18739
2017:03:10 15:19:24	use DataLoaderChildrenStory to init data.
2017:03:10 15:19:24	loading preprocessed files.
2017:03:10 15:19:31	the sample size is 97314, the vocab size is 18739
2017:03:10 15:19:40	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159179

2017:03:10 15:19:43	------ do the pretrain ------ 

2017:03:10 15:25:16	use DataLoaderChildrenStory to init data.
2017:03:10 15:25:16	loading preprocessed files.
2017:03:10 15:25:24	the sample size is 97314, the vocab size is 18739
2017:03:10 15:26:05	use DataLoaderChildrenStory to init data.
2017:03:10 15:26:05	loading preprocessed files.
2017:03:10 15:26:12	the sample size is 97314, the vocab size is 18739
2017:03:10 15:27:10	use DataLoaderChildrenStory to init data.
2017:03:10 15:27:10	loading preprocessed files.
2017:03:10 15:27:17	the sample size is 97314, the vocab size is 18739
2017:03:10 15:27:23	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159643

2017:03:10 15:27:27	------ do the pretrain ------ 

2017:03:10 15:28:54	use DataLoaderChildrenStory to init data.
2017:03:10 15:28:54	loading preprocessed files.
2017:03:10 15:29:01	the sample size is 97314, the vocab size is 18739
2017:03:10 15:29:07	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159747

2017:03:10 15:31:03	use DataLoaderChildrenStory to init data.
2017:03:10 15:31:03	loading preprocessed files.
2017:03:10 15:31:10	the sample size is 97314, the vocab size is 18739
2017:03:10 15:31:17	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159877

2017:03:10 15:31:49	use DataLoaderChildrenStory to init data.
2017:03:10 15:31:49	loading preprocessed files.
2017:03:10 15:31:57	the sample size is 97314, the vocab size is 18739
2017:03:10 15:32:19	use DataLoaderChildrenStory to init data.
2017:03:10 15:32:19	loading preprocessed files.
2017:03:10 15:32:26	the sample size is 97314, the vocab size is 18739
2017:03:10 15:32:32	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159952

2017:03:10 15:33:32	use DataLoaderChildrenStory to init data.
2017:03:10 15:33:32	loading preprocessed files.
2017:03:10 15:33:40	the sample size is 97314, the vocab size is 18739
2017:03:10 15:34:06	use DataLoaderChildrenStory to init data.
2017:03:10 15:34:06	loading preprocessed files.
2017:03:10 15:34:25	use DataLoaderChildrenStory to init data.
2017:03:10 15:34:25	loading preprocessed files.
2017:03:10 15:34:32	the sample size is 97314, the vocab size is 18739
2017:03:10 15:35:07	use DataLoaderChildrenStory to init data.
2017:03:10 15:35:07	loading preprocessed files.
2017:03:10 15:35:15	the sample size is 97314, the vocab size is 18739
2017:03:10 15:36:35	use DataLoaderChildrenStory to init data.
2017:03:10 15:36:35	loading preprocessed files.
2017:03:10 15:36:43	the sample size is 97314, the vocab size is 18739
2017:03:10 15:37:23	use DataLoaderChildrenStory to init data.
2017:03:10 15:37:23	loading preprocessed files.
2017:03:10 15:37:31	the sample size is 97314, the vocab size is 18739
2017:03:10 15:37:59	use DataLoaderChildrenStory to init data.
2017:03:10 15:37:59	loading preprocessed files.
2017:03:10 15:38:06	the sample size is 97314, the vocab size is 18739
2017:03:10 15:38:13	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489160292

2017:03:10 15:38:16	------ do the pretrain ------ 

2017:03:10 15:39:12	use DataLoaderChildrenStory to init data.
2017:03:10 15:39:12	loading preprocessed files.
2017:03:10 15:39:19	the sample size is 97314, the vocab size is 18739
2017:03:10 15:40:22	use DataLoaderChildrenStory to init data.
2017:03:10 15:40:22	loading preprocessed files.
2017:03:10 15:40:30	the sample size is 97314, the vocab size is 18739
2017:03:10 15:41:50	use DataLoaderChildrenStory to init data.
2017:03:10 15:41:50	loading preprocessed files.
2017:03:10 15:41:57	the sample size is 97314, the vocab size is 18739
2017:03:10 16:52:18	use DataLoaderChildrenStory to init data.
2017:03:10 16:52:18	loading preprocessed files.
2017:03:10 16:52:25	the sample size is 97314, the vocab size is 18739
2017:03:10 16:52:46	use DataLoaderChildrenStory to init data.
2017:03:10 16:52:46	loading preprocessed files.
2017:03:10 16:52:52	the sample size is 97314, the vocab size is 18739
2017:03:10 16:54:08	use DataLoaderChildrenStory to init data.
2017:03:10 16:54:08	loading preprocessed files.
2017:03:10 16:54:15	the sample size is 97314, the vocab size is 18739
2017:03:10 16:55:27	use DataLoaderChildrenStory to init data.
2017:03:10 16:55:27	loading preprocessed files.
2017:03:10 16:55:34	the sample size is 97314, the vocab size is 18739
2017:03:10 16:55:58	use DataLoaderChildrenStory to init data.
2017:03:10 16:55:58	loading preprocessed files.
2017:03:10 16:56:05	the sample size is 97314, the vocab size is 18739
2017:03:10 17:03:23	use DataLoaderChildrenStory to init data.
2017:03:10 17:03:23	loading preprocessed files.
2017:03:10 17:03:30	the sample size is 97314, the vocab size is 18739
2017:03:10 17:03:37	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489165416

2017:03:10 17:03:41	------ do the pretrain ------ 

2017:03:10 17:04:59	use DataLoaderChildrenStory to init data.
2017:03:10 17:04:59	loading preprocessed files.
2017:03:10 17:05:06	the sample size is 97314, the vocab size is 18739
2017:03:10 17:05:40	use DataLoaderChildrenStory to init data.
2017:03:10 17:05:40	loading preprocessed files.
2017:03:10 17:05:47	the sample size is 97314, the vocab size is 18739
2017:03:10 17:06:29	use DataLoaderChildrenStory to init data.
2017:03:10 17:06:29	loading preprocessed files.
2017:03:10 17:06:36	the sample size is 97314, the vocab size is 18739
2017:03:10 17:07:44	use DataLoaderChildrenStory to init data.
2017:03:10 17:07:44	loading preprocessed files.
2017:03:10 17:07:50	the sample size is 97314, the vocab size is 18739
2017:03:10 17:08:01	use DataLoaderChildrenStory to init data.
2017:03:10 17:08:01	loading preprocessed files.
2017:03:10 17:08:08	the sample size is 97314, the vocab size is 18739
2017:03:10 17:10:51	use DataLoaderChildrenStory to init data.
2017:03:10 17:10:51	loading preprocessed files.
2017:03:10 17:10:58	the sample size is 97314, the vocab size is 18739
2017:03:10 17:11:20	use DataLoaderChildrenStory to init data.
2017:03:10 17:11:20	loading preprocessed files.
2017:03:10 17:11:27	the sample size is 97314, the vocab size is 18739
2017:03:10 17:16:09	use DataLoaderChildrenStory to init data.
2017:03:10 17:16:09	loading preprocessed files.
2017:03:10 17:16:16	the sample size is 97314, the vocab size is 18739
2017:03:10 17:16:26	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166186

2017:03:10 17:16:32	------ do the pretrain ------ 

2017:03:10 17:16:48	use DataLoaderChildrenStory to init data.
2017:03:10 17:16:48	loading preprocessed files.
2017:03:10 17:16:55	the sample size is 97314, the vocab size is 18739
2017:03:10 17:17:07	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166227

2017:03:10 17:17:13	------ do the pretrain ------ 

2017:03:10 17:18:18	use DataLoaderChildrenStory to init data.
2017:03:10 17:18:18	loading preprocessed files.
2017:03:10 17:18:25	the sample size is 97314, the vocab size is 18739
2017:03:10 17:18:34	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166314

2017:03:10 17:18:39	------ do the pretrain ------ 

2017:03:10 17:19:43	use DataLoaderChildrenStory to init data.
2017:03:10 17:19:43	loading preprocessed files.
2017:03:10 17:19:50	the sample size is 97314, the vocab size is 18739
2017:03:10 17:19:59	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166399

2017:03:10 17:20:04	------ do the pretrain ------ 

2017:03:10 17:21:52	use DataLoaderChildrenStory to init data.
2017:03:10 17:21:52	loading preprocessed files.
2017:03:10 17:21:58	the sample size is 97314, the vocab size is 18739
2017:03:10 17:22:05	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489166524

2017:03:10 17:22:08	------ do the pretrain ------ 

2017:03:11 14:08:57	use DataLoaderChildrenStory to init data.
2017:03:11 14:08:57	loading preprocessed files.
2017:03:11 14:09:06	the sample size is 97314, the vocab size is 18739
2017:03:11 14:09:38	use DataLoaderChildrenStory to init data.
2017:03:11 14:09:38	loading preprocessed files.
2017:03:11 14:09:46	the sample size is 97314, the vocab size is 18739
2017:03:11 14:13:02	use DataLoaderChildrenStory to init data.
2017:03:11 14:13:02	loading preprocessed files.
2017:03:11 14:13:09	the sample size is 97314, the vocab size is 18739
2017:03:11 14:22:59	use DataLoaderChildrenStory to init data.
2017:03:11 14:22:59	loading preprocessed files.
2017:03:11 14:23:06	the sample size is 97314, the vocab size is 18739
2017:03:11 14:23:16	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV2.TextGANV2/1489242196

2017:03:11 14:23:21	------ do the pretrain ------ 

2017:03:12 21:48:43	use DataLoaderChildrenStory to init data.
2017:03:12 21:49:11	use DataLoaderChildrenStory to init data.
2017:03:12 21:49:11	loading preprocessed files.
2017:03:12 21:49:19	the sample size is 97314, the vocab size is 18739
2017:03:12 21:50:02	use DataLoaderChildrenStory to init data.
2017:03:12 21:50:02	loading preprocessed files.
2017:03:12 21:50:09	the sample size is 97314, the vocab size is 18739
2017:03:12 21:50:16	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355415

2017:03:12 21:50:19	------ do the pretrain ------ 

2017:03:12 21:53:24	use DataLoaderChildrenStory to init data.
2017:03:12 21:53:24	loading preprocessed files.
2017:03:12 21:53:32	the sample size is 97314, the vocab size is 18739
2017:03:12 21:53:38	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355618

2017:03:12 21:53:42	------ do the pretrain ------ 

2017:03:12 21:53:43	save best model to: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355618/checkpoints/bestmodel-0.

2017:03:12 21:53:43	------ do the standard GAN training ------ 

2017:03:12 21:53:43	------ generate sentence from latent space / noice ------ 

2017:03:12 21:55:14	use DataLoaderChildrenStory to init data.
2017:03:12 21:55:14	loading preprocessed files.
2017:03:12 21:55:21	the sample size is 97314, the vocab size is 18739
2017:03:12 21:55:27	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355727

2017:03:12 21:55:31	------ do the pretrain ------ 

2017:03:12 21:55:32	save best model to: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355727/checkpoints/bestmodel-0.

2017:03:12 21:55:32	------ do the standard GAN training ------ 

2017:03:12 21:55:32	------ generate sentence from latent space / noice ------ 

2017:03:12 21:56:51	use DataLoaderChildrenStory to init data.
2017:03:12 21:56:51	loading preprocessed files.
2017:03:12 21:56:59	the sample size is 97314, the vocab size is 18739
2017:03:12 21:57:05	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355825

2017:03:12 21:57:08	------ do the pretrain ------ 

2017:03:12 21:57:09	save best model to: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355825/checkpoints/bestmodel-0.

2017:03:12 21:57:09	------ do the standard GAN training ------ 

2017:03:12 21:57:09	------ generate sentence from latent space / noice ------ 

2017:03:12 21:58:05	use DataLoaderChildrenStory to init data.
2017:03:12 21:58:05	loading preprocessed files.
2017:03:12 21:58:12	the sample size is 97314, the vocab size is 18739
2017:03:12 21:58:18	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355898

2017:03:12 21:58:22	------ do the pretrain ------ 

2017:03:12 21:58:23	save best model to: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355898/checkpoints/bestmodel-0.

2017:03:12 21:58:23	------ do the standard GAN training ------ 

2017:03:12 21:58:23	------ generate sentence from latent space / noice ------ 

2017:03:12 21:58:55	use DataLoaderChildrenStory to init data.
2017:03:12 21:58:55	loading preprocessed files.
2017:03:12 21:59:03	the sample size is 97314, the vocab size is 18739
2017:03:12 21:59:10	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355949

2017:03:12 22:01:03	use DataLoaderChildrenStory to init data.
2017:03:12 22:01:03	loading preprocessed files.
2017:03:12 22:01:11	the sample size is 97314, the vocab size is 18739
2017:03:12 22:01:18	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489356078

2017:03:12 22:01:22	------ do the pretrain ------ 

2017:03:12 22:01:22	save best model to: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489356078/checkpoints/bestmodel-0.

2017:03:12 22:01:22	------ do the standard GAN training ------ 

2017:03:12 22:01:22	------ generate sentence from latent space / noice ------ 

2017:03:12 23:21:39	use DataLoaderChildrenStory to init data.
2017:03:12 23:21:39	loading preprocessed files.
2017:03:12 23:21:47	the sample size is 97314, the vocab size is 18739
2017:03:12 23:22:36	use DataLoaderChildrenStory to init data.
2017:03:12 23:22:36	loading preprocessed files.
2017:03:12 23:22:43	the sample size is 97314, the vocab size is 18739
2017:03:12 23:23:19	use DataLoaderChildrenStory to init data.
2017:03:12 23:23:19	loading preprocessed files.
2017:03:12 23:23:26	the sample size is 97314, the vocab size is 18739
2017:03:12 23:23:45	use DataLoaderChildrenStory to init data.
2017:03:12 23:23:45	loading preprocessed files.
2017:03:12 23:23:52	the sample size is 97314, the vocab size is 18739
2017:03:12 23:28:21	use DataLoaderChildrenStory to init data.
2017:03:12 23:28:21	loading preprocessed files.
2017:03:12 23:28:28	the sample size is 97314, the vocab size is 18739
2017:03:12 23:31:40	use DataLoaderChildrenStory to init data.
2017:03:12 23:31:40	loading preprocessed files.
2017:03:12 23:31:47	the sample size is 97314, the vocab size is 18739
2017:03:12 23:36:45	use DataLoaderChildrenStory to init data.
2017:03:12 23:36:45	loading preprocessed files.
2017:03:12 23:36:52	the sample size is 97314, the vocab size is 18739
2017:03:12 23:36:59	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361819

2017:03:12 23:37:03	------ do the pretrain ------ 

2017:03:12 23:37:04	------ do the standard GAN training ------ 

2017:03:12 23:37:04	total execution time: 18
2017:03:12 23:37:40	use DataLoaderChildrenStory to init data.
2017:03:12 23:37:40	loading preprocessed files.
2017:03:12 23:37:47	the sample size is 97314, the vocab size is 18739
2017:03:12 23:39:15	use DataLoaderChildrenStory to init data.
2017:03:12 23:39:15	loading preprocessed files.
2017:03:12 23:39:22	the sample size is 97314, the vocab size is 18739
2017:03:12 23:39:29	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968

2017:03:12 23:39:33	------ do the pretrain ------ 

2017:03:12 23:39:33	save best model to: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0.

2017:03:12 23:39:33	------ do the standard GAN training ------ 

2017:03:12 23:39:33	total execution time: 18
2017:03:12 23:39:52	use DataLoaderChildrenStory to init data.
2017:03:12 23:39:52	loading preprocessed files.
2017:03:12 23:39:58	the sample size is 97314, the vocab size is 18739
2017:03:12 23:43:09	use DataLoaderChildrenStory to init data.
2017:03:12 23:43:09	loading preprocessed files.
2017:03:12 23:43:17	the sample size is 97314, the vocab size is 18739
2017:03:12 23:45:19	use DataLoaderChildrenStory to init data.
2017:03:12 23:45:19	loading preprocessed files.
2017:03:12 23:45:27	the sample size is 97314, the vocab size is 18739
2017:03:13 09:17:42	use DataLoaderChildrenStory to init data.
2017:03:13 09:17:42	loading preprocessed files.
2017:03:13 09:17:50	the sample size is 97314, the vocab size is 18739
2017:03:13 09:18:17	use DataLoaderChildrenStory to init data.
2017:03:13 09:18:17	loading preprocessed files.
2017:03:13 09:18:25	the sample size is 97314, the vocab size is 18739
2017:03:13 09:19:57	use DataLoaderChildrenStory to init data.
2017:03:13 09:19:57	loading preprocessed files.
2017:03:13 09:20:05	the sample size is 97314, the vocab size is 18739
2017:03:13 09:21:10	use DataLoaderChildrenStory to init data.
2017:03:13 09:21:10	loading preprocessed files.
2017:03:13 09:21:16	the sample size is 97314, the vocab size is 18739
2017:03:13 09:29:20	use DataLoaderChildrenStory to init data.
2017:03:13 09:29:20	loading preprocessed files.
2017:03:13 09:29:28	the sample size is 97314, the vocab size is 18739
2017:03:13 09:33:55	use DataLoaderChildrenStory to init data.
2017:03:13 09:33:55	loading preprocessed files.
2017:03:13 09:34:02	the sample size is 97314, the vocab size is 18739
2017:03:13 09:35:25	use DataLoaderChildrenStory to init data.
2017:03:13 09:35:25	loading preprocessed files.
2017:03:13 09:35:32	the sample size is 97314, the vocab size is 18739
2017:03:13 09:37:10	use DataLoaderChildrenStory to init data.
2017:03:13 09:37:10	loading preprocessed files.
2017:03:13 09:37:18	the sample size is 97314, the vocab size is 18739
2017:03:13 09:38:06	use DataLoaderChildrenStory to init data.
2017:03:13 09:38:06	loading preprocessed files.
2017:03:13 09:38:13	the sample size is 97314, the vocab size is 18739
2017:03:13 09:53:11	use DataLoaderChildrenStory to init data.
2017:03:13 09:53:11	loading preprocessed files.
2017:03:13 09:53:19	the sample size is 97314, the vocab size is 18739
2017:03:13 09:54:12	use DataLoaderChildrenStory to init data.
2017:03:13 09:54:12	loading preprocessed files.
2017:03:13 09:54:20	the sample size is 97314, the vocab size is 18739
2017:03:13 09:55:47	use DataLoaderChildrenStory to init data.
2017:03:13 09:55:47	loading preprocessed files.
2017:03:13 09:55:54	the sample size is 97314, the vocab size is 18739
2017:03:13 09:56:07	use DataLoaderChildrenStory to init data.
2017:03:13 09:56:07	loading preprocessed files.
2017:03:13 09:56:13	the sample size is 97314, the vocab size is 18739
2017:03:13 10:31:59	use DataLoaderChildrenStory to init data.
2017:03:13 10:31:59	loading preprocessed files.
2017:03:13 10:32:08	the sample size is 97314, the vocab size is 18739
2017:03:13 10:33:09	use DataLoaderChildrenStory to init data.
2017:03:13 10:33:09	loading preprocessed files.
2017:03:13 10:33:17	the sample size is 97314, the vocab size is 18739
2017:03:13 10:40:03	use DataLoaderChildrenStory to init data.
2017:03:13 10:40:03	loading preprocessed files.
2017:03:13 10:40:12	the sample size is 97314, the vocab size is 18739
2017:03:13 10:43:03	use DataLoaderChildrenStory to init data.
2017:03:13 10:43:03	loading preprocessed files.
2017:03:13 10:43:10	the sample size is 97314, the vocab size is 18739
2017:03:13 11:24:55	use DataLoaderChildrenStory to init data.
2017:03:13 11:24:55	loading preprocessed files.
2017:03:13 11:25:10	the sample size is 97314, the vocab size is 18739
2017:03:13 11:25:49	use DataLoaderChildrenStory to init data.
2017:03:13 11:25:49	loading preprocessed files.
2017:03:13 11:25:57	the sample size is 97314, the vocab size is 18739
2017:03:13 11:26:27	use DataLoaderChildrenStory to init data.
2017:03:13 11:26:27	loading preprocessed files.
2017:03:13 11:26:36	the sample size is 97314, the vocab size is 18739
2017:03:13 11:27:02	use DataLoaderChildrenStory to init data.
2017:03:13 11:27:02	loading preprocessed files.
2017:03:13 11:27:10	the sample size is 97314, the vocab size is 18739
2017:03:13 14:06:27	use DataLoaderChildrenStory to init data.
2017:03:13 14:06:27	loading preprocessed files.
2017:03:13 14:06:35	the sample size is 97314, the vocab size is 18739
2017:03:13 14:06:42	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489414002

2017:03:13 14:06:46	------ do the pretrain ------ 

2017:03:13 14:06:46	save bestmodel:1.

2017:03:13 14:06:46	------ do the standard GAN training ------ 

2017:03:13 14:06:46	total execution time: 19
2017:03:13 14:07:05	use DataLoaderChildrenStory to init data.
2017:03:13 14:07:05	loading preprocessed files.
2017:03:13 14:07:12	the sample size is 97314, the vocab size is 18739
2017:03:13 14:07:19	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489414038

2017:03:13 14:07:22	------ do the pretrain ------ 

2017:03:13 14:07:22	pretrain epoch 0
2017:03:13 14:58:07	use DataLoaderChildrenStory to init data.
2017:03:13 14:58:07	loading preprocessed files.
2017:03:13 14:58:15	the sample size is 97314, the vocab size is 18739
2017:03:13 14:59:09	use DataLoaderChildrenStory to init data.
2017:03:13 14:59:09	loading preprocessed files.
2017:03:13 14:59:16	the sample size is 97314, the vocab size is 18739
2017:03:13 14:59:49	use DataLoaderChildrenStory to init data.
2017:03:13 14:59:49	loading preprocessed files.
2017:03:13 14:59:56	the sample size is 97314, the vocab size is 18739
2017:03:13 15:00:04	use DataLoaderChildrenStory to init data.
2017:03:13 15:00:04	loading preprocessed files.
2017:03:13 15:00:11	the sample size is 97314, the vocab size is 18739
2017:03:13 15:00:34	use DataLoaderChildrenStory to init data.
2017:03:13 15:00:34	loading preprocessed files.
2017:03:13 15:00:41	the sample size is 97314, the vocab size is 18739
2017:03:13 15:01:23	use DataLoaderChildrenStory to init data.
2017:03:13 15:01:23	loading preprocessed files.
2017:03:13 15:01:30	the sample size is 97314, the vocab size is 18739
2017:03:13 15:02:59	use DataLoaderChildrenStory to init data.
2017:03:13 15:02:59	loading preprocessed files.
2017:03:13 15:03:05	the sample size is 97314, the vocab size is 18739
2017:03:13 15:03:30	use DataLoaderChildrenStory to init data.
2017:03:13 15:03:30	loading preprocessed files.
2017:03:13 15:03:37	the sample size is 97314, the vocab size is 18739
2017:03:13 15:04:00	use DataLoaderChildrenStory to init data.
2017:03:13 15:04:00	loading preprocessed files.
2017:03:13 15:04:07	the sample size is 97314, the vocab size is 18739
2017:03:13 15:06:46	use DataLoaderChildrenStory to init data.
2017:03:13 15:06:46	loading preprocessed files.
2017:03:13 15:06:53	the sample size is 97314, the vocab size is 18739
2017:03:13 15:07:50	use DataLoaderChildrenStory to init data.
2017:03:13 15:07:50	loading preprocessed files.
2017:03:13 15:07:56	the sample size is 97314, the vocab size is 18739
2017:03:13 15:08:03	restore checkpoint_file from path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0
2017:03:13 15:09:05	use DataLoaderChildrenStory to init data.
2017:03:13 15:09:05	loading preprocessed files.
2017:03:13 15:09:12	the sample size is 97314, the vocab size is 18739
2017:03:13 15:09:18	restore checkpoint_file from path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0
2017:03:13 15:09:19	generate sentence and write to path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints
2017:03:13 15:09:23	use DataLoaderChildrenStory to init data.
2017:03:13 15:09:23	loading preprocessed files.
2017:03:13 15:09:30	the sample size is 97314, the vocab size is 18739
2017:03:13 15:09:36	restore checkpoint_file from path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0
2017:03:13 15:09:37	generate sentence and write to path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints
2017:03:13 15:53:32	use DataLoaderChildrenStory to init data.
2017:03:13 15:53:32	loading preprocessed files.
2017:03:13 15:53:40	the sample size is 97314, the vocab size is 18739
2017:03:13 15:53:46	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489420426

2017:03:13 15:54:33	use DataLoaderChildrenStory to init data.
2017:03:13 15:54:33	loading preprocessed files.
2017:03:13 15:54:40	the sample size is 97314, the vocab size is 18739
2017:03:13 15:54:47	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489420487

2017:03:13 15:54:50	------ do the pretrain ------ 

2017:03:13 15:54:50	pretrain epoch 0
2017:03:13 16:13:18	use DataLoaderChildrenStory to init data.
2017:03:13 16:13:18	loading preprocessed files.
2017:03:13 16:13:25	the sample size is 97314, the vocab size is 18739
2017:03:13 16:14:08	use DataLoaderChildrenStory to init data.
2017:03:13 16:14:08	loading preprocessed files.
2017:03:13 16:14:16	the sample size is 97314, the vocab size is 18739
2017:03:13 16:14:36	use DataLoaderChildrenStory to init data.
2017:03:13 16:14:36	loading preprocessed files.
2017:03:13 16:14:44	the sample size is 97314, the vocab size is 18739
2017:03:13 16:16:23	use DataLoaderChildrenStory to init data.
2017:03:13 16:16:23	loading preprocessed files.
2017:03:13 16:16:30	the sample size is 97314, the vocab size is 18739
2017:03:13 16:16:44	use DataLoaderChildrenStory to init data.
2017:03:13 16:16:44	loading preprocessed files.
2017:03:13 16:16:51	the sample size is 97314, the vocab size is 18739
2017:03:13 16:17:13	use DataLoaderChildrenStory to init data.
2017:03:13 16:17:13	loading preprocessed files.
2017:03:13 16:17:20	the sample size is 97314, the vocab size is 18739
2017:03:13 16:20:50	use DataLoaderChildrenStory to init data.
2017:03:13 16:20:50	loading preprocessed files.
2017:03:13 16:20:57	the sample size is 97314, the vocab size is 18739
2017:03:13 16:21:24	use DataLoaderChildrenStory to init data.
2017:03:13 16:21:24	loading preprocessed files.
2017:03:13 16:21:31	the sample size is 97314, the vocab size is 18739
2017:03:13 16:21:49	use DataLoaderChildrenStory to init data.
2017:03:13 16:21:49	loading preprocessed files.
2017:03:13 16:21:56	the sample size is 97314, the vocab size is 18739
2017:03:13 16:23:14	use DataLoaderChildrenStory to init data.
2017:03:13 16:23:14	loading preprocessed files.
2017:03:13 16:23:21	the sample size is 97314, the vocab size is 18739
2017:03:13 16:29:59	use DataLoaderChildrenStory to init data.
2017:03:13 16:29:59	loading preprocessed files.
2017:03:13 16:30:07	the sample size is 97314, the vocab size is 18739
2017:03:13 16:34:17	use DataLoaderChildrenStory to init data.
2017:03:13 16:34:17	loading preprocessed files.
2017:03:13 16:34:25	the sample size is 97314, the vocab size is 18739
2017:03:13 16:34:31	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489422871

2017:03:13 16:34:35	------ do the pretrain ------ 

2017:03:13 16:34:35	pretrain epoch 0
2017:03:13 16:35:53	use DataLoaderChildrenStory to init data.
2017:03:13 16:35:53	loading preprocessed files.
2017:03:13 16:36:01	the sample size is 97314, the vocab size is 18739
2017:03:13 16:38:09	use DataLoaderChildrenStory to init data.
2017:03:13 16:38:09	loading preprocessed files.
2017:03:13 16:38:16	the sample size is 97314, the vocab size is 18739
2017:03:13 16:38:30	use DataLoaderChildrenStory to init data.
2017:03:13 16:38:30	loading preprocessed files.
2017:03:13 16:38:37	the sample size is 97314, the vocab size is 18739
2017:03:13 16:38:43	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489423123

2017:03:13 16:38:46	------ do the pretrain ------ 

2017:03:13 16:38:46	pretrain epoch 0
2017:03:13 16:39:26	use DataLoaderChildrenStory to init data.
2017:03:13 16:39:26	loading preprocessed files.
2017:03:13 16:39:33	the sample size is 97314, the vocab size is 18739
2017:03:13 16:40:34	use DataLoaderChildrenStory to init data.
2017:03:13 16:40:34	loading preprocessed files.
2017:03:13 16:40:41	the sample size is 97314, the vocab size is 18739
2017:03:13 16:56:10	use DataLoaderChildrenStory to init data.
2017:03:13 16:56:10	loading preprocessed files.
2017:03:13 16:56:17	the sample size is 97314, the vocab size is 18739
2017:03:13 16:56:43	use DataLoaderChildrenStory to init data.
2017:03:13 16:56:43	loading preprocessed files.
2017:03:13 16:56:50	the sample size is 97314, the vocab size is 18739
2017:03:13 16:56:59	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424219

2017:03:13 16:58:58	use DataLoaderChildrenStory to init data.
2017:03:13 16:58:58	loading preprocessed files.
2017:03:13 16:59:06	the sample size is 97314, the vocab size is 18739
2017:03:13 16:59:31	use DataLoaderChildrenStory to init data.
2017:03:13 16:59:31	loading preprocessed files.
2017:03:13 16:59:38	the sample size is 97314, the vocab size is 18739
2017:03:13 16:59:56	use DataLoaderChildrenStory to init data.
2017:03:13 16:59:56	loading preprocessed files.
2017:03:13 17:00:03	the sample size is 97314, the vocab size is 18739
2017:03:13 17:01:12	use DataLoaderChildrenStory to init data.
2017:03:13 17:01:12	loading preprocessed files.
2017:03:13 17:01:19	the sample size is 97314, the vocab size is 18739
2017:03:13 17:02:25	use DataLoaderChildrenStory to init data.
2017:03:13 17:02:25	loading preprocessed files.
2017:03:13 17:02:32	the sample size is 97314, the vocab size is 18739
2017:03:13 17:04:50	use DataLoaderChildrenStory to init data.
2017:03:13 17:04:50	loading preprocessed files.
2017:03:13 17:04:57	the sample size is 97314, the vocab size is 18739
2017:03:13 17:05:08	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424707

2017:03:13 17:05:13	------ do the pretrain ------ 

2017:03:13 17:05:39	use DataLoaderChildrenStory to init data.
2017:03:13 17:05:39	loading preprocessed files.
2017:03:13 17:05:46	the sample size is 97314, the vocab size is 18739
2017:03:13 17:05:56	use DataLoaderChildrenStory to init data.
2017:03:13 17:05:56	loading preprocessed files.
2017:03:13 17:06:03	the sample size is 97314, the vocab size is 18739
2017:03:13 17:06:14	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424774

2017:03:13 17:07:25	use DataLoaderChildrenStory to init data.
2017:03:13 17:07:25	loading preprocessed files.
2017:03:13 17:07:32	the sample size is 97314, the vocab size is 18739
2017:03:13 17:07:44	use DataLoaderChildrenStory to init data.
2017:03:13 17:07:44	loading preprocessed files.
2017:03:13 17:07:51	the sample size is 97314, the vocab size is 18739
2017:03:13 17:08:01	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424881

2017:03:13 17:08:06	------ do the pretrain ------ 

2017:03:13 17:08:08	save bestmodel:1.

2017:03:13 17:08:08	------ do the standard GAN training ------ 

2017:03:13 17:08:08	total execution time: 23
2017:03:13 18:18:23	use DataLoaderChildrenStory to init data.
2017:03:13 18:18:23	loading preprocessed files.
2017:03:13 18:18:29	the sample size is 97314, the vocab size is 18739
2017:03:13 18:22:18	use DataLoaderChildrenStory to init data.
2017:03:13 18:22:18	loading preprocessed files.
2017:03:13 18:22:24	the sample size is 97314, the vocab size is 18739
2017:03:13 18:37:52	use DataLoaderChildrenStory to init data.
2017:03:13 18:37:52	loading preprocessed files.
2017:03:13 18:37:59	the sample size is 97314, the vocab size is 18739
2017:03:13 18:39:38	use DataLoaderChildrenStory to init data.
2017:03:13 18:39:38	loading preprocessed files.
2017:03:13 18:39:45	the sample size is 97314, the vocab size is 18739
2017:03:13 18:40:12	use DataLoaderChildrenStory to init data.
2017:03:13 18:40:12	loading preprocessed files.
2017:03:13 18:40:19	the sample size is 97314, the vocab size is 18739
2017:03:13 18:42:15	use DataLoaderChildrenStory to init data.
2017:03:13 18:42:15	loading preprocessed files.
2017:03:13 18:42:22	the sample size is 97314, the vocab size is 18739
2017:03:13 18:42:27	use DataLoaderChildrenStory to init data.
2017:03:13 18:42:27	loading preprocessed files.
2017:03:13 18:42:36	the sample size is 97314, the vocab size is 18739
2017:03:13 18:42:46	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489430566

2017:03:13 18:42:51	------ do the pretrain ------ 

2017:03:13 18:42:51	pretrain epoch 0
2017:03:13 18:42:59	use DataLoaderChildrenStory to init data.
2017:03:13 18:42:59	loading preprocessed files.
2017:03:13 18:43:06	the sample size is 97314, the vocab size is 18739
2017:03:13 18:45:09	use DataLoaderChildrenStory to init data.
2017:03:13 18:45:09	loading preprocessed files.
2017:03:13 18:45:16	the sample size is 97314, the vocab size is 18739
2017:03:13 18:46:43	use DataLoaderChildrenStory to init data.
2017:03:13 18:46:43	loading preprocessed files.
2017:03:13 18:46:50	the sample size is 97314, the vocab size is 18739
2017:03:13 18:47:02	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV2.TextGANV2/1489430822

2017:03:13 18:47:07	------ do the pretrain ------ 

2017:03:13 18:47:07	pretrain epoch 0
2017:03:13 18:47:19	use DataLoaderChildrenStory to init data.
2017:03:13 18:47:19	loading preprocessed files.
2017:03:13 18:47:26	the sample size is 97314, the vocab size is 18739
2017:03:13 18:47:36	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489430856

2017:03:13 18:47:41	------ do the pretrain ------ 

2017:03:13 18:47:41	pretrain epoch 0
2017:03:13 18:47:52	use DataLoaderChildrenStory to init data.
2017:03:13 18:47:52	loading preprocessed files.
2017:03:13 18:47:59	the sample size is 97314, the vocab size is 18739
2017:03:13 18:48:26	use DataLoaderChildrenStory to init data.
2017:03:13 18:48:26	loading preprocessed files.
2017:03:13 18:48:33	the sample size is 97314, the vocab size is 18739
2017:03:13 18:48:39	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489430919

2017:03:13 18:48:43	------ do the pretrain ------ 

2017:03:13 18:48:43	pretrain epoch 0
2017:03:13 22:46:06	use DataLoaderChildrenStory to init data.
2017:03:13 22:46:06	loading preprocessed files.
2017:03:13 22:46:14	the sample size is 97314, the vocab size is 18739
2017:03:13 22:47:29	use DataLoaderChildrenStory to init data.
2017:03:13 22:47:29	loading preprocessed files.
2017:03:13 22:47:36	the sample size is 97314, the vocab size is 18739
2017:03:13 22:48:15	use DataLoaderChildrenStory to init data.
2017:03:13 22:48:15	loading preprocessed files.
2017:03:13 22:48:22	the sample size is 97314, the vocab size is 18739
2017:03:13 22:48:36	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV3.TextGANV3/1489445316

2017:03:13 22:48:42	------ do the pretrain ------ 

2017:03:13 22:48:42	pretrain epoch 0
2017:03:13 22:57:20	use DataLoaderChildrenStory to init data.
2017:03:13 22:57:20	loading preprocessed files.
2017:03:13 22:57:27	the sample size is 97314, the vocab size is 18739
2017:03:13 22:57:33	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489445853

2017:03:13 22:57:37	------ do the pretrain ------ 

2017:03:13 22:57:37	pretrain epoch 0
2017:03:13 23:03:25	use DataLoaderChildrenStory to init data.
2017:03:13 23:03:25	loading preprocessed files.
2017:03:13 23:03:32	the sample size is 97314, the vocab size is 18739
2017:03:13 23:03:44	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489446224

2017:03:13 23:03:49	------ do the pretrain ------ 

2017:03:13 23:03:49	pretrain epoch 0
2017:03:13 23:06:38	use DataLoaderChildrenStory to init data.
2017:03:13 23:06:38	loading preprocessed files.
2017:03:13 23:06:46	the sample size is 97314, the vocab size is 18739
2017:03:13 23:06:59	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV2.TextGANV2/1489446419

2017:03:13 23:07:04	------ do the pretrain ------ 

2017:03:13 23:07:04	pretrain epoch 0
2017:03:14 00:19:28	use DataLoaderChildrenStory to init data.
2017:03:14 00:19:28	loading preprocessed files.
2017:03:14 00:19:35	the sample size is 97314, the vocab size is 18739
2017:03:14 00:20:27	use DataLoaderChildrenStory to init data.
2017:03:14 00:20:27	loading preprocessed files.
2017:03:14 00:20:34	the sample size is 97314, the vocab size is 18739
2017:03:14 00:21:26	use DataLoaderChildrenStory to init data.
2017:03:14 00:21:26	loading preprocessed files.
2017:03:14 00:21:33	the sample size is 97314, the vocab size is 18739
2017:03:14 00:22:14	use DataLoaderChildrenStory to init data.
2017:03:14 00:22:14	loading preprocessed files.
2017:03:14 00:22:21	the sample size is 97314, the vocab size is 18739
2017:03:14 00:23:13	use DataLoaderChildrenStory to init data.
2017:03:14 00:23:13	loading preprocessed files.
2017:03:14 00:23:21	the sample size is 97314, the vocab size is 18739
2017:03:14 00:24:32	use DataLoaderChildrenStory to init data.
2017:03:14 00:24:32	loading preprocessed files.
2017:03:14 00:24:39	the sample size is 97314, the vocab size is 18739
2017:03:14 00:24:50	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451090

2017:03:14 00:24:56	------ do the pretrain ------ 

2017:03:14 00:24:57	save 1-th bestmodel to path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451090/checkpoints/bestmodel.

2017:03:14 00:24:57	------ do the standard GAN training ------ 

2017:03:14 00:24:57	train epoch 0
2017:03:14 00:25:58	use DataLoaderChildrenStory to init data.
2017:03:14 00:25:58	loading preprocessed files.
2017:03:14 00:26:05	the sample size is 97314, the vocab size is 18739
2017:03:14 00:26:17	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451177

2017:03:14 00:26:23	------ do the pretrain ------ 

2017:03:14 00:26:24	save 1-th bestmodel to path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451177/checkpoints/bestmodel.

2017:03:14 00:26:24	------ do the standard GAN training ------ 

2017:03:14 00:26:24	train epoch 0
2017:03:14 00:26:44	use DataLoaderChildrenStory to init data.
2017:03:14 00:26:44	loading preprocessed files.
2017:03:14 00:26:53	the sample size is 97314, the vocab size is 18739
2017:03:14 00:27:05	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV3.TextGANV3/1489451225

2017:03:14 00:27:11	------ do the pretrain ------ 

2017:03:14 00:27:13	save 1-th bestmodel to path: /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGANV3.TextGANV3/1489451225/checkpoints/bestmodel.

2017:03:14 00:27:13	------ do the standard GAN training ------ 

2017:03:14 00:27:13	train epoch 0
2017:03:14 19:17:14	use DataLoaderChildrenStory to init data.
2017:03:14 19:17:14	loading preprocessed files.
2017:03:14 19:17:22	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:20:35	use DataLoaderChildrenStory to init data.
2017:03:14 19:20:35	loading preprocessed files.
2017:03:14 19:20:43	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:20:49	writing to /home/tlin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489519249

2017:03:14 19:20:53	------ do the pretrain ------ 

2017:03:14 19:20:53	pretrain epoch 0
2017:03:14 19:31:59	use DataLoaderChildrenStory to init data.
2017:03:14 19:31:59	loading preprocessed files.
2017:03:14 19:32:06	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:32:52	use DataLoaderChildrenStory to init data.
2017:03:14 19:32:52	loading preprocessed files.
2017:03:14 19:32:59	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:33:06	writing to /home/tlin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textGAN.TextGAN/1489519985

2017:03:14 19:33:10	------ do the pretrain ------ 

2017:03:14 19:33:10	pretrain epoch 0
2017:03:14 20:21:01	use DataLoaderChildrenStory to init data.
2017:03:14 20:21:01	loading preprocessed files.
2017:03:14 20:21:08	the number of sentence is 97314, the vocab size is 18739
2017:03:14 20:21:15	writing to /home/tlin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textGAN.TextGAN/1489522875

2017:03:14 20:21:18	------ do the pretrain ------ 

2017:03:14 20:21:18	pretrain epoch 0
2017:03:15 10:13:19	use DataLoaderChildrenStory to init data.
2017:03:15 10:13:19	loading preprocessed files.
2017:03:15 10:13:26	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:14:24	use DataLoaderChildrenStory to init data.
2017:03:15 10:14:24	loading preprocessed files.
2017:03:15 10:14:31	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:16:07	use DataLoaderChildrenStory to init data.
2017:03:15 10:16:07	loading preprocessed files.
2017:03:15 10:16:14	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:16:41	use DataLoaderChildrenStory to init data.
2017:03:15 10:16:41	loading preprocessed files.
2017:03:15 10:16:48	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:16:59	use DataLoaderChildrenStory to init data.
2017:03:15 10:16:59	loading preprocessed files.
2017:03:15 10:17:05	the number of sentence is 97314, the vocab size is 18739
2017:03:15 14:28:04	use DataLoaderChildrenStory to init data.
2017:03:15 14:28:04	loading preprocessed files.
2017:03:15 14:28:11	the number of sentence is 97314, the vocab size is 18739
2017:03:15 14:28:23	writing to /home/tlin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textGANV1.TextGANV1/1489588103

2017:03:15 14:28:29	------ do the pretrain ------ 

2017:03:15 14:28:29	pretrain epoch 0
