2017:03:02 23:33:47	reading and processing the text file
2017:03:02 23:33:58	flatmap a list of sentence list to a list of sentence.
2017:03:02 23:37:06	reading and processing the text file
2017:03:02 23:37:17	flatmap a list of sentence list to a list of sentence.
2017:03:02 23:37:35	mapping from index to word.
2017:03:02 23:37:35	mapping from word to index.
2017:03:02 23:39:30	reading and processing the text file
2017:03:02 23:39:30	preprocess the dataset.
2017:03:02 23:39:36	build a vocabulary.
2017:03:02 23:39:36	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:39:53	...mapping from index to word.
2017:03:02 23:39:53	...mapping from word to index.
2017:03:02 23:39:53	...map word to index.
2017:03:02 23:41:00	reading and processing the text file.
2017:03:02 23:41:00	preprocess the dataset.
2017:03:02 23:41:05	build a vocabulary.
2017:03:02 23:41:05	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:41:23	...mapping from index to word.
2017:03:02 23:41:23	...mapping from word to index.
2017:03:02 23:41:23	...map word to index.
2017:03:02 23:41:27	reading and processing the text file.
2017:03:02 23:41:27	preprocess the dataset.
2017:03:02 23:41:31	build a vocabulary.
2017:03:02 23:41:31	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:41:51	reading and processing the text file.
2017:03:02 23:41:51	preprocess the dataset.
2017:03:02 23:41:55	build a vocabulary.
2017:03:02 23:41:55	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:42:30	reading and processing the text file.
2017:03:02 23:42:30	preprocess the dataset.
2017:03:02 23:42:34	build a vocabulary.
2017:03:02 23:42:34	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:42:35	...mapping from index to word.
2017:03:02 23:42:35	...mapping from word to index.
2017:03:02 23:42:35	...map word to index.
2017:03:02 23:43:05	reading and processing the text file.
2017:03:02 23:43:05	preprocess the dataset.
2017:03:02 23:43:09	build a vocabulary.
2017:03:02 23:43:09	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:43:10	...mapping from index to word.
2017:03:02 23:43:10	...mapping from word to index.
2017:03:02 23:43:10	...map word to index.
2017:03:02 23:43:37	reading and processing the text file.
2017:03:02 23:43:37	preprocess the dataset.
2017:03:02 23:43:42	build a vocabulary.
2017:03:02 23:43:42	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:43:43	...mapping from index to word.
2017:03:02 23:43:43	...mapping from word to index.
2017:03:02 23:43:43	...map word to index.
2017:03:02 23:44:45	reading and processing the text file.
2017:03:02 23:44:45	preprocess the dataset.
2017:03:02 23:44:49	build a vocabulary.
2017:03:02 23:44:49	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:44:50	...mapping from index to word.
2017:03:02 23:44:50	...mapping from word to index.
2017:03:02 23:44:50	...map word to index.
2017:03:02 23:45:10	reading and processing the text file.
2017:03:02 23:45:10	preprocess the dataset.
2017:03:02 23:45:14	build a vocabulary.
2017:03:02 23:45:14	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:45:15	...mapping from index to word.
2017:03:02 23:45:15	...mapping from word to index.
2017:03:02 23:45:15	...map word to index.
2017:03:02 23:45:37	reading and processing the text file.
2017:03:02 23:45:37	preprocess the dataset.
2017:03:02 23:45:41	build a vocabulary.
2017:03:02 23:45:41	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:45:42	...mapping from index to word.
2017:03:02 23:45:42	...mapping from word to index.
2017:03:02 23:45:43	...map word to index.
2017:03:02 23:47:16	reading and processing the text file.
2017:03:02 23:47:16	preprocess the dataset.
2017:03:02 23:47:20	build a vocabulary.
2017:03:02 23:47:20	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:47:22	...mapping from index to word.
2017:03:02 23:47:22	...mapping from word to index.
2017:03:02 23:47:22	...map word to index.
2017:03:02 23:48:16	reading and processing the text file.
2017:03:02 23:48:16	preprocess the dataset.
2017:03:02 23:48:20	build a vocabulary.
2017:03:02 23:48:20	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:48:21	...mapping from index to word.
2017:03:02 23:48:22	...mapping from word to index.
2017:03:02 23:48:22	...map word to index.
2017:03:02 23:48:50	reading and processing the text file.
2017:03:02 23:48:50	preprocess the dataset.
2017:03:02 23:48:54	build a vocabulary.
2017:03:02 23:48:54	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:48:56	...mapping from index to word.
2017:03:02 23:48:56	...mapping from word to index.
2017:03:02 23:48:56	...map word to index.
2017:03:02 23:50:52	reading and processing the text file.
2017:03:02 23:50:52	preprocess the dataset.
2017:03:02 23:50:56	build a vocabulary.
2017:03:02 23:50:56	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:50:58	...mapping from index to word.
2017:03:02 23:50:58	...mapping from word to index.
2017:03:02 23:50:58	...map word to index.
2017:03:02 23:51:12	reading and processing the text file.
2017:03:02 23:51:12	preprocess the dataset.
2017:03:02 23:51:17	build a vocabulary.
2017:03:02 23:51:17	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:51:18	...mapping from index to word.
2017:03:02 23:51:18	...mapping from word to index.
2017:03:02 23:51:18	...map word to index.
2017:03:02 23:51:53	reading and processing the text file.
2017:03:02 23:51:53	preprocess the dataset.
2017:03:02 23:52:06	reading and processing the text file.
2017:03:02 23:52:06	preprocess the dataset.
2017:03:02 23:52:16	reading and processing the text file.
2017:03:02 23:52:16	preprocess the dataset.
2017:03:02 23:52:22	build a vocabulary.
2017:03:02 23:52:22	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:52:23	...mapping from index to word.
2017:03:02 23:52:23	...mapping from word to index.
2017:03:02 23:52:23	...map word to index.
2017:03:02 23:53:08	reading and processing the text file.
2017:03:02 23:53:08	preprocess the dataset.
2017:03:02 23:53:16	build a vocabulary.
2017:03:02 23:53:16	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:53:18	...mapping from index to word.
2017:03:02 23:53:18	...mapping from word to index.
2017:03:02 23:53:18	...map word to index.
2017:03:02 23:53:33	reading and processing the text file.
2017:03:02 23:53:33	preprocess the dataset.
2017:03:02 23:53:41	build a vocabulary.
2017:03:02 23:53:41	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:53:42	...mapping from index to word.
2017:03:02 23:53:42	...mapping from word to index.
2017:03:02 23:53:42	...map word to index.
2017:03:02 23:54:31	reading and processing the text file.
2017:03:02 23:54:31	preprocess the dataset.
2017:03:02 23:54:39	build a vocabulary.
2017:03:02 23:54:39	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:54:40	...mapping from index to word.
2017:03:02 23:54:40	...mapping from word to index.
2017:03:02 23:54:40	...map word to index.
2017:03:02 23:56:49	reading and processing the text file.
2017:03:02 23:56:49	preprocess the dataset.
2017:03:02 23:56:58	build a vocabulary.
2017:03:02 23:56:58	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:56:59	...mapping from index to word.
2017:03:02 23:56:59	...mapping from word to index.
2017:03:02 23:56:59	...map word to index.
2017:03:02 23:57:37	reading and processing the text file.
2017:03:02 23:57:37	preprocess the dataset.
2017:03:02 23:57:45	build a vocabulary.
2017:03:02 23:57:45	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:57:47	...mapping from index to word.
2017:03:02 23:57:47	...mapping from word to index.
2017:03:02 23:57:47	...map word to index.
2017:03:02 23:58:10	reading and processing the text file.
2017:03:02 23:58:10	preprocess the dataset.
2017:03:02 23:58:23	reading and processing the text file.
2017:03:02 23:58:23	preprocess the dataset.
2017:03:02 23:58:32	reading and processing the text file.
2017:03:02 23:58:32	preprocess the dataset.
2017:03:02 23:58:41	build a vocabulary.
2017:03:02 23:58:41	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:58:42	...mapping from index to word.
2017:03:02 23:58:42	...mapping from word to index.
2017:03:02 23:58:42	...map word to index.
2017:03:02 23:58:56	reading and processing the text file.
2017:03:02 23:58:56	preprocess the dataset.
2017:03:02 23:59:05	build a vocabulary.
2017:03:02 23:59:05	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:59:07	...mapping from index to word.
2017:03:02 23:59:07	...mapping from word to index.
2017:03:02 23:59:07	...map word to index.
2017:03:02 23:59:41	reading and processing the text file.
2017:03:02 23:59:41	preprocess the dataset.
2017:03:02 23:59:51	build a vocabulary.
2017:03:02 23:59:51	...flatmap a list of sentence list to a list of sentence.
2017:03:02 23:59:52	...mapping from index to word.
2017:03:02 23:59:53	...mapping from word to index.
2017:03:02 23:59:53	...map word to index.
2017:03:03 00:00:30	reading and processing the text file.
2017:03:03 00:00:30	preprocess the dataset.
2017:03:03 00:00:41	build a vocabulary.
2017:03:03 00:00:41	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:00:43	...mapping from index to word.
2017:03:03 00:00:43	...mapping from word to index.
2017:03:03 00:00:43	...map word to index.
2017:03:03 00:01:13	reading and processing the text file.
2017:03:03 00:01:13	preprocess the dataset.
2017:03:03 00:01:25	build a vocabulary.
2017:03:03 00:01:25	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:01:26	...mapping from index to word.
2017:03:03 00:01:26	...mapping from word to index.
2017:03:03 00:01:26	...map word to index.
2017:03:03 00:02:08	reading and processing the text file.
2017:03:03 00:02:08	preprocess the dataset.
2017:03:03 00:02:19	build a vocabulary.
2017:03:03 00:02:19	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:02:20	...mapping from index to word.
2017:03:03 00:02:20	...mapping from word to index.
2017:03:03 00:02:21	...map word to index.
2017:03:03 00:03:35	reading and processing the text file.
2017:03:03 00:03:35	preprocess the dataset.
2017:03:03 00:03:40	build a vocabulary.
2017:03:03 00:03:40	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:03:41	...mapping from index to word.
2017:03:03 00:03:41	...mapping from word to index.
2017:03:03 00:03:41	...map word to index.
2017:03:03 00:05:19	reading and processing the text file.
2017:03:03 00:05:19	preprocess the dataset.
2017:03:03 00:05:35	reading and processing the text file.
2017:03:03 00:05:35	preprocess the dataset.
2017:03:03 00:05:51	reading and processing the text file.
2017:03:03 00:05:51	preprocess the dataset.
2017:03:03 00:05:57	build a vocabulary.
2017:03:03 00:05:57	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:05:58	...mapping from index to word.
2017:03:03 00:05:58	...mapping from word to index.
2017:03:03 00:05:58	...map word to index.
2017:03:03 00:06:30	reading and processing the text file.
2017:03:03 00:06:30	preprocess the dataset.
2017:03:03 00:06:35	build a vocabulary.
2017:03:03 00:06:35	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:06:36	...mapping from index to word.
2017:03:03 00:06:36	...mapping from word to index.
2017:03:03 00:06:36	...map word to index.
2017:03:03 00:08:22	reading and processing the text file.
2017:03:03 00:08:22	preprocess the dataset.
2017:03:03 00:08:28	build a vocabulary.
2017:03:03 00:08:28	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:08:29	...mapping from index to word.
2017:03:03 00:08:29	...mapping from word to index.
2017:03:03 00:08:29	...map word to index.
2017:03:03 00:08:50	reading and processing the text file.
2017:03:03 00:08:50	preprocess the dataset.
2017:03:03 00:08:56	build a vocabulary.
2017:03:03 00:08:56	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:08:57	...mapping from index to word.
2017:03:03 00:08:57	...mapping from word to index.
2017:03:03 00:08:57	...map word to index.
2017:03:03 00:09:04	reading and processing the text file.
2017:03:03 00:09:04	preprocess the dataset.
2017:03:03 00:09:09	build a vocabulary.
2017:03:03 00:09:09	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:09:11	...mapping from index to word.
2017:03:03 00:09:11	...mapping from word to index.
2017:03:03 00:09:11	...map word to index.
2017:03:03 00:09:33	reading and processing the text file.
2017:03:03 00:09:33	preprocess the dataset.
2017:03:03 00:09:38	build a vocabulary.
2017:03:03 00:09:38	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:09:39	...mapping from index to word.
2017:03:03 00:09:39	...mapping from word to index.
2017:03:03 00:09:40	...map word to index.
2017:03:03 00:10:48	reading and processing the text file.
2017:03:03 00:10:48	preprocess the dataset.
2017:03:03 00:10:54	build a vocabulary.
2017:03:03 00:10:54	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:10:54	...mapping from index to word.
2017:03:03 00:10:54	...mapping from word to index.
2017:03:03 00:10:54	...map word to index.
2017:03:03 00:12:17	reading and processing the text file.
2017:03:03 00:12:17	preprocess the dataset.
2017:03:03 00:12:24	build a vocabulary.
2017:03:03 00:12:24	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:12:25	...mapping from index to word.
2017:03:03 00:12:25	...mapping from word to index.
2017:03:03 00:12:25	...map word to index.
2017:03:03 00:12:56	reading and processing the text file.
2017:03:03 00:12:56	preprocess the dataset.
2017:03:03 00:13:02	build a vocabulary.
2017:03:03 00:13:02	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:13:03	...mapping from index to word.
2017:03:03 00:13:03	...mapping from word to index.
2017:03:03 00:13:03	...map word to index.
2017:03:03 00:13:26	reading and processing the text file.
2017:03:03 00:13:26	preprocess the dataset.
2017:03:03 00:14:05	reading and processing the text file.
2017:03:03 00:14:05	preprocess the dataset.
2017:03:03 00:14:08	build a vocabulary.
2017:03:03 00:14:08	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:14:08	...mapping from index to word.
2017:03:03 00:14:08	...mapping from word to index.
2017:03:03 00:14:08	...map word to index.
2017:03:03 00:14:31	reading and processing the text file.
2017:03:03 00:14:31	preprocess the dataset.
2017:03:03 00:14:33	build a vocabulary.
2017:03:03 00:14:33	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:14:33	...mapping from index to word.
2017:03:03 00:14:33	...mapping from word to index.
2017:03:03 00:14:33	...map word to index.
2017:03:03 00:16:29	reading and processing the text file.
2017:03:03 00:16:29	preprocess the dataset.
2017:03:03 00:16:35	build a vocabulary.
2017:03:03 00:16:35	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:16:36	...mapping from index to word.
2017:03:03 00:16:36	...mapping from word to index.
2017:03:03 00:16:36	...map word to index.
2017:03:03 00:21:05	reading and processing the text file.
2017:03:03 00:21:05	preprocess the dataset.
2017:03:03 00:21:11	build a vocabulary.
2017:03:03 00:21:11	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:21:12	...mapping from index to word.
2017:03:03 00:21:12	...mapping from word to index.
2017:03:03 00:21:12	...map word to index.
2017:03:03 00:21:38	reading and processing the text file.
2017:03:03 00:21:38	preprocess the dataset.
2017:03:03 00:21:44	build a vocabulary.
2017:03:03 00:21:44	...flatmap a list of sentence list to a list of sentence.
2017:03:03 00:21:46	...mapping from index to word.
2017:03:03 00:21:46	...mapping from word to index.
2017:03:03 00:21:46	...map word to index.
2017:03:03 09:53:37	loading preprocessed files.
2017:03:03 09:54:07	loading preprocessed files.
2017:03:03 09:54:56	loading preprocessed files.
2017:03:03 09:55:36	loading preprocessed files.
2017:03:03 09:59:26	reading and processing the text file.
2017:03:03 09:59:26	preprocess the dataset.
2017:03:03 09:59:34	build a vocabulary.
2017:03:03 09:59:34	...flatmap a list of sentence list to a list of sentence.
2017:03:03 09:59:39	...mapping from index to word.
2017:03:03 09:59:39	...mapping from word to index.
2017:03:03 09:59:39	...map word to index.
2017:03:03 10:02:52	reading and processing the text file.
2017:03:03 10:02:52	preprocess the dataset.
2017:03:03 10:02:58	build a vocabulary.
2017:03:03 10:02:58	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:03:02	...mapping from index to word.
2017:03:03 10:03:02	...mapping from word to index.
2017:03:03 10:03:02	...map word to index.
2017:03:03 10:07:36	reading and processing the text file.
2017:03:03 10:07:36	preprocess the dataset.
2017:03:03 10:07:41	build a vocabulary.
2017:03:03 10:07:41	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:07:45	...mapping from index to word.
2017:03:03 10:07:45	...mapping from word to index.
2017:03:03 10:07:45	...map word to index.
2017:03:03 10:10:24	reading and processing the text file.
2017:03:03 10:10:24	preprocess the dataset.
2017:03:03 10:10:30	build a vocabulary.
2017:03:03 10:10:30	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:10:34	...mapping from index to word.
2017:03:03 10:10:34	...mapping from word to index.
2017:03:03 10:10:34	...map word to index.
2017:03:03 10:12:18	reading and processing the text file.
2017:03:03 10:12:18	preprocess the dataset.
2017:03:03 10:12:24	build a vocabulary.
2017:03:03 10:12:24	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:12:29	...mapping from index to word.
2017:03:03 10:12:29	...mapping from word to index.
2017:03:03 10:12:29	...map word to index.
2017:03:03 10:13:56	reading and processing the text file.
2017:03:03 10:13:56	preprocess the dataset.
2017:03:03 10:14:04	build a vocabulary.
2017:03:03 10:14:04	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:14:09	...mapping from index to word.
2017:03:03 10:14:09	...mapping from word to index.
2017:03:03 10:14:09	...map word to index.
2017:03:03 10:15:59	reading and processing the text file.
2017:03:03 10:15:59	preprocess the dataset.
2017:03:03 10:16:06	build a vocabulary.
2017:03:03 10:16:06	...flatmap a list of sentence list to a list of sentence.
2017:03:03 10:16:11	...mapping from index to word.
2017:03:03 10:16:11	...mapping from word to index.
2017:03:03 10:16:11	...map word to index.
2017:03:03 11:05:37	reading and processing the text file.
2017:03:03 11:05:37	preprocess the dataset.
2017:03:03 11:05:45	build a vocabulary.
2017:03:03 11:05:45	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:05:50	...mapping from index to word.
2017:03:03 11:05:50	...mapping from word to index.
2017:03:03 11:05:50	...map word to index.
2017:03:03 11:06:51	the vocabulary size is 40
2017:03:03 11:09:54	reading and processing the text file.
2017:03:03 11:09:54	preprocess the dataset.
2017:03:03 11:10:01	build a vocabulary.
2017:03:03 11:10:01	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:10:05	...mapping from index to word.
2017:03:03 11:10:05	...mapping from word to index.
2017:03:03 11:10:05	...map word to index.
2017:03:03 11:11:37	reading and processing the text file.
2017:03:03 11:11:37	preprocess the dataset.
2017:03:03 11:11:43	build a vocabulary.
2017:03:03 11:11:43	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:11:44	...mapping from index to word.
2017:03:03 11:11:44	...mapping from word to index.
2017:03:03 11:11:44	...map word to index.
2017:03:03 11:12:05	reading and processing the text file.
2017:03:03 11:12:05	preprocess the dataset.
2017:03:03 11:12:10	build a vocabulary.
2017:03:03 11:12:10	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:12:11	...mapping from index to word.
2017:03:03 11:12:11	...mapping from word to index.
2017:03:03 11:12:11	...map word to index.
2017:03:03 11:12:58	reading and processing the text file.
2017:03:03 11:12:58	preprocess the dataset.
2017:03:03 11:13:05	build a vocabulary.
2017:03:03 11:13:05	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:13:06	...mapping from index to word.
2017:03:03 11:13:06	...mapping from word to index.
2017:03:03 11:13:06	...map word to index.
2017:03:03 11:13:23	reading and processing the text file.
2017:03:03 11:13:23	preprocess the dataset.
2017:03:03 11:13:30	build a vocabulary.
2017:03:03 11:13:30	...flatmap a list of sentence list to a list of sentence.
2017:03:03 11:13:31	...mapping from index to word.
2017:03:03 11:13:32	...mapping from word to index.
2017:03:03 11:13:32	...map word to index.
2017:03:03 11:14:41	the vocabulary size is 29264
2017:03:03 13:49:46	loading preprocessed files.
2017:03:03 13:50:37	the vocabulary size is 29264.
2017:03:03 14:02:25	loading preprocessed files.
2017:03:03 14:07:19	reading and processing the text file.
2017:03:03 14:07:19	preprocess the dataset.
2017:03:03 14:07:24	build a vocabulary.
2017:03:03 14:07:24	...flatmap a list of sentence list to a list of sentence.
2017:03:03 14:07:25	...mapping from index to word.
2017:03:03 14:07:26	...mapping from word to index.
2017:03:03 14:07:26	...map word to index.
2017:03:03 14:13:54	reading and processing the text file.
2017:03:03 14:13:54	preprocess the dataset.
2017:03:03 14:14:00	build a vocabulary.
2017:03:03 14:14:00	...flatmap a list of sentence list to a list of sentence.
2017:03:03 14:14:02	...mapping from index to word.
2017:03:03 14:14:02	...mapping from word to index.
2017:03:03 14:14:02	...map word to index.
2017:03:03 14:15:07	the vocabulary size is 29264.
2017:03:03 14:25:50	reading and processing the text file.
2017:03:03 14:25:50	preprocess the dataset.
2017:03:03 14:26:25	reading and processing the text file.
2017:03:03 14:26:25	preprocess the dataset.
2017:03:03 14:33:12	reading and processing the text file.
2017:03:03 14:33:12	preprocess the dataset and extract the valid content.
2017:03:03 14:34:33	reading and processing the text file.
2017:03:03 14:34:33	preprocess the dataset and extract the valid content.
2017:03:03 14:34:33	init data from the raw dataset.
2017:03:03 14:36:19	reading and processing the text file.
2017:03:03 14:36:19	preprocess the dataset and extract the valid content.
2017:03:03 14:36:19	init data from the raw dataset.
2017:03:03 14:36:44	...Parse the emails into a list email objects
2017:03:03 14:38:10	...Get fields from parsed email objects
2017:03:03 14:38:31	...Parse content from emails
2017:03:03 14:38:34	...Split multiple email addresses
2017:03:03 14:38:41	...Extract the root of 'file' as 'user'
2017:03:03 14:38:42	extract content from email data frame.
2017:03:03 14:39:14	reading and processing the text file.
2017:03:03 14:39:14	preprocess the dataset and extract the valid content.
2017:03:03 14:39:49	reading and processing the text file.
2017:03:03 14:39:49	preprocess the dataset and extract the valid content.
2017:03:03 14:40:00	reading and processing the text file.
2017:03:03 14:40:00	preprocess the dataset and extract the valid content.
2017:03:03 14:40:00	init data from the raw dataset.
2017:03:03 14:40:24	...Parse the emails into a list email objects
2017:03:03 14:41:44	...Get fields from parsed email objects
2017:03:03 14:42:03	...Parse content from emails
2017:03:03 14:42:05	...Split multiple email addresses
2017:03:03 14:42:10	...Extract the root of 'file' as 'user'
2017:03:03 14:42:11	extract content from email data frame.
2017:03:03 14:45:37	reading and processing the text file.
2017:03:03 14:45:37	preprocess the dataset and extract the valid content.
2017:03:03 14:45:37	init data from the raw dataset.
2017:03:03 14:46:01	...Parse the emails into a list email objects
2017:03:03 14:47:22	...Get fields from parsed email objects
2017:03:03 14:47:42	...Parse content from emails
2017:03:03 14:47:44	...Split multiple email addresses
2017:03:03 14:47:49	...Extract the root of 'file' as 'user'
2017:03:03 14:47:50	extract content from email data frame.
2017:03:03 14:49:06	reading and processing the text file.
2017:03:03 14:49:06	preprocess the dataset and extract the valid content.
2017:03:03 14:49:47	reading and processing the text file.
2017:03:03 14:49:47	preprocess the dataset and extract the valid content.
2017:03:03 14:49:47	init data from the raw dataset.
2017:03:03 14:50:11	...Parse the emails into a list email objects
2017:03:03 14:51:34	...Get fields from parsed email objects
2017:03:03 14:51:54	...Parse content from emails
2017:03:03 14:51:57	...Split multiple email addresses
2017:03:03 14:52:01	...Extract the root of 'file' as 'user'
2017:03:03 14:52:03	extract content from email data frame.
2017:03:03 15:07:09	reading and processing the text file.
2017:03:03 15:07:09	preprocess the dataset and extract the valid content.
2017:03:03 15:07:09	init data from the raw dataset.
2017:03:03 15:08:27	reading and processing the text file.
2017:03:03 15:08:27	preprocess the dataset and extract the valid content.
2017:03:03 15:08:27	init data from the raw dataset.
2017:03:03 15:09:43	reading and processing the text file.
2017:03:03 15:09:43	preprocess the dataset and extract the valid content.
2017:03:03 15:10:11	reading and processing the text file.
2017:03:03 15:10:11	preprocess the dataset and extract the valid content.
2017:03:03 15:10:11	init data from the raw dataset.
2017:03:03 15:10:43	reading and processing the text file.
2017:03:03 15:10:43	preprocess the dataset and extract the valid content.
2017:03:03 15:11:59	reading and processing the text file.
2017:03:03 15:11:59	preprocess the dataset and extract the valid content.
2017:03:03 15:11:59	init data from the raw dataset.
2017:03:03 15:13:17	reading and processing the text file.
2017:03:03 15:13:17	preprocess the dataset and extract the valid content.
2017:03:03 15:13:29	reading and processing the text file.
2017:03:03 15:13:29	preprocess the dataset and extract the valid content.
2017:03:03 15:13:29	init data from the raw dataset.
2017:03:03 15:14:56	reading and processing the text file.
2017:03:03 15:14:56	preprocess the dataset and extract the valid content.
2017:03:03 15:15:05	reading and processing the text file.
2017:03:03 15:15:05	preprocess the dataset and extract the valid content.
2017:03:03 15:15:05	init data from the raw dataset.
2017:03:03 15:16:57	reading and processing the text file.
2017:03:03 15:16:57	preprocess the dataset and extract the valid content.
2017:03:03 15:17:07	reading and processing the text file.
2017:03:03 15:17:07	preprocess the dataset and extract the valid content.
2017:03:03 15:17:07	init data from the raw dataset.
2017:03:03 15:17:22	reading and processing the text file.
2017:03:03 15:17:22	preprocess the dataset and extract the valid content.
2017:03:03 15:17:30	reading and processing the text file.
2017:03:03 15:17:30	preprocess the dataset and extract the valid content.
2017:03:03 15:17:30	init data from the raw dataset.
2017:03:03 15:19:05	reading and processing the text file.
2017:03:03 15:19:05	preprocess the dataset and extract the valid content.
2017:03:03 15:19:13	reading and processing the text file.
2017:03:03 15:19:13	preprocess the dataset and extract the valid content.
2017:03:03 15:19:13	init data from the raw dataset.
2017:03:03 15:19:54	reading and processing the text file.
2017:03:03 15:19:54	preprocess the dataset and extract the valid content.
2017:03:03 15:19:54	init data from the raw dataset.
2017:03:03 15:22:10	reading and processing the text file.
2017:03:03 15:22:10	preprocess the dataset and extract the valid content.
2017:03:03 15:22:10	...load data.
2017:03:03 15:22:10	...clean data.
2017:03:03 15:22:20	reading and processing the text file.
2017:03:03 15:22:20	preprocess the dataset and extract the valid content.
2017:03:03 15:22:20	...load data.
2017:03:03 15:22:20	...clean data.
2017:03:03 15:22:39	reading and processing the text file.
2017:03:03 15:22:39	preprocess the dataset and extract the valid content.
2017:03:03 15:22:39	...load data.
2017:03:03 15:22:39	...clean data.
2017:03:03 15:23:45	reading and processing the text file.
2017:03:03 15:23:45	preprocess the dataset and extract the valid content.
2017:03:03 15:23:45	...load data.
2017:03:03 15:23:45	...clean data.
2017:03:03 15:24:59	reading and processing the text file.
2017:03:03 15:24:59	preprocess the dataset and extract the valid content.
2017:03:03 15:24:59	...load data.
2017:03:03 15:24:59	...clean data.
2017:03:03 15:25:10	reading and processing the text file.
2017:03:03 15:25:10	preprocess the dataset and extract the valid content.
2017:03:03 15:25:10	...load data.
2017:03:03 15:25:10	...clean data.
2017:03:03 15:25:26	reading and processing the text file.
2017:03:03 15:25:26	preprocess the dataset and extract the valid content.
2017:03:03 15:25:26	...load data.
2017:03:03 15:25:26	...clean data.
2017:03:03 15:25:49	reading and processing the text file.
2017:03:03 15:25:49	preprocess the dataset and extract the valid content.
2017:03:03 15:25:49	...load data.
2017:03:03 15:25:49	...clean data.
2017:03:03 15:26:41	reading and processing the text file.
2017:03:03 15:26:41	preprocess the dataset and extract the valid content.
2017:03:03 15:26:41	...load data.
2017:03:03 15:26:41	...clean data.
2017:03:03 15:27:15	reading and processing the text file.
2017:03:03 15:27:15	preprocess the dataset and extract the valid content.
2017:03:03 15:27:15	...load data.
2017:03:03 15:27:15	...clean data.
2017:03:03 15:27:39	reading and processing the text file.
2017:03:03 15:27:39	preprocess the dataset and extract the valid content.
2017:03:03 15:27:39	...load data.
2017:03:03 15:27:39	...clean data.
2017:03:03 15:29:06	reading and processing the text file.
2017:03:03 15:29:06	preprocess the dataset and extract the valid content.
2017:03:03 15:29:06	...load data.
2017:03:03 15:29:06	...clean data.
2017:03:03 15:30:18	reading and processing the text file.
2017:03:03 15:30:18	preprocess the dataset and extract the valid content.
2017:03:03 15:30:18	...load data.
2017:03:03 15:30:18	...clean data.
2017:03:03 15:33:23	reading and processing the text file.
2017:03:03 15:33:23	preprocess the dataset and extract the valid content.
2017:03:03 15:33:23	...load data.
2017:03:03 15:33:23	...clean data.
2017:03:03 15:34:20	reading and processing the text file.
2017:03:03 15:34:20	preprocess the dataset and extract the valid content.
2017:03:03 15:34:20	...load data.
2017:03:03 15:34:20	...clean data.
2017:03:03 15:34:25	reading and processing the text file.
2017:03:03 15:34:25	preprocess the dataset and extract the valid content.
2017:03:03 15:34:25	...load data.
2017:03:03 15:34:25	...clean data.
2017:03:03 15:35:45	reading and processing the text file.
2017:03:03 15:35:45	preprocess the dataset and extract the valid content.
2017:03:03 15:35:45	...load data.
2017:03:03 15:35:45	...clean data.
2017:03:03 15:36:06	reading and processing the text file.
2017:03:03 15:36:06	preprocess the dataset and extract the valid content.
2017:03:03 15:36:06	...load data.
2017:03:03 15:36:06	...clean data.
2017:03:03 15:36:20	reading and processing the text file.
2017:03:03 15:36:20	preprocess the dataset and extract the valid content.
2017:03:03 15:36:20	...load data.
2017:03:03 15:36:20	...clean data.
2017:03:03 15:36:37	reading and processing the text file.
2017:03:03 15:36:37	preprocess the dataset and extract the valid content.
2017:03:03 15:36:37	...load data.
2017:03:03 15:36:37	...clean data.
2017:03:03 15:37:12	reading and processing the text file.
2017:03:03 15:37:12	preprocess the dataset and extract the valid content.
2017:03:03 15:37:12	...load data.
2017:03:03 15:37:12	...clean data.
2017:03:03 15:37:28	reading and processing the text file.
2017:03:03 15:37:28	preprocess the dataset and extract the valid content.
2017:03:03 15:37:28	...load data.
2017:03:03 15:37:28	...clean data.
2017:03:03 15:38:08	reading and processing the text file.
2017:03:03 15:38:08	preprocess the dataset and extract the valid content.
2017:03:03 15:38:08	...load data.
2017:03:03 15:38:08	...clean data.
2017:03:03 15:38:39	reading and processing the text file.
2017:03:03 15:38:39	preprocess the dataset and extract the valid content.
2017:03:03 15:38:39	...load data.
2017:03:03 15:38:39	...clean data.
2017:03:03 15:38:54	reading and processing the text file.
2017:03:03 15:38:54	preprocess the dataset and extract the valid content.
2017:03:03 15:38:54	...load data.
2017:03:03 15:38:54	...clean data.
2017:03:03 15:39:09	reading and processing the text file.
2017:03:03 15:39:09	preprocess the dataset and extract the valid content.
2017:03:03 15:39:09	...load data.
2017:03:03 15:39:09	...clean data.
2017:03:03 15:39:32	reading and processing the text file.
2017:03:03 15:39:32	preprocess the dataset and extract the valid content.
2017:03:03 15:39:32	...load data.
2017:03:03 15:39:32	...clean data.
2017:03:03 15:40:03	reading and processing the text file.
2017:03:03 15:40:03	preprocess the dataset and extract the valid content.
2017:03:03 15:40:03	...load data.
2017:03:03 15:40:03	...clean data.
2017:03:03 15:41:35	reading and processing the text file.
2017:03:03 15:41:35	preprocess the dataset and extract the valid content.
2017:03:03 15:41:35	...load data.
2017:03:03 15:41:35	...clean data.
2017:03:03 15:41:54	reading and processing the text file.
2017:03:03 15:41:54	preprocess the dataset and extract the valid content.
2017:03:03 15:41:54	...load data.
2017:03:03 15:41:54	...clean data.
2017:03:03 15:42:16	reading and processing the text file.
2017:03:03 15:42:16	preprocess the dataset and extract the valid content.
2017:03:03 15:42:16	...load data.
2017:03:03 15:42:16	...clean data.
2017:03:03 15:42:51	reading and processing the text file.
2017:03:03 15:42:51	preprocess the dataset and extract the valid content.
2017:03:03 15:42:51	...load data.
2017:03:03 15:42:51	...clean data.
2017:03:03 15:44:22	reading and processing the text file.
2017:03:03 15:44:22	preprocess the dataset and extract the valid content.
2017:03:03 15:44:22	...load data.
2017:03:03 15:44:22	...clean data.
2017:03:03 15:44:45	reading and processing the text file.
2017:03:03 15:44:45	preprocess the dataset and extract the valid content.
2017:03:03 15:44:45	...load data.
2017:03:03 15:44:45	...clean data.
2017:03:03 15:45:46	reading and processing the text file.
2017:03:03 15:45:46	preprocess the dataset and extract the valid content.
2017:03:03 15:45:46	...load data.
2017:03:03 15:45:46	...clean data.
2017:03:03 15:45:53	reading and processing the text file.
2017:03:03 15:45:53	preprocess the dataset and extract the valid content.
2017:03:03 15:45:53	...load data.
2017:03:03 15:45:53	...clean data.
2017:03:03 15:46:54	reading and processing the text file.
2017:03:03 15:46:54	preprocess the dataset and extract the valid content.
2017:03:03 15:46:54	...load data.
2017:03:03 15:46:54	...clean data.
2017:03:03 15:47:38	reading and processing the text file.
2017:03:03 15:47:38	preprocess the dataset and extract the valid content.
2017:03:03 15:47:38	...load data.
2017:03:03 15:47:38	...clean data.
2017:03:03 15:47:54	reading and processing the text file.
2017:03:03 15:47:54	preprocess the dataset and extract the valid content.
2017:03:03 15:47:54	...load data.
2017:03:03 15:47:54	...clean data.
2017:03:03 15:48:02	reading and processing the text file.
2017:03:03 15:48:02	preprocess the dataset and extract the valid content.
2017:03:03 15:48:02	...load data.
2017:03:03 15:48:02	...clean data.
2017:03:03 15:48:59	reading and processing the text file.
2017:03:03 15:48:59	preprocess the dataset and extract the valid content.
2017:03:03 15:48:59	...load data.
2017:03:03 15:48:59	...clean data.
2017:03:03 15:50:26	reading and processing the text file.
2017:03:03 15:50:26	preprocess the dataset and extract the valid content.
2017:03:03 15:50:26	...load data.
2017:03:03 15:50:26	...clean data.
2017:03:03 15:51:11	reading and processing the text file.
2017:03:03 15:51:11	preprocess the dataset and extract the valid content.
2017:03:03 15:51:11	...load data.
2017:03:03 15:51:11	...clean data.
2017:03:03 15:51:12	build a vocabulary.
2017:03:03 15:51:12	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:51:14	...mapping from index to word.
2017:03:03 15:51:14	...mapping from word to index.
2017:03:03 15:51:14	...map word to index.
2017:03:03 15:51:14	the vocabulary size is 62.
2017:03:03 15:51:52	reading and processing the text file.
2017:03:03 15:51:52	preprocess the dataset and extract the valid content.
2017:03:03 15:51:52	...load data.
2017:03:03 15:51:52	...clean data.
2017:03:03 15:51:53	build a vocabulary.
2017:03:03 15:51:53	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:51:54	...mapping from index to word.
2017:03:03 15:51:54	...mapping from word to index.
2017:03:03 15:51:54	...map word to index.
2017:03:03 15:51:54	the vocabulary size is 62.
2017:03:03 15:53:14	reading and processing the text file.
2017:03:03 15:53:14	preprocess the dataset and extract the valid content.
2017:03:03 15:53:14	...load data.
2017:03:03 15:53:14	...clean data.
2017:03:03 15:54:32	reading and processing the text file.
2017:03:03 15:54:32	preprocess the dataset and extract the valid content.
2017:03:03 15:54:32	...load data.
2017:03:03 15:54:32	...clean data.
2017:03:03 15:54:33	build a vocabulary.
2017:03:03 15:54:33	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:54:33	...mapping from index to word.
2017:03:03 15:54:33	...mapping from word to index.
2017:03:03 15:54:33	...map word to index.
2017:03:03 15:54:33	the vocabulary size is 34472.
2017:03:03 15:56:56	reading and processing the text file.
2017:03:03 15:56:56	preprocess the dataset.
2017:03:03 15:57:01	build a vocabulary.
2017:03:03 15:57:01	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:57:02	...mapping from index to word.
2017:03:03 15:57:02	...mapping from word to index.
2017:03:03 15:57:02	...map word to index.
2017:03:03 15:57:12	reading and processing the text file.
2017:03:03 15:57:12	preprocess the dataset.
2017:03:03 15:57:17	build a vocabulary.
2017:03:03 15:57:17	...flatmap a list of sentence list to a list of sentence.
2017:03:03 15:57:18	...mapping from index to word.
2017:03:03 15:57:18	...mapping from word to index.
2017:03:03 15:57:18	...map word to index.
2017:03:03 15:58:10	the vocabulary size is 29265.
2017:03:03 16:00:13	reading and processing the text file.
2017:03:03 16:00:13	preprocess the dataset and extract the valid content.
2017:03:03 16:00:13	...load data.
2017:03:03 16:00:13	...clean data.
2017:03:03 16:00:13	build a vocabulary.
2017:03:03 16:00:13	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:00:14	...mapping from index to word.
2017:03:03 16:00:14	...mapping from word to index.
2017:03:03 16:00:14	...map word to index.
2017:03:03 16:00:29	the vocabulary size is 34472.
2017:03:03 16:01:22	use DataLoaderBBC to init data.
2017:03:03 16:01:22	reading and processing the text file.
2017:03:03 16:01:22	preprocess the dataset and extract the valid content.
2017:03:03 16:01:22	...load data.
2017:03:03 16:01:22	...clean data.
2017:03:03 16:01:23	build a vocabulary.
2017:03:03 16:01:23	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:01:23	...mapping from index to word.
2017:03:03 16:01:24	...mapping from word to index.
2017:03:03 16:01:24	...map word to index.
2017:03:03 16:01:42	use DataLoaderBBC to init data.
2017:03:03 16:01:42	reading and processing the text file.
2017:03:03 16:01:42	preprocess the dataset and extract the valid content.
2017:03:03 16:01:42	...load data.
2017:03:03 16:01:42	...clean data.
2017:03:03 16:01:43	build a vocabulary.
2017:03:03 16:01:43	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:01:43	...mapping from index to word.
2017:03:03 16:01:43	...mapping from word to index.
2017:03:03 16:01:43	...map word to index.
2017:03:03 16:02:00	the vocabulary size is 34472.
2017:03:03 16:02:11	use DataLoaderBBC to init data.
2017:03:03 16:02:11	reading and processing the text file.
2017:03:03 16:02:11	preprocess the dataset and extract the valid content.
2017:03:03 16:02:11	...load data.
2017:03:03 16:02:11	...clean data.
2017:03:03 16:02:12	build a vocabulary.
2017:03:03 16:02:12	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:02:12	...mapping from index to word.
2017:03:03 16:02:12	...mapping from word to index.
2017:03:03 16:02:12	...map word to index.
2017:03:03 16:02:27	the vocabulary size is 34472.
2017:03:03 16:02:46	use DataLoaderChildrenStory to init data.
2017:03:03 16:02:46	reading and processing the text file.
2017:03:03 16:02:46	preprocess the dataset.
2017:03:03 16:02:51	build a vocabulary.
2017:03:03 16:02:51	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:02:52	...mapping from index to word.
2017:03:03 16:02:52	...mapping from word to index.
2017:03:03 16:02:52	...map word to index.
2017:03:03 16:03:37	the vocabulary size is 29265.
2017:03:03 16:04:12	use DataLoaderChildrenStory to init data.
2017:03:03 16:04:12	reading and processing the text file.
2017:03:03 16:04:12	preprocess the dataset.
2017:03:03 16:04:17	build a vocabulary.
2017:03:03 16:04:17	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:04:18	...mapping from index to word.
2017:03:03 16:04:18	...mapping from word to index.
2017:03:03 16:04:18	...map word to index.
2017:03:03 16:05:10	the vocabulary size is 29265.
2017:03:03 16:07:22	use DataLoaderChildrenStory to init data.
2017:03:03 16:07:22	reading and processing the text file.
2017:03:03 16:07:22	preprocess the dataset.
2017:03:03 16:07:27	build a vocabulary.
2017:03:03 16:07:27	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:07:28	...mapping from index to word.
2017:03:03 16:07:29	...mapping from word to index.
2017:03:03 16:07:29	...map word to index.
2017:03:03 16:08:29	the vocabulary size is 29265.
2017:03:03 16:08:47	use DataLoaderBBC to init data.
2017:03:03 16:08:47	reading and processing the text file.
2017:03:03 16:08:47	preprocess the dataset and extract the valid content.
2017:03:03 16:08:47	...load data.
2017:03:03 16:08:47	...clean data.
2017:03:03 16:08:48	build a vocabulary.
2017:03:03 16:08:48	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:08:48	...mapping from index to word.
2017:03:03 16:08:49	...mapping from word to index.
2017:03:03 16:08:49	...map word to index.
2017:03:03 16:09:18	the vocabulary size is 34472.
2017:03:03 16:11:02	use DataLoaderBBC to init data.
2017:03:03 16:11:02	reading and processing the text file.
2017:03:03 16:11:02	preprocess the dataset and extract the valid content.
2017:03:03 16:11:02	...load data.
2017:03:03 16:11:02	...clean data.
2017:03:03 16:11:03	build a vocabulary.
2017:03:03 16:11:03	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:11:03	...mapping from index to word.
2017:03:03 16:11:04	...mapping from word to index.
2017:03:03 16:11:04	...map word to index.
2017:03:03 16:11:27	the vocabulary size is 34472.
2017:03:03 16:12:52	use DataLoaderBBC to init data.
2017:03:03 16:12:52	reading and processing the text file.
2017:03:03 16:12:52	preprocess the dataset and extract the valid content.
2017:03:03 16:12:52	...load data.
2017:03:03 16:12:52	...clean data.
2017:03:03 16:12:53	build a vocabulary.
2017:03:03 16:12:53	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:12:53	...mapping from index to word.
2017:03:03 16:12:53	...mapping from word to index.
2017:03:03 16:12:53	...map word to index.
2017:03:03 16:13:09	the vocabulary size is 34472.
2017:03:03 16:13:44	use DataLoaderChildrenStory to init data.
2017:03:03 16:13:44	reading and processing the text file.
2017:03:03 16:13:44	preprocess the dataset.
2017:03:03 16:13:49	build a vocabulary.
2017:03:03 16:13:49	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:13:50	...mapping from index to word.
2017:03:03 16:13:51	...mapping from word to index.
2017:03:03 16:13:51	...map word to index.
2017:03:03 16:14:50	the vocabulary size is 29265.
2017:03:03 16:16:20	use DataLoaderEnron to init data.
2017:03:03 16:16:20	reading and processing the text file.
2017:03:03 16:16:20	preprocess the dataset and extract the valid content.
2017:03:03 16:17:33	use DataLoaderChildrenStory to init data.
2017:03:03 16:17:33	reading and processing the text file.
2017:03:03 16:17:33	preprocess the dataset.
2017:03:03 16:17:38	build a vocabulary.
2017:03:03 16:17:38	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:17:39	...mapping from index to word.
2017:03:03 16:17:39	...mapping from word to index.
2017:03:03 16:17:39	...map word to index.
2017:03:03 16:18:39	the vocabulary size is 29265.
2017:03:03 16:19:50	use DataLoaderBBC to init data.
2017:03:03 16:19:50	reading and processing the text file.
2017:03:03 16:19:50	preprocess the dataset and extract the valid content.
2017:03:03 16:19:50	...load data.
2017:03:03 16:19:50	...clean data.
2017:03:03 16:19:51	build a vocabulary.
2017:03:03 16:19:51	...flatmap a list of sentence list to a list of sentence.
2017:03:03 16:19:52	...mapping from index to word.
2017:03:03 16:19:52	...mapping from word to index.
2017:03:03 16:19:52	...map word to index.
2017:03:03 16:20:10	the vocabulary size is 34472.
2017:03:03 16:20:45	use DataLoaderEnron to init data.
2017:03:03 16:20:45	reading and processing the text file.
2017:03:03 16:20:45	preprocess the dataset and extract the valid content.
2017:03:03 16:20:45	init data from the raw dataset.
2017:03:03 16:21:07	...Parse the emails into a list email objects
2017:03:03 16:22:40	...Get fields from parsed email objects
2017:03:03 16:23:00	...Parse content from emails
2017:03:03 16:23:03	...Split multiple email addresses
2017:03:03 16:23:07	...Extract the root of 'file' as 'user'
2017:03:03 16:23:09	extract content from email data frame.
2017:03:03 16:29:27	use DataLoaderEnron to init data.
2017:03:03 16:29:27	reading and processing the text file.
2017:03:03 16:29:27	preprocess the dataset and extract the valid content.
2017:03:03 16:29:27	...load data.
2017:03:03 16:29:27	load context for further preprocessing.
2017:03:03 16:29:34	...clean data.
2017:03:03 16:31:00	use DataLoaderEnron to init data.
2017:03:03 16:31:00	reading and processing the text file.
2017:03:03 16:31:00	preprocess the dataset and extract the valid content.
2017:03:03 16:31:00	...load data.
2017:03:03 16:31:00	......load context for further preprocessing.
2017:03:03 16:31:01	...clean data.
2017:03:03 16:32:10	use DataLoaderEnron to init data.
2017:03:03 16:32:10	reading and processing the text file.
2017:03:03 16:32:10	preprocess the dataset and extract the valid content.
2017:03:03 16:32:10	...load data.
2017:03:03 16:32:10	......load context for further preprocessing.
2017:03:03 16:32:10	...clean data.
2017:03:03 16:32:47	use DataLoaderEnron to init data.
2017:03:03 16:32:47	reading and processing the text file.
2017:03:03 16:32:47	preprocess the dataset and extract the valid content.
2017:03:03 16:32:47	...load data.
2017:03:03 16:32:47	......load context for further preprocessing.
2017:03:03 16:32:48	...clean data.
2017:03:03 16:33:54	use DataLoaderEnron to init data.
2017:03:03 16:33:54	reading and processing the text file.
2017:03:03 16:33:54	preprocess the dataset and extract the valid content.
2017:03:03 16:33:54	...load data.
2017:03:03 16:33:54	......load context for further preprocessing.
2017:03:03 16:33:55	...clean data.
2017:03:03 16:36:11	use DataLoaderEnron to init data.
2017:03:03 16:36:11	reading and processing the text file.
2017:03:03 16:36:11	preprocess the dataset and extract the valid content.
2017:03:03 16:36:11	...load data.
2017:03:03 16:36:11	......load context for further preprocessing.
2017:03:03 16:36:12	...clean data.
2017:03:03 16:36:23	use DataLoaderEnron to init data.
2017:03:03 16:36:23	reading and processing the text file.
2017:03:03 16:36:23	preprocess the dataset and extract the valid content.
2017:03:03 16:36:23	...load data.
2017:03:03 16:36:23	......load context for further preprocessing.
2017:03:03 16:36:23	...clean data.
2017:03:03 16:36:40	use DataLoaderEnron to init data.
2017:03:03 16:36:40	reading and processing the text file.
2017:03:03 16:36:40	preprocess the dataset and extract the valid content.
2017:03:03 16:36:40	...load data.
2017:03:03 16:36:40	......load context for further preprocessing.
2017:03:03 16:36:40	...clean data.
2017:03:03 16:56:39	use DataLoaderWikiText to init data.
2017:03:03 16:56:39	reading and processing the text file.
2017:03:03 16:56:39	preprocess the dataset.
2017:03:03 16:57:35	use DataLoaderWikiText to init data.
2017:03:03 16:57:35	reading and processing the text file.
2017:03:03 16:57:35	preprocess the dataset.
2017:03:03 16:59:38	use DataLoaderWikiText to init data.
2017:03:03 16:59:38	reading and processing the text file.
2017:03:03 16:59:38	preprocess the dataset.
2017:03:03 16:59:49	use DataLoaderWikiText to init data.
2017:03:03 16:59:49	reading and processing the text file.
2017:03:03 16:59:49	preprocess the dataset.
2017:03:03 17:00:23	use DataLoaderWikiText to init data.
2017:03:03 17:00:23	reading and processing the text file.
2017:03:03 17:00:23	preprocess the dataset.
2017:03:03 17:00:45	use DataLoaderWikiText to init data.
2017:03:03 17:00:45	reading and processing the text file.
2017:03:03 17:00:45	preprocess the dataset.
2017:03:03 17:01:47	use DataLoaderWikiText to init data.
2017:03:03 17:01:47	reading and processing the text file.
2017:03:03 17:01:47	preprocess the dataset.
2017:03:03 17:02:32	use DataLoaderWikiText to init data.
2017:03:03 17:02:32	reading and processing the text file.
2017:03:03 17:02:32	preprocess the dataset.
2017:03:03 17:02:58	use DataLoaderWikiText to init data.
2017:03:03 17:02:58	reading and processing the text file.
2017:03:03 17:02:58	preprocess the dataset.
2017:03:03 17:03:07	use DataLoaderWikiText to init data.
2017:03:03 17:03:07	reading and processing the text file.
2017:03:03 17:03:07	preprocess the dataset.
2017:03:03 17:03:44	use DataLoaderWikiText to init data.
2017:03:03 17:03:44	reading and processing the text file.
2017:03:03 17:03:44	preprocess the dataset.
2017:03:03 17:04:12	use DataLoaderWikiText to init data.
2017:03:03 17:04:12	reading and processing the text file.
2017:03:03 17:04:12	preprocess the dataset.
2017:03:03 17:04:54	use DataLoaderWikiText to init data.
2017:03:03 17:04:54	reading and processing the text file.
2017:03:03 17:04:54	preprocess the dataset.
2017:03:03 17:05:22	use DataLoaderWikiText to init data.
2017:03:03 17:05:22	reading and processing the text file.
2017:03:03 17:05:22	preprocess the dataset.
2017:03:03 17:05:52	use DataLoaderWikiText to init data.
2017:03:03 17:05:52	reading and processing the text file.
2017:03:03 17:05:52	preprocess the dataset.
2017:03:03 17:06:04	use DataLoaderWikiText to init data.
2017:03:03 17:06:04	reading and processing the text file.
2017:03:03 17:06:04	preprocess the dataset.
2017:03:03 17:06:50	use DataLoaderWikiText to init data.
2017:03:03 17:06:50	reading and processing the text file.
2017:03:03 17:06:50	preprocess the dataset.
2017:03:03 17:07:21	use DataLoaderWikiText to init data.
2017:03:03 17:07:21	reading and processing the text file.
2017:03:03 17:07:21	preprocess the dataset.
2017:03:03 17:08:02	use DataLoaderWikiText to init data.
2017:03:03 17:08:02	reading and processing the text file.
2017:03:03 17:08:02	preprocess the dataset.
2017:03:03 17:08:12	use DataLoaderWikiText to init data.
2017:03:03 17:08:12	reading and processing the text file.
2017:03:03 17:08:12	preprocess the dataset.
2017:03:03 17:09:02	use DataLoaderWikiText to init data.
2017:03:03 17:09:02	reading and processing the text file.
2017:03:03 17:09:02	preprocess the dataset.
2017:03:03 17:09:38	use DataLoaderWikiText to init data.
2017:03:03 17:09:38	reading and processing the text file.
2017:03:03 17:09:38	preprocess the dataset.
2017:03:03 17:10:05	use DataLoaderWikiText to init data.
2017:03:03 17:10:05	reading and processing the text file.
2017:03:03 17:10:05	preprocess the dataset.
2017:03:03 17:11:04	use DataLoaderWikiText to init data.
2017:03:03 17:11:04	reading and processing the text file.
2017:03:03 17:11:04	preprocess the dataset.
2017:03:03 17:11:20	use DataLoaderWikiText to init data.
2017:03:03 17:11:20	reading and processing the text file.
2017:03:03 17:11:20	preprocess the dataset.
2017:03:03 17:12:25	use DataLoaderWikiText to init data.
2017:03:03 17:12:25	reading and processing the text file.
2017:03:03 17:12:25	preprocess the dataset.
2017:03:03 17:12:56	use DataLoaderWikiText to init data.
2017:03:03 17:12:56	reading and processing the text file.
2017:03:03 17:12:56	preprocess the dataset.
2017:03:03 17:13:31	use DataLoaderWikiText to init data.
2017:03:03 17:13:31	reading and processing the text file.
2017:03:03 17:13:31	preprocess the dataset.
2017:03:03 17:14:54	use DataLoaderWikiText to init data.
2017:03:03 17:14:54	reading and processing the text file.
2017:03:03 17:14:54	preprocess the dataset.
2017:03:03 17:14:55	build a vocabulary.
2017:03:03 17:14:55	...flatmap a list of sentence list to a list of sentence.
2017:03:03 17:14:56	...mapping from index to word.
2017:03:03 17:14:56	...mapping from word to index.
2017:03:03 17:14:56	...map word to index.
2017:03:03 17:16:45	use DataLoaderWikiText to init data.
2017:03:03 17:16:45	loading preprocessed files.
2017:03:03 17:17:24	use DataLoaderWikiText to init data.
2017:03:03 17:17:24	loading preprocessed files.
2017:03:03 17:18:52	use DataLoaderWikiText to init data.
2017:03:03 17:18:52	reading and processing the text file.
2017:03:03 17:18:52	preprocess the dataset.
2017:03:03 17:18:53	build a vocabulary.
2017:03:03 17:18:53	...flatmap a list of sentence list to a list of sentence.
2017:03:03 17:18:54	...mapping from index to word.
2017:03:03 17:18:54	...mapping from word to index.
2017:03:03 17:18:54	...map word to index.
2017:03:03 17:19:34	the vocabulary size is 34093.
2017:03:03 21:13:39	use DataLoaderChildrenStory to init data.
2017:03:03 21:13:39	reading and processing the text file.
2017:03:03 21:13:39	preprocess the dataset.
2017:03:03 21:14:03	use DataLoaderChildrenStory to init data.
2017:03:03 21:14:03	reading and processing the text file.
2017:03:03 21:14:03	preprocess the dataset.
2017:03:03 21:14:08	build a vocabulary.
2017:03:03 21:14:08	...flatmap a list of sentence list to a list of sentence.
2017:03:03 21:14:09	...mapping from index to word.
2017:03:03 21:14:09	...mapping from word to index.
2017:03:03 21:14:09	...map word to index.
2017:03:03 21:15:25	use DataLoaderChildrenStory to init data.
2017:03:03 21:15:25	loading preprocessed files.
2017:03:03 21:16:37	use DataLoaderChildrenStory to init data.
2017:03:03 21:16:37	loading preprocessed files.
2017:03:03 21:17:24	use DataLoaderChildrenStory to init data.
2017:03:03 21:17:24	reading and processing the text file.
2017:03:03 21:17:24	preprocess the dataset.
2017:03:03 21:17:29	build a vocabulary.
2017:03:03 21:17:29	...flatmap a list of sentence list to a list of sentence.
2017:03:03 21:17:30	...mapping from index to word.
2017:03:03 21:17:30	...mapping from word to index.
2017:03:03 21:17:30	...map word to index.
2017:03:03 21:18:28	the vocabulary size is 29265.
2017:03:03 21:19:27	use DataLoaderChildrenStory to init data.
2017:03:03 21:19:27	loading preprocessed files.
2017:03:03 21:20:15	the vocabulary size is 29265.
2017:03:07 14:51:41	use DataLoaderChildrenStory to init data.
2017:03:07 14:51:41	reading and processing the text file.
2017:03:07 14:51:41	preprocess the dataset.
2017:03:07 14:51:46	build a vocabulary.
2017:03:07 14:51:46	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:53:08	use DataLoaderChildrenStory to init data.
2017:03:07 14:53:08	reading and processing the text file.
2017:03:07 14:53:08	preprocess the dataset.
2017:03:07 14:53:13	build a vocabulary.
2017:03:07 14:53:13	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:53:20	use DataLoaderChildrenStory to init data.
2017:03:07 14:53:20	reading and processing the text file.
2017:03:07 14:53:20	preprocess the dataset.
2017:03:07 14:53:24	build a vocabulary.
2017:03:07 14:53:24	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:53:29	use DataLoaderChildrenStory to init data.
2017:03:07 14:53:29	reading and processing the text file.
2017:03:07 14:53:29	preprocess the dataset.
2017:03:07 14:53:33	build a vocabulary.
2017:03:07 14:53:33	...flatmap a list of sentence list to a list of sentence.
2017:03:07 14:54:06	use DataLoaderChildrenStory to init data.
2017:03:07 14:54:06	reading and processing the text file.
2017:03:07 14:54:06	preprocess the dataset.
2017:03:07 14:54:10	build a vocabulary.
2017:03:07 14:54:10	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:01:50	use DataLoaderChildrenStory to init data.
2017:03:07 15:01:50	reading and processing the text file.
2017:03:07 15:01:50	preprocess the dataset.
2017:03:07 15:17:53	use DataLoaderChildrenStory to init data.
2017:03:07 15:17:53	reading and processing the text file.
2017:03:07 15:17:53	preprocess the dataset.
2017:03:07 15:17:59	build a vocabulary.
2017:03:07 15:17:59	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:18:00	...mapping from index to word.
2017:03:07 15:18:00	...mapping from word to index.
2017:03:07 15:18:00	...map word to index.
2017:03:07 15:19:37	use DataLoaderChildrenStory to init data.
2017:03:07 15:19:37	reading and processing the text file.
2017:03:07 15:19:37	preprocess the dataset.
2017:03:07 15:19:42	build a vocabulary.
2017:03:07 15:19:42	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:19:42	...mapping from index to word.
2017:03:07 15:19:42	...mapping from word to index.
2017:03:07 15:19:42	...map word to index.
2017:03:07 15:22:54	use DataLoaderChildrenStory to init data.
2017:03:07 15:22:54	reading and processing the text file.
2017:03:07 15:22:54	preprocess the dataset.
2017:03:07 15:22:58	build a vocabulary.
2017:03:07 15:22:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:22:59	...mapping from index to word.
2017:03:07 15:22:59	...mapping from word to index.
2017:03:07 15:22:59	...map word to index.
2017:03:07 15:23:33	use DataLoaderChildrenStory to init data.
2017:03:07 15:23:33	reading and processing the text file.
2017:03:07 15:23:33	preprocess the dataset.
2017:03:07 15:23:38	build a vocabulary.
2017:03:07 15:23:38	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:23:38	...mapping from index to word.
2017:03:07 15:23:38	...mapping from word to index.
2017:03:07 15:23:38	...map word to index.
2017:03:07 15:23:52	use DataLoaderChildrenStory to init data.
2017:03:07 15:23:52	reading and processing the text file.
2017:03:07 15:23:52	preprocess the dataset.
2017:03:07 15:23:56	build a vocabulary.
2017:03:07 15:23:56	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:23:56	...mapping from index to word.
2017:03:07 15:23:56	...mapping from word to index.
2017:03:07 15:23:56	...map word to index.
2017:03:07 15:24:21	use DataLoaderChildrenStory to init data.
2017:03:07 15:24:21	reading and processing the text file.
2017:03:07 15:24:21	preprocess the dataset.
2017:03:07 15:24:25	build a vocabulary.
2017:03:07 15:24:25	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:24:25	...mapping from index to word.
2017:03:07 15:24:25	...mapping from word to index.
2017:03:07 15:24:25	...map word to index.
2017:03:07 15:25:28	use DataLoaderChildrenStory to init data.
2017:03:07 15:25:28	reading and processing the text file.
2017:03:07 15:25:28	preprocess the dataset.
2017:03:07 15:25:32	build a vocabulary.
2017:03:07 15:25:32	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:25:32	...mapping from index to word.
2017:03:07 15:25:32	...mapping from word to index.
2017:03:07 15:25:32	...map word to index.
2017:03:07 15:27:23	use DataLoaderChildrenStory to init data.
2017:03:07 15:27:23	reading and processing the text file.
2017:03:07 15:27:23	preprocess the dataset.
2017:03:07 15:27:27	build a vocabulary.
2017:03:07 15:27:27	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:28:29	use DataLoaderChildrenStory to init data.
2017:03:07 15:28:29	reading and processing the text file.
2017:03:07 15:28:29	preprocess the dataset.
2017:03:07 15:28:32	build a vocabulary.
2017:03:07 15:28:32	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:28:32	...mapping from index to word.
2017:03:07 15:28:32	...mapping from word to index.
2017:03:07 15:28:32	...map word to index.
2017:03:07 15:28:49	use DataLoaderChildrenStory to init data.
2017:03:07 15:28:49	reading and processing the text file.
2017:03:07 15:28:49	preprocess the dataset.
2017:03:07 15:28:53	build a vocabulary.
2017:03:07 15:28:53	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:28:53	...mapping from index to word.
2017:03:07 15:28:53	...mapping from word to index.
2017:03:07 15:28:53	...map word to index.
2017:03:07 15:30:54	use DataLoaderChildrenStory to init data.
2017:03:07 15:30:54	reading and processing the text file.
2017:03:07 15:30:54	preprocess the dataset.
2017:03:07 15:30:58	build a vocabulary.
2017:03:07 15:30:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:30:58	...mapping from index to word.
2017:03:07 15:30:58	...mapping from word to index.
2017:03:07 15:30:58	...map word to index.
2017:03:07 15:33:58	use DataLoaderChildrenStory to init data.
2017:03:07 15:33:58	reading and processing the text file.
2017:03:07 15:33:58	preprocess the dataset.
2017:03:07 15:34:03	build a vocabulary.
2017:03:07 15:34:03	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:34:04	...mapping from index to word.
2017:03:07 15:34:04	...mapping from word to index.
2017:03:07 15:34:04	...map word to index.
2017:03:07 15:34:32	use DataLoaderChildrenStory to init data.
2017:03:07 15:34:32	reading and processing the text file.
2017:03:07 15:34:32	preprocess the dataset.
2017:03:07 15:34:37	build a vocabulary.
2017:03:07 15:34:37	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:34:37	...mapping from index to word.
2017:03:07 15:34:37	...mapping from word to index.
2017:03:07 15:34:37	...map word to index.
2017:03:07 15:36:09	use DataLoaderChildrenStory to init data.
2017:03:07 15:36:09	reading and processing the text file.
2017:03:07 15:36:09	preprocess the dataset.
2017:03:07 15:36:16	build a vocabulary.
2017:03:07 15:36:16	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:36:16	...mapping from index to word.
2017:03:07 15:36:16	...mapping from word to index.
2017:03:07 15:36:16	...map word to index.
2017:03:07 15:37:14	use DataLoaderChildrenStory to init data.
2017:03:07 15:37:14	reading and processing the text file.
2017:03:07 15:37:14	preprocess the dataset.
2017:03:07 15:37:20	build a vocabulary.
2017:03:07 15:37:20	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:37:21	...mapping from index to word.
2017:03:07 15:37:21	...mapping from word to index.
2017:03:07 15:37:21	...map word to index.
2017:03:07 15:37:33	use DataLoaderChildrenStory to init data.
2017:03:07 15:37:33	reading and processing the text file.
2017:03:07 15:37:33	preprocess the dataset.
2017:03:07 15:37:39	build a vocabulary.
2017:03:07 15:37:39	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:37:39	...mapping from index to word.
2017:03:07 15:37:39	...mapping from word to index.
2017:03:07 15:37:39	...map word to index.
2017:03:07 15:37:55	use DataLoaderChildrenStory to init data.
2017:03:07 15:37:55	reading and processing the text file.
2017:03:07 15:37:55	preprocess the dataset.
2017:03:07 15:38:01	build a vocabulary.
2017:03:07 15:38:01	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:38:01	...mapping from index to word.
2017:03:07 15:38:01	...mapping from word to index.
2017:03:07 15:38:01	...map word to index.
2017:03:07 15:43:08	use DataLoaderChildrenStory to init data.
2017:03:07 15:43:08	reading and processing the text file.
2017:03:07 15:43:08	preprocess the dataset.
2017:03:07 15:43:14	...mask and pad the sentence.
2017:03:07 15:43:14	build a vocabulary.
2017:03:07 15:43:14	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:43:14	...mapping from index to word.
2017:03:07 15:43:14	...mapping from word to index.
2017:03:07 15:43:14	...map word to index.
2017:03:07 15:44:44	use DataLoaderChildrenStory to init data.
2017:03:07 15:44:44	reading and processing the text file.
2017:03:07 15:44:44	preprocess the dataset.
2017:03:07 15:44:50	...mask and pad the sentence.
2017:03:07 15:44:50	build a vocabulary.
2017:03:07 15:44:50	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:44:50	...mapping from index to word.
2017:03:07 15:44:50	...mapping from word to index.
2017:03:07 15:44:50	...map word to index.
2017:03:07 15:54:01	use DataLoaderChildrenStory to init data.
2017:03:07 15:54:01	reading and processing the text file.
2017:03:07 15:54:01	preprocess the dataset.
2017:03:07 15:54:12	...mask and pad the sentence.
2017:03:07 15:55:33	use DataLoaderChildrenStory to init data.
2017:03:07 15:55:33	reading and processing the text file.
2017:03:07 15:55:33	preprocess the dataset.
2017:03:07 15:55:38	...mask and pad the sentence.
2017:03:07 15:55:38	build a vocabulary.
2017:03:07 15:55:38	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:55:39	...mapping from index to word.
2017:03:07 15:55:39	...mapping from word to index.
2017:03:07 15:55:39	...map word to index.
2017:03:07 15:55:53	use DataLoaderChildrenStory to init data.
2017:03:07 15:55:53	reading and processing the text file.
2017:03:07 15:55:53	preprocess the dataset.
2017:03:07 15:55:58	...mask and pad the sentence.
2017:03:07 15:55:58	build a vocabulary.
2017:03:07 15:55:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:55:58	...mapping from index to word.
2017:03:07 15:55:58	...mapping from word to index.
2017:03:07 15:55:58	...map word to index.
2017:03:07 15:56:05	use DataLoaderChildrenStory to init data.
2017:03:07 15:56:05	reading and processing the text file.
2017:03:07 15:56:05	preprocess the dataset.
2017:03:07 15:56:12	...mask and pad the sentence.
2017:03:07 15:56:12	build a vocabulary.
2017:03:07 15:56:12	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:56:12	...mapping from index to word.
2017:03:07 15:56:12	...mapping from word to index.
2017:03:07 15:56:12	...map word to index.
2017:03:07 15:56:27	use DataLoaderChildrenStory to init data.
2017:03:07 15:56:27	reading and processing the text file.
2017:03:07 15:56:27	preprocess the dataset.
2017:03:07 15:56:32	...mask and pad the sentence.
2017:03:07 15:56:32	build a vocabulary.
2017:03:07 15:56:32	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:56:32	...mapping from index to word.
2017:03:07 15:56:32	...mapping from word to index.
2017:03:07 15:56:32	...map word to index.
2017:03:07 15:58:30	use DataLoaderChildrenStory to init data.
2017:03:07 15:58:31	reading and processing the text file.
2017:03:07 15:58:31	preprocess the dataset.
2017:03:07 15:58:37	...mask and pad the sentence.
2017:03:07 15:58:56	use DataLoaderChildrenStory to init data.
2017:03:07 15:58:56	reading and processing the text file.
2017:03:07 15:58:56	preprocess the dataset.
2017:03:07 15:59:00	...mask and pad the sentence.
2017:03:07 15:59:00	......max len:19, median len:9.0, min len:2
2017:03:07 15:59:00	build a vocabulary.
2017:03:07 15:59:00	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:59:00	...mapping from index to word.
2017:03:07 15:59:00	...mapping from word to index.
2017:03:07 15:59:00	...map word to index.
2017:03:07 15:59:18	use DataLoaderChildrenStory to init data.
2017:03:07 15:59:18	reading and processing the text file.
2017:03:07 15:59:18	preprocess the dataset.
2017:03:07 15:59:24	...mask and pad the sentence.
2017:03:07 15:59:24	......max len:19, median len:9.0, min len:2
2017:03:07 15:59:24	build a vocabulary.
2017:03:07 15:59:24	...flatmap a list of sentence list to a list of sentence.
2017:03:07 15:59:24	...mapping from index to word.
2017:03:07 15:59:24	...mapping from word to index.
2017:03:07 15:59:24	...map word to index.
2017:03:07 16:00:30	use DataLoaderChildrenStory to init data.
2017:03:07 16:00:30	reading and processing the text file.
2017:03:07 16:00:30	preprocess the dataset.
2017:03:07 16:00:34	...mask and pad the sentence.
2017:03:07 16:00:35	......max len:19, median len:9.0, min len:2
2017:03:07 16:00:35	build a vocabulary.
2017:03:07 16:00:35	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:00:35	...mapping from index to word.
2017:03:07 16:00:35	...mapping from word to index.
2017:03:07 16:00:35	...map word to index.
2017:03:07 16:06:24	use DataLoaderChildrenStory to init data.
2017:03:07 16:06:24	reading and processing the text file.
2017:03:07 16:06:24	preprocess the dataset.
2017:03:07 16:06:30	...mask and pad the sentence.
2017:03:07 16:06:30	......max len:18, median len:8.0, min len:1
2017:03:07 16:06:31	build a vocabulary.
2017:03:07 16:06:31	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:06:31	...mapping from index to word.
2017:03:07 16:06:31	...mapping from word to index.
2017:03:07 16:06:31	...map word to index.
2017:03:07 16:07:35	use DataLoaderChildrenStory to init data.
2017:03:07 16:07:35	reading and processing the text file.
2017:03:07 16:07:35	preprocess the dataset.
2017:03:07 16:07:42	...mask and pad the sentence.
2017:03:07 16:07:42	......max len:18, median len:8.0, min len:1
2017:03:07 16:07:42	build a vocabulary.
2017:03:07 16:07:42	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:07:42	...mapping from index to word.
2017:03:07 16:07:43	...mapping from word to index.
2017:03:07 16:07:43	...map word to index.
2017:03:07 16:14:26	use DataLoaderChildrenStory to init data.
2017:03:07 16:14:26	reading and processing the text file.
2017:03:07 16:14:26	preprocess the dataset.
2017:03:07 16:14:37	...mask and pad the sentence.
2017:03:07 16:14:37	......max len:18, median len:8.0, min len:1
2017:03:07 16:14:37	build a vocabulary.
2017:03:07 16:14:37	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:14:38	...mapping from index to word.
2017:03:07 16:14:38	...mapping from word to index.
2017:03:07 16:14:38	...map word to index.
2017:03:07 16:17:17	use DataLoaderChildrenStory to init data.
2017:03:07 16:17:17	reading and processing the text file.
2017:03:07 16:17:17	preprocess the dataset.
2017:03:07 16:17:26	...mask and pad the sentence.
2017:03:07 16:17:26	......max len:18, median len:8.0, min len:1
2017:03:07 16:17:27	build a vocabulary.
2017:03:07 16:17:27	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:17:27	...mapping from index to word.
2017:03:07 16:17:28	...mapping from word to index.
2017:03:07 16:17:28	...map word to index.
2017:03:07 16:25:58	use DataLoaderChildrenStory to init data.
2017:03:07 16:25:58	reading and processing the text file.
2017:03:07 16:25:58	preprocess the dataset.
2017:03:07 16:26:06	...mask and pad the sentence.
2017:03:07 16:26:06	......max len:18, median len:8.0, min len:1
2017:03:07 16:26:06	build a vocabulary.
2017:03:07 16:26:06	...flatmap a list of sentence list to a list of sentence.
2017:03:07 16:26:07	...mapping from index to word.
2017:03:07 16:26:07	...mapping from word to index.
2017:03:07 16:26:07	...map word to index.
2017:03:07 16:26:08	...some data statistics.
2017:03:07 16:26:08	...save processed data to file.
2017:03:07 16:26:10	the sample size is 78290, the vocab size is 17612
2017:03:07 20:34:49	use DataLoaderChildrenStory to init data.
2017:03:07 20:34:49	reading and processing the text file.
2017:03:07 20:34:49	preprocess the dataset.
2017:03:07 20:34:59	...mask and pad the sentence.
2017:03:07 20:34:59	......max len:19, median len:9.0, min len:2
2017:03:07 20:35:00	build a vocabulary.
2017:03:07 20:35:00	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:35:01	...mapping from index to word.
2017:03:07 20:35:01	...mapping from word to index.
2017:03:07 20:35:01	...map word to index.
2017:03:07 20:35:02	...some data statistics.
2017:03:07 20:35:02	...save processed data to file.
2017:03:07 20:35:05	the sample size is 95182, the vocab size is 18626
2017:03:07 20:36:30	use DataLoaderChildrenStory to init data.
2017:03:07 20:36:30	reading and processing the text file.
2017:03:07 20:36:30	preprocess the dataset.
2017:03:07 20:36:34	...mask and pad the sentence.
2017:03:07 20:36:34	......max len:19, median len:8.0, min len:2
2017:03:07 20:36:35	build a vocabulary.
2017:03:07 20:36:35	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:36:35	...mapping from index to word.
2017:03:07 20:36:36	...mapping from word to index.
2017:03:07 20:36:36	...map word to index.
2017:03:07 20:36:37	...some data statistics.
2017:03:07 20:36:37	...save processed data to file.
2017:03:07 20:36:40	the sample size is 95080, the vocab size is 22861
2017:03:07 20:37:14	use DataLoaderChildrenStory to init data.
2017:03:07 20:37:14	reading and processing the text file.
2017:03:07 20:37:14	preprocess the dataset.
2017:03:07 20:37:18	...mask and pad the sentence.
2017:03:07 20:37:18	......max len:19, median len:8.0, min len:2
2017:03:07 20:37:19	build a vocabulary.
2017:03:07 20:37:19	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:37:20	...mapping from index to word.
2017:03:07 20:37:20	...mapping from word to index.
2017:03:07 20:37:20	...map word to index.
2017:03:07 20:37:20	...some data statistics.
2017:03:07 20:37:20	...save processed data to file.
2017:03:07 20:37:24	the sample size is 95080, the vocab size is 22861
2017:03:07 20:37:27	use DataLoaderChildrenStory to init data.
2017:03:07 20:37:27	reading and processing the text file.
2017:03:07 20:37:27	preprocess the dataset.
2017:03:07 20:37:37	...mask and pad the sentence.
2017:03:07 20:37:37	......max len:19, median len:9.0, min len:2
2017:03:07 20:37:38	build a vocabulary.
2017:03:07 20:37:38	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:37:39	...mapping from index to word.
2017:03:07 20:37:39	...mapping from word to index.
2017:03:07 20:37:39	...map word to index.
2017:03:07 20:37:40	...some data statistics.
2017:03:07 20:37:40	...save processed data to file.
2017:03:07 20:37:43	the sample size is 95182, the vocab size is 18626
2017:03:07 20:38:48	use DataLoaderChildrenStory to init data.
2017:03:07 20:38:48	reading and processing the text file.
2017:03:07 20:38:48	preprocess the dataset.
2017:03:07 20:38:58	...mask and pad the sentence.
2017:03:07 20:38:58	......max len:19, median len:9.0, min len:2
2017:03:07 20:38:58	build a vocabulary.
2017:03:07 20:38:58	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:38:59	...mapping from index to word.
2017:03:07 20:38:59	...mapping from word to index.
2017:03:07 20:38:59	...map word to index.
2017:03:07 20:39:00	...some data statistics.
2017:03:07 20:39:00	...save processed data to file.
2017:03:07 20:39:03	the sample size is 95182, the vocab size is 18626
2017:03:07 20:40:34	use DataLoaderChildrenStory to init data.
2017:03:07 20:40:34	reading and processing the text file.
2017:03:07 20:40:34	preprocess the dataset.
2017:03:07 20:40:44	...mask and pad the sentence.
2017:03:07 20:40:44	......max len:19, median len:9.0, min len:2
2017:03:07 20:40:44	build a vocabulary.
2017:03:07 20:40:44	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:40:45	...mapping from index to word.
2017:03:07 20:40:45	...mapping from word to index.
2017:03:07 20:40:45	...map word to index.
2017:03:07 20:40:46	...some data statistics.
2017:03:07 20:40:46	...save processed data to file.
2017:03:07 20:40:49	the sample size is 95182, the vocab size is 18626
2017:03:07 20:42:08	use DataLoaderChildrenStory to init data.
2017:03:07 20:42:08	reading and processing the text file.
2017:03:07 20:42:08	preprocess the dataset.
2017:03:07 20:42:17	...mask and pad the sentence.
2017:03:07 20:42:17	......max len:19, median len:9.0, min len:2
2017:03:07 20:42:18	build a vocabulary.
2017:03:07 20:42:18	...flatmap a list of sentence list to a list of sentence.
2017:03:07 20:42:19	...mapping from index to word.
2017:03:07 20:42:19	...mapping from word to index.
2017:03:07 20:42:19	...map word to index.
2017:03:07 20:42:19	...some data statistics.
2017:03:07 20:42:19	...save processed data to file.
2017:03:07 20:42:22	the sample size is 95182, the vocab size is 18626
2017:03:07 21:52:40	use DataLoaderChildrenStory to init data.
2017:03:07 21:52:40	reading and processing the text file.
2017:03:07 21:52:40	preprocess the dataset.
2017:03:07 21:52:48	...mask and pad the sentence.
2017:03:07 21:52:48	......max len:19, median len:9.0, min len:2
2017:03:07 21:52:48	build a vocabulary.
2017:03:07 21:52:48	...flatmap a list of sentence list to a list of sentence.
2017:03:07 21:52:49	...mapping from index to word.
2017:03:07 21:52:49	...mapping from word to index.
2017:03:07 21:52:49	...map word to index.
2017:03:07 21:52:50	...some data statistics.
2017:03:07 21:52:50	...save processed data to file.
2017:03:07 21:52:53	the sample size is 95182, the vocab size is 18627
2017:03:07 21:56:38	use DataLoaderChildrenStory to init data.
2017:03:07 21:56:38	loading preprocessed files.
2017:03:07 21:56:43	the sample size is 95182, the vocab size is 18627
2017:03:07 21:57:30	use DataLoaderChildrenStory to init data.
2017:03:07 21:57:30	loading preprocessed files.
2017:03:07 21:57:36	the sample size is 95182, the vocab size is 18627
2017:03:07 21:58:33	use DataLoaderChildrenStory to init data.
2017:03:07 21:58:33	loading preprocessed files.
2017:03:07 21:58:38	the sample size is 95182, the vocab size is 18627
2017:03:07 22:08:37	use DataLoaderChildrenStory to init data.
2017:03:07 22:08:37	loading preprocessed files.
2017:03:07 22:08:42	the sample size is 95182, the vocab size is 18627
2017:03:07 22:19:08	use DataLoaderChildrenStory to init data.
2017:03:07 22:19:08	loading preprocessed files.
2017:03:07 22:19:13	the sample size is 95182, the vocab size is 18627
2017:03:07 22:21:11	use DataLoaderChildrenStory to init data.
2017:03:07 22:21:11	loading preprocessed files.
2017:03:07 22:21:16	the sample size is 95182, the vocab size is 18627
2017:03:07 22:25:46	use DataLoaderChildrenStory to init data.
2017:03:07 22:25:46	loading preprocessed files.
2017:03:07 22:25:50	the sample size is 95182, the vocab size is 18627
2017:03:07 22:27:14	use DataLoaderChildrenStory to init data.
2017:03:07 22:27:14	loading preprocessed files.
2017:03:07 22:27:18	the sample size is 95182, the vocab size is 18627
2017:03:07 22:27:40	use DataLoaderChildrenStory to init data.
2017:03:07 22:27:40	loading preprocessed files.
2017:03:07 22:27:44	the sample size is 95182, the vocab size is 18627
2017:03:07 23:24:29	use DataLoaderChildrenStory to init data.
2017:03:07 23:24:29	loading preprocessed files.
2017:03:07 23:24:33	the sample size is 95182, the vocab size is 18627
2017:03:07 23:26:00	use DataLoaderChildrenStory to init data.
2017:03:07 23:26:00	loading preprocessed files.
2017:03:07 23:26:04	the sample size is 95182, the vocab size is 18627
2017:03:07 23:49:16	use DataLoaderChildrenStory to init data.
2017:03:07 23:49:16	loading preprocessed files.
2017:03:08 23:42:48	use DataLoaderChildrenStory to init data.
2017:03:08 23:42:48	loading preprocessed files.
2017:03:08 23:42:52	the sample size is 95182, the vocab size is 18627
2017:03:08 23:44:30	use DataLoaderChildrenStory to init data.
2017:03:08 23:44:30	reading and processing the text file.
2017:03:08 23:44:30	preprocess the dataset.
2017:03:08 23:44:35	...mask and pad the sentence.
2017:03:08 23:44:35	......max len:19, median len:9.0, min len:2
2017:03:08 23:44:35	build a vocabulary.
2017:03:08 23:44:35	...flatmap a list of sentence list to a list of sentence.
2017:03:08 23:44:36	...mapping from index to word.
2017:03:08 23:44:36	...mapping from word to index.
2017:03:08 23:44:36	...map word to index.
2017:03:08 23:44:37	...some data statistics.
2017:03:08 23:44:37	...save processed data to file.
2017:03:08 23:44:40	the sample size is 95182, the vocab size is 18628
2017:03:08 23:45:20	use DataLoaderChildrenStory to init data.
2017:03:08 23:45:20	loading preprocessed files.
2017:03:08 23:45:27	the sample size is 95182, the vocab size is 18628
2017:03:08 23:46:58	use DataLoaderChildrenStory to init data.
2017:03:08 23:46:58	loading preprocessed files.
2017:03:08 23:47:04	the sample size is 95182, the vocab size is 18628
2017:03:08 23:47:16	use DataLoaderChildrenStory to init data.
2017:03:08 23:47:16	loading preprocessed files.
2017:03:08 23:47:23	the sample size is 95182, the vocab size is 18628
2017:03:08 23:48:11	use DataLoaderChildrenStory to init data.
2017:03:08 23:48:11	loading preprocessed files.
2017:03:08 23:48:18	the sample size is 95182, the vocab size is 18628
2017:03:08 23:48:45	use DataLoaderChildrenStory to init data.
2017:03:08 23:48:45	loading preprocessed files.
2017:03:08 23:48:51	the sample size is 95182, the vocab size is 18628
2017:03:08 23:49:08	use DataLoaderChildrenStory to init data.
2017:03:08 23:49:08	loading preprocessed files.
2017:03:08 23:49:14	the sample size is 95182, the vocab size is 18628
2017:03:08 23:49:36	use DataLoaderChildrenStory to init data.
2017:03:08 23:49:36	loading preprocessed files.
2017:03:08 23:49:43	the sample size is 95182, the vocab size is 18628
2017:03:08 23:49:58	use DataLoaderChildrenStory to init data.
2017:03:08 23:49:58	loading preprocessed files.
2017:03:08 23:50:05	the sample size is 95182, the vocab size is 18628
2017:03:08 23:52:24	use DataLoaderChildrenStory to init data.
2017:03:08 23:52:24	loading preprocessed files.
2017:03:08 23:52:31	the sample size is 95182, the vocab size is 18628
2017:03:08 23:53:22	use DataLoaderChildrenStory to init data.
2017:03:08 23:53:22	loading preprocessed files.
2017:03:08 23:53:28	the sample size is 95182, the vocab size is 18628
2017:03:08 23:55:43	use DataLoaderChildrenStory to init data.
2017:03:08 23:55:43	loading preprocessed files.
2017:03:08 23:55:49	the sample size is 95182, the vocab size is 18628
2017:03:08 23:56:43	use DataLoaderChildrenStory to init data.
2017:03:08 23:56:43	loading preprocessed files.
2017:03:08 23:56:49	the sample size is 95182, the vocab size is 18628
2017:03:08 23:57:17	use DataLoaderChildrenStory to init data.
2017:03:08 23:57:17	loading preprocessed files.
2017:03:08 23:57:24	the sample size is 95182, the vocab size is 18628
2017:03:08 23:58:38	use DataLoaderChildrenStory to init data.
2017:03:08 23:58:38	loading preprocessed files.
2017:03:08 23:58:45	the sample size is 95182, the vocab size is 18628
2017:03:09 00:00:36	use DataLoaderChildrenStory to init data.
2017:03:09 00:00:36	loading preprocessed files.
2017:03:09 00:00:42	the sample size is 95182, the vocab size is 18628
2017:03:09 00:01:10	use DataLoaderChildrenStory to init data.
2017:03:09 00:01:10	loading preprocessed files.
2017:03:09 00:01:17	the sample size is 95182, the vocab size is 18628
2017:03:09 00:02:37	use DataLoaderChildrenStory to init data.
2017:03:09 00:02:37	loading preprocessed files.
2017:03:09 00:02:44	the sample size is 95182, the vocab size is 18628
2017:03:09 00:03:02	use DataLoaderChildrenStory to init data.
2017:03:09 00:03:02	loading preprocessed files.
2017:03:09 00:03:09	the sample size is 95182, the vocab size is 18628
2017:03:09 00:06:41	use DataLoaderChildrenStory to init data.
2017:03:09 00:06:41	loading preprocessed files.
2017:03:09 00:06:48	the sample size is 95182, the vocab size is 18628
2017:03:09 00:07:02	use DataLoaderChildrenStory to init data.
2017:03:09 00:07:02	loading preprocessed files.
2017:03:09 00:07:09	the sample size is 95182, the vocab size is 18628
2017:03:09 00:07:44	use DataLoaderChildrenStory to init data.
2017:03:09 00:07:44	loading preprocessed files.
2017:03:09 00:07:50	the sample size is 95182, the vocab size is 18628
2017:03:09 00:08:29	use DataLoaderChildrenStory to init data.
2017:03:09 00:08:29	loading preprocessed files.
2017:03:09 00:08:36	the sample size is 95182, the vocab size is 18628
2017:03:09 00:09:51	use DataLoaderChildrenStory to init data.
2017:03:09 00:09:51	loading preprocessed files.
2017:03:09 00:09:57	the sample size is 95182, the vocab size is 18628
2017:03:09 00:10:31	use DataLoaderChildrenStory to init data.
2017:03:09 00:10:31	loading preprocessed files.
2017:03:09 00:10:38	the sample size is 95182, the vocab size is 18628
2017:03:09 00:11:37	use DataLoaderChildrenStory to init data.
2017:03:09 00:11:37	loading preprocessed files.
2017:03:09 00:11:43	the sample size is 95182, the vocab size is 18628
2017:03:09 00:13:27	use DataLoaderChildrenStory to init data.
2017:03:09 00:13:27	loading preprocessed files.
2017:03:09 00:13:34	the sample size is 95182, the vocab size is 18628
2017:03:09 00:14:10	use DataLoaderChildrenStory to init data.
2017:03:09 00:14:10	loading preprocessed files.
2017:03:09 00:14:16	the sample size is 95182, the vocab size is 18628
2017:03:09 00:19:02	use DataLoaderChildrenStory to init data.
2017:03:09 00:19:02	loading preprocessed files.
2017:03:09 00:19:09	the sample size is 95182, the vocab size is 18628
2017:03:09 00:20:20	use DataLoaderChildrenStory to init data.
2017:03:09 00:20:20	loading preprocessed files.
2017:03:09 00:20:27	the sample size is 95182, the vocab size is 18628
2017:03:09 00:21:09	use DataLoaderChildrenStory to init data.
2017:03:09 00:21:09	loading preprocessed files.
2017:03:09 00:21:15	the sample size is 95182, the vocab size is 18628
2017:03:09 00:23:13	use DataLoaderChildrenStory to init data.
2017:03:09 00:23:13	loading preprocessed files.
2017:03:09 00:23:19	the sample size is 95182, the vocab size is 18628
2017:03:09 00:23:46	use DataLoaderChildrenStory to init data.
2017:03:09 00:23:46	loading preprocessed files.
2017:03:09 00:23:53	the sample size is 95182, the vocab size is 18628
2017:03:09 00:25:09	use DataLoaderChildrenStory to init data.
2017:03:09 00:25:09	loading preprocessed files.
2017:03:09 00:25:16	the sample size is 95182, the vocab size is 18628
2017:03:09 00:25:55	use DataLoaderChildrenStory to init data.
2017:03:09 00:25:55	loading preprocessed files.
2017:03:09 00:26:01	the sample size is 95182, the vocab size is 18628
2017:03:09 00:27:10	use DataLoaderChildrenStory to init data.
2017:03:09 00:27:10	loading preprocessed files.
2017:03:09 00:27:16	the sample size is 95182, the vocab size is 18628
2017:03:09 00:28:00	use DataLoaderChildrenStory to init data.
2017:03:09 00:28:00	loading preprocessed files.
2017:03:09 00:28:06	the sample size is 95182, the vocab size is 18628
2017:03:09 15:36:56	use DataLoaderChildrenStory to init data.
2017:03:09 15:36:56	reading and processing the text file.
2017:03:09 15:36:56	preprocess the dataset.
2017:03:09 15:37:01	...mask and pad the sentence.
2017:03:09 15:37:01	......max len:19, median len:9.0, min len:2
2017:03:09 15:37:02	build a vocabulary.
2017:03:09 15:37:02	...flatmap a list of sentence list to a list of sentence.
2017:03:09 15:37:03	...mapping from index to word.
2017:03:09 15:37:03	...mapping from word to index.
2017:03:09 15:37:03	...map word to index.
2017:03:09 15:37:03	...some data statistics.
2017:03:09 15:37:03	...save processed data to file.
2017:03:09 15:37:07	the sample size is 95182, the vocab size is 18628
2017:03:09 15:39:15	use DataLoaderChildrenStory to init data.
2017:03:09 15:39:15	loading preprocessed files.
2017:03:09 15:39:23	the sample size is 95182, the vocab size is 18628
2017:03:09 15:40:58	use DataLoaderChildrenStory to init data.
2017:03:09 15:40:58	loading preprocessed files.
2017:03:09 15:41:05	the sample size is 95182, the vocab size is 18628
2017:03:09 16:23:00	use DataLoaderChildrenStory to init data.
2017:03:09 16:23:00	loading preprocessed files.
2017:03:09 16:23:07	the sample size is 95182, the vocab size is 18628
2017:03:09 16:23:10	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076590

2017:03:09 16:24:52	use DataLoaderChildrenStory to init data.
2017:03:09 16:24:52	loading preprocessed files.
2017:03:09 16:24:59	the sample size is 95182, the vocab size is 18628
2017:03:09 16:25:03	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076703

2017:03:09 16:25:33	use DataLoaderChildrenStory to init data.
2017:03:09 16:25:33	loading preprocessed files.
2017:03:09 16:25:40	the sample size is 95182, the vocab size is 18628
2017:03:09 16:25:43	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076743

2017:03:09 16:26:13	use DataLoaderChildrenStory to init data.
2017:03:09 16:26:13	loading preprocessed files.
2017:03:09 16:26:20	the sample size is 95182, the vocab size is 18628
2017:03:09 16:26:23	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489076783

2017:03:09 17:02:45	use DataLoaderChildrenStory to init data.
2017:03:09 17:02:45	loading preprocessed files.
2017:03:09 17:02:54	the sample size is 95182, the vocab size is 18628
2017:03:09 17:02:57	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489078977

2017:03:09 17:03:25	use DataLoaderChildrenStory to init data.
2017:03:09 17:03:25	loading preprocessed files.
2017:03:09 17:03:32	the sample size is 95182, the vocab size is 18628
2017:03:09 17:03:35	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489079015

2017:03:09 17:04:17	use DataLoaderChildrenStory to init data.
2017:03:09 17:04:17	loading preprocessed files.
2017:03:09 17:04:24	the sample size is 95182, the vocab size is 18628
2017:03:09 17:04:28	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489079067

2017:03:09 18:32:49	use DataLoaderChildrenStory to init data.
2017:03:09 18:32:49	loading preprocessed files.
2017:03:09 18:32:56	the sample size is 95182, the vocab size is 18628
2017:03:09 18:32:59	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489084379

2017:03:09 19:43:35	use DataLoaderChildrenStory to init data.
2017:03:09 19:43:35	loading preprocessed files.
2017:03:09 19:43:42	the sample size is 95182, the vocab size is 18628
2017:03:09 19:43:46	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489088626

2017:03:09 19:53:00	use DataLoaderChildrenStory to init data.
2017:03:09 19:53:00	loading preprocessed files.
2017:03:09 19:53:10	the sample size is 95182, the vocab size is 18628
2017:03:09 19:53:53	use DataLoaderChildrenStory to init data.
2017:03:09 19:53:53	loading preprocessed files.
2017:03:09 19:53:59	the sample size is 95182, the vocab size is 18628
2017:03:09 19:55:09	use DataLoaderChildrenStory to init data.
2017:03:09 19:55:09	loading preprocessed files.
2017:03:09 19:55:17	the sample size is 95182, the vocab size is 18628
2017:03:09 19:55:26	use DataLoaderChildrenStory to init data.
2017:03:09 19:55:26	loading preprocessed files.
2017:03:09 19:55:33	the sample size is 95182, the vocab size is 18628
2017:03:09 19:55:36	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089336

2017:03:09 19:56:35	use DataLoaderChildrenStory to init data.
2017:03:09 19:56:35	loading preprocessed files.
2017:03:09 19:56:41	the sample size is 95182, the vocab size is 18628
2017:03:09 19:56:44	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089404

2017:03:09 19:58:36	use DataLoaderChildrenStory to init data.
2017:03:09 19:58:36	loading preprocessed files.
2017:03:09 19:58:44	the sample size is 95182, the vocab size is 18628
2017:03:09 19:58:47	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089527

2017:03:09 19:59:32	use DataLoaderChildrenStory to init data.
2017:03:09 19:59:32	loading preprocessed files.
2017:03:09 19:59:39	the sample size is 95182, the vocab size is 18628
2017:03:09 19:59:42	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089582

2017:03:09 20:00:30	use DataLoaderChildrenStory to init data.
2017:03:09 20:00:30	loading preprocessed files.
2017:03:09 20:00:37	the sample size is 95182, the vocab size is 18628
2017:03:09 20:00:40	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089640

2017:03:09 20:02:00	use DataLoaderChildrenStory to init data.
2017:03:09 20:02:00	loading preprocessed files.
2017:03:09 20:02:07	the sample size is 95182, the vocab size is 18628
2017:03:09 20:02:36	use DataLoaderChildrenStory to init data.
2017:03:09 20:02:36	loading preprocessed files.
2017:03:09 20:02:43	the sample size is 95182, the vocab size is 18628
2017:03:09 20:02:47	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089767

2017:03:09 20:03:45	use DataLoaderChildrenStory to init data.
2017:03:09 20:03:45	loading preprocessed files.
2017:03:09 20:03:54	the sample size is 95182, the vocab size is 18628
2017:03:09 20:03:57	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489089837

2017:03:09 20:04:38	use DataLoaderChildrenStory to init data.
2017:03:09 20:04:38	loading preprocessed files.
2017:03:09 20:04:44	the sample size is 95182, the vocab size is 18628
2017:03:09 20:05:17	use DataLoaderChildrenStory to init data.
2017:03:09 20:05:17	loading preprocessed files.
2017:03:09 20:05:24	the sample size is 95182, the vocab size is 18628
2017:03:09 20:06:13	use DataLoaderChildrenStory to init data.
2017:03:09 20:06:13	loading preprocessed files.
2017:03:09 20:06:20	the sample size is 95182, the vocab size is 18628
2017:03:09 20:06:43	use DataLoaderChildrenStory to init data.
2017:03:09 20:06:43	loading preprocessed files.
2017:03:09 20:06:49	the sample size is 95182, the vocab size is 18628
2017:03:09 20:08:02	use DataLoaderChildrenStory to init data.
2017:03:09 20:08:02	loading preprocessed files.
2017:03:09 20:08:09	the sample size is 95182, the vocab size is 18628
2017:03:09 20:08:17	use DataLoaderChildrenStory to init data.
2017:03:09 20:08:17	loading preprocessed files.
2017:03:09 20:08:23	the sample size is 95182, the vocab size is 18628
2017:03:09 20:08:26	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090106

2017:03:09 20:11:05	use DataLoaderChildrenStory to init data.
2017:03:09 20:11:05	loading preprocessed files.
2017:03:09 20:11:13	the sample size is 95182, the vocab size is 18628
2017:03:09 20:11:46	use DataLoaderChildrenStory to init data.
2017:03:09 20:11:46	loading preprocessed files.
2017:03:09 20:11:53	the sample size is 95182, the vocab size is 18628
2017:03:09 20:11:56	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090316

2017:03:09 20:13:00	use DataLoaderChildrenStory to init data.
2017:03:09 20:13:00	loading preprocessed files.
2017:03:09 20:13:08	the sample size is 95182, the vocab size is 18628
2017:03:09 20:13:12	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090391

2017:03:09 20:21:58	use DataLoaderChildrenStory to init data.
2017:03:09 20:21:58	reading and processing the text file.
2017:03:09 20:21:58	preprocess the dataset.
2017:03:09 20:22:03	...mask and pad the sentence.
2017:03:09 20:22:03	......max len:20, median len:10.0, min len:3
2017:03:09 20:22:04	build a vocabulary.
2017:03:09 20:22:04	...flatmap a list of sentence list to a list of sentence.
2017:03:09 20:22:05	...mapping from index to word.
2017:03:09 20:22:05	...mapping from word to index.
2017:03:09 20:22:05	...map word to index.
2017:03:09 20:22:07	...some data statistics.
2017:03:09 20:22:07	...save processed data to file.
2017:03:09 20:22:12	the sample size is 97314, the vocab size is 18739
2017:03:09 20:22:15	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489090935

2017:03:09 20:27:28	use DataLoaderChildrenStory to init data.
2017:03:09 20:27:28	loading preprocessed files.
2017:03:09 20:27:41	the sample size is 97314, the vocab size is 18739
2017:03:09 20:27:44	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489091264

2017:03:10 10:05:00	use DataLoaderChildrenStory to init data.
2017:03:10 10:05:00	loading preprocessed files.
2017:03:10 10:05:08	the sample size is 97314, the vocab size is 18739
2017:03:10 10:09:00	use DataLoaderChildrenStory to init data.
2017:03:10 10:09:00	loading preprocessed files.
2017:03:10 10:09:08	the sample size is 97314, the vocab size is 18739
2017:03:10 10:17:11	use DataLoaderChildrenStory to init data.
2017:03:10 10:17:11	loading preprocessed files.
2017:03:10 10:17:19	the sample size is 97314, the vocab size is 18739
2017:03:10 10:22:41	use DataLoaderChildrenStory to init data.
2017:03:10 10:22:41	loading preprocessed files.
2017:03:10 10:22:49	the sample size is 97314, the vocab size is 18739
2017:03:10 10:23:06	use DataLoaderChildrenStory to init data.
2017:03:10 10:23:06	loading preprocessed files.
2017:03:10 10:23:13	the sample size is 97314, the vocab size is 18739
2017:03:10 12:52:55	use DataLoaderChildrenStory to init data.
2017:03:10 12:52:55	loading preprocessed files.
2017:03:10 12:53:03	the sample size is 97314, the vocab size is 18739
2017:03:10 12:53:37	use DataLoaderChildrenStory to init data.
2017:03:10 12:53:37	loading preprocessed files.
2017:03:10 12:53:43	the sample size is 97314, the vocab size is 18739
2017:03:10 13:24:25	use DataLoaderChildrenStory to init data.
2017:03:10 13:24:25	loading preprocessed files.
2017:03:10 13:24:33	the sample size is 97314, the vocab size is 18739
2017:03:10 13:25:03	use DataLoaderChildrenStory to init data.
2017:03:10 13:25:03	loading preprocessed files.
2017:03:10 13:25:12	the sample size is 97314, the vocab size is 18739
2017:03:10 13:27:03	use DataLoaderChildrenStory to init data.
2017:03:10 13:27:03	loading preprocessed files.
2017:03:10 13:27:11	the sample size is 97314, the vocab size is 18739
2017:03:10 13:30:02	use DataLoaderChildrenStory to init data.
2017:03:10 13:30:02	loading preprocessed files.
2017:03:10 13:30:10	the sample size is 97314, the vocab size is 18739
2017:03:10 13:31:53	use DataLoaderChildrenStory to init data.
2017:03:10 13:31:53	loading preprocessed files.
2017:03:10 13:32:01	the sample size is 97314, the vocab size is 18739
2017:03:10 14:04:41	use DataLoaderChildrenStory to init data.
2017:03:10 14:04:41	loading preprocessed files.
2017:03:10 14:04:48	the sample size is 97314, the vocab size is 18739
2017:03:10 14:06:44	use DataLoaderChildrenStory to init data.
2017:03:10 14:06:44	loading preprocessed files.
2017:03:10 14:06:51	the sample size is 97314, the vocab size is 18739
2017:03:10 14:08:09	use DataLoaderChildrenStory to init data.
2017:03:10 14:08:09	loading preprocessed files.
2017:03:10 14:08:17	the sample size is 97314, the vocab size is 18739
2017:03:10 14:09:06	use DataLoaderChildrenStory to init data.
2017:03:10 14:09:06	loading preprocessed files.
2017:03:10 14:09:14	the sample size is 97314, the vocab size is 18739
2017:03:10 14:16:31	use DataLoaderChildrenStory to init data.
2017:03:10 14:16:31	loading preprocessed files.
2017:03:10 14:16:39	the sample size is 97314, the vocab size is 18739
2017:03:10 14:18:23	use DataLoaderChildrenStory to init data.
2017:03:10 14:18:23	loading preprocessed files.
2017:03:10 14:18:30	the sample size is 97314, the vocab size is 18739
2017:03:10 14:21:17	use DataLoaderChildrenStory to init data.
2017:03:10 14:21:17	loading preprocessed files.
2017:03:10 14:21:24	the sample size is 97314, the vocab size is 18739
2017:03:10 14:21:46	use DataLoaderChildrenStory to init data.
2017:03:10 14:21:46	loading preprocessed files.
2017:03:10 14:21:55	the sample size is 97314, the vocab size is 18739
2017:03:10 14:22:01	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489155721

2017:03:10 14:22:03	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489155721

2017:03:10 14:22:05	------ do the pretrain ------ 

2017:03:10 14:24:47	use DataLoaderChildrenStory to init data.
2017:03:10 14:24:47	loading preprocessed files.
2017:03:10 14:24:55	the sample size is 97314, the vocab size is 18739
2017:03:10 14:25:01	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489155901

2017:03:10 14:25:05	------ do the pretrain ------ 

2017:03:10 15:18:57	use DataLoaderChildrenStory to init data.
2017:03:10 15:18:57	loading preprocessed files.
2017:03:10 15:19:05	the sample size is 97314, the vocab size is 18739
2017:03:10 15:19:24	use DataLoaderChildrenStory to init data.
2017:03:10 15:19:24	loading preprocessed files.
2017:03:10 15:19:31	the sample size is 97314, the vocab size is 18739
2017:03:10 15:19:40	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159179

2017:03:10 15:19:43	------ do the pretrain ------ 

2017:03:10 15:25:16	use DataLoaderChildrenStory to init data.
2017:03:10 15:25:16	loading preprocessed files.
2017:03:10 15:25:24	the sample size is 97314, the vocab size is 18739
2017:03:10 15:26:05	use DataLoaderChildrenStory to init data.
2017:03:10 15:26:05	loading preprocessed files.
2017:03:10 15:26:12	the sample size is 97314, the vocab size is 18739
2017:03:10 15:27:10	use DataLoaderChildrenStory to init data.
2017:03:10 15:27:10	loading preprocessed files.
2017:03:10 15:27:17	the sample size is 97314, the vocab size is 18739
2017:03:10 15:27:23	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159643

2017:03:10 15:27:27	------ do the pretrain ------ 

2017:03:10 15:28:54	use DataLoaderChildrenStory to init data.
2017:03:10 15:28:54	loading preprocessed files.
2017:03:10 15:29:01	the sample size is 97314, the vocab size is 18739
2017:03:10 15:29:07	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159747

2017:03:10 15:31:03	use DataLoaderChildrenStory to init data.
2017:03:10 15:31:03	loading preprocessed files.
2017:03:10 15:31:10	the sample size is 97314, the vocab size is 18739
2017:03:10 15:31:17	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159877

2017:03:10 15:31:49	use DataLoaderChildrenStory to init data.
2017:03:10 15:31:49	loading preprocessed files.
2017:03:10 15:31:57	the sample size is 97314, the vocab size is 18739
2017:03:10 15:32:19	use DataLoaderChildrenStory to init data.
2017:03:10 15:32:19	loading preprocessed files.
2017:03:10 15:32:26	the sample size is 97314, the vocab size is 18739
2017:03:10 15:32:32	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489159952

2017:03:10 15:33:32	use DataLoaderChildrenStory to init data.
2017:03:10 15:33:32	loading preprocessed files.
2017:03:10 15:33:40	the sample size is 97314, the vocab size is 18739
2017:03:10 15:34:06	use DataLoaderChildrenStory to init data.
2017:03:10 15:34:06	loading preprocessed files.
2017:03:10 15:34:25	use DataLoaderChildrenStory to init data.
2017:03:10 15:34:25	loading preprocessed files.
2017:03:10 15:34:32	the sample size is 97314, the vocab size is 18739
2017:03:10 15:35:07	use DataLoaderChildrenStory to init data.
2017:03:10 15:35:07	loading preprocessed files.
2017:03:10 15:35:15	the sample size is 97314, the vocab size is 18739
2017:03:10 15:36:35	use DataLoaderChildrenStory to init data.
2017:03:10 15:36:35	loading preprocessed files.
2017:03:10 15:36:43	the sample size is 97314, the vocab size is 18739
2017:03:10 15:37:23	use DataLoaderChildrenStory to init data.
2017:03:10 15:37:23	loading preprocessed files.
2017:03:10 15:37:31	the sample size is 97314, the vocab size is 18739
2017:03:10 15:37:59	use DataLoaderChildrenStory to init data.
2017:03:10 15:37:59	loading preprocessed files.
2017:03:10 15:38:06	the sample size is 97314, the vocab size is 18739
2017:03:10 15:38:13	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489160292

2017:03:10 15:38:16	------ do the pretrain ------ 

2017:03:10 15:39:12	use DataLoaderChildrenStory to init data.
2017:03:10 15:39:12	loading preprocessed files.
2017:03:10 15:39:19	the sample size is 97314, the vocab size is 18739
2017:03:10 15:40:22	use DataLoaderChildrenStory to init data.
2017:03:10 15:40:22	loading preprocessed files.
2017:03:10 15:40:30	the sample size is 97314, the vocab size is 18739
2017:03:10 15:41:50	use DataLoaderChildrenStory to init data.
2017:03:10 15:41:50	loading preprocessed files.
2017:03:10 15:41:57	the sample size is 97314, the vocab size is 18739
2017:03:10 16:52:18	use DataLoaderChildrenStory to init data.
2017:03:10 16:52:18	loading preprocessed files.
2017:03:10 16:52:25	the sample size is 97314, the vocab size is 18739
2017:03:10 16:52:46	use DataLoaderChildrenStory to init data.
2017:03:10 16:52:46	loading preprocessed files.
2017:03:10 16:52:52	the sample size is 97314, the vocab size is 18739
2017:03:10 16:54:08	use DataLoaderChildrenStory to init data.
2017:03:10 16:54:08	loading preprocessed files.
2017:03:10 16:54:15	the sample size is 97314, the vocab size is 18739
2017:03:10 16:55:27	use DataLoaderChildrenStory to init data.
2017:03:10 16:55:27	loading preprocessed files.
2017:03:10 16:55:34	the sample size is 97314, the vocab size is 18739
2017:03:10 16:55:58	use DataLoaderChildrenStory to init data.
2017:03:10 16:55:58	loading preprocessed files.
2017:03:10 16:56:05	the sample size is 97314, the vocab size is 18739
2017:03:10 17:03:23	use DataLoaderChildrenStory to init data.
2017:03:10 17:03:23	loading preprocessed files.
2017:03:10 17:03:30	the sample size is 97314, the vocab size is 18739
2017:03:10 17:03:37	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489165416

2017:03:10 17:03:41	------ do the pretrain ------ 

2017:03:10 17:04:59	use DataLoaderChildrenStory to init data.
2017:03:10 17:04:59	loading preprocessed files.
2017:03:10 17:05:06	the sample size is 97314, the vocab size is 18739
2017:03:10 17:05:40	use DataLoaderChildrenStory to init data.
2017:03:10 17:05:40	loading preprocessed files.
2017:03:10 17:05:47	the sample size is 97314, the vocab size is 18739
2017:03:10 17:06:29	use DataLoaderChildrenStory to init data.
2017:03:10 17:06:29	loading preprocessed files.
2017:03:10 17:06:36	the sample size is 97314, the vocab size is 18739
2017:03:10 17:07:44	use DataLoaderChildrenStory to init data.
2017:03:10 17:07:44	loading preprocessed files.
2017:03:10 17:07:50	the sample size is 97314, the vocab size is 18739
2017:03:10 17:08:01	use DataLoaderChildrenStory to init data.
2017:03:10 17:08:01	loading preprocessed files.
2017:03:10 17:08:08	the sample size is 97314, the vocab size is 18739
2017:03:10 17:10:51	use DataLoaderChildrenStory to init data.
2017:03:10 17:10:51	loading preprocessed files.
2017:03:10 17:10:58	the sample size is 97314, the vocab size is 18739
2017:03:10 17:11:20	use DataLoaderChildrenStory to init data.
2017:03:10 17:11:20	loading preprocessed files.
2017:03:10 17:11:27	the sample size is 97314, the vocab size is 18739
2017:03:10 17:16:09	use DataLoaderChildrenStory to init data.
2017:03:10 17:16:09	loading preprocessed files.
2017:03:10 17:16:16	the sample size is 97314, the vocab size is 18739
2017:03:10 17:16:26	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166186

2017:03:10 17:16:32	------ do the pretrain ------ 

2017:03:10 17:16:48	use DataLoaderChildrenStory to init data.
2017:03:10 17:16:48	loading preprocessed files.
2017:03:10 17:16:55	the sample size is 97314, the vocab size is 18739
2017:03:10 17:17:07	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166227

2017:03:10 17:17:13	------ do the pretrain ------ 

2017:03:10 17:18:18	use DataLoaderChildrenStory to init data.
2017:03:10 17:18:18	loading preprocessed files.
2017:03:10 17:18:25	the sample size is 97314, the vocab size is 18739
2017:03:10 17:18:34	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166314

2017:03:10 17:18:39	------ do the pretrain ------ 

2017:03:10 17:19:43	use DataLoaderChildrenStory to init data.
2017:03:10 17:19:43	loading preprocessed files.
2017:03:10 17:19:50	the sample size is 97314, the vocab size is 18739
2017:03:10 17:19:59	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489166399

2017:03:10 17:20:04	------ do the pretrain ------ 

2017:03:10 17:21:52	use DataLoaderChildrenStory to init data.
2017:03:10 17:21:52	loading preprocessed files.
2017:03:10 17:21:58	the sample size is 97314, the vocab size is 18739
2017:03:10 17:22:05	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489166524

2017:03:10 17:22:08	------ do the pretrain ------ 

2017:03:11 14:08:57	use DataLoaderChildrenStory to init data.
2017:03:11 14:08:57	loading preprocessed files.
2017:03:11 14:09:06	the sample size is 97314, the vocab size is 18739
2017:03:11 14:09:38	use DataLoaderChildrenStory to init data.
2017:03:11 14:09:38	loading preprocessed files.
2017:03:11 14:09:46	the sample size is 97314, the vocab size is 18739
2017:03:11 14:13:02	use DataLoaderChildrenStory to init data.
2017:03:11 14:13:02	loading preprocessed files.
2017:03:11 14:13:09	the sample size is 97314, the vocab size is 18739
2017:03:11 14:22:59	use DataLoaderChildrenStory to init data.
2017:03:11 14:22:59	loading preprocessed files.
2017:03:11 14:23:06	the sample size is 97314, the vocab size is 18739
2017:03:11 14:23:16	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV2.TextGANV2/1489242196

2017:03:11 14:23:21	------ do the pretrain ------ 

2017:03:12 21:48:43	use DataLoaderChildrenStory to init data.
2017:03:12 21:49:11	use DataLoaderChildrenStory to init data.
2017:03:12 21:49:11	loading preprocessed files.
2017:03:12 21:49:19	the sample size is 97314, the vocab size is 18739
2017:03:12 21:50:02	use DataLoaderChildrenStory to init data.
2017:03:12 21:50:02	loading preprocessed files.
2017:03:12 21:50:09	the sample size is 97314, the vocab size is 18739
2017:03:12 21:50:16	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355415

2017:03:12 21:50:19	------ do the pretrain ------ 

2017:03:12 21:53:24	use DataLoaderChildrenStory to init data.
2017:03:12 21:53:24	loading preprocessed files.
2017:03:12 21:53:32	the sample size is 97314, the vocab size is 18739
2017:03:12 21:53:38	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355618

2017:03:12 21:53:42	------ do the pretrain ------ 

2017:03:12 21:53:43	save best model to: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355618/checkpoints/bestmodel-0.

2017:03:12 21:53:43	------ do the standard GAN training ------ 

2017:03:12 21:53:43	------ generate sentence from latent space / noice ------ 

2017:03:12 21:55:14	use DataLoaderChildrenStory to init data.
2017:03:12 21:55:14	loading preprocessed files.
2017:03:12 21:55:21	the sample size is 97314, the vocab size is 18739
2017:03:12 21:55:27	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355727

2017:03:12 21:55:31	------ do the pretrain ------ 

2017:03:12 21:55:32	save best model to: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355727/checkpoints/bestmodel-0.

2017:03:12 21:55:32	------ do the standard GAN training ------ 

2017:03:12 21:55:32	------ generate sentence from latent space / noice ------ 

2017:03:12 21:56:51	use DataLoaderChildrenStory to init data.
2017:03:12 21:56:51	loading preprocessed files.
2017:03:12 21:56:59	the sample size is 97314, the vocab size is 18739
2017:03:12 21:57:05	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355825

2017:03:12 21:57:08	------ do the pretrain ------ 

2017:03:12 21:57:09	save best model to: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355825/checkpoints/bestmodel-0.

2017:03:12 21:57:09	------ do the standard GAN training ------ 

2017:03:12 21:57:09	------ generate sentence from latent space / noice ------ 

2017:03:12 21:58:05	use DataLoaderChildrenStory to init data.
2017:03:12 21:58:05	loading preprocessed files.
2017:03:12 21:58:12	the sample size is 97314, the vocab size is 18739
2017:03:12 21:58:18	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355898

2017:03:12 21:58:22	------ do the pretrain ------ 

2017:03:12 21:58:23	save best model to: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355898/checkpoints/bestmodel-0.

2017:03:12 21:58:23	------ do the standard GAN training ------ 

2017:03:12 21:58:23	------ generate sentence from latent space / noice ------ 

2017:03:12 21:58:55	use DataLoaderChildrenStory to init data.
2017:03:12 21:58:55	loading preprocessed files.
2017:03:12 21:59:03	the sample size is 97314, the vocab size is 18739
2017:03:12 21:59:10	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489355949

2017:03:12 22:01:03	use DataLoaderChildrenStory to init data.
2017:03:12 22:01:03	loading preprocessed files.
2017:03:12 22:01:11	the sample size is 97314, the vocab size is 18739
2017:03:12 22:01:18	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489356078

2017:03:12 22:01:22	------ do the pretrain ------ 

2017:03:12 22:01:22	save best model to: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489356078/checkpoints/bestmodel-0.

2017:03:12 22:01:22	------ do the standard GAN training ------ 

2017:03:12 22:01:22	------ generate sentence from latent space / noice ------ 

2017:03:12 23:21:39	use DataLoaderChildrenStory to init data.
2017:03:12 23:21:39	loading preprocessed files.
2017:03:12 23:21:47	the sample size is 97314, the vocab size is 18739
2017:03:12 23:22:36	use DataLoaderChildrenStory to init data.
2017:03:12 23:22:36	loading preprocessed files.
2017:03:12 23:22:43	the sample size is 97314, the vocab size is 18739
2017:03:12 23:23:19	use DataLoaderChildrenStory to init data.
2017:03:12 23:23:19	loading preprocessed files.
2017:03:12 23:23:26	the sample size is 97314, the vocab size is 18739
2017:03:12 23:23:45	use DataLoaderChildrenStory to init data.
2017:03:12 23:23:45	loading preprocessed files.
2017:03:12 23:23:52	the sample size is 97314, the vocab size is 18739
2017:03:12 23:28:21	use DataLoaderChildrenStory to init data.
2017:03:12 23:28:21	loading preprocessed files.
2017:03:12 23:28:28	the sample size is 97314, the vocab size is 18739
2017:03:12 23:31:40	use DataLoaderChildrenStory to init data.
2017:03:12 23:31:40	loading preprocessed files.
2017:03:12 23:31:47	the sample size is 97314, the vocab size is 18739
2017:03:12 23:36:45	use DataLoaderChildrenStory to init data.
2017:03:12 23:36:45	loading preprocessed files.
2017:03:12 23:36:52	the sample size is 97314, the vocab size is 18739
2017:03:12 23:36:59	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361819

2017:03:12 23:37:03	------ do the pretrain ------ 

2017:03:12 23:37:04	------ do the standard GAN training ------ 

2017:03:12 23:37:04	total execution time: 18
2017:03:12 23:37:40	use DataLoaderChildrenStory to init data.
2017:03:12 23:37:40	loading preprocessed files.
2017:03:12 23:37:47	the sample size is 97314, the vocab size is 18739
2017:03:12 23:39:15	use DataLoaderChildrenStory to init data.
2017:03:12 23:39:15	loading preprocessed files.
2017:03:12 23:39:22	the sample size is 97314, the vocab size is 18739
2017:03:12 23:39:29	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968

2017:03:12 23:39:33	------ do the pretrain ------ 

2017:03:12 23:39:33	save best model to: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0.

2017:03:12 23:39:33	------ do the standard GAN training ------ 

2017:03:12 23:39:33	total execution time: 18
2017:03:12 23:39:52	use DataLoaderChildrenStory to init data.
2017:03:12 23:39:52	loading preprocessed files.
2017:03:12 23:39:58	the sample size is 97314, the vocab size is 18739
2017:03:12 23:43:09	use DataLoaderChildrenStory to init data.
2017:03:12 23:43:09	loading preprocessed files.
2017:03:12 23:43:17	the sample size is 97314, the vocab size is 18739
2017:03:12 23:45:19	use DataLoaderChildrenStory to init data.
2017:03:12 23:45:19	loading preprocessed files.
2017:03:12 23:45:27	the sample size is 97314, the vocab size is 18739
2017:03:13 09:17:42	use DataLoaderChildrenStory to init data.
2017:03:13 09:17:42	loading preprocessed files.
2017:03:13 09:17:50	the sample size is 97314, the vocab size is 18739
2017:03:13 09:18:17	use DataLoaderChildrenStory to init data.
2017:03:13 09:18:17	loading preprocessed files.
2017:03:13 09:18:25	the sample size is 97314, the vocab size is 18739
2017:03:13 09:19:57	use DataLoaderChildrenStory to init data.
2017:03:13 09:19:57	loading preprocessed files.
2017:03:13 09:20:05	the sample size is 97314, the vocab size is 18739
2017:03:13 09:21:10	use DataLoaderChildrenStory to init data.
2017:03:13 09:21:10	loading preprocessed files.
2017:03:13 09:21:16	the sample size is 97314, the vocab size is 18739
2017:03:13 09:29:20	use DataLoaderChildrenStory to init data.
2017:03:13 09:29:20	loading preprocessed files.
2017:03:13 09:29:28	the sample size is 97314, the vocab size is 18739
2017:03:13 09:33:55	use DataLoaderChildrenStory to init data.
2017:03:13 09:33:55	loading preprocessed files.
2017:03:13 09:34:02	the sample size is 97314, the vocab size is 18739
2017:03:13 09:35:25	use DataLoaderChildrenStory to init data.
2017:03:13 09:35:25	loading preprocessed files.
2017:03:13 09:35:32	the sample size is 97314, the vocab size is 18739
2017:03:13 09:37:10	use DataLoaderChildrenStory to init data.
2017:03:13 09:37:10	loading preprocessed files.
2017:03:13 09:37:18	the sample size is 97314, the vocab size is 18739
2017:03:13 09:38:06	use DataLoaderChildrenStory to init data.
2017:03:13 09:38:06	loading preprocessed files.
2017:03:13 09:38:13	the sample size is 97314, the vocab size is 18739
2017:03:13 09:53:11	use DataLoaderChildrenStory to init data.
2017:03:13 09:53:11	loading preprocessed files.
2017:03:13 09:53:19	the sample size is 97314, the vocab size is 18739
2017:03:13 09:54:12	use DataLoaderChildrenStory to init data.
2017:03:13 09:54:12	loading preprocessed files.
2017:03:13 09:54:20	the sample size is 97314, the vocab size is 18739
2017:03:13 09:55:47	use DataLoaderChildrenStory to init data.
2017:03:13 09:55:47	loading preprocessed files.
2017:03:13 09:55:54	the sample size is 97314, the vocab size is 18739
2017:03:13 09:56:07	use DataLoaderChildrenStory to init data.
2017:03:13 09:56:07	loading preprocessed files.
2017:03:13 09:56:13	the sample size is 97314, the vocab size is 18739
2017:03:13 10:31:59	use DataLoaderChildrenStory to init data.
2017:03:13 10:31:59	loading preprocessed files.
2017:03:13 10:32:08	the sample size is 97314, the vocab size is 18739
2017:03:13 10:33:09	use DataLoaderChildrenStory to init data.
2017:03:13 10:33:09	loading preprocessed files.
2017:03:13 10:33:17	the sample size is 97314, the vocab size is 18739
2017:03:13 10:40:03	use DataLoaderChildrenStory to init data.
2017:03:13 10:40:03	loading preprocessed files.
2017:03:13 10:40:12	the sample size is 97314, the vocab size is 18739
2017:03:13 10:43:03	use DataLoaderChildrenStory to init data.
2017:03:13 10:43:03	loading preprocessed files.
2017:03:13 10:43:10	the sample size is 97314, the vocab size is 18739
2017:03:13 11:24:55	use DataLoaderChildrenStory to init data.
2017:03:13 11:24:55	loading preprocessed files.
2017:03:13 11:25:10	the sample size is 97314, the vocab size is 18739
2017:03:13 11:25:49	use DataLoaderChildrenStory to init data.
2017:03:13 11:25:49	loading preprocessed files.
2017:03:13 11:25:57	the sample size is 97314, the vocab size is 18739
2017:03:13 11:26:27	use DataLoaderChildrenStory to init data.
2017:03:13 11:26:27	loading preprocessed files.
2017:03:13 11:26:36	the sample size is 97314, the vocab size is 18739
2017:03:13 11:27:02	use DataLoaderChildrenStory to init data.
2017:03:13 11:27:02	loading preprocessed files.
2017:03:13 11:27:10	the sample size is 97314, the vocab size is 18739
2017:03:13 14:06:27	use DataLoaderChildrenStory to init data.
2017:03:13 14:06:27	loading preprocessed files.
2017:03:13 14:06:35	the sample size is 97314, the vocab size is 18739
2017:03:13 14:06:42	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489414002

2017:03:13 14:06:46	------ do the pretrain ------ 

2017:03:13 14:06:46	save bestmodel:1.

2017:03:13 14:06:46	------ do the standard GAN training ------ 

2017:03:13 14:06:46	total execution time: 19
2017:03:13 14:07:05	use DataLoaderChildrenStory to init data.
2017:03:13 14:07:05	loading preprocessed files.
2017:03:13 14:07:12	the sample size is 97314, the vocab size is 18739
2017:03:13 14:07:19	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489414038

2017:03:13 14:07:22	------ do the pretrain ------ 

2017:03:13 14:07:22	pretrain epoch 0
2017:03:13 14:58:07	use DataLoaderChildrenStory to init data.
2017:03:13 14:58:07	loading preprocessed files.
2017:03:13 14:58:15	the sample size is 97314, the vocab size is 18739
2017:03:13 14:59:09	use DataLoaderChildrenStory to init data.
2017:03:13 14:59:09	loading preprocessed files.
2017:03:13 14:59:16	the sample size is 97314, the vocab size is 18739
2017:03:13 14:59:49	use DataLoaderChildrenStory to init data.
2017:03:13 14:59:49	loading preprocessed files.
2017:03:13 14:59:56	the sample size is 97314, the vocab size is 18739
2017:03:13 15:00:04	use DataLoaderChildrenStory to init data.
2017:03:13 15:00:04	loading preprocessed files.
2017:03:13 15:00:11	the sample size is 97314, the vocab size is 18739
2017:03:13 15:00:34	use DataLoaderChildrenStory to init data.
2017:03:13 15:00:34	loading preprocessed files.
2017:03:13 15:00:41	the sample size is 97314, the vocab size is 18739
2017:03:13 15:01:23	use DataLoaderChildrenStory to init data.
2017:03:13 15:01:23	loading preprocessed files.
2017:03:13 15:01:30	the sample size is 97314, the vocab size is 18739
2017:03:13 15:02:59	use DataLoaderChildrenStory to init data.
2017:03:13 15:02:59	loading preprocessed files.
2017:03:13 15:03:05	the sample size is 97314, the vocab size is 18739
2017:03:13 15:03:30	use DataLoaderChildrenStory to init data.
2017:03:13 15:03:30	loading preprocessed files.
2017:03:13 15:03:37	the sample size is 97314, the vocab size is 18739
2017:03:13 15:04:00	use DataLoaderChildrenStory to init data.
2017:03:13 15:04:00	loading preprocessed files.
2017:03:13 15:04:07	the sample size is 97314, the vocab size is 18739
2017:03:13 15:06:46	use DataLoaderChildrenStory to init data.
2017:03:13 15:06:46	loading preprocessed files.
2017:03:13 15:06:53	the sample size is 97314, the vocab size is 18739
2017:03:13 15:07:50	use DataLoaderChildrenStory to init data.
2017:03:13 15:07:50	loading preprocessed files.
2017:03:13 15:07:56	the sample size is 97314, the vocab size is 18739
2017:03:13 15:08:03	restore checkpoint_file from path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0
2017:03:13 15:09:05	use DataLoaderChildrenStory to init data.
2017:03:13 15:09:05	loading preprocessed files.
2017:03:13 15:09:12	the sample size is 97314, the vocab size is 18739
2017:03:13 15:09:18	restore checkpoint_file from path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0
2017:03:13 15:09:19	generate sentence and write to path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints
2017:03:13 15:09:23	use DataLoaderChildrenStory to init data.
2017:03:13 15:09:23	loading preprocessed files.
2017:03:13 15:09:30	the sample size is 97314, the vocab size is 18739
2017:03:13 15:09:36	restore checkpoint_file from path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints/bestmodel-0
2017:03:13 15:09:37	generate sentence and write to path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489361968/checkpoints
2017:03:13 15:53:32	use DataLoaderChildrenStory to init data.
2017:03:13 15:53:32	loading preprocessed files.
2017:03:13 15:53:40	the sample size is 97314, the vocab size is 18739
2017:03:13 15:53:46	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489420426

2017:03:13 15:54:33	use DataLoaderChildrenStory to init data.
2017:03:13 15:54:33	loading preprocessed files.
2017:03:13 15:54:40	the sample size is 97314, the vocab size is 18739
2017:03:13 15:54:47	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489420487

2017:03:13 15:54:50	------ do the pretrain ------ 

2017:03:13 15:54:50	pretrain epoch 0
2017:03:13 16:13:18	use DataLoaderChildrenStory to init data.
2017:03:13 16:13:18	loading preprocessed files.
2017:03:13 16:13:25	the sample size is 97314, the vocab size is 18739
2017:03:13 16:14:08	use DataLoaderChildrenStory to init data.
2017:03:13 16:14:08	loading preprocessed files.
2017:03:13 16:14:16	the sample size is 97314, the vocab size is 18739
2017:03:13 16:14:36	use DataLoaderChildrenStory to init data.
2017:03:13 16:14:36	loading preprocessed files.
2017:03:13 16:14:44	the sample size is 97314, the vocab size is 18739
2017:03:13 16:16:23	use DataLoaderChildrenStory to init data.
2017:03:13 16:16:23	loading preprocessed files.
2017:03:13 16:16:30	the sample size is 97314, the vocab size is 18739
2017:03:13 16:16:44	use DataLoaderChildrenStory to init data.
2017:03:13 16:16:44	loading preprocessed files.
2017:03:13 16:16:51	the sample size is 97314, the vocab size is 18739
2017:03:13 16:17:13	use DataLoaderChildrenStory to init data.
2017:03:13 16:17:13	loading preprocessed files.
2017:03:13 16:17:20	the sample size is 97314, the vocab size is 18739
2017:03:13 16:20:50	use DataLoaderChildrenStory to init data.
2017:03:13 16:20:50	loading preprocessed files.
2017:03:13 16:20:57	the sample size is 97314, the vocab size is 18739
2017:03:13 16:21:24	use DataLoaderChildrenStory to init data.
2017:03:13 16:21:24	loading preprocessed files.
2017:03:13 16:21:31	the sample size is 97314, the vocab size is 18739
2017:03:13 16:21:49	use DataLoaderChildrenStory to init data.
2017:03:13 16:21:49	loading preprocessed files.
2017:03:13 16:21:56	the sample size is 97314, the vocab size is 18739
2017:03:13 16:23:14	use DataLoaderChildrenStory to init data.
2017:03:13 16:23:14	loading preprocessed files.
2017:03:13 16:23:21	the sample size is 97314, the vocab size is 18739
2017:03:13 16:29:59	use DataLoaderChildrenStory to init data.
2017:03:13 16:29:59	loading preprocessed files.
2017:03:13 16:30:07	the sample size is 97314, the vocab size is 18739
2017:03:13 16:34:17	use DataLoaderChildrenStory to init data.
2017:03:13 16:34:17	loading preprocessed files.
2017:03:13 16:34:25	the sample size is 97314, the vocab size is 18739
2017:03:13 16:34:31	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489422871

2017:03:13 16:34:35	------ do the pretrain ------ 

2017:03:13 16:34:35	pretrain epoch 0
2017:03:13 16:35:53	use DataLoaderChildrenStory to init data.
2017:03:13 16:35:53	loading preprocessed files.
2017:03:13 16:36:01	the sample size is 97314, the vocab size is 18739
2017:03:13 16:38:09	use DataLoaderChildrenStory to init data.
2017:03:13 16:38:09	loading preprocessed files.
2017:03:13 16:38:16	the sample size is 97314, the vocab size is 18739
2017:03:13 16:38:30	use DataLoaderChildrenStory to init data.
2017:03:13 16:38:30	loading preprocessed files.
2017:03:13 16:38:37	the sample size is 97314, the vocab size is 18739
2017:03:13 16:38:43	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489423123

2017:03:13 16:38:46	------ do the pretrain ------ 

2017:03:13 16:38:46	pretrain epoch 0
2017:03:13 16:39:26	use DataLoaderChildrenStory to init data.
2017:03:13 16:39:26	loading preprocessed files.
2017:03:13 16:39:33	the sample size is 97314, the vocab size is 18739
2017:03:13 16:40:34	use DataLoaderChildrenStory to init data.
2017:03:13 16:40:34	loading preprocessed files.
2017:03:13 16:40:41	the sample size is 97314, the vocab size is 18739
2017:03:13 16:56:10	use DataLoaderChildrenStory to init data.
2017:03:13 16:56:10	loading preprocessed files.
2017:03:13 16:56:17	the sample size is 97314, the vocab size is 18739
2017:03:13 16:56:43	use DataLoaderChildrenStory to init data.
2017:03:13 16:56:43	loading preprocessed files.
2017:03:13 16:56:50	the sample size is 97314, the vocab size is 18739
2017:03:13 16:56:59	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424219

2017:03:13 16:58:58	use DataLoaderChildrenStory to init data.
2017:03:13 16:58:58	loading preprocessed files.
2017:03:13 16:59:06	the sample size is 97314, the vocab size is 18739
2017:03:13 16:59:31	use DataLoaderChildrenStory to init data.
2017:03:13 16:59:31	loading preprocessed files.
2017:03:13 16:59:38	the sample size is 97314, the vocab size is 18739
2017:03:13 16:59:56	use DataLoaderChildrenStory to init data.
2017:03:13 16:59:56	loading preprocessed files.
2017:03:13 17:00:03	the sample size is 97314, the vocab size is 18739
2017:03:13 17:01:12	use DataLoaderChildrenStory to init data.
2017:03:13 17:01:12	loading preprocessed files.
2017:03:13 17:01:19	the sample size is 97314, the vocab size is 18739
2017:03:13 17:02:25	use DataLoaderChildrenStory to init data.
2017:03:13 17:02:25	loading preprocessed files.
2017:03:13 17:02:32	the sample size is 97314, the vocab size is 18739
2017:03:13 17:04:50	use DataLoaderChildrenStory to init data.
2017:03:13 17:04:50	loading preprocessed files.
2017:03:13 17:04:57	the sample size is 97314, the vocab size is 18739
2017:03:13 17:05:08	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424707

2017:03:13 17:05:13	------ do the pretrain ------ 

2017:03:13 17:05:39	use DataLoaderChildrenStory to init data.
2017:03:13 17:05:39	loading preprocessed files.
2017:03:13 17:05:46	the sample size is 97314, the vocab size is 18739
2017:03:13 17:05:56	use DataLoaderChildrenStory to init data.
2017:03:13 17:05:56	loading preprocessed files.
2017:03:13 17:06:03	the sample size is 97314, the vocab size is 18739
2017:03:13 17:06:14	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424774

2017:03:13 17:07:25	use DataLoaderChildrenStory to init data.
2017:03:13 17:07:25	loading preprocessed files.
2017:03:13 17:07:32	the sample size is 97314, the vocab size is 18739
2017:03:13 17:07:44	use DataLoaderChildrenStory to init data.
2017:03:13 17:07:44	loading preprocessed files.
2017:03:13 17:07:51	the sample size is 97314, the vocab size is 18739
2017:03:13 17:08:01	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489424881

2017:03:13 17:08:06	------ do the pretrain ------ 

2017:03:13 17:08:08	save bestmodel:1.

2017:03:13 17:08:08	------ do the standard GAN training ------ 

2017:03:13 17:08:08	total execution time: 23
2017:03:13 18:18:23	use DataLoaderChildrenStory to init data.
2017:03:13 18:18:23	loading preprocessed files.
2017:03:13 18:18:29	the sample size is 97314, the vocab size is 18739
2017:03:13 18:22:18	use DataLoaderChildrenStory to init data.
2017:03:13 18:22:18	loading preprocessed files.
2017:03:13 18:22:24	the sample size is 97314, the vocab size is 18739
2017:03:13 18:37:52	use DataLoaderChildrenStory to init data.
2017:03:13 18:37:52	loading preprocessed files.
2017:03:13 18:37:59	the sample size is 97314, the vocab size is 18739
2017:03:13 18:39:38	use DataLoaderChildrenStory to init data.
2017:03:13 18:39:38	loading preprocessed files.
2017:03:13 18:39:45	the sample size is 97314, the vocab size is 18739
2017:03:13 18:40:12	use DataLoaderChildrenStory to init data.
2017:03:13 18:40:12	loading preprocessed files.
2017:03:13 18:40:19	the sample size is 97314, the vocab size is 18739
2017:03:13 18:42:15	use DataLoaderChildrenStory to init data.
2017:03:13 18:42:15	loading preprocessed files.
2017:03:13 18:42:22	the sample size is 97314, the vocab size is 18739
2017:03:13 18:42:27	use DataLoaderChildrenStory to init data.
2017:03:13 18:42:27	loading preprocessed files.
2017:03:13 18:42:36	the sample size is 97314, the vocab size is 18739
2017:03:13 18:42:46	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489430566

2017:03:13 18:42:51	------ do the pretrain ------ 

2017:03:13 18:42:51	pretrain epoch 0
2017:03:13 18:42:59	use DataLoaderChildrenStory to init data.
2017:03:13 18:42:59	loading preprocessed files.
2017:03:13 18:43:06	the sample size is 97314, the vocab size is 18739
2017:03:13 18:45:09	use DataLoaderChildrenStory to init data.
2017:03:13 18:45:09	loading preprocessed files.
2017:03:13 18:45:16	the sample size is 97314, the vocab size is 18739
2017:03:13 18:46:43	use DataLoaderChildrenStory to init data.
2017:03:13 18:46:43	loading preprocessed files.
2017:03:13 18:46:50	the sample size is 97314, the vocab size is 18739
2017:03:13 18:47:02	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV2.TextGANV2/1489430822

2017:03:13 18:47:07	------ do the pretrain ------ 

2017:03:13 18:47:07	pretrain epoch 0
2017:03:13 18:47:19	use DataLoaderChildrenStory to init data.
2017:03:13 18:47:19	loading preprocessed files.
2017:03:13 18:47:26	the sample size is 97314, the vocab size is 18739
2017:03:13 18:47:36	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489430856

2017:03:13 18:47:41	------ do the pretrain ------ 

2017:03:13 18:47:41	pretrain epoch 0
2017:03:13 18:47:52	use DataLoaderChildrenStory to init data.
2017:03:13 18:47:52	loading preprocessed files.
2017:03:13 18:47:59	the sample size is 97314, the vocab size is 18739
2017:03:13 18:48:26	use DataLoaderChildrenStory to init data.
2017:03:13 18:48:26	loading preprocessed files.
2017:03:13 18:48:33	the sample size is 97314, the vocab size is 18739
2017:03:13 18:48:39	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489430919

2017:03:13 18:48:43	------ do the pretrain ------ 

2017:03:13 18:48:43	pretrain epoch 0
2017:03:13 22:46:06	use DataLoaderChildrenStory to init data.
2017:03:13 22:46:06	loading preprocessed files.
2017:03:13 22:46:14	the sample size is 97314, the vocab size is 18739
2017:03:13 22:47:29	use DataLoaderChildrenStory to init data.
2017:03:13 22:47:29	loading preprocessed files.
2017:03:13 22:47:36	the sample size is 97314, the vocab size is 18739
2017:03:13 22:48:15	use DataLoaderChildrenStory to init data.
2017:03:13 22:48:15	loading preprocessed files.
2017:03:13 22:48:22	the sample size is 97314, the vocab size is 18739
2017:03:13 22:48:36	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV3.TextGANV3/1489445316

2017:03:13 22:48:42	------ do the pretrain ------ 

2017:03:13 22:48:42	pretrain epoch 0
2017:03:13 22:57:20	use DataLoaderChildrenStory to init data.
2017:03:13 22:57:20	loading preprocessed files.
2017:03:13 22:57:27	the sample size is 97314, the vocab size is 18739
2017:03:13 22:57:33	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489445853

2017:03:13 22:57:37	------ do the pretrain ------ 

2017:03:13 22:57:37	pretrain epoch 0
2017:03:13 23:03:25	use DataLoaderChildrenStory to init data.
2017:03:13 23:03:25	loading preprocessed files.
2017:03:13 23:03:32	the sample size is 97314, the vocab size is 18739
2017:03:13 23:03:44	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV1.TextGANV1/1489446224

2017:03:13 23:03:49	------ do the pretrain ------ 

2017:03:13 23:03:49	pretrain epoch 0
2017:03:13 23:06:38	use DataLoaderChildrenStory to init data.
2017:03:13 23:06:38	loading preprocessed files.
2017:03:13 23:06:46	the sample size is 97314, the vocab size is 18739
2017:03:13 23:06:59	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV2.TextGANV2/1489446419

2017:03:13 23:07:04	------ do the pretrain ------ 

2017:03:13 23:07:04	pretrain epoch 0
2017:03:14 00:19:28	use DataLoaderChildrenStory to init data.
2017:03:14 00:19:28	loading preprocessed files.
2017:03:14 00:19:35	the sample size is 97314, the vocab size is 18739
2017:03:14 00:20:27	use DataLoaderChildrenStory to init data.
2017:03:14 00:20:27	loading preprocessed files.
2017:03:14 00:20:34	the sample size is 97314, the vocab size is 18739
2017:03:14 00:21:26	use DataLoaderChildrenStory to init data.
2017:03:14 00:21:26	loading preprocessed files.
2017:03:14 00:21:33	the sample size is 97314, the vocab size is 18739
2017:03:14 00:22:14	use DataLoaderChildrenStory to init data.
2017:03:14 00:22:14	loading preprocessed files.
2017:03:14 00:22:21	the sample size is 97314, the vocab size is 18739
2017:03:14 00:23:13	use DataLoaderChildrenStory to init data.
2017:03:14 00:23:13	loading preprocessed files.
2017:03:14 00:23:21	the sample size is 97314, the vocab size is 18739
2017:03:14 00:24:32	use DataLoaderChildrenStory to init data.
2017:03:14 00:24:32	loading preprocessed files.
2017:03:14 00:24:39	the sample size is 97314, the vocab size is 18739
2017:03:14 00:24:50	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451090

2017:03:14 00:24:56	------ do the pretrain ------ 

2017:03:14 00:24:57	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451090/checkpoints/bestmodel.

2017:03:14 00:24:57	------ do the standard GAN training ------ 

2017:03:14 00:24:57	train epoch 0
2017:03:14 00:25:58	use DataLoaderChildrenStory to init data.
2017:03:14 00:25:58	loading preprocessed files.
2017:03:14 00:26:05	the sample size is 97314, the vocab size is 18739
2017:03:14 00:26:17	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451177

2017:03:14 00:26:23	------ do the pretrain ------ 

2017:03:14 00:26:24	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV4.TextGANV4/1489451177/checkpoints/bestmodel.

2017:03:14 00:26:24	------ do the standard GAN training ------ 

2017:03:14 00:26:24	train epoch 0
2017:03:14 00:26:44	use DataLoaderChildrenStory to init data.
2017:03:14 00:26:44	loading preprocessed files.
2017:03:14 00:26:53	the sample size is 97314, the vocab size is 18739
2017:03:14 00:27:05	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV3.TextGANV3/1489451225

2017:03:14 00:27:11	------ do the pretrain ------ 

2017:03:14 00:27:13	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGANV3.TextGANV3/1489451225/checkpoints/bestmodel.

2017:03:14 00:27:13	------ do the standard GAN training ------ 

2017:03:14 00:27:13	train epoch 0
2017:03:14 19:17:14	use DataLoaderChildrenStory to init data.
2017:03:14 19:17:14	loading preprocessed files.
2017:03:14 19:17:22	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:20:35	use DataLoaderChildrenStory to init data.
2017:03:14 19:20:35	loading preprocessed files.
2017:03:14 19:20:43	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:20:49	writing to /home/lin/notebooks/code/demo3/data/training/runs/code.model.textGAN.TextGAN/1489519249

2017:03:14 19:20:53	------ do the pretrain ------ 

2017:03:14 19:20:53	pretrain epoch 0
2017:03:14 19:31:59	use DataLoaderChildrenStory to init data.
2017:03:14 19:31:59	loading preprocessed files.
2017:03:14 19:32:06	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:32:52	use DataLoaderChildrenStory to init data.
2017:03:14 19:32:52	loading preprocessed files.
2017:03:14 19:32:59	the number of sentence is 97314, the vocab size is 18739
2017:03:14 19:33:06	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textGAN.TextGAN/1489519985

2017:03:14 19:33:10	------ do the pretrain ------ 

2017:03:14 19:33:10	pretrain epoch 0
2017:03:14 20:21:01	use DataLoaderChildrenStory to init data.
2017:03:14 20:21:01	loading preprocessed files.
2017:03:14 20:21:08	the number of sentence is 97314, the vocab size is 18739
2017:03:14 20:21:15	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textGAN.TextGAN/1489522875

2017:03:14 20:21:18	------ do the pretrain ------ 

2017:03:14 20:21:18	pretrain epoch 0
2017:03:15 10:13:19	use DataLoaderChildrenStory to init data.
2017:03:15 10:13:19	loading preprocessed files.
2017:03:15 10:13:26	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:14:24	use DataLoaderChildrenStory to init data.
2017:03:15 10:14:24	loading preprocessed files.
2017:03:15 10:14:31	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:16:07	use DataLoaderChildrenStory to init data.
2017:03:15 10:16:07	loading preprocessed files.
2017:03:15 10:16:14	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:16:41	use DataLoaderChildrenStory to init data.
2017:03:15 10:16:41	loading preprocessed files.
2017:03:15 10:16:48	the number of sentence is 97314, the vocab size is 18739
2017:03:15 10:16:59	use DataLoaderChildrenStory to init data.
2017:03:15 10:16:59	loading preprocessed files.
2017:03:15 10:17:05	the number of sentence is 97314, the vocab size is 18739
2017:03:15 14:28:04	use DataLoaderChildrenStory to init data.
2017:03:15 14:28:04	loading preprocessed files.
2017:03:15 14:28:11	the number of sentence is 97314, the vocab size is 18739
2017:03:15 14:28:23	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textGANV1.TextGANV1/1489588103

2017:03:15 14:28:29	------ do the pretrain ------ 

2017:03:15 14:28:29	pretrain epoch 0
2017:03:16 12:44:20	use DataLoaderChildrenStory to init data.
2017:03:16 12:44:20	loading preprocessed files.
2017:03:16 12:44:28	the number of sentence is 97314, the vocab size is 18739
2017:03:16 12:47:45	use DataLoaderChildrenStory to init data.
2017:03:16 12:47:45	loading preprocessed files.
2017:03:16 12:47:52	the number of sentence is 97314, the vocab size is 18739
2017:03:16 12:48:09	use DataLoaderChildrenStory to init data.
2017:03:16 12:48:09	loading preprocessed files.
2017:03:16 12:48:16	the number of sentence is 97314, the vocab size is 18739
2017:03:16 12:49:09	use DataLoaderChildrenStory to init data.
2017:03:16 12:49:09	loading preprocessed files.
2017:03:16 12:49:16	the number of sentence is 97314, the vocab size is 18739
2017:03:16 12:50:06	use DataLoaderChildrenStory to init data.
2017:03:16 12:50:06	loading preprocessed files.
2017:03:16 12:50:13	the number of sentence is 97314, the vocab size is 18739
2017:03:16 12:50:34	use DataLoaderChildrenStory to init data.
2017:03:16 12:50:34	reading and processing the text file.
2017:03:16 12:50:34	preprocess the dataset.
2017:03:16 12:50:38	...mask and pad the sentence.
2017:03:16 12:50:38	......max len:21, median len:10.0, min len:3
2017:03:16 12:50:39	build a vocabulary.
2017:03:16 12:50:39	...flatmap a list of sentence list to a list of sentence.
2017:03:16 12:50:40	...mapping from index to word.
2017:03:16 12:50:40	...mapping from word to index.
2017:03:16 12:50:40	...map word to index.
2017:03:16 12:50:41	...some data statistics.
2017:03:16 12:50:41	...save processed data to file.
2017:03:16 12:50:45	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:51:36	use DataLoaderChildrenStory to init data.
2017:03:16 12:51:36	loading preprocessed files.
2017:03:16 12:51:44	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:52:26	use DataLoaderChildrenStory to init data.
2017:03:16 12:52:26	loading preprocessed files.
2017:03:16 12:52:34	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:52:53	use DataLoaderChildrenStory to init data.
2017:03:16 12:52:53	loading preprocessed files.
2017:03:16 12:53:01	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:53:43	use DataLoaderChildrenStory to init data.
2017:03:16 12:53:43	loading preprocessed files.
2017:03:16 12:53:50	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:56:40	use DataLoaderChildrenStory to init data.
2017:03:16 12:56:41	loading preprocessed files.
2017:03:16 12:56:55	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:59:12	use DataLoaderChildrenStory to init data.
2017:03:16 12:59:12	loading preprocessed files.
2017:03:16 12:59:21	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:59:44	use DataLoaderChildrenStory to init data.
2017:03:16 12:59:44	loading preprocessed files.
2017:03:16 12:59:51	the number of sentence is 97241, the vocab size is 19396
2017:03:16 12:59:54	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489669194

2017:03:16 12:59:55	------ do the pretrain ------ 

2017:03:16 12:59:55	train epoch 0
2017:03:16 13:00:11	use DataLoaderChildrenStory to init data.
2017:03:16 13:00:11	loading preprocessed files.
2017:03:16 13:00:18	the number of sentence is 97241, the vocab size is 19396
2017:03:16 13:00:21	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489669220

2017:03:16 13:00:21	------ do the pretrain ------ 

2017:03:16 13:00:21	train epoch 0
2017:03:16 13:29:15	use DataLoaderChildrenStory to init data.
2017:03:16 13:29:15	reading and processing the text file.
2017:03:16 13:29:15	preprocess the dataset.
2017:03:16 13:29:24	...mask and pad the sentence.
2017:03:16 13:29:24	......max len:21, median len:10.0, min len:3
2017:03:16 13:29:25	build a vocabulary.
2017:03:16 13:29:25	...flatmap a list of sentence list to a list of sentence.
2017:03:16 13:29:27	...mapping from index to word.
2017:03:16 13:29:27	...mapping from word to index.
2017:03:16 13:29:27	...map word to index.
2017:03:16 13:29:29	...some data statistics.
2017:03:16 13:29:29	...save processed data to file.
2017:03:16 13:29:35	the number of sentence is 97241, the vocab size is 19396
2017:03:16 13:29:42	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489670982

2017:03:16 13:29:45	------ training ------ 

2017:03:16 13:29:45	train epoch 0
2017:03:16 13:32:20	use DataLoaderChildrenStory to init data.
2017:03:16 13:32:20	loading preprocessed files.
2017:03:16 13:32:30	the number of sentence is 97241, the vocab size is 19396
2017:03:16 13:32:35	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489671155

2017:03:16 13:32:36	------ training ------ 

2017:03:16 13:32:36	train epoch 0
2017:03:16 13:33:16	use DataLoaderChildrenStory to init data.
2017:03:16 13:33:17	loading preprocessed files.
2017:03:16 13:33:25	the number of sentence is 97241, the vocab size is 19396
2017:03:16 13:33:29	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489671209

2017:03:16 13:33:31	------ training ------ 

2017:03:16 13:33:31	train epoch 0
2017:03:16 13:33:50	train loss: 9.8720369339, execution speed: 4.75 seconds/batch

2017:03:16 13:34:28	use DataLoaderChildrenStory to init data.
2017:03:16 13:34:28	loading preprocessed files.
2017:03:16 13:34:35	the number of sentence is 97241, the vocab size is 19396
2017:03:16 13:34:39	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489671279

2017:03:16 13:34:41	------ training ------ 

2017:03:16 13:34:41	train epoch 0
2017:03:16 13:35:01	train loss: 9.87321853638, execution speed: 5.00 seconds/batch

2017:03:16 13:36:03	use DataLoaderChildrenStory to init data.
2017:03:16 13:36:03	loading preprocessed files.
2017:03:16 13:36:11	the number of sentence is 97241, the vocab size is 19396
2017:03:16 13:36:14	writing to /home/lin/notebooks/code/demo3/data/training/runs/DataLoaderChildrenStory/code.model.textG.TextG/1489671374

2017:03:16 13:36:16	------ training ------ 

2017:03:16 13:36:16	train epoch 0
2017:03:16 13:36:34	train loss: 9.87308216095, execution speed: 4.50 seconds/batch

2017:03:16 13:36:40	val loss: 9.87268066406, execution speed: 1.50 seconds/batch

2017:03:16 16:32:36	use DataLoaderShakespeare to init data.
2017:03:16 16:32:36	reading and processing the text file.
2017:03:16 16:32:36	preprocess the dataset.
2017:03:16 16:33:24	use DataLoaderShakespeare to init data.
2017:03:16 16:33:24	reading and processing the text file.
2017:03:16 16:33:24	preprocess the dataset.
2017:03:16 16:38:51	use DataLoaderShakespeare to init data.
2017:03:16 16:38:51	reading and processing the text file.
2017:03:16 16:38:51	preprocess the dataset.
2017:03:16 16:39:06	build a vocabulary.
2017:03:16 16:39:06	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:39:06	...mapping from index to word.
2017:03:16 16:39:06	...mapping from word to index.
2017:03:16 16:39:06	...map word to index.
2017:03:16 16:39:06	...some data statistics.
2017:03:16 16:46:11	use DataLoaderShakespeare to init data.
2017:03:16 16:46:11	reading and processing the text file.
2017:03:16 16:46:11	preprocess the dataset.
2017:03:16 16:46:27	build a vocabulary.
2017:03:16 16:46:27	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:46:27	...mapping from index to word.
2017:03:16 16:46:27	...mapping from word to index.
2017:03:16 16:46:27	...map word to index.
2017:03:16 16:46:27	...some data statistics.
2017:03:16 16:46:27	...save processed data to file.
2017:03:16 16:48:27	use DataLoaderShakespeare to init data.
2017:03:16 16:48:27	reading and processing the text file.
2017:03:16 16:48:27	preprocess the dataset.
2017:03:16 16:48:41	build a vocabulary.
2017:03:16 16:48:41	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:48:42	...mapping from index to word.
2017:03:16 16:48:42	...mapping from word to index.
2017:03:16 16:48:42	...map word to index.
2017:03:16 16:48:42	...some data statistics.
2017:03:16 16:48:42	...save processed data to file.
2017:03:16 16:49:13	use DataLoaderShakespeare to init data.
2017:03:16 16:49:13	reading and processing the text file.
2017:03:16 16:49:13	preprocess the dataset.
2017:03:16 16:49:28	build a vocabulary.
2017:03:16 16:49:28	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:49:28	...mapping from index to word.
2017:03:16 16:49:28	...mapping from word to index.
2017:03:16 16:49:28	...map word to index.
2017:03:16 16:49:28	...some data statistics.
2017:03:16 16:49:28	...save processed data to file.
2017:03:16 16:50:43	use DataLoaderShakespeare to init data.
2017:03:16 16:50:43	reading and processing the text file.
2017:03:16 16:50:43	preprocess the dataset.
2017:03:16 16:50:57	build a vocabulary.
2017:03:16 16:50:57	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:50:58	...mapping from index to word.
2017:03:16 16:50:58	...mapping from word to index.
2017:03:16 16:50:58	...map word to index.
2017:03:16 16:50:58	...some data statistics.
2017:03:16 16:50:58	...save processed data to file.
2017:03:16 16:52:54	use DataLoaderShakespeare to init data.
2017:03:16 16:52:54	reading and processing the text file.
2017:03:16 16:52:54	preprocess the dataset.
2017:03:16 16:53:08	build a vocabulary.
2017:03:16 16:53:08	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:53:08	...mapping from index to word.
2017:03:16 16:53:08	...mapping from word to index.
2017:03:16 16:53:08	...map word to index.
2017:03:16 16:53:08	...some data statistics.
2017:03:16 16:53:08	...save processed data to file.
2017:03:16 16:53:08	the number of sentence is 243200, the vocab size is 38
2017:03:16 16:53:51	use DataLoaderShakespeare to init data.
2017:03:16 16:53:52	reading and processing the text file.
2017:03:16 16:53:52	preprocess the dataset.
2017:03:16 16:54:08	build a vocabulary.
2017:03:16 16:54:08	...flatmap a list of sentence list to a list of sentence.
2017:03:16 16:54:09	...mapping from index to word.
2017:03:16 16:54:09	...mapping from word to index.
2017:03:16 16:54:09	...map word to index.
2017:03:16 16:54:09	...some data statistics.
2017:03:16 16:54:09	...save processed data to file.
2017:03:16 16:54:09	the number of sentence is 243200, the vocab size is 38
2017:03:16 16:54:13	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489683252

2017:03:16 16:54:13	------ training ------ 

2017:03:16 16:54:13	train epoch 0
2017:03:16 16:56:00	use DataLoaderShakespeare to init data.
2017:03:16 16:56:00	loading preprocessed files.
2017:03:16 16:56:00	the number of sentence is 243200, the vocab size is 38
2017:03:16 16:56:03	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489683362

2017:03:16 16:56:03	------ training ------ 

2017:03:16 16:56:03	train epoch 0
2017:03:16 16:58:23	use DataLoaderShakespeare to init data.
2017:03:16 16:58:23	loading preprocessed files.
2017:03:16 16:58:23	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:01:47	use DataLoaderShakespeare to init data.
2017:03:16 17:01:47	loading preprocessed files.
2017:03:16 17:01:48	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:02:00	use DataLoaderShakespeare to init data.
2017:03:16 17:02:00	loading preprocessed files.
2017:03:16 17:02:01	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:02:16	use DataLoaderShakespeare to init data.
2017:03:16 17:02:16	loading preprocessed files.
2017:03:16 17:02:16	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:02:19	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489683738

2017:03:16 17:02:20	------ training ------ 

2017:03:16 17:02:20	train epoch 0
2017:03:16 17:04:50	use DataLoaderShakespeare to init data.
2017:03:16 17:04:50	loading preprocessed files.
2017:03:16 17:04:51	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:04:52	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489683892

2017:03:16 17:04:53	------ training ------ 

2017:03:16 17:04:53	train epoch 0
2017:03:16 17:17:46	use DataLoaderShakespeare to init data.
2017:03:16 17:17:46	loading preprocessed files.
2017:03:16 17:17:46	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:17:48	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489684667

2017:03:16 17:17:48	------ training ------ 

2017:03:16 17:17:48	train epoch 0
2017:03:16 17:18:40	use DataLoaderShakespeare to init data.
2017:03:16 17:18:40	loading preprocessed files.
2017:03:16 17:18:40	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:18:42	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489684722

2017:03:16 17:18:43	------ training ------ 

2017:03:16 17:18:43	train epoch 0
2017:03:16 17:20:44	use DataLoaderShakespeare to init data.
2017:03:16 17:20:44	loading preprocessed files.
2017:03:16 17:20:45	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:20:47	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489684846

2017:03:16 17:20:48	------ training ------ 

2017:03:16 17:20:48	train epoch 0
2017:03:16 17:21:04	use DataLoaderShakespeare to init data.
2017:03:16 17:21:04	reading and processing the text file.
2017:03:16 17:21:04	preprocess the dataset.
2017:03:16 17:21:18	build a vocabulary.
2017:03:16 17:21:18	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:21:18	...mapping from index to word.
2017:03:16 17:21:18	...mapping from word to index.
2017:03:16 17:21:18	...map word to index.
2017:03:16 17:21:18	...some data statistics.
2017:03:16 17:21:18	...save processed data to file.
2017:03:16 17:21:18	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:21:20	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489684880

2017:03:16 17:21:21	------ training ------ 

2017:03:16 17:21:21	train epoch 0
2017:03:16 17:21:47	use DataLoaderShakespeare to init data.
2017:03:16 17:21:47	reading and processing the text file.
2017:03:16 17:21:47	preprocess the dataset.
2017:03:16 17:22:01	build a vocabulary.
2017:03:16 17:22:01	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:22:01	...mapping from index to word.
2017:03:16 17:22:01	...mapping from word to index.
2017:03:16 17:22:01	...map word to index.
2017:03:16 17:22:01	...some data statistics.
2017:03:16 17:22:01	...save processed data to file.
2017:03:16 17:22:01	the number of sentence is 243200, the vocab size is 38
2017:03:16 17:22:03	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489684923

2017:03:16 17:22:04	------ training ------ 

2017:03:16 17:22:04	train epoch 0
2017:03:16 17:22:37	use DataLoaderShakespeare to init data.
2017:03:16 17:22:37	reading and processing the text file.
2017:03:16 17:22:37	preprocess the dataset.
2017:03:16 17:22:53	build a vocabulary.
2017:03:16 17:22:53	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:22:53	...mapping from index to word.
2017:03:16 17:22:53	...mapping from word to index.
2017:03:16 17:22:53	...map word to index.
2017:03:16 17:22:53	...some data statistics.
2017:03:16 17:22:53	...save processed data to file.
2017:03:16 17:22:53	the number of sentence is 243200, the vocab size is 14004
2017:03:16 17:22:55	writing to /home/lin/notebooks/code/demo2/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489684975

2017:03:16 17:22:56	------ training ------ 

2017:03:16 17:22:56	train epoch 0
2017:03:16 17:23:54	use DataLoaderShakespeare to init data.
2017:03:16 17:23:54	reading and processing the text file.
2017:03:16 17:23:54	preprocess the dataset.
2017:03:16 17:24:08	build a vocabulary.
2017:03:16 17:24:08	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:24:08	...mapping from index to word.
2017:03:16 17:24:08	...mapping from word to index.
2017:03:16 17:24:08	...map word to index.
2017:03:16 17:24:08	...some data statistics.
2017:03:16 17:24:08	...save processed data to file.
2017:03:16 17:25:02	use DataLoaderShakespeare to init data.
2017:03:16 17:25:02	reading and processing the text file.
2017:03:16 17:25:02	preprocess the dataset.
2017:03:16 17:25:16	build a vocabulary.
2017:03:16 17:25:16	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:25:16	...mapping from index to word.
2017:03:16 17:25:16	...mapping from word to index.
2017:03:16 17:25:16	...map word to index.
2017:03:16 17:25:16	...some data statistics.
2017:03:16 17:25:16	...save processed data to file.
2017:03:16 17:25:30	use DataLoaderShakespeare to init data.
2017:03:16 17:25:30	loading preprocessed files.
2017:03:16 17:27:08	use DataLoaderShakespeare to init data.
2017:03:16 17:27:08	loading preprocessed files.
2017:03:16 17:27:31	use DataLoaderShakespeare to init data.
2017:03:16 17:27:31	loading preprocessed files.
2017:03:16 17:27:53	use DataLoaderShakespeare to init data.
2017:03:16 17:27:53	loading preprocessed files.
2017:03:16 17:28:02	use DataLoaderShakespeare to init data.
2017:03:16 17:28:02	reading and processing the text file.
2017:03:16 17:28:02	preprocess the dataset.
2017:03:16 17:28:15	build a vocabulary.
2017:03:16 17:28:15	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:28:15	...mapping from index to word.
2017:03:16 17:28:15	...mapping from word to index.
2017:03:16 17:28:15	...map word to index.
2017:03:16 17:28:15	...some data statistics.
2017:03:16 17:28:46	use DataLoaderShakespeare to init data.
2017:03:16 17:28:46	reading and processing the text file.
2017:03:16 17:28:46	preprocess the dataset.
2017:03:16 17:29:00	build a vocabulary.
2017:03:16 17:29:00	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:29:00	...mapping from index to word.
2017:03:16 17:29:00	...mapping from word to index.
2017:03:16 17:29:00	...map word to index.
2017:03:16 17:29:00	...some data statistics.
2017:03:16 17:29:00	......existing 243264 words, vocabulary size is 14004
2017:03:16 17:29:00	...save processed data to file.
2017:03:16 17:29:01	the number of sentence is 243200, the vocab size is 14004
2017:03:16 17:29:03	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489685342

2017:03:16 17:29:03	------ training ------ 

2017:03:16 17:29:03	train epoch 0
2017:03:16 17:30:28	use DataLoaderShakespeare to init data.
2017:03:16 17:30:28	reading and processing the text file.
2017:03:16 17:30:28	preprocess the dataset.
2017:03:16 17:30:41	build a vocabulary.
2017:03:16 17:30:41	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:30:41	...mapping from index to word.
2017:03:16 17:30:41	...mapping from word to index.
2017:03:16 17:30:41	...map word to index.
2017:03:16 17:30:41	...some data statistics.
2017:03:16 17:30:41	......existing 243264 words, vocabulary size is 14004
2017:03:16 17:30:41	...save processed data to file.
2017:03:16 17:30:41	...number of batches: 0
2017:03:16 17:31:12	use DataLoaderShakespeare to init data.
2017:03:16 17:31:12	reading and processing the text file.
2017:03:16 17:31:12	preprocess the dataset.
2017:03:16 17:31:25	build a vocabulary.
2017:03:16 17:31:25	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:31:25	...mapping from index to word.
2017:03:16 17:31:25	...mapping from word to index.
2017:03:16 17:31:25	...map word to index.
2017:03:16 17:31:25	...some data statistics.
2017:03:16 17:31:25	......existing 243264 words, vocabulary size is 14004
2017:03:16 17:31:25	...save processed data to file.
2017:03:16 17:31:26	...number of batches: 8
2017:03:16 17:31:26	the number of sentence is 10240, the vocab size is 14004
2017:03:16 17:31:27	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489685487

2017:03:16 17:31:28	------ training ------ 

2017:03:16 17:31:28	train epoch 0
2017:03:16 17:31:33	train loss: 9.5472984314, execution speed: 0.50 seconds/batch

2017:03:16 17:31:34	val loss: 9.54658508301, execution speed: 0.12 seconds/batch

2017:03:16 17:31:35	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489685487/checkpoints/bestmodel.

2017:03:16 17:31:35	train epoch 1
2017:03:16 17:33:03	use DataLoaderShakespeare to init data.
2017:03:16 17:33:03	reading and processing the text file.
2017:03:16 17:33:03	preprocess the dataset.
2017:03:16 17:33:17	build a vocabulary.
2017:03:16 17:33:17	...flatmap a list of sentence list to a list of sentence.
2017:03:16 17:33:17	...mapping from index to word.
2017:03:16 17:33:17	...mapping from word to index.
2017:03:16 17:33:17	...map word to index.
2017:03:16 17:33:17	...some data statistics.
2017:03:16 17:33:17	......existing 243264 words, vocabulary size is 14004
2017:03:16 17:33:17	...save processed data to file.
2017:03:16 17:33:17	...number of batches: 8
2017:03:16 17:33:17	the number of sentence is 10240, the vocab size is 14004
2017:03:16 17:33:19	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489685599

2017:03:16 17:33:20	------ training ------ 

2017:03:16 17:33:20	train epoch 0
2017:03:16 17:33:24	train loss: 9.54664516449, execution speed: 0.50 seconds/batch

2017:03:16 17:33:26	val loss: 9.54594230652, execution speed: 0.12 seconds/batch

2017:03:16 17:33:26	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489685599/checkpoints/bestmodel.

2017:03:16 17:33:26	train epoch 1
2017:03:16 17:33:30	train loss: 9.54544448853, execution speed: 0.50 seconds/batch

2017:03:16 17:33:32	val loss: 9.54474544525, execution speed: 0.12 seconds/batch

2017:03:16 17:33:32	train epoch 2
2017:03:16 19:35:34	use DataLoaderBBC to init data.
2017:03:16 19:36:07	use DataLoaderBBC to init data.
2017:03:16 19:36:07	reading and processing the text file.
2017:03:16 19:36:07	preprocess the dataset.
2017:03:16 19:36:07	...load data.
2017:03:16 19:36:07	load context for further preprocessing.
2017:03:16 19:36:28	use DataLoaderBBC to init data.
2017:03:16 19:36:28	reading and processing the text file.
2017:03:16 19:36:28	preprocess the dataset.
2017:03:16 19:36:28	...load data.
2017:03:16 19:36:28	load context for further preprocessing.
2017:03:16 19:37:39	build a vocabulary.
2017:03:16 19:37:39	...flatmap a list of sentence list to a list of sentence.
2017:03:16 19:37:39	...mapping from index to word.
2017:03:16 19:37:39	...mapping from word to index.
2017:03:16 19:37:39	...map word to index.
2017:03:16 19:37:40	...some data statistics.
2017:03:16 19:37:40	......existing 954949 words, vocabulary size is 34571
2017:03:16 19:37:40	...save processed data to file.
2017:03:16 19:37:41	...number of batches: 8
2017:03:16 19:37:41	the number of sentence is 10240, the vocab size is 34571
2017:03:16 19:37:43	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489693063

2017:03:16 19:37:44	------ training ------ 

2017:03:16 19:37:44	train epoch 0
2017:03:16 19:38:00	train loss: 10.4502439499, execution speed: 2.00 seconds/batch

2017:03:16 19:38:06	val loss: 10.4495401382, execution speed: 0.62 seconds/batch

2017:03:16 19:38:06	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489693063/checkpoints/bestmodel.

2017:03:16 19:38:06	train epoch 1
2017:03:16 19:38:20	train loss: 10.4490385056, execution speed: 1.75 seconds/batch

2017:03:16 19:39:10	use DataLoaderBBC to init data.
2017:03:16 19:39:10	reading and processing the text file.
2017:03:16 19:39:10	preprocess the dataset.
2017:03:16 19:39:10	...load data.
2017:03:16 19:39:10	load context for further preprocessing.
2017:03:16 19:40:13	build a vocabulary.
2017:03:16 19:40:13	...flatmap a list of sentence list to a list of sentence.
2017:03:16 19:40:14	...mapping from index to word.
2017:03:16 19:40:14	...mapping from word to index.
2017:03:16 19:40:14	...map word to index.
2017:03:16 19:40:14	...some data statistics.
2017:03:16 19:40:14	......existing 954949 words, vocabulary size is 34571
2017:03:16 19:40:14	...save processed data to file.
2017:03:16 19:40:15	...number of batches: 8
2017:03:16 19:40:15	the number of sentence is 10240, the vocab size is 34571
2017:03:16 19:40:18	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489693217

2017:03:16 19:40:19	------ training ------ 

2017:03:16 19:40:19	train epoch 0
2017:03:16 19:40:51	use DataLoaderBBC to init data.
2017:03:16 19:40:51	reading and processing the text file.
2017:03:16 19:40:51	preprocess the dataset.
2017:03:16 19:40:51	...load data.
2017:03:16 19:40:51	init content from raw.
2017:03:16 19:40:51	init data from the raw dataset.
2017:03:16 19:42:18	use DataLoaderBBC to init data.
2017:03:16 19:42:18	reading and processing the text file.
2017:03:16 19:42:18	preprocess the dataset.
2017:03:16 19:42:18	...load data.
2017:03:16 19:42:18	init content from raw.
2017:03:16 19:42:18	init data from the raw dataset.
2017:03:16 19:43:15	use DataLoaderBBC to init data.
2017:03:16 19:43:15	reading and processing the text file.
2017:03:16 19:43:15	preprocess the dataset.
2017:03:16 19:43:15	...load data.
2017:03:16 19:43:15	init content from raw.
2017:03:16 19:43:15	init data from the raw dataset.
2017:03:16 19:43:44	use DataLoaderBBC to init data.
2017:03:16 19:43:44	reading and processing the text file.
2017:03:16 19:43:44	preprocess the dataset.
2017:03:16 19:43:44	...load data.
2017:03:16 19:43:44	init content from raw.
2017:03:16 19:43:44	init data from the raw dataset.
2017:03:16 19:43:46	clean data.
2017:03:16 19:44:08	use DataLoaderBBC to init data.
2017:03:16 19:44:08	reading and processing the text file.
2017:03:16 19:44:08	preprocess the dataset.
2017:03:16 19:44:08	load data.
2017:03:16 19:44:08	init content from raw.
2017:03:16 19:44:08	init data from the raw dataset.
2017:03:16 19:44:11	clean data.
2017:03:16 19:44:50	use DataLoaderBBC to init data.
2017:03:16 19:44:50	reading and processing the text file.
2017:03:16 19:44:50	preprocess the dataset.
2017:03:16 19:44:50	load data.
2017:03:16 19:44:50	init content from raw.
2017:03:16 19:44:50	init data from the raw dataset.
2017:03:16 19:45:36	use DataLoaderBBC to init data.
2017:03:16 19:45:36	reading and processing the text file.
2017:03:16 19:45:36	preprocess the dataset.
2017:03:16 19:45:36	load data.
2017:03:16 19:45:36	init content from raw.
2017:03:16 19:45:36	init data from the raw dataset.
2017:03:16 19:46:20	use DataLoaderBBC to init data.
2017:03:16 19:46:20	reading and processing the text file.
2017:03:16 19:46:20	preprocess the dataset.
2017:03:16 19:46:20	load data.
2017:03:16 19:46:20	init content from raw.
2017:03:16 19:46:20	init data from the raw dataset.
2017:03:16 19:46:21	load context for further preprocessing.
2017:03:16 19:46:21	clean data.
2017:03:16 19:46:22	build a vocabulary.
2017:03:16 19:46:22	...flatmap a list of sentence list to a list of sentence.
2017:03:16 19:46:22	...mapping from index to word.
2017:03:16 19:46:22	...mapping from word to index.
2017:03:16 19:47:30	...map word to index.
2017:03:16 19:47:30	...some data statistics.
2017:03:16 19:47:30	......existing 954949 words, vocabulary size is 34571
2017:03:16 19:47:30	...save processed data to file.
2017:03:16 19:47:32	...number of batches: 8
2017:03:16 19:47:32	the number of sentence is 10240, the vocab size is 34571
2017:03:16 19:47:34	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489693654

2017:03:16 19:47:36	------ training ------ 

2017:03:16 19:47:36	train epoch 0
2017:03:16 19:47:52	train loss: 10.4507255554, execution speed: 2.00 seconds/batch

2017:03:16 19:47:57	val loss: 10.4500274658, execution speed: 0.50 seconds/batch

2017:03:16 19:47:57	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489693654/checkpoints/bestmodel.

2017:03:16 19:47:57	train epoch 1
2017:03:16 19:48:12	train loss: 10.4495229721, execution speed: 1.75 seconds/batch

2017:03:16 19:48:17	val loss: 10.4488182068, execution speed: 0.50 seconds/batch

2017:03:16 19:48:17	train epoch 2
2017:03:16 19:57:37	use DataLoaderBBC to init data.
2017:03:16 19:57:37	reading and processing the text file.
2017:03:16 19:57:37	preprocess the dataset.
2017:03:16 19:57:37	load data.
2017:03:16 19:57:37	init content from raw.
2017:03:16 19:57:37	init data from the raw dataset.
2017:03:16 19:57:38	load context for further preprocessing.
2017:03:16 19:57:38	clean data.
2017:03:16 19:57:39	build a vocabulary.
2017:03:16 19:57:39	...flatmap a list of sentence list to a list of sentence.
2017:03:16 19:57:39	...mapping from index to word.
2017:03:16 19:57:39	...mapping from word to index.
2017:03:16 19:58:45	...map word to index.
2017:03:16 19:58:45	...some data statistics.
2017:03:16 19:58:45	......existing 954949 words, vocabulary size is 34571
2017:03:16 19:58:45	...save processed data to file.
2017:03:16 19:58:46	...number of batches: 8
2017:03:16 19:58:46	the number of sentence is 10240, the vocab size is 34571
2017:03:16 19:58:48	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694328

2017:03:16 19:58:49	------ training ------ 

2017:03:16 19:58:49	train epoch 0
2017:03:16 20:00:25	use DataLoaderBBC to init data.
2017:03:16 20:00:25	reading and processing the text file.
2017:03:16 20:00:25	preprocess the dataset.
2017:03:16 20:00:25	load data.
2017:03:16 20:00:25	init content from raw.
2017:03:16 20:00:25	init data from the raw dataset.
2017:03:16 20:00:26	load context for further preprocessing.
2017:03:16 20:00:26	clean data.
2017:03:16 20:00:27	build a vocabulary.
2017:03:16 20:00:27	...flatmap a list of sentence list to a list of sentence.
2017:03:16 20:00:27	...mapping from index to word.
2017:03:16 20:00:27	...mapping from word to index.
2017:03:16 20:01:32	...map word to index.
2017:03:16 20:01:33	...some data statistics.
2017:03:16 20:01:33	......existing 954949 words, vocabulary size is 34571
2017:03:16 20:01:33	...save processed data to file.
2017:03:16 20:01:34	...number of batches: 8
2017:03:16 20:01:34	the number of sentence is 10240, the vocab size is 34571
2017:03:16 20:01:36	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694496

2017:03:16 20:01:37	------ training ------ 

2017:03:16 20:01:37	train epoch 0
2017:03:16 20:01:52	train loss: 10.4500589371, execution speed: 1.88 seconds/batch

2017:03:16 20:01:57	val loss: 10.4493560791, execution speed: 0.50 seconds/batch

2017:03:16 20:01:57	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694496/checkpoints/bestmodel.

2017:03:16 20:01:57	train epoch 1
2017:03:16 20:02:22	use DataLoaderBBC to init data.
2017:03:16 20:02:22	loading preprocessed files.
2017:03:16 20:02:24	......existing 954949 words, vocabulary size is 34571
2017:03:16 20:02:24	...number of batches: 8
2017:03:16 20:02:24	the number of sentence is 10240, the vocab size is 34571
2017:03:16 20:02:26	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694546

2017:03:16 20:02:27	------ training ------ 

2017:03:16 20:02:27	train epoch 0
2017:03:16 20:03:16	use DataLoaderBBC to init data.
2017:03:16 20:03:16	loading preprocessed files.
2017:03:16 20:03:18	......existing 954949 words, vocabulary size is 34571
2017:03:16 20:03:18	...number of batches: 8
2017:03:16 20:03:18	the number of sentence is 10240, the vocab size is 34571
2017:03:16 20:03:19	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694599

2017:03:16 20:03:33	use DataLoaderBBC to init data.
2017:03:16 20:03:33	loading preprocessed files.
2017:03:16 20:03:35	......existing 954949 words, vocabulary size is 34571
2017:03:16 20:03:35	...number of batches: 8
2017:03:16 20:03:35	the number of sentence is 10240, the vocab size is 34571
2017:03:16 20:03:36	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694616

2017:03:16 20:05:39	use DataLoaderBBC to init data.
2017:03:16 20:05:39	reading and processing the text file.
2017:03:16 20:05:40	preprocess the dataset.
2017:03:16 20:05:40	load data.
2017:03:16 20:05:40	init content from raw.
2017:03:16 20:05:40	init data from the raw dataset.
2017:03:16 20:05:41	load context for further preprocessing.
2017:03:16 20:05:41	clean data.
2017:03:16 20:05:42	build a vocabulary.
2017:03:16 20:05:42	...flatmap a list of sentence list to a list of sentence.
2017:03:16 20:05:42	...mapping from index to word.
2017:03:16 20:05:42	...mapping from word to index.
2017:03:16 20:06:31	use DataLoaderBBC to init data.
2017:03:16 20:06:31	reading and processing the text file.
2017:03:16 20:06:31	preprocess the dataset.
2017:03:16 20:06:31	load data.
2017:03:16 20:06:31	init content from raw.
2017:03:16 20:06:31	init data from the raw dataset.
2017:03:16 20:06:32	load context for further preprocessing.
2017:03:16 20:06:32	clean data.
2017:03:16 20:06:33	build a vocabulary.
2017:03:16 20:06:33	...flatmap a list of sentence list to a list of sentence.
2017:03:16 20:06:33	...mapping from index to word.
2017:03:16 20:06:33	...mapping from word to index.
2017:03:16 20:06:33	...map word to index.
2017:03:16 20:06:34	...some data statistics.
2017:03:16 20:06:34	......existing 954949 words, vocabulary size is 34571
2017:03:16 20:06:34	...save processed data to file.
2017:03:16 20:06:35	...number of batches: 8
2017:03:16 20:06:35	the number of sentence is 10240, the vocab size is 34571
2017:03:16 20:06:39	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489694799

2017:03:16 20:06:41	------ training ------ 

2017:03:16 20:06:41	train epoch 0
2017:03:16 20:08:55	use DataLoaderShakespeare to init data.
2017:03:16 20:08:55	reading and processing the text file.
2017:03:16 20:08:55	preprocess the dataset.
2017:03:16 20:09:10	build a vocabulary.
2017:03:16 20:09:10	...flatmap a list of sentence list to a list of sentence.
2017:03:16 20:09:10	...mapping from index to word.
2017:03:16 20:09:10	...mapping from word to index.
2017:03:16 20:09:10	...map word to index.
2017:03:16 20:09:10	...some data statistics.
2017:03:16 20:09:10	......existing 243264 words, vocabulary size is 14004
2017:03:16 20:09:10	...save processed data to file.
2017:03:16 20:09:10	...number of batches: 8
2017:03:16 20:09:10	the number of sentence is 10240, the vocab size is 14004
2017:03:16 20:09:12	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489694952

2017:03:16 20:09:13	------ training ------ 

2017:03:16 20:09:13	train epoch 0
2017:03:16 20:09:18	train loss: 9.54503154755, execution speed: 0.62 seconds/batch

2017:03:16 20:09:20	val loss: 9.54432678223, execution speed: 0.12 seconds/batch

2017:03:16 20:09:20	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489694952/checkpoints/bestmodel.

2017:03:16 20:09:20	train epoch 1
2017:03:16 20:09:25	train loss: 9.54382419586, execution speed: 0.50 seconds/batch

2017:03:16 20:09:26	val loss: 9.54311561584, execution speed: 0.12 seconds/batch

2017:03:16 20:09:26	train epoch 2
2017:03:16 20:09:31	train loss: 9.54260635376, execution speed: 0.50 seconds/batch

2017:03:16 20:09:33	val loss: 9.54187488556, execution speed: 0.12 seconds/batch

2017:03:16 20:09:33	train epoch 3
2017:03:16 20:09:38	train loss: 9.54135036469, execution speed: 0.50 seconds/batch

2017:03:16 20:09:39	val loss: 9.54060173035, execution speed: 0.12 seconds/batch

2017:03:16 20:09:39	train epoch 4
2017:03:16 20:09:44	train loss: 9.54005050659, execution speed: 0.50 seconds/batch

2017:03:16 20:09:45	val loss: 9.5392742157, execution speed: 0.12 seconds/batch

2017:03:16 20:09:45	train epoch 5
2017:03:16 20:09:50	train loss: 9.53869533539, execution speed: 0.50 seconds/batch

2017:03:16 20:09:52	val loss: 9.53787326813, execution speed: 0.12 seconds/batch

2017:03:16 20:09:52	save 2-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489694952/checkpoints/bestmodel.

2017:03:16 20:09:52	train epoch 6
2017:03:16 20:09:56	train loss: 9.53725242615, execution speed: 0.50 seconds/batch

2017:03:16 20:09:58	val loss: 9.53635597229, execution speed: 0.12 seconds/batch

2017:03:16 20:09:58	train epoch 7
2017:03:16 20:10:03	train loss: 9.53569316864, execution speed: 0.50 seconds/batch

2017:03:16 20:10:04	val loss: 9.53472518921, execution speed: 0.12 seconds/batch

2017:03:16 20:10:04	train epoch 8
2017:03:16 20:10:09	train loss: 9.53400802612, execution speed: 0.50 seconds/batch

2017:03:16 20:10:10	val loss: 9.53296089172, execution speed: 0.12 seconds/batch

2017:03:16 20:10:10	train epoch 9
2017:03:16 20:10:15	train loss: 9.53215312958, execution speed: 0.50 seconds/batch

2017:03:16 20:10:16	val loss: 9.5309753418, execution speed: 0.12 seconds/batch

2017:03:16 20:10:16	train epoch 10
2017:03:16 20:10:21	train loss: 9.53011798859, execution speed: 0.62 seconds/batch

2017:03:16 20:10:23	val loss: 9.52880477905, execution speed: 0.12 seconds/batch

2017:03:16 20:10:24	save 3-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489694952/checkpoints/bestmodel.

2017:03:16 20:10:24	train epoch 11
2017:03:16 21:17:40	use DataLoaderBBC to init data.
2017:03:16 21:17:40	reading and processing the text file.
2017:03:16 21:17:40	preprocess the dataset.
2017:03:16 21:17:40	load data.
2017:03:16 21:17:40	init content from raw.
2017:03:16 21:17:40	init data from the raw dataset.
2017:03:16 21:17:41	load context for further preprocessing.
2017:03:16 21:17:41	clean data.
2017:03:16 21:17:42	build a vocabulary.
2017:03:16 21:17:42	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:17:42	...mapping from index to word.
2017:03:16 21:17:42	...mapping from word to index.
2017:03:16 21:17:42	...map word to index.
2017:03:16 21:17:42	...some data statistics.
2017:03:16 21:17:42	......existing 954949 words, vocabulary size is 34571
2017:03:16 21:17:42	...save processed data to file.
2017:03:16 21:17:44	...number of batches: 8
2017:03:16 21:17:44	the number of sentence is 10240, the vocab size is 34571
2017:03:16 21:17:46	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489699065

2017:03:16 21:17:47	------ training ------ 

2017:03:16 21:17:47	train epoch 0
2017:03:16 21:18:11	use DataLoaderBBC to init data.
2017:03:16 21:18:11	reading and processing the text file.
2017:03:16 21:18:11	preprocess the dataset.
2017:03:16 21:18:11	load data.
2017:03:16 21:18:11	init content from raw.
2017:03:16 21:18:11	init data from the raw dataset.
2017:03:16 21:18:11	load context for further preprocessing.
2017:03:16 21:18:11	clean data.
2017:03:16 21:18:26	use DataLoaderBBC to init data.
2017:03:16 21:18:26	reading and processing the text file.
2017:03:16 21:18:26	preprocess the dataset.
2017:03:16 21:18:26	load data.
2017:03:16 21:18:26	init content from raw.
2017:03:16 21:18:26	init data from the raw dataset.
2017:03:16 21:18:26	load context for further preprocessing.
2017:03:16 21:18:26	clean data.
2017:03:16 21:18:26	build a vocabulary.
2017:03:16 21:18:26	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:18:27	...mapping from index to word.
2017:03:16 21:18:27	...mapping from word to index.
2017:03:16 21:18:27	...map word to index.
2017:03:16 21:18:27	...some data statistics.
2017:03:16 21:18:27	......existing 954949 words, vocabulary size is 34571
2017:03:16 21:18:27	...save processed data to file.
2017:03:16 21:18:38	use DataLoaderBBC to init data.
2017:03:16 21:18:38	reading and processing the text file.
2017:03:16 21:18:38	preprocess the dataset.
2017:03:16 21:18:38	load data.
2017:03:16 21:18:38	init content from raw.
2017:03:16 21:18:38	init data from the raw dataset.
2017:03:16 21:18:38	load context for further preprocessing.
2017:03:16 21:18:38	clean data.
2017:03:16 21:18:38	build a vocabulary.
2017:03:16 21:18:38	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:18:39	...mapping from index to word.
2017:03:16 21:18:39	...mapping from word to index.
2017:03:16 21:18:39	...map word to index.
2017:03:16 21:18:39	...some data statistics.
2017:03:16 21:18:39	......existing 954949 words, vocabulary size is 34571
2017:03:16 21:18:39	...save processed data to file.
2017:03:16 21:19:11	use DataLoaderBBC to init data.
2017:03:16 21:19:11	reading and processing the text file.
2017:03:16 21:19:11	preprocess the dataset.
2017:03:16 21:19:11	load data.
2017:03:16 21:19:11	init content from raw.
2017:03:16 21:19:11	init data from the raw dataset.
2017:03:16 21:19:11	load context for further preprocessing.
2017:03:16 21:19:11	clean data.
2017:03:16 21:19:12	build a vocabulary.
2017:03:16 21:19:12	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:19:12	...mapping from index to word.
2017:03:16 21:19:12	...mapping from word to index.
2017:03:16 21:19:12	...map word to index.
2017:03:16 21:19:12	...some data statistics.
2017:03:16 21:19:12	......existing 950501 words, vocabulary size is 35793
2017:03:16 21:19:12	...save processed data to file.
2017:03:16 21:20:06	use DataLoaderBBC to init data.
2017:03:16 21:20:06	reading and processing the text file.
2017:03:16 21:20:06	preprocess the dataset.
2017:03:16 21:20:06	load data.
2017:03:16 21:20:06	init content from raw.
2017:03:16 21:20:06	init data from the raw dataset.
2017:03:16 21:20:06	load context for further preprocessing.
2017:03:16 21:20:06	clean data.
2017:03:16 21:20:07	build a vocabulary.
2017:03:16 21:20:07	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:20:08	...mapping from index to word.
2017:03:16 21:20:08	...mapping from word to index.
2017:03:16 21:20:08	...map word to index.
2017:03:16 21:20:08	...some data statistics.
2017:03:16 21:20:08	......existing 950501 words, vocabulary size is 35793
2017:03:16 21:20:08	...save processed data to file.
2017:03:16 21:20:09	...number of batches: 8
2017:03:16 21:20:09	the number of sentence is 10240, the vocab size is 35793
2017:03:16 21:21:07	use DataLoaderBBC to init data.
2017:03:16 21:21:07	reading and processing the text file.
2017:03:16 21:21:07	preprocess the dataset.
2017:03:16 21:21:07	load data.
2017:03:16 21:21:07	init content from raw.
2017:03:16 21:21:07	init data from the raw dataset.
2017:03:16 21:21:07	load context for further preprocessing.
2017:03:16 21:21:07	clean data.
2017:03:16 21:21:07	build a vocabulary.
2017:03:16 21:21:07	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:21:08	...mapping from index to word.
2017:03:16 21:21:08	...mapping from word to index.
2017:03:16 21:21:08	...map word to index.
2017:03:16 21:21:08	...some data statistics.
2017:03:16 21:21:08	......existing 945920 words, vocabulary size is 34165
2017:03:16 21:21:08	...save processed data to file.
2017:03:16 21:23:51	use DataLoaderBBC to init data.
2017:03:16 21:23:51	reading and processing the text file.
2017:03:16 21:23:51	preprocess the dataset.
2017:03:16 21:23:51	load data.
2017:03:16 21:23:51	init content from raw.
2017:03:16 21:23:51	init data from the raw dataset.
2017:03:16 21:23:51	load context for further preprocessing.
2017:03:16 21:23:51	clean data.
2017:03:16 21:23:51	build a vocabulary.
2017:03:16 21:23:51	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:23:51	...mapping from index to word.
2017:03:16 21:23:51	...mapping from word to index.
2017:03:16 21:23:51	...map word to index.
2017:03:16 21:23:52	...some data statistics.
2017:03:16 21:23:52	......existing 943569 words, vocabulary size is 34007
2017:03:16 21:23:52	...save processed data to file.
2017:03:16 21:30:33	use DataLoaderBBC to init data.
2017:03:16 21:30:33	reading and processing the text file.
2017:03:16 21:30:33	preprocess the dataset.
2017:03:16 21:30:33	load data.
2017:03:16 21:30:33	init content from raw.
2017:03:16 21:30:33	init data from the raw dataset.
2017:03:16 21:30:33	load context for further preprocessing.
2017:03:16 21:30:33	clean data.
2017:03:16 21:30:34	build a vocabulary.
2017:03:16 21:30:34	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:30:34	...mapping from index to word.
2017:03:16 21:30:35	...mapping from word to index.
2017:03:16 21:30:35	...map word to index.
2017:03:16 21:30:35	...some data statistics.
2017:03:16 21:30:35	......existing 943569 words, vocabulary size is 34007
2017:03:16 21:30:35	...save processed data to file.
2017:03:16 21:30:36	...number of batches: 8
2017:03:16 21:30:36	the number of sentence is 10240, the vocab size is 34007
2017:03:16 21:33:09	use DataLoaderBBC to init data.
2017:03:16 21:33:09	reading and processing the text file.
2017:03:16 21:33:09	preprocess the dataset.
2017:03:16 21:33:09	load data.
2017:03:16 21:33:09	init content from raw.
2017:03:16 21:33:09	init data from the raw dataset.
2017:03:16 21:33:09	load context for further preprocessing.
2017:03:16 21:33:09	clean data.
2017:03:16 21:33:10	build a vocabulary.
2017:03:16 21:33:10	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:33:10	...mapping from index to word.
2017:03:16 21:33:10	...mapping from word to index.
2017:03:16 21:33:10	...map word to index.
2017:03:16 21:33:11	...some data statistics.
2017:03:16 21:33:11	......existing 943569 words, vocabulary size is 34007
2017:03:16 21:33:11	...save processed data to file.
2017:03:16 21:35:30	use DataLoaderBBC to init data.
2017:03:16 21:35:30	reading and processing the text file.
2017:03:16 21:35:30	preprocess the dataset.
2017:03:16 21:35:30	load data.
2017:03:16 21:35:30	init content from raw.
2017:03:16 21:35:30	init data from the raw dataset.
2017:03:16 21:35:44	use DataLoaderBBC to init data.
2017:03:16 21:35:44	reading and processing the text file.
2017:03:16 21:35:44	preprocess the dataset.
2017:03:16 21:35:44	load data.
2017:03:16 21:35:44	init content from raw.
2017:03:16 21:35:44	init data from the raw dataset.
2017:03:16 21:35:44	load context for further preprocessing.
2017:03:16 21:37:15	use DataLoaderBBC to init data.
2017:03:16 21:37:15	reading and processing the text file.
2017:03:16 21:37:15	preprocess the dataset.
2017:03:16 21:37:15	load data.
2017:03:16 21:37:15	init content from raw.
2017:03:16 21:37:15	init data from the raw dataset.
2017:03:16 21:37:15	load context for further preprocessing.
2017:03:16 21:38:02	use DataLoaderBBC to init data.
2017:03:16 21:38:02	reading and processing the text file.
2017:03:16 21:38:02	preprocess the dataset.
2017:03:16 21:38:02	load data.
2017:03:16 21:38:02	init content from raw.
2017:03:16 21:38:02	init data from the raw dataset.
2017:03:16 21:38:02	load context for further preprocessing.
2017:03:16 21:38:33	use DataLoaderBBC to init data.
2017:03:16 21:38:33	reading and processing the text file.
2017:03:16 21:38:33	preprocess the dataset.
2017:03:16 21:38:33	load data.
2017:03:16 21:38:33	init content from raw.
2017:03:16 21:38:33	init data from the raw dataset.
2017:03:16 21:38:33	load context for further preprocessing.
2017:03:16 21:38:33	clean data.
2017:03:16 21:38:33	build a vocabulary.
2017:03:16 21:38:33	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:38:33	...mapping from index to word.
2017:03:16 21:38:33	...mapping from word to index.
2017:03:16 21:38:33	...map word to index.
2017:03:16 21:38:33	...some data statistics.
2017:03:16 21:38:33	......existing 199 words, vocabulary size is 121
2017:03:16 21:38:33	...save processed data to file.
2017:03:16 21:38:33	...number of batches: 8
2017:03:16 21:38:49	use DataLoaderBBC to init data.
2017:03:16 21:38:49	reading and processing the text file.
2017:03:16 21:38:49	preprocess the dataset.
2017:03:16 21:38:49	load data.
2017:03:16 21:38:49	init content from raw.
2017:03:16 21:38:49	init data from the raw dataset.
2017:03:16 21:38:49	load context for further preprocessing.
2017:03:16 21:38:49	clean data.
2017:03:16 21:38:50	build a vocabulary.
2017:03:16 21:38:50	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:38:50	...mapping from index to word.
2017:03:16 21:38:50	...mapping from word to index.
2017:03:16 21:38:50	...map word to index.
2017:03:16 21:38:51	...some data statistics.
2017:03:16 21:38:51	......existing 931810 words, vocabulary size is 33444
2017:03:16 21:38:51	...save processed data to file.
2017:03:16 21:38:52	...number of batches: 8
2017:03:16 21:38:52	the number of sentence is 10240, the vocab size is 33444
2017:03:16 21:38:54	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489700334

2017:03:16 21:38:55	------ training ------ 

2017:03:16 21:38:55	train epoch 0
2017:03:16 21:40:20	use DataLoaderBBC to init data.
2017:03:16 21:40:20	reading and processing the text file.
2017:03:16 21:40:20	preprocess the dataset.
2017:03:16 21:40:20	load data.
2017:03:16 21:40:20	init content from raw.
2017:03:16 21:40:20	init data from the raw dataset.
2017:03:16 21:40:20	load context for further preprocessing.
2017:03:16 21:40:20	clean data.
2017:03:16 21:40:21	build a vocabulary.
2017:03:16 21:40:21	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:40:21	...mapping from index to word.
2017:03:16 21:40:21	...mapping from word to index.
2017:03:16 21:40:21	...map word to index.
2017:03:16 21:40:21	...some data statistics.
2017:03:16 21:40:21	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:40:21	...save processed data to file.
2017:03:16 21:40:22	...number of batches: 8
2017:03:16 21:40:22	the number of sentence is 10240, the vocab size is 33434
2017:03:16 21:40:24	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489700424

2017:03:16 21:40:25	------ training ------ 

2017:03:16 21:40:25	train epoch 0
2017:03:16 21:41:54	use DataLoaderBBC to init data.
2017:03:16 21:41:54	reading and processing the text file.
2017:03:16 21:41:54	preprocess the dataset.
2017:03:16 21:41:54	load data.
2017:03:16 21:41:54	init content from raw.
2017:03:16 21:41:54	init data from the raw dataset.
2017:03:16 21:41:54	load context for further preprocessing.
2017:03:16 21:41:54	clean data.
2017:03:16 21:41:54	build a vocabulary.
2017:03:16 21:41:54	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:41:55	...mapping from index to word.
2017:03:16 21:41:55	...mapping from word to index.
2017:03:16 21:41:55	...map word to index.
2017:03:16 21:41:55	...some data statistics.
2017:03:16 21:41:55	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:41:55	...save processed data to file.
2017:03:16 21:41:56	...number of batches: 8
2017:03:16 21:41:56	the number of sentence is 10240, the vocab size is 33434
2017:03:16 21:42:36	use DataLoaderBBC to init data.
2017:03:16 21:42:36	reading and processing the text file.
2017:03:16 21:42:36	preprocess the dataset.
2017:03:16 21:42:36	load data.
2017:03:16 21:42:36	init content from raw.
2017:03:16 21:42:36	init data from the raw dataset.
2017:03:16 21:42:36	load context for further preprocessing.
2017:03:16 21:42:36	clean data.
2017:03:16 21:42:37	build a vocabulary.
2017:03:16 21:42:37	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:42:37	...mapping from index to word.
2017:03:16 21:42:37	...mapping from word to index.
2017:03:16 21:42:37	...map word to index.
2017:03:16 21:42:37	...some data statistics.
2017:03:16 21:42:37	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:42:37	...save processed data to file.
2017:03:16 21:44:11	use DataLoaderBBC to init data.
2017:03:16 21:44:11	reading and processing the text file.
2017:03:16 21:44:11	preprocess the dataset.
2017:03:16 21:44:11	load data.
2017:03:16 21:44:11	init content from raw.
2017:03:16 21:44:11	init data from the raw dataset.
2017:03:16 21:44:12	load context for further preprocessing.
2017:03:16 21:44:12	clean data.
2017:03:16 21:44:12	build a vocabulary.
2017:03:16 21:44:12	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:44:12	...mapping from index to word.
2017:03:16 21:44:12	...mapping from word to index.
2017:03:16 21:44:12	...map word to index.
2017:03:16 21:44:13	...some data statistics.
2017:03:16 21:44:13	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:44:13	...save processed data to file.
2017:03:16 21:44:14	...number of batches: 8
2017:03:16 21:44:14	the number of sentence is 10240, the vocab size is 33434
2017:03:16 21:45:38	use DataLoaderBBC to init data.
2017:03:16 21:45:38	reading and processing the text file.
2017:03:16 21:45:38	preprocess the dataset.
2017:03:16 21:45:38	load data.
2017:03:16 21:45:38	init content from raw.
2017:03:16 21:45:38	init data from the raw dataset.
2017:03:16 21:45:38	load context for further preprocessing.
2017:03:16 21:45:38	clean data.
2017:03:16 21:45:38	build a vocabulary.
2017:03:16 21:45:38	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:45:39	...mapping from index to word.
2017:03:16 21:45:39	...mapping from word to index.
2017:03:16 21:45:39	...map word to index.
2017:03:16 21:45:39	...some data statistics.
2017:03:16 21:45:39	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:45:39	...save processed data to file.
2017:03:16 21:45:40	...number of batches: 8
2017:03:16 21:45:40	the number of sentence is 10240, the vocab size is 33434
2017:03:16 21:48:26	use DataLoaderBBC to init data.
2017:03:16 21:48:26	reading and processing the text file.
2017:03:16 21:48:26	preprocess the dataset.
2017:03:16 21:48:26	load data.
2017:03:16 21:48:26	init content from raw.
2017:03:16 21:48:26	init data from the raw dataset.
2017:03:16 21:48:26	load context for further preprocessing.
2017:03:16 21:48:26	clean data.
2017:03:16 21:48:27	build a vocabulary.
2017:03:16 21:48:27	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:48:27	...mapping from index to word.
2017:03:16 21:48:27	...mapping from word to index.
2017:03:16 21:48:27	...map word to index.
2017:03:16 21:48:27	...some data statistics.
2017:03:16 21:48:27	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:48:27	...save processed data to file.
2017:03:16 21:49:20	use DataLoaderBBC to init data.
2017:03:16 21:49:20	reading and processing the text file.
2017:03:16 21:49:20	preprocess the dataset.
2017:03:16 21:49:20	load data.
2017:03:16 21:49:20	init content from raw.
2017:03:16 21:49:20	init data from the raw dataset.
2017:03:16 21:49:20	load context for further preprocessing.
2017:03:16 21:49:20	clean data.
2017:03:16 21:49:21	build a vocabulary.
2017:03:16 21:49:21	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:49:21	...mapping from index to word.
2017:03:16 21:49:21	...mapping from word to index.
2017:03:16 21:49:21	...map word to index.
2017:03:16 21:49:22	...some data statistics.
2017:03:16 21:49:22	......existing 931344 words, vocabulary size is 33434
2017:03:16 21:49:22	...save processed data to file.
2017:03:16 21:50:56	use DataLoaderBBC to init data.
2017:03:16 21:50:56	reading and processing the text file.
2017:03:16 21:50:56	preprocess the dataset.
2017:03:16 21:50:56	load data.
2017:03:16 21:50:56	init content from raw.
2017:03:16 21:50:56	init data from the raw dataset.
2017:03:16 21:50:56	load context for further preprocessing.
2017:03:16 21:50:56	clean data.
2017:03:16 21:50:58	build a vocabulary.
2017:03:16 21:50:58	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:50:58	...mapping from index to word.
2017:03:16 21:50:58	...mapping from word to index.
2017:03:16 21:50:58	...map word to index.
2017:03:16 21:52:04	use DataLoaderBBC to init data.
2017:03:16 21:52:04	reading and processing the text file.
2017:03:16 21:52:04	preprocess the dataset.
2017:03:16 21:52:04	load data.
2017:03:16 21:52:04	init content from raw.
2017:03:16 21:52:04	init data from the raw dataset.
2017:03:16 21:52:05	load context for further preprocessing.
2017:03:16 21:52:05	clean data.
2017:03:16 21:52:05	build a vocabulary.
2017:03:16 21:52:05	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:52:06	...mapping from index to word.
2017:03:16 21:52:06	...mapping from word to index.
2017:03:16 21:52:06	...map word to index.
2017:03:16 21:52:06	...some data statistics.
2017:03:16 21:52:06	......existing 888042 words, vocabulary size is 33433
2017:03:16 21:52:06	...save processed data to file.
2017:03:16 21:52:07	...number of batches: 8
2017:03:16 21:52:07	the number of sentence is 10240, the vocab size is 33433
2017:03:16 21:52:19	use DataLoaderBBC to init data.
2017:03:16 21:52:19	reading and processing the text file.
2017:03:16 21:52:19	preprocess the dataset.
2017:03:16 21:52:19	load data.
2017:03:16 21:52:19	init content from raw.
2017:03:16 21:52:19	init data from the raw dataset.
2017:03:16 21:52:19	load context for further preprocessing.
2017:03:16 21:52:19	clean data.
2017:03:16 21:52:20	build a vocabulary.
2017:03:16 21:52:20	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:52:21	...mapping from index to word.
2017:03:16 21:52:21	...mapping from word to index.
2017:03:16 21:52:21	...map word to index.
2017:03:16 21:52:21	...some data statistics.
2017:03:16 21:52:21	......existing 888042 words, vocabulary size is 33433
2017:03:16 21:52:21	...save processed data to file.
2017:03:16 21:55:33	use DataLoaderBBC to init data.
2017:03:16 21:55:33	reading and processing the text file.
2017:03:16 21:55:33	preprocess the dataset.
2017:03:16 21:55:33	load data.
2017:03:16 21:55:33	init content from raw.
2017:03:16 21:55:33	init data from the raw dataset.
2017:03:16 21:55:33	load context for further preprocessing.
2017:03:16 21:55:33	clean data.
2017:03:16 21:55:33	build a vocabulary.
2017:03:16 21:55:33	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:55:34	...mapping from index to word.
2017:03:16 21:55:34	...mapping from word to index.
2017:03:16 21:55:34	...map word to index.
2017:03:16 21:59:12	use DataLoaderBBC to init data.
2017:03:16 21:59:12	reading and processing the text file.
2017:03:16 21:59:12	preprocess the dataset.
2017:03:16 21:59:12	load data.
2017:03:16 21:59:12	init content from raw.
2017:03:16 21:59:12	init data from the raw dataset.
2017:03:16 21:59:12	load context for further preprocessing.
2017:03:16 21:59:12	clean data.
2017:03:16 21:59:13	...mask and pad the sentence.
2017:03:16 21:59:13	......max len:361, median len:20.0, min len:0
2017:03:16 21:59:14	build a vocabulary.
2017:03:16 21:59:14	...flatmap a list of sentence list to a list of sentence.
2017:03:16 21:59:19	...mapping from index to word.
2017:03:16 21:59:19	...mapping from word to index.
2017:03:16 21:59:19	...map word to index.
2017:03:16 21:59:20	...some data statistics.
2017:03:16 21:59:20	......existing 43303 words, vocabulary size is 33317
2017:03:16 21:59:20	...save processed data to file.
2017:03:16 21:59:20	...number of batches: 8
2017:03:16 21:59:20	the number of sentence is 10240, the vocab size is 33317
2017:03:16 22:00:11	use DataLoaderBBC to init data.
2017:03:16 22:00:11	reading and processing the text file.
2017:03:16 22:00:11	preprocess the dataset.
2017:03:16 22:00:11	load data.
2017:03:16 22:00:11	init content from raw.
2017:03:16 22:00:11	init data from the raw dataset.
2017:03:16 22:00:11	load context for further preprocessing.
2017:03:16 22:00:11	clean data.
2017:03:16 22:00:12	...mask and pad the sentence.
2017:03:16 22:00:12	......max len:361, median len:20.0, min len:0
2017:03:16 22:00:12	build a vocabulary.
2017:03:16 22:00:12	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:00:13	...mapping from index to word.
2017:03:16 22:00:13	...mapping from word to index.
2017:03:16 22:00:13	...map word to index.
2017:03:16 22:00:13	...some data statistics.
2017:03:16 22:00:13	......existing 43303 words, vocabulary size is 18249
2017:03:16 22:00:13	...save processed data to file.
2017:03:16 22:00:14	...number of batches: 8
2017:03:16 22:00:14	the number of sentence is 10240, the vocab size is 18249
2017:03:16 22:00:31	use DataLoaderBBC to init data.
2017:03:16 22:00:31	reading and processing the text file.
2017:03:16 22:00:31	preprocess the dataset.
2017:03:16 22:00:31	load data.
2017:03:16 22:00:31	init content from raw.
2017:03:16 22:00:31	init data from the raw dataset.
2017:03:16 22:00:31	load context for further preprocessing.
2017:03:16 22:00:31	clean data.
2017:03:16 22:00:32	...mask and pad the sentence.
2017:03:16 22:00:32	......max len:361, median len:20.0, min len:0
2017:03:16 22:00:32	build a vocabulary.
2017:03:16 22:00:32	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:01:23	use DataLoaderBBC to init data.
2017:03:16 22:01:23	reading and processing the text file.
2017:03:16 22:01:23	preprocess the dataset.
2017:03:16 22:01:23	load data.
2017:03:16 22:01:23	init content from raw.
2017:03:16 22:01:23	init data from the raw dataset.
2017:03:16 22:01:23	load context for further preprocessing.
2017:03:16 22:01:23	clean data.
2017:03:16 22:01:24	...mask and pad the sentence.
2017:03:16 22:01:24	......max len:361, median len:20.0, min len:0
2017:03:16 22:01:24	build a vocabulary.
2017:03:16 22:01:24	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:01:57	use DataLoaderBBC to init data.
2017:03:16 22:01:57	reading and processing the text file.
2017:03:16 22:01:57	preprocess the dataset.
2017:03:16 22:01:57	load data.
2017:03:16 22:01:57	init content from raw.
2017:03:16 22:01:57	init data from the raw dataset.
2017:03:16 22:01:58	load context for further preprocessing.
2017:03:16 22:01:58	clean data.
2017:03:16 22:01:58	...mask and pad the sentence.
2017:03:16 22:01:58	......max len:361, median len:20.0, min len:0
2017:03:16 22:01:59	build a vocabulary.
2017:03:16 22:01:59	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:01:59	...mapping from index to word.
2017:03:16 22:01:59	...mapping from word to index.
2017:03:16 22:01:59	...map word to index.
2017:03:16 22:01:59	...some data statistics.
2017:03:16 22:01:59	......existing 43303 words, vocabulary size is 29011
2017:03:16 22:01:59	...save processed data to file.
2017:03:16 22:03:02	use DataLoaderBBC to init data.
2017:03:16 22:03:02	reading and processing the text file.
2017:03:16 22:03:02	preprocess the dataset.
2017:03:16 22:03:02	load data.
2017:03:16 22:03:02	init content from raw.
2017:03:16 22:03:02	init data from the raw dataset.
2017:03:16 22:03:02	load context for further preprocessing.
2017:03:16 22:03:02	clean data.
2017:03:16 22:03:03	...mask and pad the sentence.
2017:03:16 22:03:03	......max len:363, median len:22.0, min len:2
2017:03:16 22:03:03	build a vocabulary.
2017:03:16 22:03:03	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:03:04	...mapping from index to word.
2017:03:16 22:03:04	...mapping from word to index.
2017:03:16 22:03:04	...map word to index.
2017:03:16 22:03:04	...some data statistics.
2017:03:16 22:03:04	......existing 43303 words, vocabulary size is 28074
2017:03:16 22:03:04	...save processed data to file.
2017:03:16 22:03:05	...number of batches: 8
2017:03:16 22:03:05	the number of sentence is 10240, the vocab size is 28074
2017:03:16 22:03:07	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489701787

2017:03:16 22:03:09	------ training ------ 

2017:03:16 22:03:09	train epoch 0
2017:03:16 22:03:36	use DataLoaderBBC to init data.
2017:03:16 22:03:36	reading and processing the text file.
2017:03:16 22:03:36	preprocess the dataset.
2017:03:16 22:03:36	load data.
2017:03:16 22:03:36	init content from raw.
2017:03:16 22:03:36	init data from the raw dataset.
2017:03:16 22:03:36	load context for further preprocessing.
2017:03:16 22:03:36	clean data.
2017:03:16 22:03:37	...mask and pad the sentence.
2017:03:16 22:03:37	......max len:363, median len:22.0, min len:2
2017:03:16 22:03:37	build a vocabulary.
2017:03:16 22:03:37	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:03:38	...mapping from index to word.
2017:03:16 22:03:38	...mapping from word to index.
2017:03:16 22:03:38	...map word to index.
2017:03:16 22:03:38	...some data statistics.
2017:03:16 22:03:38	......existing 43303 words, vocabulary size is 28075
2017:03:16 22:03:38	...save processed data to file.
2017:03:16 22:04:20	use DataLoaderBBC to init data.
2017:03:16 22:04:20	reading and processing the text file.
2017:03:16 22:04:20	preprocess the dataset.
2017:03:16 22:04:20	load data.
2017:03:16 22:04:20	init content from raw.
2017:03:16 22:04:20	init data from the raw dataset.
2017:03:16 22:04:20	load context for further preprocessing.
2017:03:16 22:04:20	clean data.
2017:03:16 22:04:21	...mask and pad the sentence.
2017:03:16 22:04:21	......max len:363, median len:22.0, min len:2
2017:03:16 22:04:21	build a vocabulary.
2017:03:16 22:04:21	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:04:21	...mapping from index to word.
2017:03:16 22:04:21	...mapping from word to index.
2017:03:16 22:04:21	...map word to index.
2017:03:16 22:04:22	...some data statistics.
2017:03:16 22:04:22	......existing 43303 words, vocabulary size is 28075
2017:03:16 22:04:22	...save processed data to file.
2017:03:16 22:05:58	use DataLoaderBBC to init data.
2017:03:16 22:05:58	reading and processing the text file.
2017:03:16 22:05:58	preprocess the dataset.
2017:03:16 22:05:58	load data.
2017:03:16 22:05:58	init content from raw.
2017:03:16 22:05:58	init data from the raw dataset.
2017:03:16 22:05:58	load context for further preprocessing.
2017:03:16 22:05:58	clean data.
2017:03:16 22:05:59	...mask and pad the sentence.
2017:03:16 22:05:59	......max len:363, median len:22.0, min len:2
2017:03:16 22:05:59	build a vocabulary.
2017:03:16 22:05:59	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:05:59	...mapping from index to word.
2017:03:16 22:05:59	...mapping from word to index.
2017:03:16 22:05:59	...map word to index.
2017:03:16 22:06:00	...some data statistics.
2017:03:16 22:06:24	use DataLoaderBBC to init data.
2017:03:16 22:06:24	reading and processing the text file.
2017:03:16 22:06:24	preprocess the dataset.
2017:03:16 22:06:24	load data.
2017:03:16 22:06:24	init content from raw.
2017:03:16 22:06:24	init data from the raw dataset.
2017:03:16 22:06:24	load context for further preprocessing.
2017:03:16 22:06:24	clean data.
2017:03:16 22:06:25	...mask and pad the sentence.
2017:03:16 22:06:25	......max len:363, median len:22.0, min len:2
2017:03:16 22:06:25	build a vocabulary.
2017:03:16 22:06:25	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:06:25	...mapping from index to word.
2017:03:16 22:06:25	...mapping from word to index.
2017:03:16 22:06:25	...map word to index.
2017:03:16 22:06:26	...some data statistics.
2017:03:16 22:06:48	use DataLoaderBBC to init data.
2017:03:16 22:06:48	reading and processing the text file.
2017:03:16 22:06:48	preprocess the dataset.
2017:03:16 22:06:48	load data.
2017:03:16 22:06:48	init content from raw.
2017:03:16 22:06:48	init data from the raw dataset.
2017:03:16 22:06:48	load context for further preprocessing.
2017:03:16 22:06:48	clean data.
2017:03:16 22:06:49	...mask and pad the sentence.
2017:03:16 22:06:49	......max len:363, median len:22.0, min len:2
2017:03:16 22:06:49	build a vocabulary.
2017:03:16 22:06:49	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:06:50	...mapping from index to word.
2017:03:16 22:06:50	...mapping from word to index.
2017:03:16 22:06:50	...map word to index.
2017:03:16 22:06:50	...some data statistics.
2017:03:16 22:07:11	use DataLoaderBBC to init data.
2017:03:16 22:07:11	reading and processing the text file.
2017:03:16 22:07:11	preprocess the dataset.
2017:03:16 22:07:11	load data.
2017:03:16 22:07:11	init content from raw.
2017:03:16 22:07:11	init data from the raw dataset.
2017:03:16 22:07:11	load context for further preprocessing.
2017:03:16 22:07:11	clean data.
2017:03:16 22:07:12	...mask and pad the sentence.
2017:03:16 22:07:12	......max len:363, median len:22.0, min len:2
2017:03:16 22:07:12	build a vocabulary.
2017:03:16 22:07:12	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:07:12	...mapping from index to word.
2017:03:16 22:07:12	...mapping from word to index.
2017:03:16 22:07:12	...map word to index.
2017:03:16 22:07:33	use DataLoaderBBC to init data.
2017:03:16 22:07:33	reading and processing the text file.
2017:03:16 22:07:33	preprocess the dataset.
2017:03:16 22:07:33	load data.
2017:03:16 22:07:33	init content from raw.
2017:03:16 22:07:33	init data from the raw dataset.
2017:03:16 22:07:33	load context for further preprocessing.
2017:03:16 22:07:33	clean data.
2017:03:16 22:07:34	...mask and pad the sentence.
2017:03:16 22:07:34	......max len:363, median len:22.0, min len:2
2017:03:16 22:07:34	build a vocabulary.
2017:03:16 22:07:34	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:07:35	...mapping from index to word.
2017:03:16 22:07:35	...mapping from word to index.
2017:03:16 22:07:35	...map word to index.
2017:03:16 22:07:35	...some data statistics.
2017:03:16 22:09:27	use DataLoaderBBC to init data.
2017:03:16 22:09:27	reading and processing the text file.
2017:03:16 22:09:27	preprocess the dataset.
2017:03:16 22:09:27	load data.
2017:03:16 22:09:27	init content from raw.
2017:03:16 22:09:27	init data from the raw dataset.
2017:03:16 22:09:27	load context for further preprocessing.
2017:03:16 22:09:27	clean data.
2017:03:16 22:09:28	...mask and pad the sentence.
2017:03:16 22:09:28	......max len:363, median len:22.0, min len:2
2017:03:16 22:09:28	build a vocabulary.
2017:03:16 22:09:28	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:09:28	...mapping from index to word.
2017:03:16 22:09:29	...mapping from word to index.
2017:03:16 22:09:29	...map word to index.
2017:03:16 22:09:29	...some data statistics.
2017:03:16 22:09:29	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 22:09:29	...save processed data to file.
2017:03:16 22:09:31	...number of batches: 8
2017:03:16 22:09:31	the number of sentence is 10240, the vocab size is 28075
2017:03:16 22:10:08	use DataLoaderBBC to init data.
2017:03:16 22:10:08	reading and processing the text file.
2017:03:16 22:10:08	preprocess the dataset.
2017:03:16 22:10:08	load data.
2017:03:16 22:10:08	init content from raw.
2017:03:16 22:10:08	init data from the raw dataset.
2017:03:16 22:10:08	load context for further preprocessing.
2017:03:16 22:10:08	clean data.
2017:03:16 22:10:08	...mask and pad the sentence.
2017:03:16 22:10:08	......max len:363, median len:22.0, min len:2
2017:03:16 22:10:09	build a vocabulary.
2017:03:16 22:10:09	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:10:09	...mapping from index to word.
2017:03:16 22:10:09	...mapping from word to index.
2017:03:16 22:10:09	...map word to index.
2017:03:16 22:10:09	...some data statistics.
2017:03:16 22:10:09	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 22:10:09	...save processed data to file.
2017:03:16 22:10:12	...number of batches: 8
2017:03:16 22:10:12	the number of sentence is 10240, the vocab size is 28075
2017:03:16 22:10:13	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489702213

2017:03:16 22:10:15	------ training ------ 

2017:03:16 22:10:15	train epoch 0
2017:03:16 22:22:05	use DataLoaderBBC to init data.
2017:03:16 22:22:05	reading and processing the text file.
2017:03:16 22:22:05	preprocess the dataset.
2017:03:16 22:22:05	load data.
2017:03:16 22:22:05	init content from raw.
2017:03:16 22:22:05	init data from the raw dataset.
2017:03:16 22:22:07	load context for further preprocessing.
2017:03:16 22:22:07	clean data.
2017:03:16 22:22:08	...mask and pad the sentence.
2017:03:16 22:22:08	......max len:363, median len:22.0, min len:2
2017:03:16 22:22:09	build a vocabulary.
2017:03:16 22:22:09	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:22:09	...mapping from index to word.
2017:03:16 22:22:09	...mapping from word to index.
2017:03:16 22:22:09	...map word to index.
2017:03:16 22:22:10	...some data statistics.
2017:03:16 22:22:10	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 22:22:10	...save processed data to file.
2017:03:16 22:22:12	...number of batches: 80
2017:03:16 22:24:04	use DataLoaderBBC to init data.
2017:03:16 22:24:04	reading and processing the text file.
2017:03:16 22:24:04	preprocess the dataset.
2017:03:16 22:24:04	load data.
2017:03:16 22:24:04	init content from raw.
2017:03:16 22:24:04	init data from the raw dataset.
2017:03:16 22:24:04	load context for further preprocessing.
2017:03:16 22:24:04	clean data.
2017:03:16 22:24:05	...mask and pad the sentence.
2017:03:16 22:24:05	......max len:363, median len:22.0, min len:2
2017:03:16 22:24:05	build a vocabulary.
2017:03:16 22:24:05	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:24:06	...mapping from index to word.
2017:03:16 22:24:06	...mapping from word to index.
2017:03:16 22:24:06	...map word to index.
2017:03:16 22:24:07	...some data statistics.
2017:03:16 22:24:07	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 22:24:07	...save processed data to file.
2017:03:16 22:24:09	...number of batches: 80
2017:03:16 22:24:09	the number of sentence is 32626, the vocab size is 28075
2017:03:16 22:24:13	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489703053

2017:03:16 22:24:15	------ training ------ 

2017:03:16 22:24:15	train epoch 0
2017:03:16 22:24:53	use DataLoaderBBC to init data.
2017:03:16 22:24:53	reading and processing the text file.
2017:03:16 22:24:53	preprocess the dataset.
2017:03:16 22:24:53	load data.
2017:03:16 22:24:53	init content from raw.
2017:03:16 22:24:53	init data from the raw dataset.
2017:03:16 22:24:54	load context for further preprocessing.
2017:03:16 22:24:54	clean data.
2017:03:16 22:24:55	...mask and pad the sentence.
2017:03:16 22:24:55	......max len:363, median len:22.0, min len:2
2017:03:16 22:24:55	build a vocabulary.
2017:03:16 22:24:55	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:24:56	...mapping from index to word.
2017:03:16 22:24:56	...mapping from word to index.
2017:03:16 22:24:56	...map word to index.
2017:03:16 22:24:56	...some data statistics.
2017:03:16 22:24:56	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 22:24:56	...save processed data to file.
2017:03:16 22:24:58	...number of batches: 80
2017:03:16 22:24:58	the number of sentence is 32626, the vocab size is 28075
2017:03:16 22:25:02	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489703102

2017:03:16 22:25:04	------ training ------ 

2017:03:16 22:25:04	train epoch 0
2017:03:16 22:25:18	use DataLoaderBBC to init data.
2017:03:16 22:25:18	reading and processing the text file.
2017:03:16 22:25:18	preprocess the dataset.
2017:03:16 22:25:18	load data.
2017:03:16 22:25:18	init content from raw.
2017:03:16 22:25:18	init data from the raw dataset.
2017:03:16 22:25:18	load context for further preprocessing.
2017:03:16 22:25:18	clean data.
2017:03:16 22:25:19	...mask and pad the sentence.
2017:03:16 22:25:19	......max len:363, median len:22.0, min len:2
2017:03:16 22:25:19	build a vocabulary.
2017:03:16 22:25:19	...flatmap a list of sentence list to a list of sentence.
2017:03:16 22:25:20	...mapping from index to word.
2017:03:16 22:25:20	...mapping from word to index.
2017:03:16 22:25:20	...map word to index.
2017:03:16 22:25:20	...some data statistics.
2017:03:16 22:25:20	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 22:25:20	...save processed data to file.
2017:03:16 22:25:22	...number of batches: 80
2017:03:16 22:25:22	the number of sentence is 32626, the vocab size is 28075
2017:03:16 22:25:25	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489703125

2017:03:16 22:25:27	------ training ------ 

2017:03:16 22:25:27	train epoch 0
2017:03:16 22:30:52	use DataLoaderBBC to init data.
2017:03:16 22:30:52	reading and processing the text file.
2017:03:16 22:30:52	preprocess the dataset.
2017:03:16 22:30:52	load data.
2017:03:16 22:30:52	init content from raw.
2017:03:16 22:30:52	init data from the raw dataset.
2017:03:16 23:24:08	use DataLoaderBBC to init data.
2017:03:16 23:24:08	reading and processing the text file.
2017:03:16 23:24:08	preprocess the dataset.
2017:03:16 23:24:08	load data.
2017:03:16 23:24:08	init content from raw.
2017:03:16 23:24:08	init data from the raw dataset.
2017:03:16 23:24:08	load context for further preprocessing.
2017:03:16 23:24:08	clean data.
2017:03:16 23:24:09	...mask and pad the sentence.
2017:03:16 23:24:09	......max len:363, median len:22.0, min len:2
2017:03:16 23:24:10	build a vocabulary.
2017:03:16 23:24:10	...flatmap a list of sentence list to a list of sentence.
2017:03:16 23:24:10	...mapping from index to word.
2017:03:16 23:24:10	...mapping from word to index.
2017:03:16 23:24:10	...map word to index.
2017:03:16 23:24:10	...some data statistics.
2017:03:16 23:24:10	......existing 32626 sentences, vocabulary size is 28075
2017:03:16 23:24:10	...save processed data to file.
2017:03:16 23:24:12	...number of batches: 80
2017:03:16 23:24:12	the number of sentence is 32626, the vocab size is 28075
2017:03:16 23:24:16	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489706656

2017:03:16 23:24:18	------ training ------ 

2017:03:16 23:24:18	train epoch 0
2017:03:17 09:43:36	use DataLoaderBBC to init data.
2017:03:17 09:43:36	reading and processing the text file.
2017:03:17 09:43:36	preprocess the dataset.
2017:03:17 09:43:36	load data.
2017:03:17 09:43:36	init content from raw.
2017:03:17 09:43:36	init data from the raw dataset.
2017:03:17 09:43:37	load context for further preprocessing.
2017:03:17 09:43:37	clean data.
2017:03:17 09:43:38	...mask and pad the sentence.
2017:03:17 09:43:38	......max len:363, median len:22.0, min len:2
2017:03:17 09:43:39	build a vocabulary.
2017:03:17 09:43:39	...flatmap a list of sentence list to a list of sentence.
2017:03:17 09:43:39	...mapping from index to word.
2017:03:17 09:43:39	...mapping from word to index.
2017:03:17 09:43:39	...map word to index.
2017:03:17 09:43:39	...some data statistics.
2017:03:17 09:43:39	......existing 32626 sentences, vocabulary size is 28075
2017:03:17 09:43:39	...save processed data to file.
2017:03:17 09:43:41	...number of batches: 254
2017:03:17 09:43:41	the number of sentence is 32626, the vocab size is 28075
2017:03:17 09:50:28	use DataLoaderBBC to init data.
2017:03:17 09:50:28	reading and processing the text file.
2017:03:17 09:50:28	preprocess the dataset.
2017:03:17 09:50:28	load data.
2017:03:17 09:50:28	init content from raw.
2017:03:17 09:50:28	init data from the raw dataset.
2017:03:17 09:50:28	load context for further preprocessing.
2017:03:17 09:50:28	clean data.
2017:03:17 09:50:29	...mask and pad the sentence.
2017:03:17 09:50:29	......max len:363, median len:22.0, min len:2
2017:03:17 09:50:29	build a vocabulary.
2017:03:17 09:50:29	...flatmap a list of sentence list to a list of sentence.
2017:03:17 09:50:30	...mapping from index to word.
2017:03:17 09:50:30	...mapping from word to index.
2017:03:17 09:50:30	...map word to index.
2017:03:17 09:50:30	...some data statistics.
2017:03:17 09:50:30	......existing 32626 sentences, vocabulary size is 28075
2017:03:17 09:50:30	...save processed data to file.
2017:03:17 09:50:32	...number of batches: 254
2017:03:17 09:50:32	the number of sentence is 32626, the vocab size is 28075
2017:03:17 09:50:35	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489744235

2017:03:18 19:39:17	use DataLoaderBBC to init data.
2017:03:18 19:39:17	reading and processing the text file.
2017:03:18 19:39:17	preprocess the dataset.
2017:03:18 19:39:17	load data.
2017:03:18 19:39:17	init content from raw.
2017:03:18 19:39:17	init data from the raw dataset.
2017:03:18 19:40:31	use DataLoaderBBC to init data.
2017:03:18 19:40:31	reading and processing the text file.
2017:03:18 19:40:31	preprocess the dataset.
2017:03:18 19:40:31	load data.
2017:03:18 19:40:31	load context for further preprocessing.
2017:03:18 19:40:31	clean data.
2017:03:18 19:40:32	...mask and pad the sentence.
2017:03:18 19:40:32	......max len:363, median len:22.0, min len:2
2017:03:18 19:40:32	build a vocabulary.
2017:03:18 19:40:32	...flatmap a list of sentence list to a list of sentence.
2017:03:18 19:40:33	...mapping from index to word.
2017:03:18 19:40:33	...mapping from word to index.
2017:03:18 19:40:33	...map word to index.
2017:03:18 19:40:33	...some data statistics.
2017:03:18 19:40:33	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:40:33	...save processed data to file.
2017:03:18 19:40:36	...number of batches: 509
2017:03:18 19:41:23	use DataLoaderBBC to init data.
2017:03:18 19:41:23	loading preprocessed files.
2017:03:18 19:41:26	...some data statistics.
2017:03:18 19:41:26	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:41:26	...number of batches: 509
2017:03:18 19:41:26	the number of sentence is 32626, the vocab size is 28075
2017:03:18 19:42:08	use DataLoaderBBC to init data.
2017:03:18 19:42:08	loading preprocessed files.
2017:03:18 19:42:12	...some data statistics.
2017:03:18 19:42:12	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:42:12	...number of batches: 509
2017:03:18 19:42:12	the number of sentence is 32626, the vocab size is 28075
2017:03:18 19:43:04	use DataLoaderBBC to init data.
2017:03:18 19:43:04	loading preprocessed files.
2017:03:18 19:43:08	...some data statistics.
2017:03:18 19:43:08	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:43:08	...number of batches: 509
2017:03:18 19:43:08	the number of sentence is 32626, the vocab size is 28075
2017:03:18 19:43:47	use DataLoaderBBC to init data.
2017:03:18 19:43:47	loading preprocessed files.
2017:03:18 19:43:51	...some data statistics.
2017:03:18 19:43:51	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:43:51	...number of batches: 509
2017:03:18 19:43:51	the number of sentence is 32626, the vocab size is 28075
2017:03:18 19:44:28	use DataLoaderBBC to init data.
2017:03:18 19:44:28	loading preprocessed files.
2017:03:18 19:44:31	...some data statistics.
2017:03:18 19:44:31	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:44:31	...number of batches: 509
2017:03:18 19:44:31	the number of sentence is 32626, the vocab size is 28075
2017:03:18 19:44:37	writing to /home/lin/notebooks/code/demo2_v/data/tinyshakespeare/training/runs/DataLoaderBBC/code.model.textG.TextG/1489866276

2017:03:18 19:44:40	------ training ------ 

2017:03:18 19:45:04	use DataLoaderBBC to init data.
2017:03:18 19:45:04	loading preprocessed files.
2017:03:18 19:45:07	...some data statistics.
2017:03:18 19:45:07	......existing 32626 sentences, vocabulary size is 28075
2017:03:18 19:45:07	...number of batches: 509
2017:03:18 19:45:07	the number of sentence is 32626, the vocab size is 28075
2017:03:18 19:45:12	writing to /home/lin/notebooks/code/demo2_v/data/tinyshakespeare/training/runs/DataLoaderBBC/code.model.textG.TextG/1489866312

2017:03:18 19:45:15	------ training ------ 

2017:03:18 19:45:15	train epoch 0
2017:03:18 19:46:04	use DataLoaderShakespeare to init data.
2017:03:18 19:46:29	use DataLoaderShakespeare to init data.
2017:03:18 19:46:29	reading and processing the text file.
2017:03:18 19:46:29	preprocess the dataset.
2017:03:18 19:46:58	use DataLoaderShakespeare to init data.
2017:03:18 19:46:58	reading and processing the text file.
2017:03:18 19:46:58	preprocess the dataset.
2017:03:18 19:47:16	build a vocabulary.
2017:03:18 19:47:16	...flatmap a list of sentence list to a list of sentence.
2017:03:18 19:47:16	...mapping from index to word.
2017:03:18 19:47:16	...mapping from word to index.
2017:03:18 19:47:16	...map word to index.
2017:03:18 19:47:16	...some data statistics.
2017:03:18 19:47:16	......existing 243264 words, vocabulary size is 14004
2017:03:18 19:47:16	...save processed data to file.
2017:03:18 19:47:17	...number of batches: 152
2017:03:18 19:47:27	use DataLoaderShakespeare to init data.
2017:03:18 19:47:27	loading preprocessed files.
2017:03:18 19:47:27	......existing 243264 words, vocabulary size is 14004
2017:03:18 19:47:27	...number of batches: 152
2017:03:18 19:47:27	the number of sentence is 243200, the vocab size is 14004
2017:03:18 19:47:32	writing to /home/lin/notebooks/code/demo2_v/data/tinyshakespeare/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489866452

2017:03:18 19:47:35	------ training ------ 

2017:03:18 19:47:35	train epoch 0
2017:03:18 19:49:58	use DataLoaderShakespeare to init data.
2017:03:18 19:49:58	reading and processing the text file.
2017:03:18 19:49:58	preprocess the dataset.
2017:03:18 19:50:15	build a vocabulary.
2017:03:18 19:50:15	...flatmap a list of sentence list to a list of sentence.
2017:03:18 19:50:15	...mapping from index to word.
2017:03:18 19:50:15	...mapping from word to index.
2017:03:18 19:50:15	...map word to index.
2017:03:18 19:50:16	...some data statistics.
2017:03:18 19:50:16	......existing 243264 words, vocabulary size is 14004
2017:03:18 19:50:16	...save processed data to file.
2017:03:18 19:50:16	...number of batches: 152
2017:03:18 19:50:16	the number of sentence is 243200, the vocab size is 14004
2017:03:18 19:50:21	writing to /home/lin/notebooks/code/demo2_v/data/tinyshakespeare/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489866621

2017:03:18 19:50:24	------ training ------ 

2017:03:18 19:50:24	train epoch 0
2017:03:18 19:51:56	use DataLoaderShakespeare to init data.
2017:03:18 19:51:56	reading and processing the text file.
2017:03:18 19:51:56	preprocess the dataset.
2017:03:18 19:52:13	build a vocabulary.
2017:03:18 19:52:13	...flatmap a list of sentence list to a list of sentence.
2017:03:18 19:52:13	...mapping from index to word.
2017:03:18 19:52:13	...mapping from word to index.
2017:03:18 19:52:13	...map word to index.
2017:03:18 19:52:13	...some data statistics.
2017:03:18 19:52:13	......existing 243264 words, vocabulary size is 14004
2017:03:18 19:52:13	...save processed data to file.
2017:03:18 19:52:13	...number of batches: 152
2017:03:18 19:52:13	the number of sentence is 243200, the vocab size is 14004
2017:03:18 19:52:18	writing to /home/lin/notebooks/code/demo2_v/data/tinyshakespeare/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489866738

2017:03:18 19:52:21	------ training ------ 

2017:03:18 19:52:21	train epoch 0
2017:03:18 19:53:08	use DataLoaderShakespeare to init data.
2017:03:18 19:53:08	loading preprocessed files.
2017:03:18 19:53:09	......existing 243264 words, vocabulary size is 14004
2017:03:18 19:53:09	...number of batches: 152
2017:03:18 19:53:09	the number of sentence is 243200, the vocab size is 14004
2017:03:18 19:53:15	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489866795

2017:03:18 19:53:17	------ training ------ 

2017:03:18 19:53:17	train epoch 0
2017:03:18 19:58:17	use DataLoaderShakespeare to init data.
2017:03:18 19:58:17	loading preprocessed files.
2017:03:18 19:58:18	......existing 243264 words, vocabulary size is 14004
2017:03:18 19:58:18	...number of batches: 152
2017:03:18 19:58:18	the number of sentence is 243200, the vocab size is 14004
2017:03:18 19:58:22	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489867102

2017:03:18 19:58:25	------ training ------ 

2017:03:18 19:58:25	train epoch 0
2017:03:18 20:06:47	use DataLoaderShakespeare to init data.
2017:03:18 20:06:47	loading preprocessed files.
2017:03:18 20:06:48	......existing 243264 words, vocabulary size is 14004
2017:03:18 20:06:48	...number of batches: 152
2017:03:18 20:06:48	the number of sentence is 243200, the vocab size is 14004
2017:03:18 20:06:52	------ training ------ 

2017:03:18 20:06:52	train epoch 0
2017:03:18 20:15:22	use DataLoaderShakespeare to init data.
2017:03:18 20:15:22	loading preprocessed files.
2017:03:18 20:15:23	......existing 243264 words, vocabulary size is 14004
2017:03:18 20:15:23	...number of batches: 152
2017:03:18 20:15:23	the number of sentence is 243200, the vocab size is 14004
2017:03:18 20:15:27	------ training ------ 

2017:03:18 20:15:27	train epoch 0
2017:03:18 20:17:29	use DataLoaderShakespeare to init data.
2017:03:18 20:17:29	loading preprocessed files.
2017:03:18 20:17:29	......existing 243264 words, vocabulary size is 14004
2017:03:18 20:17:29	...number of batches: 152
2017:03:18 20:17:29	the number of sentence is 243200, the vocab size is 14004
2017:03:18 20:17:33	------ training ------ 

2017:03:18 20:17:33	train epoch 0
2017:03:18 20:17:50	use DataLoaderShakespeare to init data.
2017:03:18 20:17:50	loading preprocessed files.
2017:03:18 20:17:51	......existing 243264 words, vocabulary size is 14004
2017:03:18 20:17:51	...number of batches: 152
2017:03:18 20:17:51	the number of sentence is 243200, the vocab size is 14004
2017:03:18 20:17:54	------ training ------ 

2017:03:18 20:17:54	train epoch 0
2017:03:18 21:49:09	use DataLoaderShakespeare to init data.
2017:03:18 21:49:09	reading and processing the text file.
2017:03:18 21:49:09	preprocess the dataset.
2017:03:18 21:49:33	use DataLoaderShakespeare to init data.
2017:03:18 21:49:33	loading preprocessed files.
2017:03:18 21:50:09	use DataLoaderShakespeare to init data.
2017:03:18 21:50:09	reading and processing the text file.
2017:03:18 21:50:09	preprocess the dataset.
2017:03:18 21:50:26	build a vocabulary.
2017:03:18 21:50:26	...flatmap a list of sentence list to a list of sentence.
2017:03:18 21:50:26	...mapping from index to word.
2017:03:18 21:50:26	...mapping from word to index.
2017:03:18 21:50:26	...map word to index.
2017:03:18 21:50:26	...some data statistics.
2017:03:18 21:50:26	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:50:26	...save processed data to file.
2017:03:18 21:50:27	...number of batches: 152
2017:03:18 21:51:16	use DataLoaderShakespeare to init data.
2017:03:18 21:51:16	reading and processing the text file.
2017:03:18 21:51:16	preprocess the dataset.
2017:03:18 21:51:32	build a vocabulary.
2017:03:18 21:51:32	...flatmap a list of sentence list to a list of sentence.
2017:03:18 21:51:32	...mapping from index to word.
2017:03:18 21:51:32	...mapping from word to index.
2017:03:18 21:51:32	...map word to index.
2017:03:18 21:51:32	...some data statistics.
2017:03:18 21:51:32	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:51:32	...save processed data to file.
2017:03:18 21:51:32	...number of batches: 152
2017:03:18 21:51:53	use DataLoaderShakespeare to init data.
2017:03:18 21:51:53	loading preprocessed files.
2017:03:18 21:51:54	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:51:54	...number of batches: 152
2017:03:18 21:53:36	use DataLoaderShakespeare to init data.
2017:03:18 21:53:36	loading preprocessed files.
2017:03:18 21:53:37	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:53:37	...number of batches: 152
2017:03:18 21:53:37	the number of sentence is 9728, the vocab size is 14004
2017:03:18 21:54:03	use DataLoaderShakespeare to init data.
2017:03:18 21:54:03	loading preprocessed files.
2017:03:18 21:54:04	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:54:04	...number of batches: 152
2017:03:18 21:54:04	the number of sentence is 9728, the vocab size is 14004
2017:03:18 21:54:30	use DataLoaderShakespeare to init data.
2017:03:18 21:54:30	loading preprocessed files.
2017:03:18 21:54:31	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:54:31	...number of batches: 152
2017:03:18 21:54:31	the number of sentence is 9728, the vocab size is 14004
2017:03:18 21:54:37	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489874076

2017:03:18 21:54:40	------ training ------ 

2017:03:18 21:54:40	train epoch 0
2017:03:18 21:55:22	use DataLoaderShakespeare to init data.
2017:03:18 21:55:22	loading preprocessed files.
2017:03:18 21:55:23	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:55:23	...number of batches: 152
2017:03:18 21:55:23	the number of sentence is 9728, the vocab size is 14004
2017:03:18 21:55:28	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489874128

2017:03:18 21:55:31	------ training ------ 

2017:03:18 21:55:31	train epoch 0
2017:03:18 21:56:00	use DataLoaderShakespeare to init data.
2017:03:18 21:56:00	loading preprocessed files.
2017:03:18 21:56:02	......existing 243264 words, vocabulary size is 14004
2017:03:18 21:56:02	...number of batches: 152
2017:03:18 21:56:02	the number of sentence is 9728, the vocab size is 14004
2017:03:18 21:56:08	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489874168

2017:03:18 21:56:10	------ training ------ 

2017:03:18 21:56:10	train epoch 0
2017:03:19 11:02:54	use DataLoaderBBC to init data.
2017:03:19 11:02:54	loading preprocessed files.
2017:03:19 11:02:58	...number of batches: 509
2017:03:19 11:08:08	use DataLoaderBBC to init data.
2017:03:19 11:08:08	loading preprocessed files.
2017:03:19 11:08:11	...get data info.
2017:03:19 11:08:11	...number of batches: 509
2017:03:19 11:08:11	...init batch data.
2017:03:19 11:08:11	num of sentence: 32576, sentence length: 30, vocab size: 28075
2017:03:19 11:08:35	use DataLoaderShakespeare to init data.
2017:03:19 11:08:35	loading preprocessed files.
2017:03:19 11:08:36	...get data info.
2017:03:19 11:08:36	...number of batches: 152
2017:03:19 11:08:36	...init batch data.
2017:03:19 11:08:36	the number of sentence is 9728, the vocab size is 14004
2017:03:19 11:08:40	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489921720

2017:03:19 11:08:43	------ training ------ 

2017:03:19 11:08:43	train epoch 0
2017:03:19 11:09:03	use DataLoaderBBC to init data.
2017:03:19 11:09:03	loading preprocessed files.
2017:03:19 11:09:06	...get data info.
2017:03:19 11:09:06	...number of batches: 509
2017:03:19 11:09:06	...init batch data.
2017:03:19 11:09:06	num of sentence: 32576, sentence length: 30, vocab size: 28075
2017:03:19 11:09:39	use DataLoaderBBC to init data.
2017:03:19 11:09:39	loading preprocessed files.
2017:03:19 11:09:43	...get data info.
2017:03:19 11:09:43	...number of batches: 509
2017:03:19 11:09:43	...init batch data.
2017:03:19 11:09:43	num of sentence: 32576, sentence length: 30, vocab size: 28075
2017:03:19 11:10:40	use DataLoaderBBC to init data.
2017:03:19 11:10:40	reading and processing the text file.
2017:03:19 11:10:40	preprocess the dataset.
2017:03:19 11:10:40	load data.
2017:03:19 11:10:40	init content from raw.
2017:03:19 11:10:40	init data from the raw dataset.
2017:03:19 11:10:41	load context for further preprocessing.
2017:03:19 11:10:41	clean data.
2017:03:19 11:10:42	...mask and pad the sentence.
2017:03:19 11:10:42	......max len:363, median len:22.0, min len:2
2017:03:19 11:10:43	build a vocabulary.
2017:03:19 11:10:43	...flatmap a list of sentence list to a list of sentence.
2017:03:19 11:10:43	...mapping from index to word.
2017:03:19 11:10:43	...mapping from word to index.
2017:03:19 11:10:43	...map word to index.
2017:03:19 11:10:43	...save processed data to file.
2017:03:19 11:10:44	...get data info.
2017:03:19 11:10:44	...number of batches: 390
2017:03:19 11:10:44	...init batch data.
2017:03:19 11:10:44	num of sentence: 24960, sentence length: 25, vocab size: 23702
2017:03:19 11:10:49	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489921848

2017:03:19 11:10:51	------ training ------ 

2017:03:19 11:10:51	train epoch 0
2017:03:19 11:12:18	use DataLoaderBBC to init data.
2017:03:19 11:12:18	reading and processing the text file.
2017:03:19 11:12:18	preprocess the dataset.
2017:03:19 11:12:18	load data.
2017:03:19 11:12:18	init content from raw.
2017:03:19 11:12:18	init data from the raw dataset.
2017:03:19 11:12:19	load context for further preprocessing.
2017:03:19 11:12:19	clean data.
2017:03:19 11:12:20	...mask and pad the sentence.
2017:03:19 11:12:20	......max len:363, median len:22.0, min len:2
2017:03:19 11:12:20	build a vocabulary.
2017:03:19 11:12:20	...flatmap a list of sentence list to a list of sentence.
2017:03:19 11:12:20	...mapping from index to word.
2017:03:19 11:12:20	...mapping from word to index.
2017:03:19 11:12:20	...map word to index.
2017:03:19 11:12:20	...save processed data to file.
2017:03:19 11:12:21	get data info.
2017:03:19 11:12:21	init batch data.
2017:03:19 11:12:21	...number of batches: 390
2017:03:19 11:12:21	num of sentence: 24960, sentence length: 25, vocab size: 23702
2017:03:19 11:12:26	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489921946

2017:03:19 11:12:28	------ training ------ 

2017:03:19 11:12:28	train epoch 0
2017:03:19 11:12:48	use DataLoaderShakespeare to init data.
2017:03:19 11:12:48	reading and processing the text file.
2017:03:19 11:12:48	preprocess the dataset.
2017:03:19 11:13:06	build a vocabulary.
2017:03:19 11:13:06	...flatmap a list of sentence list to a list of sentence.
2017:03:19 11:13:06	...mapping from index to word.
2017:03:19 11:13:06	...mapping from word to index.
2017:03:19 11:13:06	...map word to index.
2017:03:19 11:13:06	...save processed data to file.
2017:03:19 11:13:07	get data info.
2017:03:19 11:13:07	init batch data.
2017:03:19 11:13:07	...number of batches: 152
2017:03:19 11:13:07	the number of sentence is 9728, the vocab size is 14004
2017:03:19 11:13:11	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderShakespeare/code.model.textG.TextG/1489921991

2017:03:19 11:13:14	------ training ------ 

2017:03:19 11:13:14	train epoch 0
2017:03:19 12:04:05	use DataLoaderBBCV to init data.
2017:03:19 12:04:49	use DataLoaderBBCV to init data.
2017:03:19 12:04:49	reading and processing the text file.
2017:03:19 12:04:49	preprocess the dataset.
2017:03:19 12:04:49	load data.
2017:03:19 12:04:49	init content from raw.
2017:03:19 12:04:49	init data from the raw dataset.
2017:03:19 12:04:50	load context for further preprocessing.
2017:03:19 12:04:51	...build vocab and map word to index.
2017:03:19 12:04:51	build a vocabulary.
2017:03:19 12:04:51	...flatmap a list of sentence list to a list of sentence.
2017:03:19 12:04:52	...mapping from index to word.
2017:03:19 12:04:52	...mapping from word to index.
2017:03:19 12:04:52	...save processed data to file.
2017:03:19 12:04:54	get data info.
2017:03:19 12:04:54	init batch data.
2017:03:19 12:04:54	...number of batches: 589
2017:03:19 12:04:54	num of sentence: 37696, sentence length: 25, vocab size: 34008
2017:03:19 12:04:54	reading and processing the text file.
2017:03:19 12:04:54	preprocess the dataset.
2017:03:19 12:04:54	load data.
2017:03:19 12:04:54	init content from raw.
2017:03:19 12:04:54	init data from the raw dataset.
2017:03:19 12:04:54	load context for further preprocessing.
2017:03:19 12:04:55	...build vocab and map word to index.
2017:03:19 12:04:55	build a vocabulary.
2017:03:19 12:04:55	...flatmap a list of sentence list to a list of sentence.
2017:03:19 12:04:55	...mapping from index to word.
2017:03:19 12:04:55	...mapping from word to index.
2017:03:19 12:04:55	...save processed data to file.
2017:03:19 12:04:57	get data info.
2017:03:19 12:04:57	init batch data.
2017:03:19 12:04:57	...number of batches: 589
2017:03:19 12:04:57	num of sentence: 37696, sentence length: 25, vocab size: 34008
2017:03:19 12:05:02	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1489925102

2017:03:19 12:05:06	------ training ------ 

2017:03:19 12:05:06	train epoch 0
2017:03:19 12:05:42	use DataLoaderBBC to init data.
2017:03:19 12:05:42	reading and processing the text file.
2017:03:19 12:05:42	preprocess the dataset.
2017:03:19 12:05:42	load data.
2017:03:19 12:05:42	init content from raw.
2017:03:19 12:05:42	init data from the raw dataset.
2017:03:19 12:05:43	load context for further preprocessing.
2017:03:19 12:05:43	clean data.
2017:03:19 12:05:44	...mask and pad the sentence.
2017:03:19 12:05:44	......max len:363, median len:22.0, min len:2
2017:03:19 12:05:44	build a vocabulary.
2017:03:19 12:05:44	...flatmap a list of sentence list to a list of sentence.
2017:03:19 12:05:44	...mapping from index to word.
2017:03:19 12:05:44	...mapping from word to index.
2017:03:19 12:05:44	...map word to index.
2017:03:19 12:05:45	...save processed data to file.
2017:03:19 12:05:46	get data info.
2017:03:19 12:05:46	init batch data.
2017:03:19 12:05:46	...number of batches: 390
2017:03:19 12:05:46	num of sentence: 24960, sentence length: 25, vocab size: 23702
2017:03:19 12:05:50	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1489925150

2017:03:19 12:05:52	------ training ------ 

2017:03:19 12:05:52	train epoch 0
2017:03:19 23:07:35	use DataLoaderBBCV to init data.
2017:03:19 23:07:35	reading and processing the text file.
2017:03:19 23:07:35	preprocess the dataset.
2017:03:19 23:07:35	load data.
2017:03:19 23:07:35	load context for further preprocessing.
2017:03:19 23:07:36	...build vocab and map word to index.
2017:03:19 23:07:36	build a vocabulary.
2017:03:19 23:07:36	...flatmap a list of sentence list to a list of sentence.
2017:03:19 23:07:37	...mapping from index to word.
2017:03:19 23:07:37	...mapping from word to index.
2017:03:19 23:07:38	...save processed data to file.
2017:03:19 23:07:40	get data info.
2017:03:19 23:07:40	init batch data.
2017:03:19 23:07:40	...number of batches: 565
2017:03:19 23:07:40	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:08:10	use DataLoaderBBCV to init data.
2017:03:19 23:08:10	loading preprocessed files.
2017:03:19 23:08:14	get data info.
2017:03:19 23:08:14	init batch data.
2017:03:19 23:08:14	...number of batches: 565
2017:03:19 23:08:14	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:09:09	use DataLoaderBBCV to init data.
2017:03:19 23:09:09	loading preprocessed files.
2017:03:19 23:09:13	get data info.
2017:03:19 23:09:13	init batch data.
2017:03:19 23:09:13	...number of batches: 565
2017:03:19 23:09:13	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:09:22	use DataLoaderBBCV to init data.
2017:03:19 23:09:22	loading preprocessed files.
2017:03:19 23:09:26	get data info.
2017:03:19 23:09:26	init batch data.
2017:03:19 23:09:26	...number of batches: 565
2017:03:19 23:09:26	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:10:17	use DataLoaderBBCV to init data.
2017:03:19 23:10:17	loading preprocessed files.
2017:03:19 23:10:21	get data info.
2017:03:19 23:10:21	init batch data.
2017:03:19 23:10:21	...number of batches: 565
2017:03:19 23:10:21	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:10:33	use DataLoaderBBCV to init data.
2017:03:19 23:10:33	loading preprocessed files.
2017:03:19 23:10:36	get data info.
2017:03:19 23:10:36	init batch data.
2017:03:19 23:10:36	...number of batches: 565
2017:03:19 23:10:36	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:10:48	use DataLoaderBBCV to init data.
2017:03:19 23:10:48	loading preprocessed files.
2017:03:19 23:10:51	get data info.
2017:03:19 23:10:51	init batch data.
2017:03:19 23:10:51	...number of batches: 565
2017:03:19 23:10:51	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:11:44	use DataLoaderBBCV to init data.
2017:03:19 23:11:44	loading preprocessed files.
2017:03:19 23:11:48	get data info.
2017:03:19 23:11:48	init batch data.
2017:03:19 23:11:48	...number of batches: 565
2017:03:19 23:11:48	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:19 23:11:52	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1489965112

2017:03:19 23:11:56	------ training ------ 

2017:03:19 23:11:56	train epoch 0
2017:03:20 11:37:22	use DataLoaderBBCV to init data.
2017:03:20 11:37:22	loading preprocessed files.
2017:03:20 11:37:26	get data info.
2017:03:20 11:37:26	init batch data.
2017:03:20 11:37:26	...number of batches: 565
2017:03:20 11:37:26	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:20 11:37:31	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1490009851

2017:03:20 11:37:34	------ training ------ 

2017:03:20 11:37:34	train epoch 0
2017:03:20 11:37:58	use DataLoaderBBCV to init data.
2017:03:20 11:37:58	loading preprocessed files.
2017:03:20 11:38:01	get data info.
2017:03:20 11:38:01	init batch data.
2017:03:20 11:38:01	...number of batches: 565
2017:03:20 11:38:01	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:20 11:38:06	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1490009885

2017:03:20 11:38:08	------ training ------ 

2017:03:20 11:38:08	train epoch 0
2017:03:20 11:38:36	use DataLoaderBBCV to init data.
2017:03:20 11:38:36	loading preprocessed files.
2017:03:20 11:38:39	get data info.
2017:03:20 11:38:39	init batch data.
2017:03:20 11:38:39	...number of batches: 565
2017:03:20 11:38:39	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:20 11:38:43	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1490009923

2017:03:20 11:38:46	------ training ------ 

2017:03:20 11:38:46	train epoch 0
2017:03:20 11:39:17	use DataLoaderBBCV to init data.
2017:03:20 11:39:17	loading preprocessed files.
2017:03:20 11:39:21	get data info.
2017:03:20 11:39:21	init batch data.
2017:03:20 11:39:21	...number of batches: 565
2017:03:20 11:39:21	num of sentence: 36160, sentence length: 25, vocab size: 30233
2017:03:20 11:39:25	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1490009965

2017:03:20 11:39:28	------ training ------ 

2017:03:20 11:39:28	train epoch 0
2017:03:20 13:47:21	use DataLoaderBBCV to init data.
2017:03:20 13:47:21	loading preprocessed files.
2017:03:20 13:47:25	get data info.
2017:03:20 13:47:25	init batch data.
2017:03:20 13:47:25	...number of batches: 724
2017:03:20 13:47:25	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:20 13:47:30	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textG.TextG/1490017649

2017:03:20 13:47:33	------ training ------ 

2017:03:20 13:47:33	train epoch 0
2017:03:20 17:10:53	use DataLoaderBBCV to init data.
2017:03:20 17:10:53	loading preprocessed files.
2017:03:20 17:10:57	get data info.
2017:03:20 17:10:57	init batch data.
2017:03:20 17:10:57	...number of batches: 724
2017:03:20 17:10:57	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:20 17:11:28	use DataLoaderBBCV to init data.
2017:03:20 17:11:28	loading preprocessed files.
2017:03:20 17:11:31	get data info.
2017:03:20 17:11:31	init batch data.
2017:03:20 17:11:31	...number of batches: 724
2017:03:20 17:11:31	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:20 17:12:22	use DataLoaderBBCV to init data.
2017:03:20 17:12:22	loading preprocessed files.
2017:03:20 17:12:25	get data info.
2017:03:20 17:12:25	init batch data.
2017:03:20 17:12:25	...number of batches: 724
2017:03:20 17:12:25	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:20 17:13:16	use DataLoaderBBCV to init data.
2017:03:20 17:13:16	loading preprocessed files.
2017:03:20 17:13:20	get data info.
2017:03:20 17:13:20	init batch data.
2017:03:20 17:13:20	...number of batches: 724
2017:03:20 17:13:20	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:20 17:13:45	use DataLoaderBBCV to init data.
2017:03:20 17:13:45	loading preprocessed files.
2017:03:20 17:13:48	get data info.
2017:03:20 17:13:48	init batch data.
2017:03:20 17:13:48	...number of batches: 724
2017:03:20 17:13:48	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:20 17:13:51	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBCV/code.model.textGV.TextGV/1490030031

2017:03:20 17:13:54	------ training ------ 

2017:03:20 17:13:54	train epoch 0
2017:03:21 09:21:05	use DataLoaderBBC to init data.
2017:03:21 09:21:05	loading preprocessed files.
2017:03:21 09:21:07	get data info.
2017:03:21 09:21:07	init batch data.
2017:03:21 09:21:07	...number of batches: 500
2017:03:21 09:21:07	num of sentence: 25000, sentence length: 25, vocab size: 23702
2017:03:21 09:21:12	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490088072

2017:03:21 09:21:16	------ training ------ 

2017:03:21 09:21:16	train epoch 0
2017:03:21 09:21:34	use DataLoaderBBC to init data.
2017:03:21 09:21:34	reading and processing the text file.
2017:03:21 09:21:34	preprocess the dataset.
2017:03:21 09:21:34	load data.
2017:03:21 09:21:34	init content from raw.
2017:03:21 09:21:34	init data from the raw dataset.
2017:03:21 09:21:36	load context for further preprocessing.
2017:03:21 09:21:36	clean data.
2017:03:21 09:21:36	...mask and pad the sentence.
2017:03:21 09:21:36	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:21:36	build a vocabulary.
2017:03:21 09:21:36	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:28:17	use DataLoaderBBC to init data.
2017:03:21 09:28:17	reading and processing the text file.
2017:03:21 09:28:17	preprocess the dataset.
2017:03:21 09:28:17	load data.
2017:03:21 09:28:17	init content from raw.
2017:03:21 09:28:17	init data from the raw dataset.
2017:03:21 09:28:18	load context for further preprocessing.
2017:03:21 09:28:18	clean data.
2017:03:21 09:29:05	use DataLoaderBBC to init data.
2017:03:21 09:29:05	reading and processing the text file.
2017:03:21 09:29:05	preprocess the dataset.
2017:03:21 09:29:05	load data.
2017:03:21 09:29:05	init content from raw.
2017:03:21 09:29:05	init data from the raw dataset.
2017:03:21 09:29:06	load context for further preprocessing.
2017:03:21 09:29:06	clean data.
2017:03:21 09:29:37	use DataLoaderBBC to init data.
2017:03:21 09:29:37	reading and processing the text file.
2017:03:21 09:29:37	preprocess the dataset.
2017:03:21 09:29:37	load data.
2017:03:21 09:29:37	init content from raw.
2017:03:21 09:29:37	init data from the raw dataset.
2017:03:21 09:29:38	load context for further preprocessing.
2017:03:21 09:29:38	clean data.
2017:03:21 09:30:32	use DataLoaderBBC to init data.
2017:03:21 09:30:32	reading and processing the text file.
2017:03:21 09:30:32	preprocess the dataset.
2017:03:21 09:30:32	load data.
2017:03:21 09:30:32	init content from raw.
2017:03:21 09:30:32	init data from the raw dataset.
2017:03:21 09:30:32	load context for further preprocessing.
2017:03:21 09:30:32	clean data.
2017:03:21 09:30:34	...mask and pad the sentence.
2017:03:21 09:30:34	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:30:34	build a vocabulary.
2017:03:21 09:30:34	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:31:05	use DataLoaderBBC to init data.
2017:03:21 09:31:05	reading and processing the text file.
2017:03:21 09:31:05	preprocess the dataset.
2017:03:21 09:31:05	load data.
2017:03:21 09:31:05	init content from raw.
2017:03:21 09:31:05	init data from the raw dataset.
2017:03:21 09:31:05	load context for further preprocessing.
2017:03:21 09:31:05	clean data.
2017:03:21 09:31:06	...mask and pad the sentence.
2017:03:21 09:31:06	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:31:06	build a vocabulary.
2017:03:21 09:31:06	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:31:18	use DataLoaderBBC to init data.
2017:03:21 09:31:18	reading and processing the text file.
2017:03:21 09:31:18	preprocess the dataset.
2017:03:21 09:31:18	load data.
2017:03:21 09:31:18	init content from raw.
2017:03:21 09:31:18	init data from the raw dataset.
2017:03:21 09:31:18	load context for further preprocessing.
2017:03:21 09:31:18	clean data.
2017:03:21 09:31:19	...mask and pad the sentence.
2017:03:21 09:31:19	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:31:19	build a vocabulary.
2017:03:21 09:31:19	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:31:48	use DataLoaderBBC to init data.
2017:03:21 09:31:48	reading and processing the text file.
2017:03:21 09:31:48	preprocess the dataset.
2017:03:21 09:31:48	load data.
2017:03:21 09:31:48	init content from raw.
2017:03:21 09:31:48	init data from the raw dataset.
2017:03:21 09:31:49	load context for further preprocessing.
2017:03:21 09:31:49	clean data.
2017:03:21 09:31:50	...mask and pad the sentence.
2017:03:21 09:31:50	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:31:50	build a vocabulary.
2017:03:21 09:31:50	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:35:04	use DataLoaderBBC to init data.
2017:03:21 09:35:04	reading and processing the text file.
2017:03:21 09:35:04	preprocess the dataset.
2017:03:21 09:35:04	load data.
2017:03:21 09:35:04	init content from raw.
2017:03:21 09:35:04	init data from the raw dataset.
2017:03:21 09:35:05	load context for further preprocessing.
2017:03:21 09:35:05	clean data.
2017:03:21 09:35:06	...mask and pad the sentence.
2017:03:21 09:35:06	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:35:06	build a vocabulary.
2017:03:21 09:35:06	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:36:08	use DataLoaderBBC to init data.
2017:03:21 09:36:08	reading and processing the text file.
2017:03:21 09:36:08	preprocess the dataset.
2017:03:21 09:36:08	load data.
2017:03:21 09:36:08	init content from raw.
2017:03:21 09:36:08	init data from the raw dataset.
2017:03:21 09:36:09	load context for further preprocessing.
2017:03:21 09:36:09	clean data.
2017:03:21 09:36:10	...mask and pad the sentence.
2017:03:21 09:36:10	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:36:10	build a vocabulary.
2017:03:21 09:36:10	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:37:12	use DataLoaderBBC to init data.
2017:03:21 09:37:12	reading and processing the text file.
2017:03:21 09:37:12	preprocess the dataset.
2017:03:21 09:37:12	load data.
2017:03:21 09:37:12	init content from raw.
2017:03:21 09:37:12	init data from the raw dataset.
2017:03:21 09:37:13	load context for further preprocessing.
2017:03:21 09:37:13	clean data.
2017:03:21 09:37:14	...mask and pad the sentence.
2017:03:21 09:37:14	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:37:14	build a vocabulary.
2017:03:21 09:37:14	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:37:50	use DataLoaderBBC to init data.
2017:03:21 09:37:50	reading and processing the text file.
2017:03:21 09:37:50	preprocess the dataset.
2017:03:21 09:37:50	load data.
2017:03:21 09:37:50	init content from raw.
2017:03:21 09:37:50	init data from the raw dataset.
2017:03:21 09:37:50	load context for further preprocessing.
2017:03:21 09:37:50	clean data.
2017:03:21 09:37:51	...mask and pad the sentence.
2017:03:21 09:37:51	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:37:51	build a vocabulary.
2017:03:21 09:37:51	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:38:17	use DataLoaderBBC to init data.
2017:03:21 09:38:17	reading and processing the text file.
2017:03:21 09:38:17	preprocess the dataset.
2017:03:21 09:38:17	load data.
2017:03:21 09:38:17	init content from raw.
2017:03:21 09:38:17	init data from the raw dataset.
2017:03:21 09:38:17	load context for further preprocessing.
2017:03:21 09:38:17	clean data.
2017:03:21 09:38:18	...mask and pad the sentence.
2017:03:21 09:38:18	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:38:18	build a vocabulary.
2017:03:21 09:38:18	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:38:34	use DataLoaderBBC to init data.
2017:03:21 09:38:34	reading and processing the text file.
2017:03:21 09:38:34	preprocess the dataset.
2017:03:21 09:38:34	load data.
2017:03:21 09:38:34	init content from raw.
2017:03:21 09:38:34	init data from the raw dataset.
2017:03:21 09:38:34	load context for further preprocessing.
2017:03:21 09:38:34	clean data.
2017:03:21 09:38:35	...mask and pad the sentence.
2017:03:21 09:38:35	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:38:35	build a vocabulary.
2017:03:21 09:38:35	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:38:50	use DataLoaderBBC to init data.
2017:03:21 09:38:50	reading and processing the text file.
2017:03:21 09:38:50	preprocess the dataset.
2017:03:21 09:38:50	load data.
2017:03:21 09:38:50	init content from raw.
2017:03:21 09:38:50	init data from the raw dataset.
2017:03:21 09:38:51	load context for further preprocessing.
2017:03:21 09:38:51	clean data.
2017:03:21 09:38:52	...mask and pad the sentence.
2017:03:21 09:38:52	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:38:52	build a vocabulary.
2017:03:21 09:38:52	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:41:18	use DataLoaderBBC to init data.
2017:03:21 09:41:18	reading and processing the text file.
2017:03:21 09:41:18	preprocess the dataset.
2017:03:21 09:41:18	load data.
2017:03:21 09:41:18	init content from raw.
2017:03:21 09:41:18	init data from the raw dataset.
2017:03:21 09:41:20	load context for further preprocessing.
2017:03:21 09:41:20	clean data.
2017:03:21 09:41:21	...mask and pad the sentence.
2017:03:21 09:41:21	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:41:21	build a vocabulary.
2017:03:21 09:41:21	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:42:11	use DataLoaderBBC to init data.
2017:03:21 09:42:11	reading and processing the text file.
2017:03:21 09:42:11	preprocess the dataset.
2017:03:21 09:42:11	load data.
2017:03:21 09:42:11	init content from raw.
2017:03:21 09:42:11	init data from the raw dataset.
2017:03:21 09:42:11	load context for further preprocessing.
2017:03:21 09:42:11	clean data.
2017:03:21 09:42:12	...mask and pad the sentence.
2017:03:21 09:42:12	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:42:12	build a vocabulary.
2017:03:21 09:42:12	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:42:37	use DataLoaderBBC to init data.
2017:03:21 09:42:37	reading and processing the text file.
2017:03:21 09:42:37	preprocess the dataset.
2017:03:21 09:42:37	load data.
2017:03:21 09:42:37	init content from raw.
2017:03:21 09:42:37	init data from the raw dataset.
2017:03:21 09:42:37	load context for further preprocessing.
2017:03:21 09:42:37	clean data.
2017:03:21 09:42:38	...mask and pad the sentence.
2017:03:21 09:42:38	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:42:38	build a vocabulary.
2017:03:21 09:42:38	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:44:08	use DataLoaderBBC to init data.
2017:03:21 09:44:08	loading preprocessed files.
2017:03:21 09:44:11	get data info.
2017:03:21 09:44:11	init batch data.
2017:03:21 09:44:11	...number of batches: 500
2017:03:21 09:44:11	num of sentence: 25000, sentence length: 25, vocab size: 23702
2017:03:21 09:44:15	use DataLoaderBBC to init data.
2017:03:21 09:44:15	reading and processing the text file.
2017:03:21 09:44:15	preprocess the dataset.
2017:03:21 09:44:15	load data.
2017:03:21 09:44:15	init content from raw.
2017:03:21 09:44:15	init data from the raw dataset.
2017:03:21 09:44:17	load context for further preprocessing.
2017:03:21 09:44:17	clean data.
2017:03:21 09:44:18	...mask and pad the sentence.
2017:03:21 09:44:18	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:44:18	build a vocabulary.
2017:03:21 09:44:18	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:44:34	use DataLoaderBBC to init data.
2017:03:21 09:44:34	reading and processing the text file.
2017:03:21 09:44:34	preprocess the dataset.
2017:03:21 09:44:34	load data.
2017:03:21 09:44:34	init content from raw.
2017:03:21 09:44:34	init data from the raw dataset.
2017:03:21 09:44:34	load context for further preprocessing.
2017:03:21 09:44:34	clean data.
2017:03:21 09:44:34	...mask and pad the sentence.
2017:03:21 09:44:34	......max len:26560, median len:1052.0, min len:3
2017:03:21 09:44:34	build a vocabulary.
2017:03:21 09:44:34	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:44:34	...mapping from index to word.
2017:03:21 09:44:34	...mapping from word to index.
2017:03:21 09:44:34	...map word to index.
2017:03:21 09:44:34	...save processed data to file.
2017:03:21 09:44:34	get data info.
2017:03:21 09:44:34	init batch data.
2017:03:21 09:44:34	...number of batches: 0
2017:03:21 09:44:34	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 09:45:22	use DataLoaderBBC to init data.
2017:03:21 09:45:22	reading and processing the text file.
2017:03:21 09:45:22	preprocess the dataset.
2017:03:21 09:45:22	load data.
2017:03:21 09:45:22	init content from raw.
2017:03:21 09:45:22	init data from the raw dataset.
2017:03:21 09:45:23	load context for further preprocessing.
2017:03:21 09:45:23	clean data.
2017:03:21 09:45:24	...mask and pad the sentence.
2017:03:21 09:45:24	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:45:24	build a vocabulary.
2017:03:21 09:45:24	...flatmap a list of sentence list to a list of sentence.
2017:03:21 09:45:30	use DataLoaderBBC to init data.
2017:03:21 09:45:30	reading and processing the text file.
2017:03:21 09:45:30	preprocess the dataset.
2017:03:21 09:45:30	load data.
2017:03:21 09:45:30	init content from raw.
2017:03:21 09:45:30	init data from the raw dataset.
2017:03:21 09:45:31	load context for further preprocessing.
2017:03:21 09:45:31	clean data.
2017:03:21 09:45:31	...mask and pad the sentence.
2017:03:21 09:45:31	......max len:894111, median len:894111.0, min len:894111
2017:03:21 09:45:31	build a vocabulary.
2017:03:21 09:45:31	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:40:57	use DataLoaderBBC to init data.
2017:03:21 12:40:57	reading and processing the text file.
2017:03:21 12:40:57	preprocess the dataset.
2017:03:21 12:40:57	load data.
2017:03:21 12:40:57	init content from raw.
2017:03:21 12:40:57	init data from the raw dataset.
2017:03:21 12:40:58	load context for further preprocessing.
2017:03:21 12:40:58	clean data.
2017:03:21 12:40:59	...mask and pad the sentence.
2017:03:21 12:40:59	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:40:59	build a vocabulary.
2017:03:21 12:40:59	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:40:59	...mapping from index to word.
2017:03:21 12:40:59	...mapping from word to index.
2017:03:21 12:40:59	...map word to index.
2017:03:21 12:40:59	...save processed data to file.
2017:03:21 12:40:59	get data info.
2017:03:21 12:40:59	init batch data.
2017:03:21 12:40:59	...number of batches: 0
2017:03:21 12:40:59	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:41:58	use DataLoaderBBC to init data.
2017:03:21 12:41:58	reading and processing the text file.
2017:03:21 12:41:58	preprocess the dataset.
2017:03:21 12:41:58	load data.
2017:03:21 12:41:58	init content from raw.
2017:03:21 12:41:58	init data from the raw dataset.
2017:03:21 12:41:59	load context for further preprocessing.
2017:03:21 12:41:59	clean data.
2017:03:21 12:41:59	...mask and pad the sentence.
2017:03:21 12:41:59	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:41:59	build a vocabulary.
2017:03:21 12:41:59	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:41:59	...mapping from index to word.
2017:03:21 12:41:59	...mapping from word to index.
2017:03:21 12:41:59	...map word to index.
2017:03:21 12:41:59	...save processed data to file.
2017:03:21 12:41:59	get data info.
2017:03:21 12:41:59	init batch data.
2017:03:21 12:41:59	...number of batches: 0
2017:03:21 12:41:59	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:42:10	use DataLoaderBBC to init data.
2017:03:21 12:42:10	reading and processing the text file.
2017:03:21 12:42:10	preprocess the dataset.
2017:03:21 12:42:10	load data.
2017:03:21 12:42:10	init content from raw.
2017:03:21 12:42:10	init data from the raw dataset.
2017:03:21 12:42:11	load context for further preprocessing.
2017:03:21 12:42:11	clean data.
2017:03:21 12:42:11	...mask and pad the sentence.
2017:03:21 12:42:11	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:42:11	build a vocabulary.
2017:03:21 12:42:11	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:42:11	...mapping from index to word.
2017:03:21 12:42:11	...mapping from word to index.
2017:03:21 12:42:11	...map word to index.
2017:03:21 12:42:11	...save processed data to file.
2017:03:21 12:42:11	get data info.
2017:03:21 12:42:11	init batch data.
2017:03:21 12:42:11	...number of batches: 0
2017:03:21 12:42:11	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:42:24	use DataLoaderBBC to init data.
2017:03:21 12:42:24	loading preprocessed files.
2017:03:21 12:42:24	get data info.
2017:03:21 12:42:24	init batch data.
2017:03:21 12:42:24	...number of batches: 0
2017:03:21 12:42:24	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:42:28	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490100148

2017:03:21 12:42:34	use DataLoaderBBC to init data.
2017:03:21 12:42:34	reading and processing the text file.
2017:03:21 12:42:34	preprocess the dataset.
2017:03:21 12:42:34	load data.
2017:03:21 12:42:34	init content from raw.
2017:03:21 12:42:34	init data from the raw dataset.
2017:03:21 12:42:35	load context for further preprocessing.
2017:03:21 12:42:35	clean data.
2017:03:21 12:42:37	...mask and pad the sentence.
2017:03:21 12:42:37	......max len:894111, median len:894111.0, min len:894111
2017:03:21 12:42:37	build a vocabulary.
2017:03:21 12:42:37	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:42:53	use DataLoaderBBC to init data.
2017:03:21 12:42:53	reading and processing the text file.
2017:03:21 12:42:53	preprocess the dataset.
2017:03:21 12:42:53	load data.
2017:03:21 12:42:53	init content from raw.
2017:03:21 12:42:53	init data from the raw dataset.
2017:03:21 12:43:03	load context for further preprocessing.
2017:03:21 12:43:03	clean data.
2017:03:21 12:43:04	...mask and pad the sentence.
2017:03:21 12:43:04	......max len:894111, median len:894111.0, min len:894111
2017:03:21 12:43:04	build a vocabulary.
2017:03:21 12:43:04	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:43:11	use DataLoaderBBC to init data.
2017:03:21 12:43:11	reading and processing the text file.
2017:03:21 12:43:11	preprocess the dataset.
2017:03:21 12:43:11	load data.
2017:03:21 12:43:11	init content from raw.
2017:03:21 12:43:11	init data from the raw dataset.
2017:03:21 12:43:12	load context for further preprocessing.
2017:03:21 12:43:12	clean data.
2017:03:21 12:43:13	...mask and pad the sentence.
2017:03:21 12:43:13	......max len:894111, median len:894111.0, min len:894111
2017:03:21 12:43:13	build a vocabulary.
2017:03:21 12:43:13	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:47:37	use DataLoaderBBC to init data.
2017:03:21 12:47:37	loading preprocessed files.
2017:03:21 12:47:37	get data info.
2017:03:21 12:47:37	init batch data.
2017:03:21 12:47:37	...number of batches: 0
2017:03:21 12:47:37	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:47:43	use DataLoaderBBC to init data.
2017:03:21 12:47:43	reading and processing the text file.
2017:03:21 12:47:43	preprocess the dataset.
2017:03:21 12:47:43	load data.
2017:03:21 12:47:43	init content from raw.
2017:03:21 12:47:43	init data from the raw dataset.
2017:03:21 12:47:44	load context for further preprocessing.
2017:03:21 12:47:44	clean data.
2017:03:21 12:47:44	...mask and pad the sentence.
2017:03:21 12:47:44	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:47:44	build a vocabulary.
2017:03:21 12:47:44	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:47:44	...mapping from index to word.
2017:03:21 12:47:44	...mapping from word to index.
2017:03:21 12:47:44	...map word to index.
2017:03:21 12:47:44	...save processed data to file.
2017:03:21 12:47:44	get data info.
2017:03:21 12:47:44	init batch data.
2017:03:21 12:47:44	...number of batches: 0
2017:03:21 12:47:44	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:48:29	use DataLoaderBBC to init data.
2017:03:21 12:48:29	reading and processing the text file.
2017:03:21 12:48:29	preprocess the dataset.
2017:03:21 12:48:29	load data.
2017:03:21 12:48:29	init content from raw.
2017:03:21 12:48:29	init data from the raw dataset.
2017:03:21 12:48:30	load context for further preprocessing.
2017:03:21 12:48:30	clean data.
2017:03:21 12:48:31	...mask and pad the sentence.
2017:03:21 12:48:31	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:48:31	build a vocabulary.
2017:03:21 12:48:31	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:48:31	...mapping from index to word.
2017:03:21 12:48:31	...mapping from word to index.
2017:03:21 12:48:31	...map word to index.
2017:03:21 12:48:31	...save processed data to file.
2017:03:21 12:48:31	get data info.
2017:03:21 12:48:31	init batch data.
2017:03:21 12:48:31	...number of batches: 0
2017:03:21 12:48:31	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:48:36	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490100516

2017:03:21 12:48:40	use DataLoaderBBC to init data.
2017:03:21 12:48:40	loading preprocessed files.
2017:03:21 12:48:40	get data info.
2017:03:21 12:48:40	init batch data.
2017:03:21 12:48:40	...number of batches: 0
2017:03:21 12:48:40	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:48:45	use DataLoaderBBC to init data.
2017:03:21 12:48:45	reading and processing the text file.
2017:03:21 12:48:45	preprocess the dataset.
2017:03:21 12:48:45	load data.
2017:03:21 12:48:45	init content from raw.
2017:03:21 12:48:45	init data from the raw dataset.
2017:03:21 12:48:47	load context for further preprocessing.
2017:03:21 12:48:47	clean data.
2017:03:21 12:48:47	...mask and pad the sentence.
2017:03:21 12:48:47	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:48:47	build a vocabulary.
2017:03:21 12:48:47	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:48:47	...mapping from index to word.
2017:03:21 12:48:47	...mapping from word to index.
2017:03:21 12:48:47	...map word to index.
2017:03:21 12:48:47	...save processed data to file.
2017:03:21 12:48:47	get data info.
2017:03:21 12:48:47	init batch data.
2017:03:21 12:48:47	...number of batches: 0
2017:03:21 12:48:47	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:49:13	use DataLoaderBBC to init data.
2017:03:21 12:49:13	reading and processing the text file.
2017:03:21 12:49:13	preprocess the dataset.
2017:03:21 12:49:13	load data.
2017:03:21 12:49:13	init content from raw.
2017:03:21 12:49:13	init data from the raw dataset.
2017:03:21 12:49:15	load context for further preprocessing.
2017:03:21 12:49:15	clean data.
2017:03:21 12:49:16	...mask and pad the sentence.
2017:03:21 12:49:16	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:49:16	build a vocabulary.
2017:03:21 12:49:16	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:49:16	...mapping from index to word.
2017:03:21 12:49:16	...mapping from word to index.
2017:03:21 12:49:16	...map word to index.
2017:03:21 12:49:16	...save processed data to file.
2017:03:21 12:49:16	get data info.
2017:03:21 12:49:16	init batch data.
2017:03:21 12:49:16	...number of batches: 0
2017:03:21 12:49:16	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:49:36	use DataLoaderBBC to init data.
2017:03:21 12:49:36	reading and processing the text file.
2017:03:21 12:49:36	preprocess the dataset.
2017:03:21 12:49:36	load data.
2017:03:21 12:49:36	init content from raw.
2017:03:21 12:49:36	init data from the raw dataset.
2017:03:21 12:49:44	load context for further preprocessing.
2017:03:21 12:49:44	clean data.
2017:03:21 12:49:44	...mask and pad the sentence.
2017:03:21 12:49:44	......max len:26560, median len:1052.0, min len:3
2017:03:21 12:49:44	build a vocabulary.
2017:03:21 12:49:44	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:49:44	...mapping from index to word.
2017:03:21 12:49:44	...mapping from word to index.
2017:03:21 12:49:44	...map word to index.
2017:03:21 12:49:44	...save processed data to file.
2017:03:21 12:49:44	get data info.
2017:03:21 12:49:44	init batch data.
2017:03:21 12:49:44	...number of batches: 0
2017:03:21 12:49:44	num of sentence: 0, sentence length: 25, vocab size: 219
2017:03:21 12:50:01	use DataLoaderBBC to init data.
2017:03:21 12:50:01	reading and processing the text file.
2017:03:21 12:50:01	preprocess the dataset.
2017:03:21 12:50:01	load data.
2017:03:21 12:50:01	init content from raw.
2017:03:21 12:50:01	init data from the raw dataset.
2017:03:21 12:50:03	load context for further preprocessing.
2017:03:21 12:50:03	clean data.
2017:03:21 12:50:16	use DataLoaderBBC to init data.
2017:03:21 12:50:16	reading and processing the text file.
2017:03:21 12:50:16	preprocess the dataset.
2017:03:21 12:50:16	load data.
2017:03:21 12:50:16	init content from raw.
2017:03:21 12:50:16	init data from the raw dataset.
2017:03:21 12:50:18	load context for further preprocessing.
2017:03:21 12:50:18	clean data.
2017:03:21 12:50:19	...mask and pad the sentence.
2017:03:21 12:50:19	......max len:359, median len:22.0, min len:2
2017:03:21 12:50:19	build a vocabulary.
2017:03:21 12:50:19	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:50:19	...mapping from index to word.
2017:03:21 12:50:28	use DataLoaderBBC to init data.
2017:03:21 12:50:28	reading and processing the text file.
2017:03:21 12:50:28	preprocess the dataset.
2017:03:21 12:50:28	load data.
2017:03:21 12:50:28	init content from raw.
2017:03:21 12:50:28	init data from the raw dataset.
2017:03:21 12:50:28	load context for further preprocessing.
2017:03:21 12:50:28	clean data.
2017:03:21 12:50:28	...mask and pad the sentence.
2017:03:21 12:50:28	......max len:359, median len:22.0, min len:2
2017:03:21 12:50:29	build a vocabulary.
2017:03:21 12:50:29	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:50:29	...mapping from index to word.
2017:03:21 12:50:29	...mapping from word to index.
2017:03:21 12:50:29	...map word to index.
2017:03:21 12:50:29	...save processed data to file.
2017:03:21 12:50:46	use DataLoaderBBC to init data.
2017:03:21 12:50:46	reading and processing the text file.
2017:03:21 12:50:46	preprocess the dataset.
2017:03:21 12:50:46	load data.
2017:03:21 12:50:46	init content from raw.
2017:03:21 12:50:46	init data from the raw dataset.
2017:03:21 12:50:47	load context for further preprocessing.
2017:03:21 12:50:47	clean data.
2017:03:21 12:50:47	...mask and pad the sentence.
2017:03:21 12:50:47	......max len:359, median len:22.0, min len:2
2017:03:21 12:50:47	build a vocabulary.
2017:03:21 12:50:47	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:50:48	...mapping from index to word.
2017:03:21 12:50:48	...mapping from word to index.
2017:03:21 12:50:48	...map word to index.
2017:03:21 12:50:48	...save processed data to file.
2017:03:21 12:50:49	get data info.
2017:03:21 12:50:49	init batch data.
2017:03:21 12:50:49	...number of batches: 503
2017:03:21 12:50:49	num of sentence: 25150, sentence length: 25, vocab size: 26991
2017:03:21 12:52:48	use DataLoaderBBC to init data.
2017:03:21 12:52:48	reading and processing the text file.
2017:03:21 12:52:48	preprocess the dataset.
2017:03:21 12:52:48	load data.
2017:03:21 12:52:48	init content from raw.
2017:03:21 12:52:48	init data from the raw dataset.
2017:03:21 12:52:48	load context for further preprocessing.
2017:03:21 12:52:48	clean data.
2017:03:21 12:52:49	...mask and pad the sentence.
2017:03:21 12:52:49	......max len:359, median len:22.0, min len:2
2017:03:21 12:52:49	build a vocabulary.
2017:03:21 12:52:49	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:52:50	...mapping from index to word.
2017:03:21 12:52:50	...mapping from word to index.
2017:03:21 12:52:50	...map word to index.
2017:03:21 12:52:50	...save processed data to file.
2017:03:21 12:52:51	get data info.
2017:03:21 12:52:51	init batch data.
2017:03:21 12:52:51	...number of batches: 402
2017:03:21 12:52:51	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:21 12:53:46	use DataLoaderBBC to init data.
2017:03:21 12:53:46	reading and processing the text file.
2017:03:21 12:53:46	preprocess the dataset.
2017:03:21 12:53:46	load data.
2017:03:21 12:53:46	init content from raw.
2017:03:21 12:53:46	init data from the raw dataset.
2017:03:21 12:53:46	load context for further preprocessing.
2017:03:21 12:53:46	clean data.
2017:03:21 12:53:47	...mask and pad the sentence.
2017:03:21 12:53:47	......max len:359, median len:22.0, min len:2
2017:03:21 12:53:47	......filter sentence and bound them in the range of 25
2017:03:21 12:53:47	build a vocabulary.
2017:03:21 12:53:47	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:53:47	...mapping from index to word.
2017:03:21 12:53:47	...mapping from word to index.
2017:03:21 12:53:47	...map word to index.
2017:03:21 12:53:48	...save processed data to file.
2017:03:21 12:53:49	get data info.
2017:03:21 12:53:49	init batch data.
2017:03:21 12:53:49	...number of batches: 402
2017:03:21 12:53:49	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:21 12:53:53	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490100833

2017:03:21 12:53:57	------ training ------ 

2017:03:21 12:53:57	train epoch 0
2017:03:21 12:55:25	use DataLoaderBBC to init data.
2017:03:21 12:55:25	reading and processing the text file.
2017:03:21 12:55:25	preprocess the dataset.
2017:03:21 12:55:25	load data.
2017:03:21 12:55:25	init content from raw.
2017:03:21 12:55:25	init data from the raw dataset.
2017:03:21 12:55:27	load context for further preprocessing.
2017:03:21 12:55:27	clean data.
2017:03:21 12:55:28	...mask and pad the sentence.
2017:03:21 12:55:28	......max len:359, median len:22.0, min len:2
2017:03:21 12:55:28	......filter sentence and bound them in the range of 25.
2017:03:21 12:55:28	build a vocabulary.
2017:03:21 12:55:28	...flatmap a list of sentence list to a list of sentence.
2017:03:21 12:55:28	...mapping from index to word.
2017:03:21 12:55:28	...mapping from word to index.
2017:03:21 12:55:28	...map word to index.
2017:03:21 12:55:28	...save processed data to file.
2017:03:21 12:55:29	get data info.
2017:03:21 12:55:29	init batch data.
2017:03:21 12:55:29	...number of batches: 402
2017:03:21 12:55:29	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:21 12:55:33	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490100933

2017:03:21 12:55:37	------ training ------ 

2017:03:21 12:55:37	train epoch 0
2017:03:21 12:55:59	use DataLoaderBBC to init data.
2017:03:21 12:55:59	loading preprocessed files.
2017:03:21 12:56:01	get data info.
2017:03:21 12:56:01	init batch data.
2017:03:21 12:56:01	...number of batches: 402
2017:03:21 12:56:01	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:21 12:56:05	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490100965

2017:03:21 12:56:07	------ training ------ 

2017:03:21 12:56:07	train epoch 0
2017:03:21 13:29:12	use DataLoaderBBC to init data.
2017:03:21 13:29:12	loading preprocessed files.
2017:03:21 13:29:14	get data info.
2017:03:21 13:29:14	init batch data.
2017:03:21 13:29:14	...number of batches: 402
2017:03:21 13:29:14	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:21 13:29:19	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490102959

2017:03:21 13:29:22	------ training ------ 

2017:03:21 13:29:22	train epoch 0
2017:03:21 13:29:38	use DataLoaderBBC to init data.
2017:03:21 13:29:38	reading and processing the text file.
2017:03:21 13:29:38	preprocess the dataset.
2017:03:21 13:29:38	load data.
2017:03:21 13:29:38	init content from raw.
2017:03:21 13:29:38	init data from the raw dataset.
2017:03:21 13:29:39	load context for further preprocessing.
2017:03:21 13:29:39	clean data.
2017:03:21 13:29:41	...mask and pad the sentence.
2017:03:21 13:29:41	......max len:894111, median len:894111.0, min len:894111
2017:03:21 13:29:41	......filter sentence and bound them in the range of 25.
2017:03:21 13:29:41	build a vocabulary.
2017:03:21 13:29:41	...flatmap a list of sentence list to a list of sentence.
2017:03:21 13:30:51	use DataLoaderBBC to init data.
2017:03:21 13:30:51	reading and processing the text file.
2017:03:21 13:30:51	preprocess the dataset.
2017:03:21 13:30:51	load data.
2017:03:21 13:30:51	init content from raw.
2017:03:21 13:30:51	init data from the raw dataset.
2017:03:21 13:30:51	load context for further preprocessing.
2017:03:21 13:30:51	clean data.
2017:03:21 13:30:52	...mask and pad the sentence.
2017:03:21 13:30:52	......max len:363, median len:22.0, min len:2
2017:03:21 13:30:52	......filter sentence and bound them in the range of 25.
2017:03:21 13:30:52	build a vocabulary.
2017:03:21 13:30:52	...flatmap a list of sentence list to a list of sentence.
2017:03:21 13:30:52	...mapping from index to word.
2017:03:21 13:30:52	...mapping from word to index.
2017:03:21 13:30:52	...map word to index.
2017:03:21 13:30:52	...save processed data to file.
2017:03:21 13:30:53	get data info.
2017:03:21 13:30:53	init batch data.
2017:03:21 13:30:53	...number of batches: 396
2017:03:21 13:30:53	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:30:57	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103057

2017:03:21 13:31:00	------ training ------ 

2017:03:21 13:31:00	train epoch 0
2017:03:21 13:32:15	use DataLoaderBBC to init data.
2017:03:21 13:32:15	loading preprocessed files.
2017:03:21 13:32:17	get data info.
2017:03:21 13:32:17	init batch data.
2017:03:21 13:32:17	...number of batches: 396
2017:03:21 13:32:17	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:32:23	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:32:28	save 1-th bestmodel to path: /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142/checkpoints/bestmodel.

2017:03:21 13:32:28	------ training ------ 

2017:03:21 13:32:28	train epoch 0
2017:03:21 13:48:43	use DataLoaderBBC to init data.
2017:03:21 13:48:43	loading preprocessed files.
2017:03:21 13:48:45	get data info.
2017:03:21 13:48:45	init batch data.
2017:03:21 13:48:45	...number of batches: 396
2017:03:21 13:48:45	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:48:46	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:48:48	above content is generated from lstm.
2017:03:21 13:48:48	total execution time: 5
2017:03:21 13:50:00	use DataLoaderBBC to init data.
2017:03:21 13:50:00	loading preprocessed files.
2017:03:21 13:50:02	get data info.
2017:03:21 13:50:02	init batch data.
2017:03:21 13:50:02	...number of batches: 396
2017:03:21 13:50:02	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:50:03	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:50:05	above content is generated from lstm.
2017:03:21 13:50:05	total execution time: 4
2017:03:21 13:50:24	use DataLoaderBBC to init data.
2017:03:21 13:50:24	loading preprocessed files.
2017:03:21 13:50:25	get data info.
2017:03:21 13:50:25	init batch data.
2017:03:21 13:50:25	...number of batches: 396
2017:03:21 13:50:25	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:50:26	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:50:28	generate sentence. is beam search: True?
2017:03:21 13:52:18	use DataLoaderBBC to init data.
2017:03:21 13:52:18	loading preprocessed files.
2017:03:21 13:52:20	get data info.
2017:03:21 13:52:20	init batch data.
2017:03:21 13:52:20	...number of batches: 396
2017:03:21 13:52:20	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:52:21	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:52:22	generate sentence. is beam search: True.
2017:03:21 13:55:46	use DataLoaderBBC to init data.
2017:03:21 13:55:46	loading preprocessed files.
2017:03:21 13:55:47	get data info.
2017:03:21 13:55:47	init batch data.
2017:03:21 13:55:47	...number of batches: 396
2017:03:21 13:55:47	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:55:48	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:56:17	use DataLoaderBBC to init data.
2017:03:21 13:56:17	loading preprocessed files.
2017:03:21 13:56:19	get data info.
2017:03:21 13:56:19	init batch data.
2017:03:21 13:56:19	...number of batches: 396
2017:03:21 13:56:19	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:56:20	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:56:28	use DataLoaderBBC to init data.
2017:03:21 13:56:28	loading preprocessed files.
2017:03:21 13:56:30	get data info.
2017:03:21 13:56:30	init batch data.
2017:03:21 13:56:30	...number of batches: 396
2017:03:21 13:56:30	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:56:31	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:56:31	generate sentence. is beam search: True.
2017:03:21 13:58:08	use DataLoaderBBC to init data.
2017:03:21 13:58:08	loading preprocessed files.
2017:03:21 13:58:10	get data info.
2017:03:21 13:58:10	init batch data.
2017:03:21 13:58:10	...number of batches: 396
2017:03:21 13:58:10	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 13:58:11	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 13:58:11	generate sentence. is beam search: True.
2017:03:21 14:00:01	use DataLoaderBBC to init data.
2017:03:21 14:00:01	loading preprocessed files.
2017:03:21 14:00:02	get data info.
2017:03:21 14:00:02	init batch data.
2017:03:21 14:00:02	...number of batches: 396
2017:03:21 14:00:02	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:00:03	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:00:04	generate sentence. is beam search: True.
2017:03:21 14:00:36	use DataLoaderBBC to init data.
2017:03:21 14:00:36	loading preprocessed files.
2017:03:21 14:00:37	get data info.
2017:03:21 14:00:37	init batch data.
2017:03:21 14:00:37	...number of batches: 396
2017:03:21 14:00:37	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:00:38	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:00:39	generate sentence. is beam search: True.
2017:03:21 14:03:31	use DataLoaderBBC to init data.
2017:03:21 14:03:31	loading preprocessed files.
2017:03:21 14:03:32	get data info.
2017:03:21 14:03:32	init batch data.
2017:03:21 14:03:32	...number of batches: 396
2017:03:21 14:03:32	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:03:33	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:03:34	generate sentence. is beam search: True.
2017:03:21 14:03:58	use DataLoaderBBC to init data.
2017:03:21 14:03:58	loading preprocessed files.
2017:03:21 14:04:00	get data info.
2017:03:21 14:04:00	init batch data.
2017:03:21 14:04:00	...number of batches: 396
2017:03:21 14:04:00	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:04:01	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:04:11	use DataLoaderBBC to init data.
2017:03:21 14:04:11	loading preprocessed files.
2017:03:21 14:04:13	get data info.
2017:03:21 14:04:13	init batch data.
2017:03:21 14:04:13	...number of batches: 396
2017:03:21 14:04:13	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:04:14	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:04:14	generate sentence. is beam search: True.
2017:03:21 14:04:14	above content is generated from lstm.
2017:03:21 14:04:14	total execution time: 3
2017:03:21 14:06:45	use DataLoaderBBC to init data.
2017:03:21 14:06:45	loading preprocessed files.
2017:03:21 14:06:47	get data info.
2017:03:21 14:06:47	init batch data.
2017:03:21 14:06:47	...number of batches: 396
2017:03:21 14:06:47	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:06:49	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:06:50	generate sentence. is beam search: True.
2017:03:21 14:06:50	above content is generated from lstm.
2017:03:21 14:06:50	total execution time: 4
2017:03:21 14:08:42	use DataLoaderBBC to init data.
2017:03:21 14:08:42	loading preprocessed files.
2017:03:21 14:08:44	get data info.
2017:03:21 14:08:44	init batch data.
2017:03:21 14:08:44	...number of batches: 396
2017:03:21 14:08:44	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:08:45	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:08:45	generate sentence. is beam search: True.
2017:03:21 14:12:40	use DataLoaderBBC to init data.
2017:03:21 14:12:40	loading preprocessed files.
2017:03:21 14:12:41	get data info.
2017:03:21 14:12:41	init batch data.
2017:03:21 14:12:41	...number of batches: 396
2017:03:21 14:12:42	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:12:42	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:12:43	generate sentence. is beam search: True.
2017:03:21 14:12:43	...process the given sentence.
2017:03:21 14:13:09	use DataLoaderBBC to init data.
2017:03:21 14:13:09	loading preprocessed files.
2017:03:21 14:13:11	get data info.
2017:03:21 14:13:11	init batch data.
2017:03:21 14:13:11	...number of batches: 396
2017:03:21 14:13:11	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:13:12	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:13:13	generate sentence. is beam search: True.
2017:03:21 14:13:13	...process the given sentence.
2017:03:21 14:16:39	use DataLoaderBBC to init data.
2017:03:21 14:16:39	loading preprocessed files.
2017:03:21 14:16:41	get data info.
2017:03:21 14:16:41	init batch data.
2017:03:21 14:16:41	...number of batches: 396
2017:03:21 14:16:41	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:16:42	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:16:44	generate sentence. is beam search: True.
2017:03:21 14:16:44	...process the given sentence.
2017:03:21 14:18:22	use DataLoaderBBC to init data.
2017:03:21 14:18:22	loading preprocessed files.
2017:03:21 14:18:24	get data info.
2017:03:21 14:18:24	init batch data.
2017:03:21 14:18:24	...number of batches: 396
2017:03:21 14:18:24	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:18:25	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:18:26	generate sentence. is beam search: True.
2017:03:21 14:18:26	...process the given sentence.
2017:03:21 14:19:03	use DataLoaderBBC to init data.
2017:03:21 14:19:03	loading preprocessed files.
2017:03:21 14:19:05	get data info.
2017:03:21 14:19:05	init batch data.
2017:03:21 14:19:05	...number of batches: 396
2017:03:21 14:19:05	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:19:06	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:19:07	generate sentence. is beam search: True.
2017:03:21 14:19:07	...process the given sentence.
2017:03:21 14:19:25	use DataLoaderBBC to init data.
2017:03:21 14:19:25	loading preprocessed files.
2017:03:21 14:19:27	get data info.
2017:03:21 14:19:27	init batch data.
2017:03:21 14:19:27	...number of batches: 396
2017:03:21 14:19:27	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:19:28	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:19:30	generate sentence. is beam search: True.
2017:03:21 14:19:30	...process the given sentence.
2017:03:21 14:20:39	use DataLoaderBBC to init data.
2017:03:21 14:20:39	loading preprocessed files.
2017:03:21 14:20:41	get data info.
2017:03:21 14:20:41	init batch data.
2017:03:21 14:20:41	...number of batches: 396
2017:03:21 14:20:41	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:20:42	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:20:44	generate sentence. is beam search: True.
2017:03:21 14:20:44	...process the given sentence.
2017:03:21 14:21:14	use DataLoaderBBC to init data.
2017:03:21 14:21:14	loading preprocessed files.
2017:03:21 14:21:16	get data info.
2017:03:21 14:21:16	init batch data.
2017:03:21 14:21:16	...number of batches: 396
2017:03:21 14:21:16	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:21:17	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:21:18	generate sentence. is beam search: True.
2017:03:21 14:21:18	...process the given sentence.
2017:03:21 14:21:38	use DataLoaderBBC to init data.
2017:03:21 14:21:38	loading preprocessed files.
2017:03:21 14:21:40	get data info.
2017:03:21 14:21:40	init batch data.
2017:03:21 14:21:40	...number of batches: 396
2017:03:21 14:21:40	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:21:41	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:21:43	generate sentence. is beam search: True.
2017:03:21 14:21:43	...process the given sentence.
2017:03:21 14:21:58	use DataLoaderBBC to init data.
2017:03:21 14:21:58	loading preprocessed files.
2017:03:21 14:22:00	get data info.
2017:03:21 14:22:00	init batch data.
2017:03:21 14:22:00	...number of batches: 396
2017:03:21 14:22:00	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:22:01	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:22:03	generate sentence. is beam search: True.
2017:03:21 14:22:03	...process the given sentence.
2017:03:21 14:22:30	use DataLoaderBBC to init data.
2017:03:21 14:22:30	loading preprocessed files.
2017:03:21 14:22:32	get data info.
2017:03:21 14:22:32	init batch data.
2017:03:21 14:22:32	...number of batches: 396
2017:03:21 14:22:32	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:22:33	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:22:34	generate sentence. is beam search: True.
2017:03:21 14:22:34	...process the given sentence.
2017:03:21 14:22:35	above content is generated from lstm.
2017:03:21 14:22:35	total execution time: 5
2017:03:21 14:23:24	use DataLoaderBBC to init data.
2017:03:21 14:23:24	loading preprocessed files.
2017:03:21 14:23:26	get data info.
2017:03:21 14:23:26	init batch data.
2017:03:21 14:23:26	...number of batches: 396
2017:03:21 14:23:26	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:23:27	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:23:28	generate sentence. is beam search: True.
2017:03:21 14:23:28	...process the given sentence.
2017:03:21 14:23:29	above content is generated from lstm.
2017:03:21 14:23:29	total execution time: 5
2017:03:21 14:27:53	use DataLoaderBBC to init data.
2017:03:21 14:27:53	loading preprocessed files.
2017:03:21 14:27:55	get data info.
2017:03:21 14:27:55	init batch data.
2017:03:21 14:27:55	...number of batches: 396
2017:03:21 14:27:55	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:27:56	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:27:57	generate sentence. is beam search: True.
2017:03:21 14:27:57	...process the given sentence.
2017:03:21 14:27:58	above content is generated from lstm.
2017:03:21 14:27:58	total execution time: 5
2017:03:21 14:28:17	use DataLoaderBBC to init data.
2017:03:21 14:28:17	loading preprocessed files.
2017:03:21 14:28:19	get data info.
2017:03:21 14:28:19	init batch data.
2017:03:21 14:28:19	...number of batches: 396
2017:03:21 14:28:19	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:28:19	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:28:21	generate sentence. is beam search: True.
2017:03:21 14:28:21	...process the given sentence.
2017:03:21 14:28:22	above content is generated from lstm.
2017:03:21 14:28:22	total execution time: 5
2017:03:21 14:28:44	use DataLoaderBBC to init data.
2017:03:21 14:28:44	loading preprocessed files.
2017:03:21 14:28:46	get data info.
2017:03:21 14:28:46	init batch data.
2017:03:21 14:28:46	...number of batches: 396
2017:03:21 14:28:46	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:28:47	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:28:48	generate sentence. is beam search: False.
2017:03:21 14:28:48	...process the given sentence.
2017:03:21 14:28:48	above content is generated from lstm.
2017:03:21 14:28:48	total execution time: 3
2017:03:21 14:29:30	use DataLoaderBBC to init data.
2017:03:21 14:29:30	loading preprocessed files.
2017:03:21 14:29:32	get data info.
2017:03:21 14:29:32	init batch data.
2017:03:21 14:29:32	...number of batches: 396
2017:03:21 14:29:32	num of sentence: 19800, sentence length: 25, vocab size: 23976
2017:03:21 14:29:32	writing to /home/lin/notebooks/code/demo2_v/data/training/runs/DataLoaderBBC/code.model.textG.TextG/1490103142

2017:03:21 14:29:33	generate sentence. is beam search: False.
2017:03:21 14:29:33	...process the given sentence.
2017:03:21 14:29:34	above content is generated from lstm.
2017:03:21 14:29:34	total execution time: 4
2017:03:21 22:06:25	use DataLoaderBBCV to init data.
2017:03:21 22:06:25	loading preprocessed files.
2017:03:21 22:06:29	get data info.
2017:03:21 22:06:29	init batch data.
2017:03:21 22:06:29	...number of batches: 724
2017:03:21 22:06:29	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:21 22:07:53	use DataLoaderBBCV to init data.
2017:03:21 22:07:53	loading preprocessed files.
2017:03:21 22:07:57	get data info.
2017:03:21 22:07:57	init batch data.
2017:03:21 22:07:57	...number of batches: 724
2017:03:21 22:07:57	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:21 22:08:24	use DataLoaderBBCV to init data.
2017:03:21 22:08:24	loading preprocessed files.
2017:03:21 22:08:28	get data info.
2017:03:21 22:08:28	init batch data.
2017:03:21 22:08:28	...number of batches: 724
2017:03:21 22:08:28	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:21 22:56:31	use DataLoaderBBCV to init data.
2017:03:21 22:56:32	loading preprocessed files.
2017:03:21 22:56:35	get data info.
2017:03:21 22:56:35	init batch data.
2017:03:21 22:56:35	...number of batches: 724
2017:03:21 22:56:35	num of sentence: 36200, sentence length: 25, vocab size: 30233
2017:03:21 23:02:01	use DataLoaderBBCV to init data.
2017:03:21 23:02:01	reading and processing the text file.
2017:03:21 23:02:01	preprocess the dataset.
2017:03:21 23:02:01	load data.
2017:03:21 23:02:01	init content from raw.
2017:03:21 23:02:01	init data from the raw dataset.
2017:03:21 23:02:02	load context for further preprocessing.
2017:03:21 23:02:02	...build vocab and map word to index.
2017:03:21 23:02:02	build a vocabulary.
2017:03:21 23:02:02	...flatmap a list of sentence list to a list of sentence.
2017:03:21 23:02:03	...mapping from index to word.
2017:03:21 23:02:03	...add additional <go> and <eos>.
2017:03:21 23:02:03	...mapping from word to index.
2017:03:21 23:02:03	...save processed data to file.
2017:03:21 23:02:05	get data info.
2017:03:21 23:02:05	init batch data.
2017:03:21 23:02:05	...number of batches: 674
2017:03:21 23:02:05	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:05:46	use DataLoaderBBCV to init data.
2017:03:21 23:05:46	reading and processing the text file.
2017:03:21 23:05:46	preprocess the dataset.
2017:03:21 23:05:46	load data.
2017:03:21 23:05:46	init content from raw.
2017:03:21 23:05:46	init data from the raw dataset.
2017:03:21 23:05:48	load context for further preprocessing.
2017:03:21 23:05:48	...build vocab and map word to index.
2017:03:21 23:05:48	build a vocabulary.
2017:03:21 23:05:48	...flatmap a list of sentence list to a list of sentence.
2017:03:21 23:05:48	...mapping from index to word.
2017:03:21 23:05:49	...add additional <go> and <eos>.
2017:03:21 23:05:49	...mapping from word to index.
2017:03:21 23:05:49	...save processed data to file.
2017:03:21 23:05:51	get data info.
2017:03:21 23:05:51	init batch data.
2017:03:21 23:05:51	...number of batches: 674
2017:03:21 23:05:51	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:05:55	use DataLoaderBBCV to init data.
2017:03:21 23:05:55	loading preprocessed files.
2017:03:21 23:05:58	get data info.
2017:03:21 23:05:58	init batch data.
2017:03:21 23:05:58	...number of batches: 674
2017:03:21 23:05:58	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:06:03	use DataLoaderBBCV to init data.
2017:03:21 23:06:03	loading preprocessed files.
2017:03:21 23:06:06	get data info.
2017:03:21 23:06:06	init batch data.
2017:03:21 23:06:06	...number of batches: 674
2017:03:21 23:06:06	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:06:27	use DataLoaderBBCV to init data.
2017:03:21 23:06:27	loading preprocessed files.
2017:03:21 23:06:30	get data info.
2017:03:21 23:06:30	init batch data.
2017:03:21 23:06:30	...number of batches: 674
2017:03:21 23:06:30	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:07:17	use DataLoaderBBCV to init data.
2017:03:21 23:07:17	loading preprocessed files.
2017:03:21 23:07:20	get data info.
2017:03:21 23:07:20	init batch data.
2017:03:21 23:07:20	...number of batches: 674
2017:03:21 23:07:20	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:08:31	use DataLoaderBBCV to init data.
2017:03:21 23:08:31	loading preprocessed files.
2017:03:21 23:08:34	get data info.
2017:03:21 23:08:34	init batch data.
2017:03:21 23:08:34	...number of batches: 674
2017:03:21 23:08:34	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:09:57	use DataLoaderBBCV to init data.
2017:03:21 23:09:57	loading preprocessed files.
2017:03:21 23:10:00	get data info.
2017:03:21 23:10:00	init batch data.
2017:03:21 23:10:00	...number of batches: 674
2017:03:21 23:10:00	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:11:46	use DataLoaderBBCV to init data.
2017:03:21 23:11:46	loading preprocessed files.
2017:03:21 23:11:50	get data info.
2017:03:21 23:11:50	init batch data.
2017:03:21 23:11:50	...number of batches: 674
2017:03:21 23:11:50	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:12:35	use DataLoaderBBCV to init data.
2017:03:21 23:12:35	loading preprocessed files.
2017:03:21 23:12:39	get data info.
2017:03:21 23:12:39	init batch data.
2017:03:21 23:12:39	...number of batches: 674
2017:03:21 23:12:39	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:13:07	use DataLoaderBBCV to init data.
2017:03:21 23:13:07	loading preprocessed files.
2017:03:21 23:13:11	get data info.
2017:03:21 23:13:11	init batch data.
2017:03:21 23:13:11	...number of batches: 674
2017:03:21 23:13:11	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:14:35	use DataLoaderBBCV to init data.
2017:03:21 23:14:35	loading preprocessed files.
2017:03:21 23:14:38	get data info.
2017:03:21 23:14:38	init batch data.
2017:03:21 23:14:38	...number of batches: 674
2017:03:21 23:14:38	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:14:54	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138094

2017:03:21 23:15:09	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138094/checkpoints/bestmodel.

2017:03:21 23:15:09	------ training ------ 

2017:03:21 23:15:09	train epoch 0
2017:03:21 23:16:00	use DataLoaderBBCV to init data.
2017:03:21 23:16:00	loading preprocessed files.
2017:03:21 23:16:04	get data info.
2017:03:21 23:16:04	init batch data.
2017:03:21 23:16:04	...number of batches: 674
2017:03:21 23:16:04	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:16:20	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138179

2017:03:21 23:16:29	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138179/checkpoints/bestmodel.

2017:03:21 23:16:29	------ training ------ 

2017:03:21 23:16:30	train epoch 0
2017:03:21 23:17:25	use DataLoaderBBCV to init data.
2017:03:21 23:17:25	loading preprocessed files.
2017:03:21 23:17:28	get data info.
2017:03:21 23:17:28	init batch data.
2017:03:21 23:17:28	...number of batches: 674
2017:03:21 23:17:28	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:17:42	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138261

2017:03:21 23:17:51	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138261/checkpoints/bestmodel.

2017:03:21 23:17:51	------ training ------ 

2017:03:21 23:17:51	train epoch 0
2017:03:21 23:18:25	use DataLoaderBBCV to init data.
2017:03:21 23:18:25	loading preprocessed files.
2017:03:21 23:18:29	get data info.
2017:03:21 23:18:29	init batch data.
2017:03:21 23:18:29	...number of batches: 674
2017:03:21 23:18:29	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:18:41	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138321

2017:03:21 23:18:52	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490138321/checkpoints/bestmodel.

2017:03:21 23:18:52	------ training ------ 

2017:03:21 23:18:52	train epoch 0
2017:03:21 23:34:51	use DataLoaderBBCV to init data.
2017:03:21 23:34:51	loading preprocessed files.
2017:03:21 23:34:54	get data info.
2017:03:21 23:34:54	init batch data.
2017:03:21 23:34:54	...number of batches: 674
2017:03:21 23:35:06	use DataLoaderBBCV to init data.
2017:03:21 23:35:06	loading preprocessed files.
2017:03:21 23:35:09	get data info.
2017:03:21 23:35:09	init batch data.
2017:03:21 23:35:09	...number of batches: 674
2017:03:21 23:35:22	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:35:37	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490139337

2017:03:21 23:35:48	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490139337/checkpoints/bestmodel.

2017:03:21 23:35:49	------ training ------ 

2017:03:21 23:35:49	train epoch 0
2017:03:21 23:37:27	use DataLoaderBBCV to init data.
2017:03:21 23:37:27	loading preprocessed files.
2017:03:21 23:37:31	get data info.
2017:03:21 23:37:31	init batch data.
2017:03:21 23:37:31	...number of batches: 674
2017:03:21 23:37:31	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:21 23:37:43	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490139463

2017:03:21 23:37:51	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBCV/code.model.textGAN.TextGAN/1490139463/checkpoints/bestmodel.

2017:03:21 23:37:51	------ training ------ 

2017:03:21 23:37:51	train epoch 0
2017:03:22 19:12:59	use DataLoaderBBCV to init data.
2017:03:22 19:12:59	reading and processing the text file.
2017:03:22 19:12:59	preprocess the dataset.
2017:03:22 19:12:59	load data.
2017:03:22 19:12:59	init content from raw.
2017:03:22 19:12:59	init data from the raw dataset.
2017:03:22 19:13:00	load context for further preprocessing.
2017:03:22 19:13:00	...build vocab and map word to index.
2017:03:22 19:13:00	build a vocabulary.
2017:03:22 19:13:00	...flatmap a list of sentence list to a list of sentence.
2017:03:22 19:13:01	...mapping from index to word.
2017:03:22 19:13:01	...add additional <go> and <eos>.
2017:03:22 19:13:01	...mapping from word to index.
2017:03:22 19:13:01	...save processed data to file.
2017:03:22 19:13:03	get data info.
2017:03:22 19:13:03	init batch data.
2017:03:22 19:13:03	...number of batches: 674
2017:03:22 19:13:04	num of sentence: 33700, sentence length: 25, vocab size: 59969
2017:03:22 19:14:25	use DataLoaderBBC to init data.
2017:03:22 19:14:25	reading and processing the text file.
2017:03:22 19:14:25	preprocess the dataset.
2017:03:22 19:14:25	load data.
2017:03:22 19:14:25	init content from raw.
2017:03:22 19:14:25	init data from the raw dataset.
2017:03:22 19:14:26	load context for further preprocessing.
2017:03:22 19:14:26	clean data.
2017:03:22 19:14:27	...mask and pad the sentence.
2017:03:22 19:14:27	......max len:359, median len:22.0, min len:2
2017:03:22 19:14:27	......filter sentence and bound them in the range of 25.
2017:03:22 19:14:27	build a vocabulary.
2017:03:22 19:14:27	...flatmap a list of sentence list to a list of sentence.
2017:03:22 19:14:27	...mapping from index to word.
2017:03:22 19:14:27	...mapping from word to index.
2017:03:22 19:14:27	...map word to index.
2017:03:22 19:14:27	...save processed data to file.
2017:03:22 19:14:28	get data info.
2017:03:22 19:14:28	init batch data.
2017:03:22 19:14:28	...number of batches: 402
2017:03:22 19:14:29	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:22 22:44:28	use DataLoaderBBC to init data.
2017:03:22 22:44:28	loading preprocessed files.
2017:03:22 22:44:30	get data info.
2017:03:22 22:44:30	init batch data.
2017:03:22 22:44:30	...number of batches: 402
2017:03:22 22:44:30	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:22 22:44:43	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490222682

2017:03:22 22:44:51	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490222682/checkpoints/bestmodel.

2017:03:22 22:44:51	------ training ------ 

2017:03:22 22:44:51	train epoch 0
2017:03:22 22:45:29	use DataLoaderBBC to init data.
2017:03:22 22:45:29	loading preprocessed files.
2017:03:22 22:45:31	get data info.
2017:03:22 22:45:31	init batch data.
2017:03:22 22:45:31	...number of batches: 402
2017:03:22 22:45:32	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:22 22:45:43	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490222743

2017:03:22 22:45:52	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490222743/checkpoints/bestmodel.

2017:03:22 22:45:52	------ training ------ 

2017:03:22 22:45:52	train epoch 0
2017:03:23 09:20:20	use DataLoaderBBC to init data.
2017:03:23 09:20:20	loading preprocessed files.
2017:03:23 09:20:22	get data info.
2017:03:23 09:20:22	init batch data.
2017:03:23 09:20:22	...number of batches: 402
2017:03:23 09:20:22	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:20:33	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490260833

2017:03:23 09:20:41	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490260833/checkpoints/bestmodel.

2017:03:23 09:20:41	------ training ------ 

2017:03:23 09:20:41	train epoch 0
2017:03:23 09:25:15	use DataLoaderBBC to init data.
2017:03:23 09:25:15	loading preprocessed files.
2017:03:23 09:25:17	get data info.
2017:03:23 09:25:17	init batch data.
2017:03:23 09:25:17	...number of batches: 402
2017:03:23 09:25:17	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:25:29	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490261129

2017:03:23 09:25:36	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490261129/checkpoints/bestmodel.

2017:03:23 09:25:36	------ training ------ 

2017:03:23 09:25:36	train epoch 0
2017:03:23 09:26:05	use DataLoaderBBC to init data.
2017:03:23 09:26:05	loading preprocessed files.
2017:03:23 09:26:07	get data info.
2017:03:23 09:26:07	init batch data.
2017:03:23 09:26:07	...number of batches: 402
2017:03:23 09:26:07	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:26:19	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490261178

2017:03:23 09:26:26	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV1.TextGANV1/1490261178/checkpoints/bestmodel.

2017:03:23 09:26:26	------ training ------ 

2017:03:23 09:26:26	train epoch 0
2017:03:23 09:29:27	use DataLoaderBBC to init data.
2017:03:23 09:29:27	loading preprocessed files.
2017:03:23 09:29:29	get data info.
2017:03:23 09:29:29	init batch data.
2017:03:23 09:29:29	...number of batches: 402
2017:03:23 09:29:29	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:29:45	use DataLoaderBBC to init data.
2017:03:23 09:29:45	loading preprocessed files.
2017:03:23 09:29:46	get data info.
2017:03:23 09:29:46	init batch data.
2017:03:23 09:29:46	...number of batches: 402
2017:03:23 09:29:47	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:30:36	use DataLoaderBBC to init data.
2017:03:23 09:30:36	loading preprocessed files.
2017:03:23 09:30:37	get data info.
2017:03:23 09:30:37	init batch data.
2017:03:23 09:30:37	...number of batches: 402
2017:03:23 09:30:38	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:30:49	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490261449

2017:03:23 09:30:58	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490261449/checkpoints/bestmodel.

2017:03:23 09:30:58	------ training ------ 

2017:03:23 09:30:58	train epoch 0
2017:03:23 09:59:31	use DataLoaderBBC to init data.
2017:03:23 09:59:31	loading preprocessed files.
2017:03:23 09:59:33	get data info.
2017:03:23 09:59:33	init batch data.
2017:03:23 09:59:33	...number of batches: 402
2017:03:23 09:59:33	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 09:59:46	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490263186

2017:03:23 09:59:54	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490263186/checkpoints/bestmodel.

2017:03:23 09:59:54	------ training ------ 

2017:03:23 09:59:54	train epoch 0
2017:03:23 13:08:30	use DataLoaderBBC to init data.
2017:03:23 13:08:30	loading preprocessed files.
2017:03:23 13:08:32	get data info.
2017:03:23 13:08:32	init batch data.
2017:03:23 13:08:32	...number of batches: 402
2017:03:23 13:08:32	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:09:18	use DataLoaderBBC to init data.
2017:03:23 13:09:18	loading preprocessed files.
2017:03:23 13:09:19	get data info.
2017:03:23 13:09:19	init batch data.
2017:03:23 13:09:19	...number of batches: 402
2017:03:23 13:09:19	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:09:31	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274571

2017:03:23 13:09:39	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274571/checkpoints/bestmodel.

2017:03:23 13:09:39	------ training ------ 

2017:03:23 13:09:39	train epoch 0
2017:03:23 13:10:40	use DataLoaderBBC to init data.
2017:03:23 13:10:40	loading preprocessed files.
2017:03:23 13:10:42	get data info.
2017:03:23 13:10:42	init batch data.
2017:03:23 13:10:42	...number of batches: 402
2017:03:23 13:10:43	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:10:55	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274654

2017:03:23 13:11:02	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274654/checkpoints/bestmodel.

2017:03:23 13:11:02	------ training ------ 

2017:03:23 13:11:03	train epoch 0
2017:03:23 13:11:22	use DataLoaderBBC to init data.
2017:03:23 13:11:22	loading preprocessed files.
2017:03:23 13:11:24	get data info.
2017:03:23 13:11:24	init batch data.
2017:03:23 13:11:24	...number of batches: 402
2017:03:23 13:11:24	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:11:36	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274696

2017:03:23 13:11:44	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274696/checkpoints/bestmodel.

2017:03:23 13:11:44	------ training ------ 

2017:03:23 13:11:44	train epoch 0
2017:03:23 13:12:24	use DataLoaderBBC to init data.
2017:03:23 13:12:24	loading preprocessed files.
2017:03:23 13:12:26	get data info.
2017:03:23 13:12:26	init batch data.
2017:03:23 13:12:26	...number of batches: 402
2017:03:23 13:12:26	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:12:38	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274757

2017:03:23 13:12:45	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274757/checkpoints/bestmodel.

2017:03:23 13:12:45	------ training ------ 

2017:03:23 13:12:45	train epoch 0
2017:03:23 13:13:26	use DataLoaderBBC to init data.
2017:03:23 13:13:26	loading preprocessed files.
2017:03:23 13:13:28	get data info.
2017:03:23 13:13:28	init batch data.
2017:03:23 13:13:28	...number of batches: 402
2017:03:23 13:13:28	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:13:40	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274820

2017:03:23 13:13:48	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274820/checkpoints/bestmodel.

2017:03:23 13:13:48	------ training ------ 

2017:03:23 13:13:48	train epoch 0
2017:03:23 13:14:21	use DataLoaderBBC to init data.
2017:03:23 13:14:21	loading preprocessed files.
2017:03:23 13:14:23	get data info.
2017:03:23 13:14:23	init batch data.
2017:03:23 13:14:23	...number of batches: 402
2017:03:23 13:14:23	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 13:14:37	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274877

2017:03:23 13:14:45	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490274877/checkpoints/bestmodel.

2017:03:23 13:14:45	------ training ------ 

2017:03:23 13:14:45	train epoch 0
2017:03:23 17:37:03	use DataLoaderBBC to init data.
2017:03:23 17:37:03	loading preprocessed files.
2017:03:23 17:37:05	get data info.
2017:03:23 17:37:05	init batch data.
2017:03:23 17:37:05	...number of batches: 402
2017:03:23 17:37:05	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 17:37:17	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490290637

2017:03:23 17:37:25	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490290637/checkpoints/bestmodel.

2017:03:23 17:37:25	------ training ------ 

2017:03:23 17:37:25	train epoch 0
2017:03:23 17:38:00	use DataLoaderBBC to init data.
2017:03:23 17:38:00	loading preprocessed files.
2017:03:23 17:38:02	get data info.
2017:03:23 17:38:02	init batch data.
2017:03:23 17:38:02	...number of batches: 402
2017:03:23 17:38:02	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 17:38:15	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490290695

2017:03:23 17:38:23	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490290695/checkpoints/bestmodel.

2017:03:23 17:38:23	------ training ------ 

2017:03:23 17:38:23	train epoch 0
2017:03:23 17:39:21	use DataLoaderBBC to init data.
2017:03:23 17:39:21	loading preprocessed files.
2017:03:23 17:39:23	get data info.
2017:03:23 17:39:23	init batch data.
2017:03:23 17:39:23	...number of batches: 402
2017:03:23 17:39:23	num of sentence: 20100, sentence length: 25, vocab size: 25281
2017:03:23 17:39:37	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490290776

2017:03:23 17:39:45	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490290776/checkpoints/bestmodel.

2017:03:23 17:39:45	------ training ------ 

2017:03:23 17:39:45	train epoch 0
2017:03:23 17:41:39	use DataLoaderBBC to init data.
2017:03:23 17:41:39	reading and processing the text file.
2017:03:23 17:41:39	preprocess the dataset.
2017:03:23 17:41:39	load data.
2017:03:23 17:41:39	init content from raw.
2017:03:23 17:41:39	init data from the raw dataset.
2017:03:23 17:41:40	load context for further preprocessing.
2017:03:23 17:41:40	clean data.
2017:03:23 17:41:41	...mask and pad the sentence.
2017:03:23 17:41:41	......max len:359, median len:22.0, min len:2
2017:03:23 17:41:41	......filter sentence and bound them in the range of 25.
2017:03:23 17:41:41	build a vocabulary.
2017:03:23 17:41:41	...flatmap a list of sentence list to a list of sentence.
2017:03:23 17:41:41	...mapping from index to word.
2017:03:23 17:41:42	...mapping from word to index.
2017:03:23 17:41:42	...load existing embedding
2017:03:23 17:42:18	use DataLoaderBBC to init data.
2017:03:23 17:42:18	reading and processing the text file.
2017:03:23 17:42:18	preprocess the dataset.
2017:03:23 17:42:18	load data.
2017:03:23 17:42:18	init content from raw.
2017:03:23 17:42:18	init data from the raw dataset.
2017:03:23 17:42:19	load context for further preprocessing.
2017:03:23 17:42:19	clean data.
2017:03:23 17:42:20	...mask and pad the sentence.
2017:03:23 17:42:20	......max len:359, median len:22.0, min len:2
2017:03:23 17:42:20	......filter sentence and bound them in the range of 25.
2017:03:23 17:42:20	build a vocabulary.
2017:03:23 17:42:20	...flatmap a list of sentence list to a list of sentence.
2017:03:23 17:42:21	...mapping from index to word.
2017:03:23 17:42:21	...mapping from word to index.
2017:03:23 17:42:21	...load existing embedding
2017:03:23 17:43:58	use DataLoaderBBC to init data.
2017:03:23 17:43:58	reading and processing the text file.
2017:03:23 17:43:58	preprocess the dataset.
2017:03:23 17:43:58	load data.
2017:03:23 17:43:58	init content from raw.
2017:03:23 17:43:58	init data from the raw dataset.
2017:03:23 17:43:59	load context for further preprocessing.
2017:03:23 17:43:59	clean data.
2017:03:23 17:44:00	...mask and pad the sentence.
2017:03:23 17:44:00	......max len:359, median len:22.0, min len:2
2017:03:23 17:44:00	......filter sentence and bound them in the range of 25.
2017:03:23 17:44:00	build a vocabulary.
2017:03:23 17:44:00	...flatmap a list of sentence list to a list of sentence.
2017:03:23 17:44:01	...mapping from index to word.
2017:03:23 17:44:01	...mapping from word to index.
2017:03:23 17:44:01	...load existing embedding
2017:03:23 17:44:46	use DataLoaderBBC to init data.
2017:03:23 17:44:46	reading and processing the text file.
2017:03:23 17:44:46	preprocess the dataset.
2017:03:23 17:44:46	load data.
2017:03:23 17:44:46	init content from raw.
2017:03:23 17:44:46	init data from the raw dataset.
2017:03:23 17:44:47	load context for further preprocessing.
2017:03:23 17:44:47	clean data.
2017:03:23 17:44:48	...mask and pad the sentence.
2017:03:23 17:44:48	......max len:359, median len:22.0, min len:2
2017:03:23 17:44:48	......filter sentence and bound them in the range of 25.
2017:03:23 17:44:48	build a vocabulary.
2017:03:23 17:44:48	...flatmap a list of sentence list to a list of sentence.
2017:03:23 17:44:49	...mapping from index to word.
2017:03:23 17:44:49	...mapping from word to index.
2017:03:23 17:44:49	...load existing embedding
2017:03:23 17:45:04	# of vocabulary:25278, # of existing_words:19901, num of missing
2017:03:23 17:45:05	...map word to index.
2017:03:23 17:45:05	...save processed data to file.
2017:03:23 17:45:06	get data info.
2017:03:23 17:45:06	init batch data.
2017:03:23 17:45:06	...number of batches: 402
2017:03:23 17:45:06	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 17:48:03	use DataLoaderBBC to init data.
2017:03:23 17:48:03	reading and processing the text file.
2017:03:23 17:48:03	preprocess the dataset.
2017:03:23 17:48:03	load data.
2017:03:23 17:48:03	init content from raw.
2017:03:23 17:48:03	init data from the raw dataset.
2017:03:23 17:48:04	load context for further preprocessing.
2017:03:23 17:48:04	clean data.
2017:03:23 17:48:05	...mask and pad the sentence.
2017:03:23 17:48:05	......max len:359, median len:22.0, min len:2
2017:03:23 17:48:05	......filter sentence and bound them in the range of 25.
2017:03:23 17:48:05	build a vocabulary.
2017:03:23 17:48:05	...flatmap a list of sentence list to a list of sentence.
2017:03:23 17:48:05	...mapping from index to word.
2017:03:23 17:48:05	...mapping from word to index.
2017:03:23 17:48:05	...load existing embedding
2017:03:23 17:48:20	# of vocabulary:25278, # of existing_words:19901, # of missing: 5377
2017:03:23 17:48:21	...map word to index.
2017:03:23 17:48:22	...save processed data to file.
2017:03:23 17:48:23	get data info.
2017:03:23 17:48:23	init batch data.
2017:03:23 17:48:23	...number of batches: 402
2017:03:23 17:48:23	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 17:48:38	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490291317

2017:03:23 18:59:12	use DataLoaderBBC to init data.
2017:03:23 18:59:12	loading preprocessed files.
2017:03:23 18:59:15	get data info.
2017:03:23 18:59:15	init batch data.
2017:03:23 18:59:15	...number of batches: 402
2017:03:23 18:59:15	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 18:59:31	use DataLoaderBBC to init data.
2017:03:23 18:59:31	reading and processing the text file.
2017:03:23 18:59:31	preprocess the dataset.
2017:03:23 18:59:31	load data.
2017:03:23 18:59:31	load context for further preprocessing.
2017:03:23 18:59:31	clean data.
2017:03:23 18:59:32	...mask and pad the sentence.
2017:03:23 18:59:32	......max len:359, median len:22.0, min len:2
2017:03:23 18:59:32	......filter sentence and bound them in the range of 25.
2017:03:23 18:59:32	build a vocabulary.
2017:03:23 18:59:32	...flatmap a list of sentence list to a list of sentence.
2017:03:23 18:59:32	...mapping from index to word.
2017:03:23 18:59:32	...mapping from word to index.
2017:03:23 18:59:32	...load existing embedding
2017:03:23 18:59:46	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:23 19:00:24	use DataLoaderBBC to init data.
2017:03:23 19:00:24	reading and processing the text file.
2017:03:23 19:00:24	preprocess the dataset.
2017:03:23 19:00:24	load data.
2017:03:23 19:00:24	load context for further preprocessing.
2017:03:23 19:00:24	clean data.
2017:03:23 19:00:25	...mask and pad the sentence.
2017:03:23 19:00:25	......max len:359, median len:22.0, min len:2
2017:03:23 19:00:25	......filter sentence and bound them in the range of 25.
2017:03:23 19:00:25	build a vocabulary.
2017:03:23 19:00:25	...flatmap a list of sentence list to a list of sentence.
2017:03:23 19:00:25	...mapping from index to word.
2017:03:23 19:00:26	...mapping from word to index.
2017:03:23 19:00:26	...load existing embedding
2017:03:23 19:00:40	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:23 19:00:53	...map word to index.
2017:03:23 19:00:54	...save processed data to file.
2017:03:23 19:00:55	get data info.
2017:03:23 19:00:55	init batch data.
2017:03:23 19:00:55	...number of batches: 402
2017:03:23 19:00:55	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 19:01:09	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490295668

2017:03:23 19:01:17	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490295668/checkpoints/bestmodel.

2017:03:23 19:01:17	------ training ------ 

2017:03:23 19:01:18	train epoch 0
2017:03:23 19:03:13	use DataLoaderBBC to init data.
2017:03:23 19:03:13	reading and processing the text file.
2017:03:23 19:03:13	preprocess the dataset.
2017:03:23 19:03:13	load data.
2017:03:23 19:03:13	load context for further preprocessing.
2017:03:23 19:03:13	clean data.
2017:03:23 19:03:14	...mask and pad the sentence.
2017:03:23 19:03:14	......max len:359, median len:22.0, min len:2
2017:03:23 19:03:14	......filter sentence and bound them in the range of 25.
2017:03:23 19:03:14	build a vocabulary.
2017:03:23 19:03:14	...flatmap a list of sentence list to a list of sentence.
2017:03:23 19:03:15	...mapping from index to word.
2017:03:23 19:03:15	...mapping from word to index.
2017:03:23 19:03:15	...load existing embedding
2017:03:23 19:03:30	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:23 19:03:47	size of vocabulary: (19902, 50)
2017:03:23 19:03:48	...map word to index.
2017:03:23 19:03:49	...save processed data to file.
2017:03:23 19:03:50	get data info.
2017:03:23 19:03:50	init batch data.
2017:03:23 19:03:50	...number of batches: 402
2017:03:23 19:03:50	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 19:27:56	use DataLoaderBBC to init data.
2017:03:23 19:27:56	reading and processing the text file.
2017:03:23 19:27:56	preprocess the dataset.
2017:03:23 19:27:56	load data.
2017:03:23 19:27:56	load context for further preprocessing.
2017:03:23 19:27:56	clean data.
2017:03:23 19:27:57	...mask and pad the sentence.
2017:03:23 19:27:57	......max len:359, median len:22.0, min len:2
2017:03:23 19:27:57	......filter sentence and bound them in the range of 25.
2017:03:23 19:27:57	build a vocabulary.
2017:03:23 19:27:57	...flatmap a list of sentence list to a list of sentence.
2017:03:23 19:27:57	...mapping from index to word.
2017:03:23 19:27:57	...mapping from word to index.
2017:03:23 19:27:57	...load existing embedding
2017:03:23 19:28:11	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:23 19:28:25	size of vocabulary: (19902, 50)
2017:03:23 19:28:26	...map word to index.
2017:03:23 19:28:26	...save processed data to file.
2017:03:23 19:28:27	get data info.
2017:03:23 19:28:27	init batch data.
2017:03:23 19:28:27	...number of batches: 402
2017:03:23 19:28:27	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 19:28:42	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490297321

2017:03:23 19:28:50	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490297321/checkpoints/bestmodel.

2017:03:23 19:28:50	------ training ------ 

2017:03:23 19:28:50	train epoch 0
2017:03:23 19:31:47	use DataLoaderBBC to init data.
2017:03:23 19:31:47	reading and processing the text file.
2017:03:23 19:31:47	preprocess the dataset.
2017:03:23 19:31:47	load data.
2017:03:23 19:31:47	load context for further preprocessing.
2017:03:23 19:31:47	clean data.
2017:03:23 19:31:48	...mask and pad the sentence.
2017:03:23 19:31:48	......max len:359, median len:22.0, min len:2
2017:03:23 19:31:48	......filter sentence and bound them in the range of 25.
2017:03:23 19:31:48	build a vocabulary.
2017:03:23 19:31:48	...flatmap a list of sentence list to a list of sentence.
2017:03:23 19:31:48	...mapping from index to word.
2017:03:23 19:31:48	...mapping from word to index.
2017:03:23 19:31:48	...load existing embedding
2017:03:23 19:32:06	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:23 19:32:22	size of vocabulary: (19902, 50)
2017:03:23 19:32:23	...map word to index.
2017:03:23 19:32:24	...save processed data to file.
2017:03:23 19:32:25	get data info.
2017:03:23 19:32:25	init batch data.
2017:03:23 19:32:25	...number of batches: 402
2017:03:23 19:32:25	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 19:32:46	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490297565

2017:03:23 19:33:01	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490297565/checkpoints/bestmodel.

2017:03:23 19:33:01	------ training ------ 

2017:03:23 19:33:01	train epoch 0
2017:03:23 19:33:59	use DataLoaderBBC to init data.
2017:03:23 19:33:59	reading and processing the text file.
2017:03:23 19:33:59	preprocess the dataset.
2017:03:23 19:33:59	load data.
2017:03:23 19:34:00	load context for further preprocessing.
2017:03:23 19:34:00	clean data.
2017:03:23 19:34:01	...mask and pad the sentence.
2017:03:23 19:34:01	......max len:359, median len:22.0, min len:2
2017:03:23 19:34:01	......filter sentence and bound them in the range of 25.
2017:03:23 19:34:01	build a vocabulary.
2017:03:23 19:34:01	...flatmap a list of sentence list to a list of sentence.
2017:03:23 19:34:01	...mapping from index to word.
2017:03:23 19:34:01	...mapping from word to index.
2017:03:23 19:34:01	...load existing embedding
2017:03:23 19:34:25	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:23 19:34:59	size of vocabulary: (19902, 50)
2017:03:23 19:35:01	...map word to index.
2017:03:23 19:35:02	...save processed data to file.
2017:03:23 19:35:03	get data info.
2017:03:23 19:35:03	init batch data.
2017:03:23 19:35:03	...number of batches: 402
2017:03:23 19:35:03	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:23 19:35:26	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490297726

2017:03:23 19:35:36	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490297726/checkpoints/bestmodel.

2017:03:23 19:35:36	------ training ------ 

2017:03:23 19:35:36	train epoch 0
2017:03:24 10:15:32	use DataLoaderBBC to init data.
2017:03:24 10:15:32	loading preprocessed files.
2017:03:24 10:15:34	get data info.
2017:03:24 10:15:34	init batch data.
2017:03:24 10:15:34	...number of batches: 402
2017:03:24 10:15:34	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:16:32	use DataLoaderBBC to init data.
2017:03:24 10:16:32	loading preprocessed files.
2017:03:24 10:16:34	get data info.
2017:03:24 10:16:34	init batch data.
2017:03:24 10:16:34	...number of batches: 402
2017:03:24 10:16:34	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:16:35	enter standard generator mode.
2017:03:24 10:16:35	enter GAN's generator mode.
2017:03:24 10:18:07	use DataLoaderBBC to init data.
2017:03:24 10:18:07	loading preprocessed files.
2017:03:24 10:18:10	get data info.
2017:03:24 10:18:10	init batch data.
2017:03:24 10:18:10	...number of batches: 402
2017:03:24 10:18:10	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:18:10	enter standard generator mode.
2017:03:24 10:18:11	enter GAN's generator mode.
2017:03:24 10:18:32	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490350711

2017:03:24 10:18:35	use DataLoaderBBC to init data.
2017:03:24 10:18:35	loading preprocessed files.
2017:03:24 10:18:36	get data info.
2017:03:24 10:18:36	init batch data.
2017:03:24 10:18:36	...number of batches: 402
2017:03:24 10:18:36	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:18:37	enter standard generator mode.
2017:03:24 10:18:38	enter GAN's generator mode.
2017:03:24 10:18:54	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490350734

2017:03:24 10:18:58	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490350734

2017:03:24 10:19:10	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490350734/checkpoints/bestmodel.

2017:03:24 10:19:10	------ pretraining ------ 

2017:03:24 10:19:10	train epoch 0
2017:03:24 10:24:54	use DataLoaderBBC to init data.
2017:03:24 10:24:54	loading preprocessed files.
2017:03:24 10:24:56	get data info.
2017:03:24 10:24:56	init batch data.
2017:03:24 10:24:56	...number of batches: 402
2017:03:24 10:24:56	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:24:56	enter standard generator mode.
2017:03:24 10:24:57	enter GAN's generator mode.
2017:03:24 10:25:13	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351112

2017:03:24 10:25:17	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351112

2017:03:24 10:25:29	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351112/checkpoints/bestmodel.

2017:03:24 10:25:29	------ pretraining ------ 

2017:03:24 10:25:29	train epoch 0
2017:03:24 10:26:16	use DataLoaderBBC to init data.
2017:03:24 10:26:16	loading preprocessed files.
2017:03:24 10:26:18	get data info.
2017:03:24 10:26:18	init batch data.
2017:03:24 10:26:18	...number of batches: 402
2017:03:24 10:26:18	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:26:18	enter standard generator mode.
2017:03:24 10:26:19	enter GAN's generator mode.
2017:03:24 10:26:37	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351196

2017:03:24 10:26:53	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351196/checkpoints/bestmodel.

2017:03:24 10:26:53	------ pretraining ------ 

2017:03:24 10:26:53	pretrain epoch 0
2017:03:24 10:30:58	use DataLoaderBBC to init data.
2017:03:24 10:30:58	loading preprocessed files.
2017:03:24 10:31:00	get data info.
2017:03:24 10:31:00	init batch data.
2017:03:24 10:31:00	...number of batches: 402
2017:03:24 10:31:00	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:24 10:31:01	enter standard generator mode.
2017:03:24 10:31:01	enter GAN's generator mode.
2017:03:24 10:31:22	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351481

2017:03:24 10:31:37	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351481/checkpoints/bestmodel.

2017:03:24 10:31:37	------ pretraining ------ 

2017:03:24 10:31:37	pretrain epoch 0
2017:03:24 10:36:25	use DataLoaderBBC to init data.
2017:03:24 10:36:25	loading preprocessed files.
2017:03:24 10:36:27	get data info.
2017:03:24 10:36:27	init batch data.
2017:03:24 10:36:27	...number of batches: 20
2017:03:24 10:36:27	num of sentence: 1000, sentence length: 25, vocab size: 25278
2017:03:24 10:36:28	enter standard generator mode.
2017:03:24 10:36:28	enter GAN's generator mode.
2017:03:24 10:36:45	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351804

2017:03:24 10:37:00	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351804/checkpoints/bestmodel.

2017:03:24 10:37:00	------ pretraining ------ 

2017:03:24 10:37:00	pretrain epoch 0
2017:03:24 10:37:30	pretrain loss d: 0.655119776726, pretrain loss g: 9.99217224121, execution speed: 1.45 seconds/batch
2017:03:24 10:37:32	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490351804/checkpoints/bestmodel.

2017:03:24 10:37:32	------ training ------ 

2017:03:24 10:37:32	train epoch 0
2017:03:24 10:57:51	use DataLoaderBBC to init data.
2017:03:24 10:57:51	reading and processing the text file.
2017:03:24 10:57:51	preprocess the dataset.
2017:03:24 10:57:51	load data.
2017:03:24 10:57:51	load context for further preprocessing.
2017:03:24 10:57:51	clean data.
2017:03:24 10:57:52	...mask and pad the sentence.
2017:03:24 10:57:52	......max len:359, median len:22.0, min len:2
2017:03:24 10:57:52	......filter sentence and bound them in the range of 25.
2017:03:24 10:57:52	build a vocabulary.
2017:03:24 10:57:52	...flatmap a list of sentence list to a list of sentence.
2017:03:24 10:57:53	...mapping from index to word.
2017:03:24 10:57:53	...mapping from word to index.
2017:03:24 10:57:53	...map word to index.
2017:03:24 10:57:53	...save processed data to file.
2017:03:24 10:57:54	get data info.
2017:03:24 10:57:54	init batch data.
2017:03:24 10:57:54	...number of batches: 20
2017:03:24 10:57:54	num of sentence: 1000, sentence length: 25, vocab size: 25278
2017:03:24 10:58:02	use DataLoaderBBC to init data.
2017:03:24 10:58:02	reading and processing the text file.
2017:03:24 10:58:02	preprocess the dataset.
2017:03:24 10:58:02	load data.
2017:03:24 10:58:02	load context for further preprocessing.
2017:03:24 10:58:02	clean data.
2017:03:24 10:58:03	...mask and pad the sentence.
2017:03:24 10:58:03	......max len:359, median len:22.0, min len:2
2017:03:24 10:58:03	......filter sentence and bound them in the range of 25.
2017:03:24 10:58:03	build a vocabulary.
2017:03:24 10:58:03	...flatmap a list of sentence list to a list of sentence.
2017:03:24 10:58:03	...mapping from index to word.
2017:03:24 10:58:03	...mapping from word to index.
2017:03:24 10:58:03	...map word to index.
2017:03:24 10:58:04	...save processed data to file.
2017:03:24 10:58:05	get data info.
2017:03:24 10:58:05	init batch data.
2017:03:24 10:58:05	...number of batches: 10
2017:03:24 10:58:05	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 10:59:41	use DataLoaderBBC to init data.
2017:03:24 10:59:41	reading and processing the text file.
2017:03:24 10:59:41	preprocess the dataset.
2017:03:24 10:59:41	load data.
2017:03:24 10:59:41	load context for further preprocessing.
2017:03:24 10:59:41	clean data.
2017:03:24 10:59:42	...mask and pad the sentence.
2017:03:24 10:59:42	......max len:359, median len:22.0, min len:2
2017:03:24 10:59:42	......filter sentence and bound them in the range of 25.
2017:03:24 10:59:42	build a vocabulary.
2017:03:24 10:59:42	...flatmap a list of sentence list to a list of sentence.
2017:03:24 10:59:42	...mapping from index to word.
2017:03:24 10:59:42	...mapping from word to index.
2017:03:24 10:59:42	...load existing embedding
2017:03:24 10:59:56	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:00:07	size of vocabulary: (19902, 50)
2017:03:24 11:00:08	...map word to index.
2017:03:24 11:00:08	...save processed data to file.
2017:03:24 11:00:09	get data info.
2017:03:24 11:00:09	init batch data.
2017:03:24 11:00:09	...number of batches: 10
2017:03:24 11:00:09	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:01:32	use DataLoaderBBC to init data.
2017:03:24 11:01:32	reading and processing the text file.
2017:03:24 11:01:32	preprocess the dataset.
2017:03:24 11:01:32	load data.
2017:03:24 11:01:32	load context for further preprocessing.
2017:03:24 11:01:32	clean data.
2017:03:24 11:01:33	...mask and pad the sentence.
2017:03:24 11:01:33	......max len:359, median len:22.0, min len:2
2017:03:24 11:01:33	......filter sentence and bound them in the range of 25.
2017:03:24 11:01:33	build a vocabulary.
2017:03:24 11:01:33	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:01:33	...mapping from index to word.
2017:03:24 11:01:33	...mapping from word to index.
2017:03:24 11:01:33	...load existing embedding
2017:03:24 11:01:47	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:01:57	size of vocabulary: (19902, 50)
2017:03:24 11:01:58	...map word to index.
2017:03:24 11:01:58	...save processed data to file.
2017:03:24 11:01:59	get data info.
2017:03:24 11:01:59	init batch data.
2017:03:24 11:01:59	...number of batches: 10
2017:03:24 11:01:59	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:02:00	enter standard generator mode.
2017:03:24 11:02:01	enter GAN's generator mode.
2017:03:24 11:02:20	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490353339

2017:03:24 11:02:37	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490353339/checkpoints/bestmodel.

2017:03:24 11:02:37	------ pretraining ------ 

2017:03:24 11:02:37	pretrain epoch 0
2017:03:24 11:02:57	pretrain loss d: 0.735584616661, pretrain loss g: 10.1250476837, execution speed: 1.90 seconds/batch
2017:03:24 11:02:59	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490353339/checkpoints/bestmodel.

2017:03:24 11:02:59	------ training ------ 

2017:03:24 11:02:59	train epoch 0
2017:03:24 11:03:12	train loss d: 0.172809556127, train loss g: 3.39446926117, execution speed: 1.20 seconds/batch
2017:03:24 11:03:14	val loss d: 0.0278111603111, val loss g: 4.93084049225, execution speed: 0.20 seconds/batch

2017:03:24 11:03:16	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490353339/checkpoints/bestmodel.

2017:03:24 11:03:16	train epoch 1
2017:03:24 11:17:02	use DataLoaderBBC to init data.
2017:03:24 11:17:02	reading and processing the text file.
2017:03:24 11:17:02	preprocess the dataset.
2017:03:24 11:17:02	load data.
2017:03:24 11:17:02	load context for further preprocessing.
2017:03:24 11:17:02	clean data.
2017:03:24 11:17:03	...mask and pad the sentence.
2017:03:24 11:17:03	......max len:359, median len:22.0, min len:2
2017:03:24 11:17:03	......filter sentence and bound them in the range of 25.
2017:03:24 11:17:03	build a vocabulary.
2017:03:24 11:17:03	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:17:03	...mapping from index to word.
2017:03:24 11:17:06	use DataLoaderBBC to init data.
2017:03:24 11:17:06	reading and processing the text file.
2017:03:24 11:17:06	preprocess the dataset.
2017:03:24 11:17:06	load data.
2017:03:24 11:17:06	load context for further preprocessing.
2017:03:24 11:17:06	clean data.
2017:03:24 11:17:07	...mask and pad the sentence.
2017:03:24 11:17:07	......max len:359, median len:22.0, min len:2
2017:03:24 11:17:07	......filter sentence and bound them in the range of 25.
2017:03:24 11:17:07	build a vocabulary.
2017:03:24 11:17:07	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:17:07	...mapping from index to word.
2017:03:24 11:17:07	...mapping from word to index.
2017:03:24 11:17:07	...load existing embedding
2017:03:24 11:17:21	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:17:32	size of vocabulary: (19902, 50)
2017:03:24 11:17:33	...map word to index.
2017:03:24 11:17:33	...save processed data to file.
2017:03:24 11:17:34	get data info.
2017:03:24 11:17:34	init batch data.
2017:03:24 11:17:34	...number of batches: 10
2017:03:24 11:17:34	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:17:35	enter standard seq2seq's generator mode.
2017:03:24 11:17:35	enter GAN's generator mode.
2017:03:24 11:17:51	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490354271

2017:03:24 11:18:07	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490354271/checkpoints/bestmodel.

2017:03:24 11:18:07	------ pretraining ------ 

2017:03:24 11:18:08	pretrain epoch 0
2017:03:24 11:20:06	use DataLoaderBBC to init data.
2017:03:24 11:20:06	reading and processing the text file.
2017:03:24 11:20:06	preprocess the dataset.
2017:03:24 11:20:06	load data.
2017:03:24 11:20:06	load context for further preprocessing.
2017:03:24 11:20:06	clean data.
2017:03:24 11:20:07	...mask and pad the sentence.
2017:03:24 11:20:07	......max len:359, median len:22.0, min len:2
2017:03:24 11:20:07	......filter sentence and bound them in the range of 25.
2017:03:24 11:20:07	build a vocabulary.
2017:03:24 11:20:07	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:20:07	...mapping from index to word.
2017:03:24 11:20:07	...mapping from word to index.
2017:03:24 11:20:07	...load existing embedding
2017:03:24 11:20:20	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:20:31	size of vocabulary: (19902, 50)
2017:03:24 11:20:32	...map word to index.
2017:03:24 11:20:32	...save processed data to file.
2017:03:24 11:20:33	get data info.
2017:03:24 11:20:33	init batch data.
2017:03:24 11:20:33	...number of batches: 10
2017:03:24 11:20:33	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:20:34	enter standard seq2seq's generator mode.
2017:03:24 11:20:35	enter GAN's generator mode.
2017:03:24 11:20:51	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490354450

2017:03:24 11:21:07	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490354450/checkpoints/bestmodel.

2017:03:24 11:21:07	------ pretraining ------ 

2017:03:24 11:21:07	pretrain epoch 0
2017:03:24 11:22:01	use DataLoaderBBC to init data.
2017:03:24 11:22:01	reading and processing the text file.
2017:03:24 11:22:01	preprocess the dataset.
2017:03:24 11:22:01	load data.
2017:03:24 11:22:01	load context for further preprocessing.
2017:03:24 11:22:01	clean data.
2017:03:24 11:22:02	...mask and pad the sentence.
2017:03:24 11:22:02	......max len:359, median len:22.0, min len:2
2017:03:24 11:22:02	......filter sentence and bound them in the range of 25.
2017:03:24 11:22:02	build a vocabulary.
2017:03:24 11:22:02	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:22:02	...mapping from index to word.
2017:03:24 11:22:02	...mapping from word to index.
2017:03:24 11:22:02	...load existing embedding
2017:03:24 11:22:16	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:22:28	size of vocabulary: (19902, 50)
2017:03:24 11:22:29	...map word to index.
2017:03:24 11:22:30	...save processed data to file.
2017:03:24 11:22:31	get data info.
2017:03:24 11:22:31	init batch data.
2017:03:24 11:22:31	...number of batches: 10
2017:03:24 11:22:31	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:22:31	enter standard seq2seq's generator mode.
2017:03:24 11:22:32	enter GAN's generator mode.
2017:03:24 11:22:49	writing to /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490354569

2017:03:24 11:23:06	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490354569/checkpoints/bestmodel.

2017:03:24 11:23:06	------ pretraining ------ 

2017:03:24 11:23:06	pretrain epoch 0
2017:03:24 11:44:55	use DataLoaderBBC to init data.
2017:03:24 11:44:55	reading and processing the text file.
2017:03:24 11:44:55	preprocess the dataset.
2017:03:24 11:44:55	load data.
2017:03:24 11:44:55	load context for further preprocessing.
2017:03:24 11:44:55	clean data.
2017:03:24 11:44:56	...mask and pad the sentence.
2017:03:24 11:44:56	......max len:359, median len:22.0, min len:2
2017:03:24 11:44:56	......filter sentence and bound them in the range of 25.
2017:03:24 11:44:56	build a vocabulary.
2017:03:24 11:44:56	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:44:56	...mapping from index to word.
2017:03:24 11:44:56	...mapping from word to index.
2017:03:24 11:44:56	...load existing embedding
2017:03:24 11:45:14	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:45:28	size of vocabulary: (19902, 50)
2017:03:24 11:45:30	...map word to index.
2017:03:24 11:45:31	...save processed data to file.
2017:03:24 11:45:32	get data info.
2017:03:24 11:45:32	init batch data.
2017:03:24 11:45:32	...number of batches: 10
2017:03:24 11:45:32	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:45:32	enter standard seq2seq's generator mode.
2017:03:24 11:45:33	enter GAN's generator mode.
2017:03:24 11:46:09	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490355949/checkpoints/bestmodel.

2017:03:24 11:46:09	------ pretraining ------ 

2017:03:24 11:46:10	pretrain epoch 0
2017:03:24 11:47:39	use DataLoaderBBC to init data.
2017:03:24 11:47:39	reading and processing the text file.
2017:03:24 11:47:39	preprocess the dataset.
2017:03:24 11:47:39	load data.
2017:03:24 11:47:39	load context for further preprocessing.
2017:03:24 11:47:39	clean data.
2017:03:24 11:47:39	...mask and pad the sentence.
2017:03:24 11:47:39	......max len:359, median len:22.0, min len:2
2017:03:24 11:47:40	......filter sentence and bound them in the range of 25.
2017:03:24 11:47:40	build a vocabulary.
2017:03:24 11:47:40	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:47:40	...mapping from index to word.
2017:03:24 11:47:40	...mapping from word to index.
2017:03:24 11:47:40	...load existing embedding
2017:03:24 11:47:55	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:48:16	size of vocabulary: (19902, 50)
2017:03:24 11:48:32	...map word to index.
2017:03:24 11:48:33	...save processed data to file.
2017:03:24 11:48:34	get data info.
2017:03:24 11:48:34	init batch data.
2017:03:24 11:48:34	...number of batches: 10
2017:03:24 11:48:34	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:48:35	enter standard seq2seq's generator mode.
2017:03:24 11:48:35	enter GAN's generator mode.
2017:03:24 11:49:57	use DataLoaderBBC to init data.
2017:03:24 11:49:57	reading and processing the text file.
2017:03:24 11:49:57	preprocess the dataset.
2017:03:24 11:49:57	load data.
2017:03:24 11:49:57	load context for further preprocessing.
2017:03:24 11:49:57	clean data.
2017:03:24 11:49:58	...mask and pad the sentence.
2017:03:24 11:49:58	......max len:359, median len:22.0, min len:2
2017:03:24 11:49:58	......filter sentence and bound them in the range of 25.
2017:03:24 11:49:58	build a vocabulary.
2017:03:24 11:49:58	...flatmap a list of sentence list to a list of sentence.
2017:03:24 11:49:59	...mapping from index to word.
2017:03:24 11:49:59	...mapping from word to index.
2017:03:24 11:49:59	...load existing embedding
2017:03:24 11:50:14	# of vocabulary:25278, # of existing_words:19902, # of missing: 5376
2017:03:24 11:50:27	size of vocabulary: (19902, 50)
2017:03:24 11:50:28	...map word to index.
2017:03:24 11:50:28	...save processed data to file.
2017:03:24 11:50:29	get data info.
2017:03:24 11:50:29	init batch data.
2017:03:24 11:50:29	...number of batches: 10
2017:03:24 11:50:29	num of sentence: 500, sentence length: 25, vocab size: 25278
2017:03:24 11:50:30	enter standard seq2seq's generator mode.
2017:03:24 11:50:31	enter GAN's generator mode.
2017:03:24 11:51:07	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490356250/checkpoints/bestmodel.

2017:03:24 11:51:07	------ pretraining ------ 

2017:03:24 11:51:07	pretrain epoch 0
2017:03:25 21:27:33	use DataLoaderBBC to init data.
2017:03:25 21:27:33	reading and processing the text file.
2017:03:25 21:27:33	preprocess the dataset.
2017:03:25 21:27:33	load data.
2017:03:25 21:27:33	init content from raw.
2017:03:25 21:27:33	init data from the raw dataset.
2017:03:25 21:28:25	use DataLoaderBBC to init data.
2017:03:25 21:28:25	reading and processing the text file.
2017:03:25 21:28:25	preprocess the dataset.
2017:03:25 21:28:25	load data.
2017:03:25 21:28:25	init content from raw.
2017:03:25 21:28:25	init data from the raw dataset.
2017:03:25 21:29:40	use DataLoaderBBC to init data.
2017:03:25 21:29:40	reading and processing the text file.
2017:03:25 21:29:40	preprocess the dataset.
2017:03:25 21:29:40	load data.
2017:03:25 21:29:40	init content from raw.
2017:03:25 21:29:40	init data from the raw dataset.
2017:03:25 21:33:28	use DataLoaderBBC to init data.
2017:03:25 21:33:28	reading and processing the text file.
2017:03:25 21:33:28	preprocess the dataset.
2017:03:25 21:33:28	load data.
2017:03:25 21:33:28	load context for further preprocessing.
2017:03:25 21:33:28	clean data.
2017:03:25 21:33:28	...mask and pad the sentence.
2017:03:25 21:33:28	......max len:359, median len:22.0, min len:2
2017:03:25 21:33:28	......filter sentence and bound them in the range of 25.
2017:03:25 21:33:28	build a vocabulary.
2017:03:25 21:33:28	...flatmap a list of sentence list to a list of sentence.
2017:03:25 21:33:29	...mapping from index to word.
2017:03:25 21:33:29	...mapping from word to index.
2017:03:25 21:33:29	...map word to index.
2017:03:25 21:33:29	...save processed data to file.
2017:03:25 21:33:30	get data info.
2017:03:25 21:33:30	init batch data.
2017:03:25 21:33:30	...number of batches: 402
2017:03:25 21:33:30	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 21:33:31	enter standard seq2seq's generator mode.
2017:03:25 21:33:32	enter GAN's generator mode.
2017:03:25 21:34:09	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490477630/checkpoints/bestmodel.

2017:03:25 21:34:09	------ pretraining ------ 

2017:03:25 21:34:10	pretrain epoch 0
2017:03:25 21:35:22	use DataLoaderBBC to init data.
2017:03:25 21:35:22	reading and processing the text file.
2017:03:25 21:35:22	preprocess the dataset.
2017:03:25 21:35:22	load data.
2017:03:25 21:35:22	load context for further preprocessing.
2017:03:25 21:35:22	clean data.
2017:03:25 21:35:23	...mask and pad the sentence.
2017:03:25 21:35:23	......max len:359, median len:22.0, min len:2
2017:03:25 21:35:23	......filter sentence and bound them in the range of 25.
2017:03:25 21:35:23	build a vocabulary.
2017:03:25 21:35:23	...flatmap a list of sentence list to a list of sentence.
2017:03:25 21:35:23	...mapping from index to word.
2017:03:25 21:35:23	...mapping from word to index.
2017:03:25 21:35:23	...map word to index.
2017:03:25 21:35:24	...save processed data to file.
2017:03:25 21:35:24	get data info.
2017:03:25 21:35:24	init batch data.
2017:03:25 21:35:24	...number of batches: 402
2017:03:25 21:35:25	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 21:35:25	enter standard seq2seq's generator mode.
2017:03:25 21:35:25	enter GAN's generator mode.
2017:03:25 21:36:27	use DataLoaderBBC to init data.
2017:03:25 21:36:27	reading and processing the text file.
2017:03:25 21:36:27	preprocess the dataset.
2017:03:25 21:36:27	load data.
2017:03:25 21:36:27	load context for further preprocessing.
2017:03:25 21:36:27	clean data.
2017:03:25 21:36:28	...mask and pad the sentence.
2017:03:25 21:36:28	......max len:359, median len:22.0, min len:2
2017:03:25 21:36:28	......filter sentence and bound them in the range of 25.
2017:03:25 21:36:28	build a vocabulary.
2017:03:25 21:36:28	...flatmap a list of sentence list to a list of sentence.
2017:03:25 21:36:28	...mapping from index to word.
2017:03:25 21:36:28	...mapping from word to index.
2017:03:25 21:36:28	...map word to index.
2017:03:25 21:36:28	...save processed data to file.
2017:03:25 21:36:29	get data info.
2017:03:25 21:36:29	init batch data.
2017:03:25 21:36:29	...number of batches: 402
2017:03:25 21:36:29	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 21:36:30	enter standard seq2seq's generator mode.
2017:03:25 21:36:30	enter GAN's generator mode.
2017:03:25 21:41:59	use DataLoaderBBC to init data.
2017:03:25 21:41:59	reading and processing the text file.
2017:03:25 21:41:59	preprocess the dataset.
2017:03:25 21:41:59	load data.
2017:03:25 21:41:59	load context for further preprocessing.
2017:03:25 21:41:59	clean data.
2017:03:25 21:41:59	...mask and pad the sentence.
2017:03:25 21:41:59	......max len:359, median len:22.0, min len:2
2017:03:25 21:41:59	......filter sentence and bound them in the range of 25.
2017:03:25 21:41:59	build a vocabulary.
2017:03:25 21:41:59	...flatmap a list of sentence list to a list of sentence.
2017:03:25 21:42:00	...mapping from index to word.
2017:03:25 21:42:00	...mapping from word to index.
2017:03:25 21:42:00	...map word to index.
2017:03:25 21:42:00	...save processed data to file.
2017:03:25 21:42:01	get data info.
2017:03:25 21:42:01	init batch data.
2017:03:25 21:42:01	...number of batches: 402
2017:03:25 21:42:01	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 21:42:02	enter standard seq2seq's generator mode.
2017:03:25 21:42:03	enter GAN's generator mode.
2017:03:25 21:43:24	use DataLoaderBBC to init data.
2017:03:25 21:43:24	reading and processing the text file.
2017:03:25 21:43:24	preprocess the dataset.
2017:03:25 21:43:24	load data.
2017:03:25 21:43:24	load context for further preprocessing.
2017:03:25 21:43:24	clean data.
2017:03:25 21:43:25	...mask and pad the sentence.
2017:03:25 21:43:25	......max len:359, median len:22.0, min len:2
2017:03:25 21:43:25	......filter sentence and bound them in the range of 25.
2017:03:25 21:43:25	build a vocabulary.
2017:03:25 21:43:25	...flatmap a list of sentence list to a list of sentence.
2017:03:25 21:43:25	...mapping from index to word.
2017:03:25 21:43:25	...mapping from word to index.
2017:03:25 21:43:25	...map word to index.
2017:03:25 21:43:25	...save processed data to file.
2017:03:25 21:43:26	get data info.
2017:03:25 21:43:26	init batch data.
2017:03:25 21:43:26	...number of batches: 402
2017:03:25 21:43:26	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 21:43:27	enter standard seq2seq's generator mode.
2017:03:25 21:43:27	enter GAN's generator mode.
2017:03:25 21:43:40	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490478214/checkpoints/bestmodel.

2017:03:25 21:43:40	------ pretraining ------ 

2017:03:25 21:43:40	pretrain epoch 0
2017:03:25 22:01:17	use DataLoaderBBC to init data.
2017:03:25 22:01:17	reading and processing the text file.
2017:03:25 22:01:17	preprocess the dataset.
2017:03:25 22:01:17	load data.
2017:03:25 22:01:17	load context for further preprocessing.
2017:03:25 22:01:17	clean data.
2017:03:25 22:01:18	...mask and pad the sentence.
2017:03:25 22:01:18	......max len:359, median len:22.0, min len:2
2017:03:25 22:01:18	......filter sentence and bound them in the range of 25.
2017:03:25 22:01:18	build a vocabulary.
2017:03:25 22:01:18	...flatmap a list of sentence list to a list of sentence.
2017:03:25 22:01:18	...mapping from index to word.
2017:03:25 22:01:18	...mapping from word to index.
2017:03:25 22:01:18	...map word to index.
2017:03:25 22:01:18	...save processed data to file.
2017:03:25 22:01:19	get data info.
2017:03:25 22:01:19	init batch data.
2017:03:25 22:01:19	...number of batches: 402
2017:03:25 22:01:19	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 22:01:20	enter standard seq2seq's generator mode.
2017:03:25 22:01:20	enter GAN's generator mode.
2017:03:25 22:05:11	use DataLoaderBBC to init data.
2017:03:25 22:05:11	reading and processing the text file.
2017:03:25 22:05:11	preprocess the dataset.
2017:03:25 22:05:11	load data.
2017:03:25 22:05:11	load context for further preprocessing.
2017:03:25 22:05:11	clean data.
2017:03:25 22:05:12	...mask and pad the sentence.
2017:03:25 22:05:12	......max len:359, median len:22.0, min len:2
2017:03:25 22:05:12	......filter sentence and bound them in the range of 25.
2017:03:25 22:05:12	build a vocabulary.
2017:03:25 22:05:12	...flatmap a list of sentence list to a list of sentence.
2017:03:25 22:05:12	...mapping from index to word.
2017:03:25 22:05:13	...mapping from word to index.
2017:03:25 22:05:13	...map word to index.
2017:03:25 22:05:13	...save processed data to file.
2017:03:25 22:05:14	get data info.
2017:03:25 22:05:14	init batch data.
2017:03:25 22:05:14	...number of batches: 402
2017:03:25 22:05:14	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 22:05:14	enter standard seq2seq's generator mode.
2017:03:25 22:05:15	enter GAN's generator mode.
2017:03:25 22:05:30	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490479522/checkpoints/bestmodel.

2017:03:25 22:05:30	------ pretraining ------ 

2017:03:25 22:05:30	pretrain epoch 0
2017:03:25 22:17:35	use DataLoaderBBC to init data.
2017:03:25 22:17:35	reading and processing the text file.
2017:03:25 22:17:35	preprocess the dataset.
2017:03:25 22:17:35	load data.
2017:03:25 22:17:35	load context for further preprocessing.
2017:03:25 22:17:35	clean data.
2017:03:25 22:17:36	...mask and pad the sentence.
2017:03:25 22:17:36	......max len:359, median len:22.0, min len:2
2017:03:25 22:17:36	......filter sentence and bound them in the range of 25.
2017:03:25 22:17:36	build a vocabulary.
2017:03:25 22:17:36	...flatmap a list of sentence list to a list of sentence.
2017:03:25 22:17:36	...mapping from index to word.
2017:03:25 22:17:36	...mapping from word to index.
2017:03:25 22:17:36	...map word to index.
2017:03:25 22:17:36	...save processed data to file.
2017:03:25 22:17:37	get data info.
2017:03:25 22:17:37	init batch data.
2017:03:25 22:17:37	...number of batches: 402
2017:03:25 22:17:37	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 22:17:38	enter standard seq2seq's generator mode.
2017:03:25 22:19:18	use DataLoaderBBC to init data.
2017:03:25 22:19:18	reading and processing the text file.
2017:03:25 22:19:18	preprocess the dataset.
2017:03:25 22:19:18	load data.
2017:03:25 22:19:18	load context for further preprocessing.
2017:03:25 22:19:18	clean data.
2017:03:25 22:19:19	...mask and pad the sentence.
2017:03:25 22:19:19	......max len:359, median len:22.0, min len:2
2017:03:25 22:19:19	......filter sentence and bound them in the range of 25.
2017:03:25 22:19:19	build a vocabulary.
2017:03:25 22:19:19	...flatmap a list of sentence list to a list of sentence.
2017:03:25 22:19:19	...mapping from index to word.
2017:03:25 22:19:19	...mapping from word to index.
2017:03:25 22:19:19	...map word to index.
2017:03:25 22:19:20	...save processed data to file.
2017:03:25 22:19:21	get data info.
2017:03:25 22:19:21	init batch data.
2017:03:25 22:19:21	...number of batches: 402
2017:03:25 22:19:21	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:25 22:19:21	enter standard seq2seq's generator mode.
2017:03:25 22:19:22	enter GAN's generator mode.
2017:03:25 22:19:41	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490480371/checkpoints/bestmodel.

2017:03:25 22:19:41	------ pretraining ------ 

2017:03:25 22:19:41	------ training ------ 

2017:03:25 22:19:41	train epoch 0
2017:03:27 22:22:05	use DataLoaderBBC to init data.
2017:03:27 22:22:05	reading and processing the text file.
2017:03:27 22:22:05	preprocess the dataset.
2017:03:27 22:22:05	load data.
2017:03:27 22:22:05	load context for further preprocessing.
2017:03:27 22:22:05	clean data.
2017:03:27 22:22:05	...mask and pad the sentence.
2017:03:27 22:22:05	......max len:359, median len:22.0, min len:2
2017:03:27 22:22:05	......filter sentence and bound them in the range of 25.
2017:03:27 22:22:05	build a vocabulary.
2017:03:27 22:22:05	...flatmap a list of sentence list to a list of sentence.
2017:03:27 22:22:06	...mapping from index to word.
2017:03:27 22:22:06	...mapping from word to index.
2017:03:27 22:22:06	...map word to index.
2017:03:27 22:22:06	...save processed data to file.
2017:03:27 22:22:07	get data info.
2017:03:27 22:22:07	init batch data.
2017:03:27 22:22:07	...number of batches: 3
2017:03:27 22:22:07	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:27 22:22:07	enter standard seq2seq's generator mode.
2017:03:27 22:22:08	enter GAN's generator mode.
2017:03:27 22:22:23	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653334/checkpoints/bestmodel.

2017:03:27 22:22:23	------ pretraining ------ 

2017:03:27 22:22:23	pretrain epoch 0
2017:03:27 22:22:29	pretrain loss d: 1.04585313797, pretrain loss g: 10.1354808807, execution speed: 2.00 seconds/batch

2017:03:27 22:22:30	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653334/checkpoints/bestmodel.

2017:03:27 22:22:30	pretrain epoch 1
2017:03:27 22:22:35	pretrain loss d: 0.943979799747, pretrain loss g: 10.1251029968, execution speed: 1.33 seconds/batch

2017:03:27 22:22:35	pretrain epoch 2
2017:03:27 22:22:39	pretrain loss d: 0.850120425224, pretrain loss g: 10.1138935089, execution speed: 1.33 seconds/batch

2017:03:27 22:22:39	pretrain epoch 3
2017:03:27 22:22:43	pretrain loss d: 0.762258708477, pretrain loss g: 10.1012935638, execution speed: 1.33 seconds/batch

2017:03:27 22:22:43	pretrain epoch 4
2017:03:27 22:22:47	pretrain loss d: 0.67844325304, pretrain loss g: 10.0866756439, execution speed: 1.00 seconds/batch

2017:03:27 22:22:47	------ training ------ 

2017:03:27 22:22:47	train epoch 5
2017:03:27 22:24:18	use DataLoaderBBC to init data.
2017:03:27 22:24:18	reading and processing the text file.
2017:03:27 22:24:18	preprocess the dataset.
2017:03:27 22:24:18	load data.
2017:03:27 22:24:18	load context for further preprocessing.
2017:03:27 22:24:18	clean data.
2017:03:27 22:24:19	...mask and pad the sentence.
2017:03:27 22:24:19	......max len:359, median len:22.0, min len:2
2017:03:27 22:24:19	......filter sentence and bound them in the range of 25.
2017:03:27 22:24:19	build a vocabulary.
2017:03:27 22:24:19	...flatmap a list of sentence list to a list of sentence.
2017:03:27 22:24:19	...mapping from index to word.
2017:03:27 22:24:19	...mapping from word to index.
2017:03:27 22:24:19	...map word to index.
2017:03:27 22:24:19	...save processed data to file.
2017:03:27 22:24:20	get data info.
2017:03:27 22:24:20	init batch data.
2017:03:27 22:24:20	...number of batches: 3
2017:03:27 22:24:20	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:27 22:24:21	enter standard seq2seq's generator mode.
2017:03:27 22:24:21	enter GAN's generator mode.
2017:03:27 22:24:36	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653468/checkpoints/bestmodel.

2017:03:27 22:24:36	------ pretraining ------ 

2017:03:27 22:24:36	pretrain epoch 0
2017:03:27 22:24:41	pretrain loss d: 2.11440753937, pretrain loss g: 10.1347589493, execution speed: 1.67 seconds/batch

2017:03:27 22:24:42	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653468/checkpoints/bestmodel.

2017:03:27 22:24:42	pretrain epoch 1
2017:03:27 22:24:46	pretrain loss d: 1.94855546951, pretrain loss g: 10.1235466003, execution speed: 1.33 seconds/batch

2017:03:27 22:24:46	pretrain epoch 2
2017:03:27 22:24:50	pretrain loss d: 1.7906576395, pretrain loss g: 10.1117248535, execution speed: 1.00 seconds/batch

2017:03:27 22:24:50	pretrain epoch 3
2017:03:27 22:24:54	pretrain loss d: 1.63879096508, pretrain loss g: 10.098991394, execution speed: 1.00 seconds/batch

2017:03:27 22:24:54	pretrain epoch 4
2017:03:27 22:24:58	pretrain loss d: 1.49019145966, pretrain loss g: 10.0851650238, execution speed: 1.00 seconds/batch

2017:03:27 22:24:58	------ training ------ 

2017:03:27 22:24:58	train epoch 5
2017:03:27 22:25:12	train loss d: 0.965482950211, train loss g: 1.36494779587, execution speed: 4.67 seconds/batch
2017:03:27 22:25:14	val loss d: 0.804699540138, val loss g: 1.56392395496, execution speed: 0.67 seconds/batch

2017:03:27 22:25:15	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653468/checkpoints/bestmodel.

2017:03:27 22:25:15	train epoch 6
2017:03:27 22:25:29	train loss d: 0.627956867218, train loss g: 2.22406816483, execution speed: 4.33 seconds/batch
2017:03:27 22:25:31	val loss d: 0.562562227249, val loss g: 2.27514505386, execution speed: 0.67 seconds/batch

2017:03:27 22:25:31	train epoch 7
2017:03:27 22:25:51	train loss d: 0.453762114048, train loss g: 2.74222278595, execution speed: 6.33 seconds/batch
2017:03:27 22:25:53	val loss d: 0.409299403429, val loss g: 2.67954039574, execution speed: 0.67 seconds/batch

2017:03:27 22:25:53	train epoch 8
2017:03:27 22:26:19	train loss d: 0.328791081905, train loss g: 3.01621627808, execution speed: 8.33 seconds/batch
2017:03:27 22:26:22	val loss d: 0.297562807798, val loss g: 2.88146281242, execution speed: 1.00 seconds/batch

2017:03:27 22:26:22	train epoch 9
2017:03:27 22:26:52	train loss d: 0.239784479141, train loss g: 3.1233458519, execution speed: 9.67 seconds/batch
2017:03:27 22:26:56	val loss d: 0.219559684396, val loss g: 2.96291923523, execution speed: 1.33 seconds/batch

2017:03:27 22:26:56	train epoch 10
2017:03:27 22:27:24	train loss d: 0.17894525826, train loss g: 3.16718363762, execution speed: 9.00 seconds/batch
2017:03:27 22:27:27	val loss d: 0.16762124002, val loss g: 2.99163746834, execution speed: 1.00 seconds/batch

2017:03:27 22:27:28	save 4-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653468/checkpoints/bestmodel.

2017:03:27 22:27:28	train epoch 11
2017:03:27 22:27:49	train loss d: 0.138843104243, train loss g: 3.18378543854, execution speed: 6.67 seconds/batch
2017:03:27 22:27:52	val loss d: 0.133413136005, val loss g: 3.01013588905, execution speed: 0.67 seconds/batch

2017:03:27 22:27:52	train epoch 12
2017:03:27 22:28:10	train loss d: 0.112324431539, train loss g: 3.19805765152, execution speed: 5.67 seconds/batch
2017:03:27 22:28:12	val loss d: 0.110706165433, val loss g: 3.02528905869, execution speed: 0.67 seconds/batch

2017:03:27 22:28:12	train epoch 13
2017:03:27 22:28:28	train loss d: 0.0943778902292, train loss g: 3.2140045166, execution speed: 5.00 seconds/batch
2017:03:27 22:28:31	val loss d: 0.0951481983066, val loss g: 3.04245281219, execution speed: 0.67 seconds/batch

2017:03:27 22:28:31	train epoch 14
2017:03:27 22:28:45	train loss d: 0.0816649347544, train loss g: 3.23677539825, execution speed: 4.33 seconds/batch
2017:03:27 22:30:39	use DataLoaderBBC to init data.
2017:03:27 22:30:39	reading and processing the text file.
2017:03:27 22:30:39	preprocess the dataset.
2017:03:27 22:30:39	load data.
2017:03:27 22:30:39	load context for further preprocessing.
2017:03:27 22:30:39	clean data.
2017:03:27 22:30:39	...mask and pad the sentence.
2017:03:27 22:30:39	......max len:359, median len:22.0, min len:2
2017:03:27 22:30:40	......filter sentence and bound them in the range of 25.
2017:03:27 22:30:40	build a vocabulary.
2017:03:27 22:30:40	...flatmap a list of sentence list to a list of sentence.
2017:03:27 22:30:40	...mapping from index to word.
2017:03:27 22:30:40	...mapping from word to index.
2017:03:27 22:30:40	...map word to index.
2017:03:27 22:30:40	...save processed data to file.
2017:03:27 22:30:41	get data info.
2017:03:27 22:30:41	init batch data.
2017:03:27 22:30:41	...number of batches: 3
2017:03:27 22:30:41	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:27 22:30:41	enter standard seq2seq's generator mode.
2017:03:27 22:30:42	enter GAN's generator mode.
2017:03:27 22:30:56	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653848/checkpoints/bestmodel.

2017:03:27 22:30:56	------ pretraining ------ 

2017:03:27 22:30:56	pretrain epoch 0
2017:03:27 22:31:02	pretrain loss d: 3.1021065712, pretrain loss g: 10.1357898712, execution speed: 1.67 seconds/batch

2017:03:27 22:31:03	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653848/checkpoints/bestmodel.

2017:03:27 22:31:03	pretrain epoch 1
2017:03:27 22:31:07	pretrain loss d: 2.89613962173, pretrain loss g: 10.1263942719, execution speed: 1.33 seconds/batch

2017:03:27 22:31:07	pretrain epoch 2
2017:03:27 22:31:12	pretrain loss d: 2.69595003128, pretrain loss g: 10.1163692474, execution speed: 1.33 seconds/batch

2017:03:27 22:31:12	pretrain epoch 3
2017:03:27 22:31:16	pretrain loss d: 2.50073385239, pretrain loss g: 10.1054058075, execution speed: 1.00 seconds/batch

2017:03:27 22:31:16	pretrain epoch 4
2017:03:27 22:31:19	pretrain loss d: 2.30703020096, pretrain loss g: 10.0932798386, execution speed: 1.00 seconds/batch

2017:03:27 22:31:19	------ training ------ 

2017:03:27 22:31:19	train epoch 5
2017:03:27 22:31:34	train loss d: 1.1642203331, train loss g: 2.01959228516, execution speed: 4.67 seconds/batch
2017:03:27 22:31:36	val loss d: 0.991374135017, val loss g: 2.53191518784, execution speed: 0.67 seconds/batch

2017:03:27 22:31:37	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490653848/checkpoints/bestmodel.

2017:03:27 22:31:37	train epoch 6
2017:03:27 22:31:52	train loss d: 0.837999939919, train loss g: 3.22072839737, execution speed: 4.67 seconds/batch
2017:03:27 22:31:54	val loss d: 0.758075892925, val loss g: 3.40460419655, execution speed: 0.67 seconds/batch

2017:03:27 22:31:54	train epoch 7
2017:03:28 19:29:08	use DataLoaderBBC to init data.
2017:03:28 19:29:08	reading and processing the text file.
2017:03:28 19:29:08	preprocess the dataset.
2017:03:28 19:29:08	load data.
2017:03:28 19:29:08	load context for further preprocessing.
2017:03:28 19:29:08	clean data.
2017:03:28 19:29:09	...mask and pad the sentence.
2017:03:28 19:29:09	......max len:359, median len:22.0, min len:2
2017:03:28 19:29:09	......filter sentence and bound them in the range of 25.
2017:03:28 19:29:09	build a vocabulary.
2017:03:28 19:29:09	...flatmap a list of sentence list to a list of sentence.
2017:03:28 19:29:09	...mapping from index to word.
2017:03:28 19:29:09	...mapping from word to index.
2017:03:28 19:29:09	...map word to index.
2017:03:28 19:29:10	...save processed data to file.
2017:03:28 19:29:11	get data info.
2017:03:28 19:29:11	init batch data.
2017:03:28 19:29:11	...number of batches: 402
2017:03:28 19:29:11	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:28 19:29:12	enter standard seq2seq's generator mode.
2017:03:28 19:29:13	enter GAN's generator mode.
2017:03:28 19:29:30	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490729361/checkpoints/bestmodel.

2017:03:28 19:29:30	------ pretraining ------ 

2017:03:28 19:29:30	pretrain epoch 0
2017:03:28 19:36:30	use DataLoaderBBC to init data.
2017:03:28 19:36:30	reading and processing the text file.
2017:03:28 19:36:30	preprocess the dataset.
2017:03:28 19:36:30	load data.
2017:03:28 19:36:30	load context for further preprocessing.
2017:03:28 19:36:30	clean data.
2017:03:28 19:36:30	...mask and pad the sentence.
2017:03:28 19:36:30	......max len:359, median len:22.0, min len:2
2017:03:28 19:36:30	......filter sentence and bound them in the range of 25.
2017:03:28 19:36:30	build a vocabulary.
2017:03:28 19:36:30	...flatmap a list of sentence list to a list of sentence.
2017:03:28 19:36:31	...mapping from index to word.
2017:03:28 19:36:31	...mapping from word to index.
2017:03:28 19:36:31	...map word to index.
2017:03:28 19:36:31	...save processed data to file.
2017:03:28 19:36:32	get data info.
2017:03:28 19:36:32	init batch data.
2017:03:28 19:36:32	...number of batches: 402
2017:03:28 19:36:32	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:28 19:36:33	enter standard seq2seq's generator mode.
2017:03:28 19:36:33	enter GAN's generator mode.
2017:03:28 19:36:51	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490729801/checkpoints/bestmodel.

2017:03:28 19:36:51	------ pretraining ------ 

2017:03:28 19:36:51	pretrain epoch 0
2017:03:28 19:37:05	use DataLoaderBBC to init data.
2017:03:28 19:37:05	reading and processing the text file.
2017:03:28 19:37:05	preprocess the dataset.
2017:03:28 19:37:05	load data.
2017:03:28 19:37:05	load context for further preprocessing.
2017:03:28 19:37:05	clean data.
2017:03:28 19:37:06	...mask and pad the sentence.
2017:03:28 19:37:06	......max len:359, median len:22.0, min len:2
2017:03:28 19:37:06	......filter sentence and bound them in the range of 25.
2017:03:28 19:37:06	build a vocabulary.
2017:03:28 19:37:06	...flatmap a list of sentence list to a list of sentence.
2017:03:28 19:37:06	...mapping from index to word.
2017:03:28 19:37:06	...mapping from word to index.
2017:03:28 19:37:06	...map word to index.
2017:03:28 19:37:07	...save processed data to file.
2017:03:28 19:37:08	get data info.
2017:03:28 19:37:08	init batch data.
2017:03:28 19:37:08	...number of batches: 3
2017:03:28 19:37:08	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:28 19:37:09	enter standard seq2seq's generator mode.
2017:03:28 19:37:10	enter GAN's generator mode.
2017:03:28 19:37:30	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490729840/checkpoints/bestmodel.

2017:03:28 19:37:30	------ pretraining ------ 

2017:03:28 19:37:30	pretrain epoch 0
2017:03:28 19:37:38	pretrain loss d: 3.28774952888, pretrain loss g: 10.1339015961, execution speed: 2.33 seconds/batch

2017:03:28 19:37:39	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490729840/checkpoints/bestmodel.

2017:03:28 19:37:39	pretrain epoch 1
2017:03:28 19:37:46	pretrain loss d: 3.08022904396, pretrain loss g: 10.1228904724, execution speed: 2.00 seconds/batch

2017:03:28 19:37:46	pretrain epoch 2
2017:03:30 16:36:25	use DataLoaderBBC to init data.
2017:03:30 16:36:25	reading and processing the text file.
2017:03:30 16:36:25	preprocess the dataset.
2017:03:30 16:36:25	load data.
2017:03:30 16:36:25	load context for further preprocessing.
2017:03:30 16:36:25	clean data.
2017:03:30 16:36:26	...mask and pad the sentence.
2017:03:30 16:36:26	......max len:359, median len:22.0, min len:2
2017:03:30 16:36:26	......filter sentence and bound them in the range of 25.
2017:03:30 16:36:26	build a vocabulary.
2017:03:30 16:36:26	...flatmap a list of sentence list to a list of sentence.
2017:03:30 16:36:26	...mapping from index to word.
2017:03:30 16:36:27	...mapping from word to index.
2017:03:30 16:36:27	...map word to index.
2017:03:30 16:36:27	...save processed data to file.
2017:03:30 16:36:28	get data info.
2017:03:30 16:36:28	init batch data.
2017:03:30 16:36:28	...number of batches: 402
2017:03:30 16:36:28	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:03:30 16:36:28	enter standard seq2seq's generator mode.
2017:03:30 16:36:29	enter GAN's generator mode.
2017:03:30 16:36:50	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490891800/checkpoints/bestmodel.

2017:03:30 16:36:50	------ pretraining ------ 

2017:03:30 16:36:50	pretrain epoch 0
2017:03:30 16:38:43	use DataLoaderBBC to init data.
2017:03:30 16:38:43	reading and processing the text file.
2017:03:30 16:38:43	preprocess the dataset.
2017:03:30 16:38:43	load data.
2017:03:30 16:38:43	load context for further preprocessing.
2017:03:30 16:38:43	clean data.
2017:03:30 16:38:53	use DataLoaderBBC to init data.
2017:03:30 16:38:53	reading and processing the text file.
2017:03:30 16:38:53	preprocess the dataset.
2017:03:30 16:38:53	load data.
2017:03:30 16:38:53	load context for further preprocessing.
2017:03:30 16:38:53	clean data.
2017:03:30 16:38:54	...mask and pad the sentence.
2017:03:30 16:38:54	......max len:359, median len:22.0, min len:2
2017:03:30 16:38:54	......filter sentence and bound them in the range of 25.
2017:03:30 16:38:54	build a vocabulary.
2017:03:30 16:38:54	...flatmap a list of sentence list to a list of sentence.
2017:03:30 16:38:54	...mapping from index to word.
2017:03:30 16:38:54	...mapping from word to index.
2017:03:30 16:38:54	...map word to index.
2017:03:30 16:38:54	...save processed data to file.
2017:03:30 16:38:56	get data info.
2017:03:30 16:38:56	init batch data.
2017:03:30 16:38:56	...number of batches: 3
2017:03:30 16:38:56	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 16:38:56	enter standard seq2seq's generator mode.
2017:03:30 16:38:57	enter GAN's generator mode.
2017:03:30 16:39:14	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490891945/checkpoints/bestmodel.

2017:03:30 16:39:14	------ pretraining ------ 

2017:03:30 16:39:14	pretrain epoch 0
2017:03:30 16:39:35	use DataLoaderBBC to init data.
2017:03:30 16:39:35	reading and processing the text file.
2017:03:30 16:39:35	preprocess the dataset.
2017:03:30 16:39:35	load data.
2017:03:30 16:39:35	load context for further preprocessing.
2017:03:30 16:39:35	clean data.
2017:03:30 16:39:36	...mask and pad the sentence.
2017:03:30 16:39:36	......max len:359, median len:22.0, min len:2
2017:03:30 16:39:36	......filter sentence and bound them in the range of 25.
2017:03:30 16:39:36	build a vocabulary.
2017:03:30 16:39:36	...flatmap a list of sentence list to a list of sentence.
2017:03:30 16:39:36	...mapping from index to word.
2017:03:30 16:39:36	...mapping from word to index.
2017:03:30 16:39:36	...map word to index.
2017:03:30 16:39:36	...save processed data to file.
2017:03:30 16:39:37	get data info.
2017:03:30 16:39:37	init batch data.
2017:03:30 16:39:37	...number of batches: 3
2017:03:30 16:39:37	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 16:39:38	enter standard seq2seq's generator mode.
2017:03:30 16:39:39	enter GAN's generator mode.
2017:03:30 16:39:58	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490891988/checkpoints/bestmodel.

2017:03:30 16:39:58	------ pretraining ------ 

2017:03:30 16:39:58	pretrain epoch 0
2017:03:30 20:14:49	use DataLoaderBBC to init data.
2017:03:30 20:14:49	reading and processing the text file.
2017:03:30 20:14:49	preprocess the dataset.
2017:03:30 20:14:49	load data.
2017:03:30 20:14:49	load context for further preprocessing.
2017:03:30 20:14:49	clean data.
2017:03:30 20:14:50	...mask and pad the sentence.
2017:03:30 20:14:50	......max len:359, median len:22.0, min len:2
2017:03:30 20:14:50	......filter sentence and bound them in the range of 25.
2017:03:30 20:14:50	build a vocabulary.
2017:03:30 20:14:50	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:14:50	...mapping from index to word.
2017:03:30 20:14:50	...mapping from word to index.
2017:03:30 20:14:50	...map word to index.
2017:03:30 20:14:50	...save processed data to file.
2017:03:30 20:14:51	get data info.
2017:03:30 20:14:51	init batch data.
2017:03:30 20:14:51	...number of batches: 3
2017:03:30 20:14:51	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:14:52	enter standard seq2seq's generator mode.
2017:03:30 20:14:53	enter GAN's generator mode.
2017:03:30 20:15:07	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490904899/checkpoints/bestmodel.

2017:03:30 20:15:07	------ pretraining ------ 

2017:03:30 20:15:07	pretrain epoch 0
2017:03:30 20:15:44	use DataLoaderBBC to init data.
2017:03:30 20:15:44	reading and processing the text file.
2017:03:30 20:15:44	preprocess the dataset.
2017:03:30 20:15:44	load data.
2017:03:30 20:15:44	load context for further preprocessing.
2017:03:30 20:15:44	clean data.
2017:03:30 20:15:44	...mask and pad the sentence.
2017:03:30 20:15:44	......max len:359, median len:22.0, min len:2
2017:03:30 20:15:44	......filter sentence and bound them in the range of 25.
2017:03:30 20:15:44	build a vocabulary.
2017:03:30 20:15:44	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:15:44	...mapping from index to word.
2017:03:30 20:15:45	...mapping from word to index.
2017:03:30 20:15:45	...map word to index.
2017:03:30 20:15:45	...save processed data to file.
2017:03:30 20:15:46	get data info.
2017:03:30 20:15:46	init batch data.
2017:03:30 20:15:46	...number of batches: 3
2017:03:30 20:15:46	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:15:46	enter standard seq2seq's generator mode.
2017:03:30 20:15:47	enter GAN's generator mode.
2017:03:30 20:16:03	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490904955/checkpoints/bestmodel.

2017:03:30 20:16:03	------ pretraining ------ 

2017:03:30 20:16:03	pretrain epoch 0
2017:03:30 20:20:32	use DataLoaderBBC to init data.
2017:03:30 20:20:32	reading and processing the text file.
2017:03:30 20:20:32	preprocess the dataset.
2017:03:30 20:20:32	load data.
2017:03:30 20:20:32	load context for further preprocessing.
2017:03:30 20:20:32	clean data.
2017:03:30 20:20:33	...mask and pad the sentence.
2017:03:30 20:20:33	......max len:359, median len:22.0, min len:2
2017:03:30 20:20:33	......filter sentence and bound them in the range of 25.
2017:03:30 20:20:33	build a vocabulary.
2017:03:30 20:20:33	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:20:33	...mapping from index to word.
2017:03:30 20:20:33	...mapping from word to index.
2017:03:30 20:20:33	...map word to index.
2017:03:30 20:20:34	...save processed data to file.
2017:03:30 20:20:34	get data info.
2017:03:30 20:20:34	init batch data.
2017:03:30 20:20:34	...number of batches: 3
2017:03:30 20:20:34	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:20:35	enter standard seq2seq's generator mode.
2017:03:30 20:20:36	enter GAN's generator mode.
2017:03:30 20:20:54	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490905244/checkpoints/bestmodel.

2017:03:30 20:20:54	------ pretraining ------ 

2017:03:30 20:20:54	pretrain epoch 0
2017:03:30 20:22:04	use DataLoaderBBC to init data.
2017:03:30 20:22:04	reading and processing the text file.
2017:03:30 20:22:04	preprocess the dataset.
2017:03:30 20:22:04	load data.
2017:03:30 20:22:04	load context for further preprocessing.
2017:03:30 20:22:04	clean data.
2017:03:30 20:22:05	...mask and pad the sentence.
2017:03:30 20:22:05	......max len:359, median len:22.0, min len:2
2017:03:30 20:22:05	......filter sentence and bound them in the range of 25.
2017:03:30 20:22:05	build a vocabulary.
2017:03:30 20:22:05	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:22:05	...mapping from index to word.
2017:03:30 20:22:05	...mapping from word to index.
2017:03:30 20:22:05	...map word to index.
2017:03:30 20:22:05	...save processed data to file.
2017:03:30 20:22:06	get data info.
2017:03:30 20:22:06	init batch data.
2017:03:30 20:22:06	...number of batches: 3
2017:03:30 20:22:06	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:22:07	enter standard seq2seq's generator mode.
2017:03:30 20:22:08	enter GAN's generator mode.
2017:03:30 20:22:25	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490905335/checkpoints/bestmodel.

2017:03:30 20:22:25	------ pretraining ------ 

2017:03:30 20:22:25	pretrain epoch 0
2017:03:30 20:24:07	use DataLoaderBBC to init data.
2017:03:30 20:24:07	reading and processing the text file.
2017:03:30 20:24:07	preprocess the dataset.
2017:03:30 20:24:07	load data.
2017:03:30 20:24:07	load context for further preprocessing.
2017:03:30 20:24:07	clean data.
2017:03:30 20:24:08	...mask and pad the sentence.
2017:03:30 20:24:08	......max len:359, median len:22.0, min len:2
2017:03:30 20:24:08	......filter sentence and bound them in the range of 25.
2017:03:30 20:24:08	build a vocabulary.
2017:03:30 20:24:08	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:24:08	...mapping from index to word.
2017:03:30 20:24:08	...mapping from word to index.
2017:03:30 20:24:08	...map word to index.
2017:03:30 20:24:08	...save processed data to file.
2017:03:30 20:24:09	get data info.
2017:03:30 20:24:09	init batch data.
2017:03:30 20:24:09	...number of batches: 3
2017:03:30 20:24:09	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:24:10	enter standard seq2seq's generator mode.
2017:03:30 20:24:10	enter GAN's generator mode.
2017:03:30 20:24:26	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490905457/checkpoints/bestmodel.

2017:03:30 20:24:26	------ pretraining ------ 

2017:03:30 20:24:26	pretrain epoch 0
2017:03:30 20:26:57	use DataLoaderBBC to init data.
2017:03:30 20:26:57	reading and processing the text file.
2017:03:30 20:26:57	preprocess the dataset.
2017:03:30 20:26:57	load data.
2017:03:30 20:26:57	load context for further preprocessing.
2017:03:30 20:26:57	clean data.
2017:03:30 20:26:58	...mask and pad the sentence.
2017:03:30 20:26:58	......max len:359, median len:22.0, min len:2
2017:03:30 20:26:58	......filter sentence and bound them in the range of 25.
2017:03:30 20:26:58	build a vocabulary.
2017:03:30 20:26:58	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:26:59	...mapping from index to word.
2017:03:30 20:26:59	...mapping from word to index.
2017:03:30 20:26:59	...map word to index.
2017:03:30 20:26:59	...save processed data to file.
2017:03:30 20:27:00	get data info.
2017:03:30 20:27:00	init batch data.
2017:03:30 20:27:00	...number of batches: 3
2017:03:30 20:27:00	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:27:01	enter standard seq2seq's generator mode.
2017:03:30 20:27:02	enter GAN's generator mode.
2017:03:30 20:27:18	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490905630/checkpoints/bestmodel.

2017:03:30 20:27:18	------ pretraining ------ 

2017:03:30 20:27:18	pretrain epoch 0
2017:03:30 20:35:23	use DataLoaderBBC to init data.
2017:03:30 20:35:23	reading and processing the text file.
2017:03:30 20:35:23	preprocess the dataset.
2017:03:30 20:35:23	load data.
2017:03:30 20:35:23	load context for further preprocessing.
2017:03:30 20:35:23	clean data.
2017:03:30 20:35:24	...mask and pad the sentence.
2017:03:30 20:35:24	......max len:359, median len:22.0, min len:2
2017:03:30 20:35:24	......filter sentence and bound them in the range of 25.
2017:03:30 20:35:24	build a vocabulary.
2017:03:30 20:35:24	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:35:24	...mapping from index to word.
2017:03:30 20:35:25	...mapping from word to index.
2017:03:30 20:35:25	...map word to index.
2017:03:30 20:35:25	...save processed data to file.
2017:03:30 20:35:26	get data info.
2017:03:30 20:35:26	init batch data.
2017:03:30 20:35:26	...number of batches: 3
2017:03:30 20:35:26	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:35:27	enter standard seq2seq's generator mode.
2017:03:30 20:35:27	enter GAN's generator mode.
2017:03:30 20:45:07	use DataLoaderBBC to init data.
2017:03:30 20:45:07	reading and processing the text file.
2017:03:30 20:45:07	preprocess the dataset.
2017:03:30 20:45:07	load data.
2017:03:30 20:45:07	load context for further preprocessing.
2017:03:30 20:45:07	clean data.
2017:03:30 20:45:08	...mask and pad the sentence.
2017:03:30 20:45:08	......max len:359, median len:22.0, min len:2
2017:03:30 20:45:08	......filter sentence and bound them in the range of 25.
2017:03:30 20:45:08	build a vocabulary.
2017:03:30 20:45:08	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:45:08	...mapping from index to word.
2017:03:30 20:45:08	...mapping from word to index.
2017:03:30 20:45:08	...map word to index.
2017:03:30 20:45:08	...save processed data to file.
2017:03:30 20:45:10	get data info.
2017:03:30 20:45:10	init batch data.
2017:03:30 20:45:10	...number of batches: 3
2017:03:30 20:45:10	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:45:10	enter standard seq2seq's generator mode.
2017:03:30 20:45:11	enter GAN's generator mode.
2017:03:30 20:45:30	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490906720/checkpoints/bestmodel.

2017:03:30 20:45:30	------ pretraining ------ 

2017:03:30 20:45:30	pretrain epoch 0
2017:03:30 20:45:38	pretrain loss d: 0.792539060116, pretrain loss g: 10.1373920441, execution speed: 2.33 seconds/batch

2017:03:30 20:45:39	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490906720/checkpoints/bestmodel.

2017:03:30 20:45:39	pretrain epoch 1
2017:03:30 20:45:45	pretrain loss d: 0.711838722229, pretrain loss g: 10.1279668808, execution speed: 1.67 seconds/batch

2017:03:30 20:45:45	pretrain epoch 2
2017:03:30 20:45:50	pretrain loss d: 0.638304293156, pretrain loss g: 10.1175098419, execution speed: 1.67 seconds/batch

2017:03:30 20:45:50	pretrain epoch 3
2017:03:30 20:45:56	pretrain loss d: 0.570885062218, pretrain loss g: 10.1053667068, execution speed: 1.67 seconds/batch

2017:03:30 20:45:56	pretrain epoch 4
2017:03:30 20:46:02	pretrain loss d: 0.507546782494, pretrain loss g: 10.0906238556, execution speed: 1.67 seconds/batch

2017:03:30 20:46:02	------ training ------ 

2017:03:30 20:46:02	train epoch 5
2017:03:30 20:51:11	use DataLoaderBBC to init data.
2017:03:30 20:51:11	reading and processing the text file.
2017:03:30 20:51:11	preprocess the dataset.
2017:03:30 20:51:11	load data.
2017:03:30 20:51:11	load context for further preprocessing.
2017:03:30 20:51:11	clean data.
2017:03:30 20:51:11	...mask and pad the sentence.
2017:03:30 20:51:11	......max len:359, median len:22.0, min len:2
2017:03:30 20:51:12	......filter sentence and bound them in the range of 25.
2017:03:30 20:51:12	build a vocabulary.
2017:03:30 20:51:12	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:51:12	...mapping from index to word.
2017:03:30 20:51:12	...mapping from word to index.
2017:03:30 20:51:12	...map word to index.
2017:03:30 20:51:12	...save processed data to file.
2017:03:30 20:51:13	get data info.
2017:03:30 20:51:13	init batch data.
2017:03:30 20:51:13	...number of batches: 3
2017:03:30 20:51:13	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:51:13	enter standard seq2seq's generator mode.
2017:03:30 20:51:15	enter GAN's generator mode.
2017:03:30 20:51:34	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907085/checkpoints/bestmodel.

2017:03:30 20:51:34	------ pretraining ------ 

2017:03:30 20:51:34	pretrain epoch 0
2017:03:30 20:51:41	pretrain loss d: 2.93061947823, pretrain loss g: 10.1358947754, execution speed: 2.00 seconds/batch

2017:03:30 20:51:42	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907085/checkpoints/bestmodel.

2017:03:30 20:51:42	pretrain epoch 1
2017:03:30 20:51:48	pretrain loss d: 2.73594999313, pretrain loss g: 10.120677948, execution speed: 2.00 seconds/batch

2017:03:30 20:51:48	pretrain epoch 2
2017:03:30 20:51:54	pretrain loss d: 2.55024719238, pretrain loss g: 10.1002378464, execution speed: 1.67 seconds/batch

2017:03:30 20:51:54	pretrain epoch 3
2017:03:30 20:51:58	pretrain loss d: 2.36709165573, pretrain loss g: 10.0710868835, execution speed: 1.33 seconds/batch

2017:03:30 20:51:58	pretrain epoch 4
2017:03:30 20:52:03	pretrain loss d: 2.17987680435, pretrain loss g: 10.0290288925, execution speed: 1.33 seconds/batch

2017:03:30 20:52:03	------ training ------ 

2017:03:30 20:52:03	train epoch 5
2017:03:30 20:52:51	use DataLoaderBBC to init data.
2017:03:30 20:52:51	reading and processing the text file.
2017:03:30 20:52:51	preprocess the dataset.
2017:03:30 20:52:51	load data.
2017:03:30 20:52:51	load context for further preprocessing.
2017:03:30 20:52:51	clean data.
2017:03:30 20:52:52	...mask and pad the sentence.
2017:03:30 20:52:52	......max len:359, median len:22.0, min len:2
2017:03:30 20:52:52	......filter sentence and bound them in the range of 25.
2017:03:30 20:52:52	build a vocabulary.
2017:03:30 20:52:52	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:52:52	...mapping from index to word.
2017:03:30 20:52:52	...mapping from word to index.
2017:03:30 20:52:52	...map word to index.
2017:03:30 20:52:52	...save processed data to file.
2017:03:30 20:52:53	get data info.
2017:03:30 20:52:53	init batch data.
2017:03:30 20:52:53	...number of batches: 3
2017:03:30 20:52:53	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:52:54	enter standard seq2seq's generator mode.
2017:03:30 20:52:54	enter GAN's generator mode.
2017:03:30 20:53:11	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907182/checkpoints/bestmodel.

2017:03:30 20:53:11	------ pretraining ------ 

2017:03:30 20:53:11	pretrain epoch 0
2017:03:30 20:53:17	pretrain loss d: 0.569540023804, pretrain loss g: 10.1355037689, execution speed: 1.67 seconds/batch

2017:03:30 20:53:18	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907182/checkpoints/bestmodel.

2017:03:30 20:53:18	pretrain epoch 1
2017:03:30 20:53:23	pretrain loss d: 0.507877647877, pretrain loss g: 10.1248912811, execution speed: 1.67 seconds/batch

2017:03:30 20:53:23	pretrain epoch 2
2017:03:30 20:53:28	pretrain loss d: 0.451326429844, pretrain loss g: 10.1130876541, execution speed: 1.33 seconds/batch

2017:03:30 20:53:28	pretrain epoch 3
2017:03:30 20:53:34	pretrain loss d: 0.39859110117, pretrain loss g: 10.0991630554, execution speed: 1.67 seconds/batch

2017:03:30 20:53:34	pretrain epoch 4
2017:03:30 20:53:40	pretrain loss d: 0.348591119051, pretrain loss g: 10.0817594528, execution speed: 2.00 seconds/batch

2017:03:30 20:53:40	------ training ------ 

2017:03:30 20:53:40	train epoch 5
2017:03:30 20:57:55	use DataLoaderBBC to init data.
2017:03:30 20:57:55	reading and processing the text file.
2017:03:30 20:57:55	preprocess the dataset.
2017:03:30 20:57:55	load data.
2017:03:30 20:57:55	load context for further preprocessing.
2017:03:30 20:57:56	clean data.
2017:03:30 20:57:56	...mask and pad the sentence.
2017:03:30 20:57:56	......max len:359, median len:22.0, min len:2
2017:03:30 20:57:56	......filter sentence and bound them in the range of 25.
2017:03:30 20:57:56	build a vocabulary.
2017:03:30 20:57:56	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:57:56	...mapping from index to word.
2017:03:30 20:57:56	...mapping from word to index.
2017:03:30 20:57:57	...map word to index.
2017:03:30 20:57:57	...save processed data to file.
2017:03:30 20:57:58	get data info.
2017:03:30 20:57:58	init batch data.
2017:03:30 20:57:58	...number of batches: 3
2017:03:30 20:57:58	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:57:58	enter standard seq2seq's generator mode.
2017:03:30 20:57:59	enter GAN's generator mode.
2017:03:30 20:58:14	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907485/checkpoints/bestmodel.

2017:03:30 20:58:14	------ pretraining ------ 

2017:03:30 20:58:14	pretrain epoch 0
2017:03:30 20:58:21	pretrain loss d: 1.04224300385, pretrain loss g: 10.1359138489, execution speed: 2.33 seconds/batch

2017:03:30 20:58:23	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907485/checkpoints/bestmodel.

2017:03:30 20:58:23	pretrain epoch 1
2017:03:30 20:58:28	pretrain loss d: 0.939968466759, pretrain loss g: 10.1257781982, execution speed: 1.33 seconds/batch

2017:03:30 20:58:28	pretrain epoch 2
2017:03:30 20:58:33	pretrain loss d: 0.846003651619, pretrain loss g: 10.114771843, execution speed: 1.67 seconds/batch

2017:03:30 20:58:33	pretrain epoch 3
2017:03:30 20:58:39	pretrain loss d: 0.758222579956, pretrain loss g: 10.1023845673, execution speed: 1.67 seconds/batch

2017:03:30 20:58:39	pretrain epoch 4
2017:03:30 20:58:44	pretrain loss d: 0.674439370632, pretrain loss g: 10.0880146027, execution speed: 1.33 seconds/batch

2017:03:30 20:58:44	------ training ------ 

2017:03:30 20:58:44	train epoch 5
2017:03:30 20:59:32	use DataLoaderBBC to init data.
2017:03:30 20:59:32	reading and processing the text file.
2017:03:30 20:59:32	preprocess the dataset.
2017:03:30 20:59:32	load data.
2017:03:30 20:59:32	load context for further preprocessing.
2017:03:30 20:59:32	clean data.
2017:03:30 20:59:32	...mask and pad the sentence.
2017:03:30 20:59:32	......max len:359, median len:22.0, min len:2
2017:03:30 20:59:33	......filter sentence and bound them in the range of 25.
2017:03:30 20:59:33	build a vocabulary.
2017:03:30 20:59:33	...flatmap a list of sentence list to a list of sentence.
2017:03:30 20:59:33	...mapping from index to word.
2017:03:30 20:59:33	...mapping from word to index.
2017:03:30 20:59:33	...map word to index.
2017:03:30 20:59:33	...save processed data to file.
2017:03:30 20:59:34	get data info.
2017:03:30 20:59:34	init batch data.
2017:03:30 20:59:34	...number of batches: 3
2017:03:30 20:59:34	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 20:59:35	enter standard seq2seq's generator mode.
2017:03:30 20:59:36	enter GAN's generator mode.
2017:03:30 20:59:51	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490907583/checkpoints/bestmodel.

2017:03:30 20:59:51	------ pretraining ------ 

2017:03:30 20:59:51	pretrain epoch 0
2017:03:30 20:59:57	pretrain loss d: 2.12652826309, pretrain loss g: 10.1360826492, execution speed: 1.67 seconds/batch

2017:03:30 20:59:59	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490907583/checkpoints/bestmodel.

2017:03:30 20:59:59	pretrain epoch 1
2017:03:30 21:00:05	pretrain loss d: 1.96116268635, pretrain loss g: 10.1200962067, execution speed: 2.00 seconds/batch

2017:03:30 21:00:05	pretrain epoch 2
2017:03:30 21:00:11	pretrain loss d: 1.8029384613, pretrain loss g: 10.0974617004, execution speed: 1.67 seconds/batch

2017:03:30 21:00:11	pretrain epoch 3
2017:03:30 21:00:15	pretrain loss d: 1.64693284035, pretrain loss g: 10.0636768341, execution speed: 1.33 seconds/batch

2017:03:30 21:00:15	pretrain epoch 4
2017:03:30 21:00:21	pretrain loss d: 1.48895359039, pretrain loss g: 10.0129032135, execution speed: 2.00 seconds/batch

2017:03:30 21:00:21	------ training ------ 

2017:03:30 21:00:21	train epoch 5
2017:03:30 21:00:39	train loss d: 0.84675770998, train loss g: 1.73711037636, execution speed: 5.67 seconds/batch
2017:03:30 21:00:42	val loss d: 0.704988121986, val loss g: 2.12127232552, execution speed: 0.67 seconds/batch

2017:03:30 21:00:43	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGAN.TextGAN/1490907583/checkpoints/bestmodel.

2017:03:30 21:00:43	train epoch 6
2017:03:30 21:01:08	use DataLoaderBBC to init data.
2017:03:30 21:01:08	reading and processing the text file.
2017:03:30 21:01:08	preprocess the dataset.
2017:03:30 21:01:08	load data.
2017:03:30 21:01:08	load context for further preprocessing.
2017:03:30 21:01:08	clean data.
2017:03:30 21:01:08	...mask and pad the sentence.
2017:03:30 21:01:08	......max len:359, median len:22.0, min len:2
2017:03:30 21:01:09	......filter sentence and bound them in the range of 25.
2017:03:30 21:01:09	build a vocabulary.
2017:03:30 21:01:09	...flatmap a list of sentence list to a list of sentence.
2017:03:30 21:01:09	...mapping from index to word.
2017:03:30 21:01:09	...mapping from word to index.
2017:03:30 21:01:09	...map word to index.
2017:03:30 21:01:09	...save processed data to file.
2017:03:30 21:01:10	get data info.
2017:03:30 21:01:10	init batch data.
2017:03:30 21:01:10	...number of batches: 3
2017:03:30 21:01:10	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 21:01:11	enter standard seq2seq's generator mode.
2017:03:30 21:01:12	enter GAN's generator mode.
2017:03:30 21:01:28	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907680/checkpoints/bestmodel.

2017:03:30 21:01:28	------ pretraining ------ 

2017:03:30 21:01:29	pretrain epoch 0
2017:03:30 21:01:34	pretrain loss d: 1.52500414848, pretrain loss g: 10.1337280273, execution speed: 1.67 seconds/batch

2017:03:30 21:01:36	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907680/checkpoints/bestmodel.

2017:03:30 21:01:36	pretrain epoch 1
2017:03:30 21:01:41	pretrain loss d: 1.39398741722, pretrain loss g: 10.1022195816, execution speed: 1.67 seconds/batch

2017:03:30 21:01:41	pretrain epoch 2
2017:03:30 21:01:46	pretrain loss d: 1.26852083206, pretrain loss g: 10.0481147766, execution speed: 1.33 seconds/batch

2017:03:30 21:01:46	pretrain epoch 3
2017:03:30 21:01:52	pretrain loss d: 1.14547753334, pretrain loss g: 9.97492980957, execution speed: 1.67 seconds/batch

2017:03:30 21:01:52	pretrain epoch 4
2017:03:30 21:01:59	pretrain loss d: 1.02298808098, pretrain loss g: 9.88496685028, execution speed: 2.00 seconds/batch

2017:03:30 21:01:59	------ training ------ 

2017:03:30 21:01:59	train epoch 5
2017:03:30 21:02:28	train loss d: -0.0140457078815, train loss g: 0.0167584381998, execution speed: 9.67 seconds/batch
2017:03:30 21:02:32	val loss d: -0.0220043305308, val loss g: 0.0238633807749, execution speed: 1.33 seconds/batch

2017:03:30 21:02:34	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490907680/checkpoints/bestmodel.

2017:03:30 21:02:34	train epoch 6
2017:03:30 21:14:03	use DataLoaderBBC to init data.
2017:03:30 21:14:03	reading and processing the text file.
2017:03:30 21:14:03	preprocess the dataset.
2017:03:30 21:14:03	load data.
2017:03:30 21:14:03	load context for further preprocessing.
2017:03:30 21:14:04	clean data.
2017:03:30 21:14:04	...mask and pad the sentence.
2017:03:30 21:14:04	......max len:359, median len:22.0, min len:2
2017:03:30 21:14:04	......filter sentence and bound them in the range of 25.
2017:03:30 21:14:04	build a vocabulary.
2017:03:30 21:14:04	...flatmap a list of sentence list to a list of sentence.
2017:03:30 21:14:05	...mapping from index to word.
2017:03:30 21:14:05	...mapping from word to index.
2017:03:30 21:14:05	...map word to index.
2017:03:30 21:14:05	...save processed data to file.
2017:03:30 21:14:06	get data info.
2017:03:30 21:14:06	init batch data.
2017:03:30 21:14:06	...number of batches: 3
2017:03:30 21:14:06	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 21:14:07	enter standard seq2seq's generator mode.
2017:03:30 21:14:07	enter GAN's generator mode.
2017:03:30 21:14:23	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490908455/checkpoints/bestmodel.

2017:03:30 21:14:23	------ pretraining ------ 

2017:03:30 21:14:24	pretrain epoch 0
2017:03:30 21:14:28	pretrain loss d: 1.40933966637, pretrain loss g: 10.1357574463, execution speed: 1.33 seconds/batch

2017:03:30 21:14:29	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490908455/checkpoints/bestmodel.

2017:03:30 21:14:29	pretrain epoch 1
2017:03:30 21:14:34	pretrain loss d: 1.2845389843, pretrain loss g: 10.1261501312, execution speed: 1.33 seconds/batch

2017:03:30 21:14:34	pretrain epoch 2
2017:03:30 21:14:38	pretrain loss d: 1.16578245163, pretrain loss g: 10.1157455444, execution speed: 1.33 seconds/batch

2017:03:30 21:14:38	pretrain epoch 3
2017:03:30 21:14:43	pretrain loss d: 1.05115807056, pretrain loss g: 10.1042051315, execution speed: 1.33 seconds/batch

2017:03:30 21:14:43	pretrain epoch 4
2017:03:30 21:14:47	pretrain loss d: 0.93878620863, pretrain loss g: 10.0911083221, execution speed: 1.33 seconds/batch

2017:03:30 21:14:47	------ training ------ 

2017:03:30 21:14:47	train epoch 5
2017:03:30 21:15:04	train loss d: -0.0241476725787, train loss g: 0.0273956153542, execution speed: 5.33 seconds/batch
2017:03:30 21:15:07	val loss d: -0.0300237759948, val loss g: 0.0312673076987, execution speed: 0.67 seconds/batch

2017:03:30 21:15:08	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490908455/checkpoints/bestmodel.

2017:03:30 21:15:08	train epoch 6
2017:03:30 21:15:27	train loss d: -0.050283305347, train loss g: 0.0555230602622, execution speed: 6.00 seconds/batch
2017:03:30 21:15:30	val loss d: -0.0473126284778, val loss g: 0.0497509948909, execution speed: 1.00 seconds/batch

2017:03:30 21:15:30	train epoch 7
2017:03:30 21:16:14	use DataLoaderBBC to init data.
2017:03:30 21:16:14	reading and processing the text file.
2017:03:30 21:16:14	preprocess the dataset.
2017:03:30 21:16:14	load data.
2017:03:30 21:16:14	load context for further preprocessing.
2017:03:30 21:16:14	clean data.
2017:03:30 21:16:15	...mask and pad the sentence.
2017:03:30 21:16:15	......max len:359, median len:22.0, min len:2
2017:03:30 21:16:15	......filter sentence and bound them in the range of 25.
2017:03:30 21:16:15	build a vocabulary.
2017:03:30 21:16:15	...flatmap a list of sentence list to a list of sentence.
2017:03:30 21:16:15	...mapping from index to word.
2017:03:30 21:16:15	...mapping from word to index.
2017:03:30 21:16:15	...map word to index.
2017:03:30 21:16:16	...save processed data to file.
2017:03:30 21:16:17	get data info.
2017:03:30 21:16:17	init batch data.
2017:03:30 21:16:17	...number of batches: 3
2017:03:30 21:16:17	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:03:30 21:16:17	enter standard seq2seq's generator mode.
2017:03:30 21:16:18	enter GAN's generator mode.
2017:03:30 21:16:34	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490908585/checkpoints/bestmodel.

2017:03:30 21:16:34	------ pretraining ------ 

2017:03:30 21:16:34	pretrain epoch 0
2017:03:30 21:16:40	pretrain loss d: 1.88066112995, pretrain loss g: 10.1358041763, execution speed: 1.67 seconds/batch

2017:03:30 21:16:41	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1490908585/checkpoints/bestmodel.

2017:03:30 21:16:41	pretrain epoch 1
2017:03:30 21:16:47	pretrain loss d: 1.72894287109, pretrain loss g: 10.1220855713, execution speed: 1.67 seconds/batch

2017:03:30 21:16:47	pretrain epoch 2
2017:03:30 21:16:52	pretrain loss d: 1.58231306076, pretrain loss g: 10.1054592133, execution speed: 1.67 seconds/batch

2017:03:30 21:16:52	pretrain epoch 3
2017:03:30 21:16:58	pretrain loss d: 1.44080674648, pretrain loss g: 10.0839328766, execution speed: 2.00 seconds/batch

2017:03:30 21:16:58	pretrain epoch 4
2017:03:30 21:17:02	pretrain loss d: 1.30093121529, pretrain loss g: 10.0545101166, execution speed: 1.33 seconds/batch

2017:03:30 21:17:02	------ training ------ 

2017:03:30 21:17:02	train epoch 5
2017:04:24 21:24:00	use DataLoaderBBC to init data.
2017:04:24 21:24:00	reading and processing the text file.
2017:04:24 21:24:00	preprocess the dataset.
2017:04:24 21:24:00	load data.
2017:04:24 21:24:00	load context for further preprocessing.
2017:04:24 21:24:01	clean data.
2017:04:24 21:24:01	...mask and pad the sentence.
2017:04:24 21:24:01	......max len:359, median len:22.0, min len:2
2017:04:24 21:24:01	......filter sentence and bound them in the range of 25.
2017:04:24 21:24:01	build a vocabulary.
2017:04:24 21:24:01	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:24:01	...mapping from index to word.
2017:04:24 21:24:02	...mapping from word to index.
2017:04:24 21:24:02	...map word to index.
2017:04:24 21:24:02	...save processed data to file.
2017:04:24 21:24:03	get data info.
2017:04:24 21:24:03	init batch data.
2017:04:24 21:24:03	...number of batches: 402
2017:04:24 21:24:03	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:24:03	enter standard seq2seq's generator mode.
2017:04:24 21:24:04	enter GAN's generator mode.
2017:04:24 21:26:15	use DataLoaderBBC to init data.
2017:04:24 21:26:15	reading and processing the text file.
2017:04:24 21:26:15	preprocess the dataset.
2017:04:24 21:26:15	load data.
2017:04:24 21:26:15	load context for further preprocessing.
2017:04:24 21:26:15	clean data.
2017:04:24 21:26:16	...mask and pad the sentence.
2017:04:24 21:26:16	......max len:359, median len:22.0, min len:2
2017:04:24 21:26:16	......filter sentence and bound them in the range of 25.
2017:04:24 21:26:16	build a vocabulary.
2017:04:24 21:26:16	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:26:17	...mapping from index to word.
2017:04:24 21:26:17	...mapping from word to index.
2017:04:24 21:26:17	...map word to index.
2017:04:24 21:26:17	...save processed data to file.
2017:04:24 21:26:18	get data info.
2017:04:24 21:26:18	init batch data.
2017:04:24 21:26:18	...number of batches: 402
2017:04:24 21:26:18	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:26:19	enter standard seq2seq's generator mode.
2017:04:24 21:26:19	enter GAN's generator mode.
2017:04:24 21:28:06	use DataLoaderBBC to init data.
2017:04:24 21:28:06	reading and processing the text file.
2017:04:24 21:28:06	preprocess the dataset.
2017:04:24 21:28:06	load data.
2017:04:24 21:28:06	load context for further preprocessing.
2017:04:24 21:28:06	clean data.
2017:04:24 21:28:06	...mask and pad the sentence.
2017:04:24 21:28:06	......max len:359, median len:22.0, min len:2
2017:04:24 21:28:06	......filter sentence and bound them in the range of 25.
2017:04:24 21:28:06	build a vocabulary.
2017:04:24 21:28:06	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:28:07	...mapping from index to word.
2017:04:24 21:28:07	...mapping from word to index.
2017:04:24 21:28:07	...map word to index.
2017:04:24 21:28:07	...save processed data to file.
2017:04:24 21:28:08	get data info.
2017:04:24 21:28:08	init batch data.
2017:04:24 21:28:08	...number of batches: 402
2017:04:24 21:28:08	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:28:09	enter standard seq2seq's generator mode.
2017:04:24 21:28:09	enter GAN's generator mode.
2017:04:24 21:28:26	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069297/checkpoints/bestmodel.

2017:04:24 21:28:26	------ pretraining ------ 

2017:04:24 21:28:26	pretrain epoch 0
2017:04:24 21:29:01	use DataLoaderBBC to init data.
2017:04:24 21:29:01	reading and processing the text file.
2017:04:24 21:29:01	preprocess the dataset.
2017:04:24 21:29:01	load data.
2017:04:24 21:29:01	load context for further preprocessing.
2017:04:24 21:29:02	clean data.
2017:04:24 21:29:03	...mask and pad the sentence.
2017:04:24 21:29:03	......max len:359, median len:22.0, min len:2
2017:04:24 21:29:03	......filter sentence and bound them in the range of 25.
2017:04:24 21:29:03	build a vocabulary.
2017:04:24 21:29:03	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:29:03	...mapping from index to word.
2017:04:24 21:29:03	...mapping from word to index.
2017:04:24 21:29:03	...map word to index.
2017:04:24 21:29:03	...save processed data to file.
2017:04:24 21:29:04	get data info.
2017:04:24 21:29:04	init batch data.
2017:04:24 21:29:04	...number of batches: 402
2017:04:24 21:29:04	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:29:05	enter standard seq2seq's generator mode.
2017:04:24 21:29:06	enter GAN's generator mode.
2017:04:24 21:29:21	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/checkpoints/bestmodel.

2017:04:24 21:29:21	------ pretraining ------ 

2017:04:24 21:29:22	pretrain epoch 0
2017:04:24 21:29:47	use DataLoaderBBC to init data.
2017:04:24 21:29:47	reading and processing the text file.
2017:04:24 21:29:47	preprocess the dataset.
2017:04:24 21:29:47	load data.
2017:04:24 21:29:47	load context for further preprocessing.
2017:04:24 21:29:47	clean data.
2017:04:24 21:29:47	...mask and pad the sentence.
2017:04:24 21:29:47	......max len:359, median len:22.0, min len:2
2017:04:24 21:29:48	......filter sentence and bound them in the range of 25.
2017:04:24 21:29:48	build a vocabulary.
2017:04:24 21:29:48	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:29:48	...mapping from index to word.
2017:04:24 21:29:48	...mapping from word to index.
2017:04:24 21:29:48	...map word to index.
2017:04:24 21:29:48	...save processed data to file.
2017:04:24 21:29:50	get data info.
2017:04:24 21:29:50	init batch data.
2017:04:24 21:29:50	...number of batches: 402
2017:04:24 21:29:50	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:29:50	enter standard seq2seq's generator mode.
2017:04:24 21:29:50	enter GAN's generator mode.
2017:04:24 21:31:57	use DataLoaderBBC to init data.
2017:04:24 21:31:57	reading and processing the text file.
2017:04:24 21:31:57	preprocess the dataset.
2017:04:24 21:31:57	load data.
2017:04:24 21:31:57	load context for further preprocessing.
2017:04:24 21:31:57	clean data.
2017:04:24 21:31:58	...mask and pad the sentence.
2017:04:24 21:31:58	......max len:359, median len:22.0, min len:2
2017:04:24 21:31:58	......filter sentence and bound them in the range of 25.
2017:04:24 21:31:58	build a vocabulary.
2017:04:24 21:31:58	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:31:58	...mapping from index to word.
2017:04:24 21:31:58	...mapping from word to index.
2017:04:24 21:31:58	...map word to index.
2017:04:24 21:31:59	...save processed data to file.
2017:04:24 21:32:00	get data info.
2017:04:24 21:32:00	init batch data.
2017:04:24 21:32:00	...number of batches: 402
2017:04:24 21:32:00	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:32:19	use DataLoaderBBC to init data.
2017:04:24 21:32:19	reading and processing the text file.
2017:04:24 21:32:19	preprocess the dataset.
2017:04:24 21:32:19	load data.
2017:04:24 21:32:19	load context for further preprocessing.
2017:04:24 21:32:19	clean data.
2017:04:24 21:32:20	...mask and pad the sentence.
2017:04:24 21:32:20	......max len:359, median len:22.0, min len:2
2017:04:24 21:32:20	......filter sentence and bound them in the range of 25.
2017:04:24 21:32:20	build a vocabulary.
2017:04:24 21:32:20	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:32:21	...mapping from index to word.
2017:04:24 21:32:21	...mapping from word to index.
2017:04:24 21:32:21	...map word to index.
2017:04:24 21:32:21	...save processed data to file.
2017:04:24 21:32:22	get data info.
2017:04:24 21:32:22	init batch data.
2017:04:24 21:32:22	...number of batches: 402
2017:04:24 21:32:22	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:32:59	use DataLoaderBBC to init data.
2017:04:24 21:32:59	reading and processing the text file.
2017:04:24 21:32:59	preprocess the dataset.
2017:04:24 21:32:59	load data.
2017:04:24 21:32:59	load context for further preprocessing.
2017:04:24 21:32:59	clean data.
2017:04:24 21:32:59	...mask and pad the sentence.
2017:04:24 21:32:59	......max len:359, median len:22.0, min len:2
2017:04:24 21:32:59	......filter sentence and bound them in the range of 25.
2017:04:24 21:32:59	build a vocabulary.
2017:04:24 21:32:59	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:33:00	...mapping from index to word.
2017:04:24 21:33:00	...mapping from word to index.
2017:04:24 21:33:00	...map word to index.
2017:04:24 21:33:00	...save processed data to file.
2017:04:24 21:33:01	get data info.
2017:04:24 21:33:01	init batch data.
2017:04:24 21:33:01	...number of batches: 402
2017:04:24 21:33:01	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:33:01	generate sentence. beam search:False.
2017:04:24 21:33:01	...decide sampling type.
2017:04:24 21:33:01	...start sampling.
2017:04:24 21:41:03	use DataLoaderBBC to init data.
2017:04:24 21:41:03	reading and processing the text file.
2017:04:24 21:41:03	preprocess the dataset.
2017:04:24 21:41:03	load data.
2017:04:24 21:41:03	load context for further preprocessing.
2017:04:24 21:41:03	clean data.
2017:04:24 21:41:03	...mask and pad the sentence.
2017:04:24 21:41:03	......max len:359, median len:22.0, min len:2
2017:04:24 21:41:03	......filter sentence and bound them in the range of 25.
2017:04:24 21:41:03	build a vocabulary.
2017:04:24 21:41:03	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:41:04	...mapping from index to word.
2017:04:24 21:41:04	...mapping from word to index.
2017:04:24 21:41:04	...map word to index.
2017:04:24 21:41:04	...save processed data to file.
2017:04:24 21:41:05	get data info.
2017:04:24 21:41:05	init batch data.
2017:04:24 21:41:05	...number of batches: 402
2017:04:24 21:41:05	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:41:44	use DataLoaderBBC to init data.
2017:04:24 21:41:44	reading and processing the text file.
2017:04:24 21:41:44	preprocess the dataset.
2017:04:24 21:41:44	load data.
2017:04:24 21:41:44	load context for further preprocessing.
2017:04:24 21:41:44	clean data.
2017:04:24 21:41:45	...mask and pad the sentence.
2017:04:24 21:41:45	......max len:359, median len:22.0, min len:2
2017:04:24 21:41:45	......filter sentence and bound them in the range of 25.
2017:04:24 21:41:45	build a vocabulary.
2017:04:24 21:41:45	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:41:45	...mapping from index to word.
2017:04:24 21:41:45	...mapping from word to index.
2017:04:24 21:41:45	...map word to index.
2017:04:24 21:41:45	...save processed data to file.
2017:04:24 21:41:47	get data info.
2017:04:24 21:41:47	init batch data.
2017:04:24 21:41:47	...number of batches: 402
2017:04:24 21:41:47	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:42:32	use DataLoaderBBC to init data.
2017:04:24 21:42:32	reading and processing the text file.
2017:04:24 21:42:32	preprocess the dataset.
2017:04:24 21:42:32	load data.
2017:04:24 21:42:32	load context for further preprocessing.
2017:04:24 21:42:32	clean data.
2017:04:24 21:42:32	...mask and pad the sentence.
2017:04:24 21:42:32	......max len:359, median len:22.0, min len:2
2017:04:24 21:42:32	......filter sentence and bound them in the range of 25.
2017:04:24 21:42:32	build a vocabulary.
2017:04:24 21:42:32	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:42:33	...mapping from index to word.
2017:04:24 21:42:33	...mapping from word to index.
2017:04:24 21:42:33	...map word to index.
2017:04:24 21:42:33	...save processed data to file.
2017:04:24 21:42:35	get data info.
2017:04:24 21:42:35	init batch data.
2017:04:24 21:42:35	...number of batches: 402
2017:04:24 21:42:35	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:43:52	use DataLoaderBBC to init data.
2017:04:24 21:43:52	reading and processing the text file.
2017:04:24 21:43:52	preprocess the dataset.
2017:04:24 21:43:52	load data.
2017:04:24 21:43:52	load context for further preprocessing.
2017:04:24 21:43:52	clean data.
2017:04:24 21:43:52	...mask and pad the sentence.
2017:04:24 21:43:52	......max len:359, median len:22.0, min len:2
2017:04:24 21:43:52	......filter sentence and bound them in the range of 25.
2017:04:24 21:43:52	build a vocabulary.
2017:04:24 21:43:52	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:43:53	...mapping from index to word.
2017:04:24 21:43:53	...mapping from word to index.
2017:04:24 21:43:53	...map word to index.
2017:04:24 21:43:53	...save processed data to file.
2017:04:24 21:43:54	get data info.
2017:04:24 21:43:54	init batch data.
2017:04:24 21:43:54	...number of batches: 402
2017:04:24 21:43:54	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:43:54	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/checkpoints
2017:04:24 21:45:00	use DataLoaderBBC to init data.
2017:04:24 21:45:00	reading and processing the text file.
2017:04:24 21:45:00	preprocess the dataset.
2017:04:24 21:45:00	load data.
2017:04:24 21:45:00	load context for further preprocessing.
2017:04:24 21:45:00	clean data.
2017:04:24 21:45:01	...mask and pad the sentence.
2017:04:24 21:45:01	......max len:359, median len:22.0, min len:2
2017:04:24 21:45:01	......filter sentence and bound them in the range of 25.
2017:04:24 21:45:01	build a vocabulary.
2017:04:24 21:45:01	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:45:01	...mapping from index to word.
2017:04:24 21:45:02	...mapping from word to index.
2017:04:24 21:45:02	...map word to index.
2017:04:24 21:45:02	...save processed data to file.
2017:04:24 21:45:03	get data info.
2017:04:24 21:45:03	init batch data.
2017:04:24 21:45:03	...number of batches: 402
2017:04:24 21:45:03	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:45:03	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/checkpoints
2017:04:24 21:47:23	use DataLoaderBBC to init data.
2017:04:24 21:47:23	reading and processing the text file.
2017:04:24 21:47:23	preprocess the dataset.
2017:04:24 21:47:23	load data.
2017:04:24 21:47:23	load context for further preprocessing.
2017:04:24 21:47:23	clean data.
2017:04:24 21:47:23	...mask and pad the sentence.
2017:04:24 21:47:23	......max len:359, median len:22.0, min len:2
2017:04:24 21:47:23	......filter sentence and bound them in the range of 25.
2017:04:24 21:47:23	build a vocabulary.
2017:04:24 21:47:23	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:47:24	...mapping from index to word.
2017:04:24 21:47:24	...mapping from word to index.
2017:04:24 21:47:24	...map word to index.
2017:04:24 21:47:24	...save processed data to file.
2017:04:24 21:47:25	get data info.
2017:04:24 21:47:25	init batch data.
2017:04:24 21:47:25	...number of batches: 402
2017:04:24 21:47:25	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:47:25	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/checkpoints
2017:04:24 21:49:19	use DataLoaderBBC to init data.
2017:04:24 21:49:19	reading and processing the text file.
2017:04:24 21:49:19	preprocess the dataset.
2017:04:24 21:49:19	load data.
2017:04:24 21:49:19	load context for further preprocessing.
2017:04:24 21:49:19	clean data.
2017:04:24 21:49:19	...mask and pad the sentence.
2017:04:24 21:49:19	......max len:359, median len:22.0, min len:2
2017:04:24 21:49:19	......filter sentence and bound them in the range of 25.
2017:04:24 21:49:19	build a vocabulary.
2017:04:24 21:49:19	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:49:19	...mapping from index to word.
2017:04:24 21:49:20	...mapping from word to index.
2017:04:24 21:49:20	...map word to index.
2017:04:24 21:49:20	...save processed data to file.
2017:04:24 21:49:21	get data info.
2017:04:24 21:49:21	init batch data.
2017:04:24 21:49:21	...number of batches: 402
2017:04:24 21:49:21	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:49:21	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/checkpoints
2017:04:24 21:52:20	use DataLoaderBBC to init data.
2017:04:24 21:52:20	reading and processing the text file.
2017:04:24 21:52:20	preprocess the dataset.
2017:04:24 21:52:20	load data.
2017:04:24 21:52:20	load context for further preprocessing.
2017:04:24 21:52:20	clean data.
2017:04:24 21:52:21	...mask and pad the sentence.
2017:04:24 21:52:21	......max len:359, median len:22.0, min len:2
2017:04:24 21:52:21	......filter sentence and bound them in the range of 25.
2017:04:24 21:52:21	build a vocabulary.
2017:04:24 21:52:21	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:52:21	...mapping from index to word.
2017:04:24 21:52:21	...mapping from word to index.
2017:04:24 21:52:21	...map word to index.
2017:04:24 21:52:21	...save processed data to file.
2017:04:24 21:52:22	get data info.
2017:04:24 21:52:22	init batch data.
2017:04:24 21:52:22	...number of batches: 402
2017:04:24 21:52:22	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:52:22	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/checkpoints/
2017:04:24 21:52:43	use DataLoaderBBC to init data.
2017:04:24 21:52:43	reading and processing the text file.
2017:04:24 21:52:43	preprocess the dataset.
2017:04:24 21:52:43	load data.
2017:04:24 21:52:43	load context for further preprocessing.
2017:04:24 21:52:43	clean data.
2017:04:24 21:52:44	...mask and pad the sentence.
2017:04:24 21:52:44	......max len:359, median len:22.0, min len:2
2017:04:24 21:52:44	......filter sentence and bound them in the range of 25.
2017:04:24 21:52:44	build a vocabulary.
2017:04:24 21:52:44	...flatmap a list of sentence list to a list of sentence.
2017:04:24 21:52:44	...mapping from index to word.
2017:04:24 21:52:44	...mapping from word to index.
2017:04:24 21:52:44	...map word to index.
2017:04:24 21:52:44	...save processed data to file.
2017:04:24 21:52:45	get data info.
2017:04:24 21:52:45	init batch data.
2017:04:24 21:52:45	...number of batches: 402
2017:04:24 21:52:45	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:24 21:52:45	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/
2017:04:24 21:52:46	generate sentence. beam search:False.
2017:04:24 21:52:46	...decide sampling type.
2017:04:24 21:52:46	...start sampling.
2017:04:25 17:50:39	use DataLoaderBBC to init data.
2017:04:25 17:50:39	reading and processing the text file.
2017:04:25 17:50:39	preprocess the dataset.
2017:04:25 17:50:39	load data.
2017:04:25 17:50:39	load context for further preprocessing.
2017:04:25 17:50:39	clean data.
2017:04:25 17:50:40	...mask and pad the sentence.
2017:04:25 17:50:40	......max len:359, median len:22.0, min len:2
2017:04:25 17:50:40	......filter sentence and bound them in the range of 25.
2017:04:25 17:50:40	build a vocabulary.
2017:04:25 17:50:40	...flatmap a list of sentence list to a list of sentence.
2017:04:25 17:50:40	...mapping from index to word.
2017:04:25 17:50:40	...mapping from word to index.
2017:04:25 17:50:40	...map word to index.
2017:04:25 17:50:41	...save processed data to file.
2017:04:25 17:50:42	get data info.
2017:04:25 17:50:42	init batch data.
2017:04:25 17:50:42	...number of batches: 402
2017:04:25 17:50:42	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 17:50:43	enter standard seq2seq's generator mode.
2017:04:25 17:52:51	use DataLoaderBBC to init data.
2017:04:25 17:52:51	reading and processing the text file.
2017:04:25 17:52:51	preprocess the dataset.
2017:04:25 17:52:51	load data.
2017:04:25 17:52:51	load context for further preprocessing.
2017:04:25 17:52:51	clean data.
2017:04:25 17:52:51	...mask and pad the sentence.
2017:04:25 17:52:51	......max len:359, median len:22.0, min len:2
2017:04:25 17:52:51	......filter sentence and bound them in the range of 25.
2017:04:25 17:52:51	build a vocabulary.
2017:04:25 17:52:51	...flatmap a list of sentence list to a list of sentence.
2017:04:25 17:52:52	...mapping from index to word.
2017:04:25 17:52:52	...mapping from word to index.
2017:04:25 17:52:52	...map word to index.
2017:04:25 17:52:52	...save processed data to file.
2017:04:25 17:52:53	get data info.
2017:04:25 17:52:53	init batch data.
2017:04:25 17:52:53	...number of batches: 402
2017:04:25 17:52:53	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 17:52:54	enter standard seq2seq's generator mode.
2017:04:25 17:52:54	enter GAN's generator mode.
2017:04:25 17:53:11	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493142782/checkpoints/bestmodel.

2017:04:25 17:53:11	------ pretraining ------ 

2017:04:25 17:53:11	pretrain epoch 0
2017:04:25 17:53:51	use DataLoaderBBC to init data.
2017:04:25 17:53:51	reading and processing the text file.
2017:04:25 17:53:51	preprocess the dataset.
2017:04:25 17:53:51	load data.
2017:04:25 17:53:51	load context for further preprocessing.
2017:04:25 17:53:51	clean data.
2017:04:25 17:53:52	...mask and pad the sentence.
2017:04:25 17:53:52	......max len:359, median len:22.0, min len:2
2017:04:25 17:53:52	......filter sentence and bound them in the range of 25.
2017:04:25 17:53:52	build a vocabulary.
2017:04:25 17:53:52	...flatmap a list of sentence list to a list of sentence.
2017:04:25 17:53:52	...mapping from index to word.
2017:04:25 17:53:53	...mapping from word to index.
2017:04:25 17:53:53	...map word to index.
2017:04:25 17:53:53	...save processed data to file.
2017:04:25 17:53:54	get data info.
2017:04:25 17:53:54	init batch data.
2017:04:25 17:53:54	...number of batches: 3
2017:04:25 17:53:54	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 17:53:55	enter standard seq2seq's generator mode.
2017:04:25 17:53:56	enter GAN's generator mode.
2017:04:25 17:54:14	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493142845/checkpoints/bestmodel.

2017:04:25 17:54:14	------ pretraining ------ 

2017:04:25 17:54:14	------ training ------ 

2017:04:25 17:54:14	train epoch 1
2017:04:25 17:54:34	train loss d: -0.0264800135046, train loss g: 0.0391112118959, execution speed: 6.67 seconds/batch
2017:04:25 17:54:38	val loss d: -0.0345684699714, val loss g: 0.0430845916271, execution speed: 1.00 seconds/batch

2017:04:25 17:54:38	train epoch 2
2017:04:25 17:55:01	train loss d: -0.0540355630219, train loss g: 0.0636623948812, execution speed: 7.33 seconds/batch
2017:04:25 17:55:04	val loss d: -0.0581888109446, val loss g: 0.0640974491835, execution speed: 1.00 seconds/batch

2017:04:25 17:55:04	train epoch 3
2017:04:25 17:55:37	train loss d: -0.0720109269023, train loss g: 0.0774326249957, execution speed: 10.67 seconds/batch
2017:04:25 17:55:41	val loss d: -0.0733253732324, val loss g: 0.0761407613754, execution speed: 1.33 seconds/batch

2017:04:25 17:55:41	train epoch 4
2017:04:25 17:56:09	train loss d: -0.0815027505159, train loss g: 0.084356084466, execution speed: 9.00 seconds/batch
2017:04:25 17:56:13	val loss d: -0.0821822583675, val loss g: 0.0832390785217, execution speed: 1.33 seconds/batch

2017:04:25 17:56:13	train epoch 5
2017:04:25 17:56:38	train loss d: -0.0889141261578, train loss g: 0.0906890183687, execution speed: 8.00 seconds/batch
2017:04:25 17:56:42	val loss d: -0.0891350060701, val loss g: 0.0892518982291, execution speed: 1.00 seconds/batch

2017:04:25 17:56:43	save 2-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493142845/checkpoints/bestmodel.

2017:04:25 17:56:43	train epoch 6
2017:04:25 17:57:08	train loss d: -0.0932000279427, train loss g: 0.0940466672182, execution speed: 8.00 seconds/batch
2017:04:25 17:57:11	val loss d: -0.0908040255308, val loss g: 0.090515114367, execution speed: 0.67 seconds/batch

2017:04:25 17:57:11	train epoch 7
2017:04:25 17:57:31	train loss d: -0.0907394587994, train loss g: 0.0908522382379, execution speed: 6.67 seconds/batch
2017:04:25 17:57:34	val loss d: -0.0857955515385, val loss g: 0.0853022783995, execution speed: 1.00 seconds/batch

2017:04:25 17:57:34	train epoch 8
2017:04:25 17:57:57	train loss d: -0.0833116397262, train loss g: 0.0829513072968, execution speed: 7.33 seconds/batch
2017:04:25 17:58:00	val loss d: -0.0769085288048, val loss g: 0.0762864649296, execution speed: 1.00 seconds/batch

2017:04:25 17:58:00	train epoch 9
2017:04:25 17:58:23	train loss d: -0.0736189112067, train loss g: 0.0730305686593, execution speed: 7.33 seconds/batch
2017:04:25 17:58:27	val loss d: -0.0671431049705, val loss g: 0.0664086267352, execution speed: 1.00 seconds/batch

2017:04:25 17:58:27	train epoch 10
2017:04:25 17:58:50	train loss d: -0.0639328062534, train loss g: 0.0631966590881, execution speed: 7.67 seconds/batch
2017:04:25 17:58:54	val loss d: -0.0586400032043, val loss g: 0.0578118562698, execution speed: 1.00 seconds/batch

2017:04:25 17:58:56	save 3-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493142845/checkpoints/bestmodel.

2017:04:25 17:58:56	train epoch 11
2017:04:25 17:59:22	train loss d: -0.0552996881306, train loss g: 0.0544647052884, execution speed: 8.67 seconds/batch
2017:04:25 17:59:26	val loss d: -0.0510616116226, val loss g: 0.050171405077, execution speed: 1.00 seconds/batch

2017:04:25 17:59:26	train epoch 12
2017:04:25 17:59:49	train loss d: -0.0474506765604, train loss g: 0.0465530082583, execution speed: 7.67 seconds/batch
2017:04:25 17:59:52	val loss d: -0.0432531684637, val loss g: 0.0423243381083, execution speed: 1.00 seconds/batch

2017:04:25 17:59:52	train epoch 13
2017:04:25 18:00:14	train loss d: -0.0399754345417, train loss g: 0.0390383973718, execution speed: 7.00 seconds/batch
2017:04:25 18:00:18	val loss d: -0.0358707457781, val loss g: 0.0349202789366, execution speed: 1.33 seconds/batch

2017:04:25 18:00:18	train epoch 14
2017:04:25 18:00:40	train loss d: -0.033619582653, train loss g: 0.0326517224312, execution speed: 7.33 seconds/batch
2017:04:25 18:00:43	val loss d: -0.029664227739, val loss g: 0.0286840908229, execution speed: 0.67 seconds/batch

2017:04:25 18:00:43	train epoch 15
2017:04:25 18:01:03	train loss d: -0.0282272808254, train loss g: 0.0272394530475, execution speed: 6.67 seconds/batch
2017:04:25 18:01:07	val loss d: -0.0241405721754, val loss g: 0.0231396146119, execution speed: 1.00 seconds/batch

2017:04:25 18:01:08	save 4-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493142845/checkpoints/bestmodel.

2017:04:25 18:01:08	train epoch 16
2017:04:25 18:06:20	use DataLoaderBBC to init data.
2017:04:25 18:06:20	reading and processing the text file.
2017:04:25 18:06:20	preprocess the dataset.
2017:04:25 18:06:20	load data.
2017:04:25 18:06:20	load context for further preprocessing.
2017:04:25 18:06:20	clean data.
2017:04:25 18:06:21	...mask and pad the sentence.
2017:04:25 18:06:21	......max len:359, median len:22.0, min len:2
2017:04:25 18:06:21	......filter sentence and bound them in the range of 25.
2017:04:25 18:06:21	build a vocabulary.
2017:04:25 18:06:21	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:06:21	...mapping from index to word.
2017:04:25 18:06:21	...mapping from word to index.
2017:04:25 18:06:21	...map word to index.
2017:04:25 18:06:21	...save processed data to file.
2017:04:25 18:06:23	get data info.
2017:04:25 18:06:23	init batch data.
2017:04:25 18:06:23	...number of batches: 3
2017:04:25 18:06:23	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 18:06:23	enter standard seq2seq's generator mode.
2017:04:25 18:06:24	enter GAN's generator mode.
2017:04:25 18:06:50	use DataLoaderBBC to init data.
2017:04:25 18:06:50	reading and processing the text file.
2017:04:25 18:06:50	preprocess the dataset.
2017:04:25 18:06:50	load data.
2017:04:25 18:06:50	load context for further preprocessing.
2017:04:25 18:06:50	clean data.
2017:04:25 18:06:50	...mask and pad the sentence.
2017:04:25 18:06:50	......max len:359, median len:22.0, min len:2
2017:04:25 18:06:50	......filter sentence and bound them in the range of 25.
2017:04:25 18:06:50	build a vocabulary.
2017:04:25 18:06:50	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:06:51	...mapping from index to word.
2017:04:25 18:06:51	...mapping from word to index.
2017:04:25 18:06:51	...map word to index.
2017:04:25 18:06:51	...save processed data to file.
2017:04:25 18:06:52	get data info.
2017:04:25 18:06:52	init batch data.
2017:04:25 18:06:52	...number of batches: 3
2017:04:25 18:06:52	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 18:06:53	enter standard seq2seq's generator mode.
2017:04:25 18:06:53	enter GAN's generator mode.
2017:04:25 18:07:09	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV4.TextGANV4/1493143621/checkpoints/bestmodel.

2017:04:25 18:07:09	------ pretraining ------ 

2017:04:25 18:07:09	------ training ------ 

2017:04:25 18:07:09	train epoch 1
2017:04:25 18:22:28	use DataLoaderBBC to init data.
2017:04:25 18:22:28	reading and processing the text file.
2017:04:25 18:22:28	preprocess the dataset.
2017:04:25 18:22:28	load data.
2017:04:25 18:22:28	load context for further preprocessing.
2017:04:25 18:22:28	clean data.
2017:04:25 18:22:29	...mask and pad the sentence.
2017:04:25 18:22:29	......max len:359, median len:22.0, min len:2
2017:04:25 18:22:29	......filter sentence and bound them in the range of 25.
2017:04:25 18:22:29	build a vocabulary.
2017:04:25 18:22:29	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:22:29	...mapping from index to word.
2017:04:25 18:22:30	...mapping from word to index.
2017:04:25 18:22:30	...map word to index.
2017:04:25 18:22:30	...save processed data to file.
2017:04:25 18:22:31	get data info.
2017:04:25 18:22:31	init batch data.
2017:04:25 18:22:31	...number of batches: 3
2017:04:25 18:22:31	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 18:22:48	use DataLoaderBBC to init data.
2017:04:25 18:22:48	reading and processing the text file.
2017:04:25 18:22:48	preprocess the dataset.
2017:04:25 18:22:48	load data.
2017:04:25 18:22:48	load context for further preprocessing.
2017:04:25 18:22:48	clean data.
2017:04:25 18:22:49	...mask and pad the sentence.
2017:04:25 18:22:49	......max len:359, median len:22.0, min len:2
2017:04:25 18:22:49	......filter sentence and bound them in the range of 25.
2017:04:25 18:22:49	build a vocabulary.
2017:04:25 18:22:49	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:22:49	...mapping from index to word.
2017:04:25 18:22:50	...mapping from word to index.
2017:04:25 18:22:50	...map word to index.
2017:04:25 18:22:50	...save processed data to file.
2017:04:25 18:22:51	get data info.
2017:04:25 18:22:51	init batch data.
2017:04:25 18:22:51	...number of batches: 3
2017:04:25 18:22:51	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 18:22:51	enter standard seq2seq's generator mode.
2017:04:25 18:22:52	enter GAN's generator mode.
2017:04:25 18:23:07	save 1-th bestmodel to path: /home/lin/notebooks/code/demo3_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493144579/checkpoints/bestmodel.

2017:04:25 18:23:07	------ pretraining ------ 

2017:04:25 18:23:07	------ training ------ 

2017:04:25 18:23:07	train epoch 1
2017:04:25 18:23:28	train loss d: -0.0234889052808, train loss g: 0.036705031991, execution speed: 6.67 seconds/batch
2017:04:25 18:24:01	use DataLoaderBBC to init data.
2017:04:25 18:24:01	reading and processing the text file.
2017:04:25 18:24:01	preprocess the dataset.
2017:04:25 18:24:01	load data.
2017:04:25 18:24:01	load context for further preprocessing.
2017:04:25 18:24:01	clean data.
2017:04:25 18:24:01	...mask and pad the sentence.
2017:04:25 18:24:01	......max len:359, median len:22.0, min len:2
2017:04:25 18:24:01	......filter sentence and bound them in the range of 25.
2017:04:25 18:24:01	build a vocabulary.
2017:04:25 18:24:01	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:24:02	...mapping from index to word.
2017:04:25 18:24:02	...mapping from word to index.
2017:04:25 18:24:02	...map word to index.
2017:04:25 18:24:02	...save processed data to file.
2017:04:25 18:24:03	get data info.
2017:04:25 18:24:03	init batch data.
2017:04:25 18:24:03	...number of batches: 402
2017:04:25 18:24:03	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 18:24:03	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493069353/
2017:04:25 18:24:03	generate sentence. beam search:False.
2017:04:25 18:24:03	...decide sampling type.
2017:04:25 18:24:03	...start sampling.
2017:04:25 18:25:06	use DataLoaderBBC to init data.
2017:04:25 18:25:06	reading and processing the text file.
2017:04:25 18:25:06	preprocess the dataset.
2017:04:25 18:25:06	load data.
2017:04:25 18:25:06	load context for further preprocessing.
2017:04:25 18:25:06	clean data.
2017:04:25 18:25:07	...mask and pad the sentence.
2017:04:25 18:25:07	......max len:359, median len:22.0, min len:2
2017:04:25 18:25:07	......filter sentence and bound them in the range of 25.
2017:04:25 18:25:07	build a vocabulary.
2017:04:25 18:25:07	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:25:07	...mapping from index to word.
2017:04:25 18:25:08	...mapping from word to index.
2017:04:25 18:25:08	...map word to index.
2017:04:25 18:25:08	...save processed data to file.
2017:04:25 18:25:09	get data info.
2017:04:25 18:25:09	init batch data.
2017:04:25 18:25:09	...number of batches: 3
2017:04:25 18:25:09	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 18:25:10	enter standard seq2seq's generator mode.
2017:04:25 18:25:10	enter GAN's generator mode.
2017:04:25 18:25:26	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493144718/checkpoints/bestmodel.

2017:04:25 18:25:26	------ pretraining ------ 

2017:04:25 18:25:26	------ training ------ 

2017:04:25 18:25:26	train epoch 1
2017:04:25 18:25:36	use DataLoaderBBC to init data.
2017:04:25 18:25:36	reading and processing the text file.
2017:04:25 18:25:36	preprocess the dataset.
2017:04:25 18:25:36	load data.
2017:04:25 18:25:36	load context for further preprocessing.
2017:04:25 18:25:36	clean data.
2017:04:25 18:25:37	...mask and pad the sentence.
2017:04:25 18:25:37	......max len:359, median len:22.0, min len:2
2017:04:25 18:25:37	......filter sentence and bound them in the range of 25.
2017:04:25 18:25:37	build a vocabulary.
2017:04:25 18:25:37	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:25:37	...mapping from index to word.
2017:04:25 18:25:37	...mapping from word to index.
2017:04:25 18:25:38	...map word to index.
2017:04:25 18:25:38	...save processed data to file.
2017:04:25 18:25:39	get data info.
2017:04:25 18:25:39	init batch data.
2017:04:25 18:25:39	...number of batches: 402
2017:04:25 18:25:39	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 18:25:39	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493144718
2017:04:25 18:25:39	generate sentence. beam search:False.
2017:04:25 18:25:39	...decide sampling type.
2017:04:25 18:25:39	...start sampling.
2017:04:25 18:29:37	use DataLoaderBBC to init data.
2017:04:25 18:29:37	reading and processing the text file.
2017:04:25 18:29:37	preprocess the dataset.
2017:04:25 18:29:37	load data.
2017:04:25 18:29:37	load context for further preprocessing.
2017:04:25 18:29:37	clean data.
2017:04:25 18:29:38	...mask and pad the sentence.
2017:04:25 18:29:38	......max len:359, median len:22.0, min len:2
2017:04:25 18:29:38	......filter sentence and bound them in the range of 25.
2017:04:25 18:29:38	build a vocabulary.
2017:04:25 18:29:38	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:29:38	...mapping from index to word.
2017:04:25 18:29:38	...mapping from word to index.
2017:04:25 18:29:38	...map word to index.
2017:04:25 18:29:39	...save processed data to file.
2017:04:25 18:29:40	get data info.
2017:04:25 18:29:40	init batch data.
2017:04:25 18:29:40	...number of batches: 402
2017:04:25 18:29:40	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 18:29:40	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493144718
2017:04:25 18:29:48	use DataLoaderBBC to init data.
2017:04:25 18:29:48	reading and processing the text file.
2017:04:25 18:29:48	preprocess the dataset.
2017:04:25 18:29:48	load data.
2017:04:25 18:29:48	load context for further preprocessing.
2017:04:25 18:29:48	clean data.
2017:04:25 18:29:49	...mask and pad the sentence.
2017:04:25 18:29:49	......max len:359, median len:22.0, min len:2
2017:04:25 18:29:49	......filter sentence and bound them in the range of 25.
2017:04:25 18:29:49	build a vocabulary.
2017:04:25 18:29:49	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:29:49	...mapping from index to word.
2017:04:25 18:29:49	...mapping from word to index.
2017:04:25 18:29:49	...map word to index.
2017:04:25 18:29:50	...save processed data to file.
2017:04:25 18:29:51	get data info.
2017:04:25 18:29:51	init batch data.
2017:04:25 18:29:51	...number of batches: 3
2017:04:25 18:29:51	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 18:29:52	enter standard seq2seq's generator mode.
2017:04:25 18:29:53	enter GAN's generator mode.
2017:04:25 18:30:15	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493145004/checkpoints/bestmodel.

2017:04:25 18:30:15	------ pretraining ------ 

2017:04:25 18:30:15	------ training ------ 

2017:04:25 18:30:15	train epoch 1
2017:04:25 18:30:34	train loss d: -0.0263103656471, train loss g: 0.0404685139656, execution speed: 6.33 seconds/batch
2017:04:25 18:30:37	val loss d: -0.0334702953696, val loss g: 0.0432083569467, execution speed: 0.67 seconds/batch

2017:04:25 18:30:37	train epoch 2
2017:04:25 18:30:53	train loss d: -0.0492468029261, train loss g: 0.0585812106729, execution speed: 5.00 seconds/batch
2017:04:25 18:30:55	val loss d: -0.0509028658271, val loss g: 0.0568124093115, execution speed: 0.67 seconds/batch

2017:04:25 18:30:55	train epoch 3
2017:04:25 18:31:13	train loss d: -0.0593897737563, train loss g: 0.0644520819187, execution speed: 6.00 seconds/batch
2017:04:25 18:31:16	val loss d: -0.0564494617283, val loss g: 0.0596797019243, execution speed: 0.67 seconds/batch

2017:04:25 18:31:16	train epoch 4
2017:04:25 18:31:38	train loss d: -0.0590367466211, train loss g: 0.0619364976883, execution speed: 7.33 seconds/batch
2017:04:25 18:31:42	val loss d: -0.0554260201752, val loss g: 0.0575260072947, execution speed: 1.00 seconds/batch

2017:04:25 18:31:42	train epoch 5
2017:04:25 18:32:09	train loss d: -0.0558155104518, train loss g: 0.0578743219376, execution speed: 8.67 seconds/batch
2017:04:25 18:32:13	val loss d: -0.052752751857, val loss g: 0.0543844401836, execution speed: 1.33 seconds/batch

2017:04:25 18:32:14	save 2-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493145004/checkpoints/bestmodel.

2017:04:25 18:32:14	train epoch 6
2017:04:25 18:33:02	use DataLoaderBBC to init data.
2017:04:25 18:33:02	reading and processing the text file.
2017:04:25 18:33:02	preprocess the dataset.
2017:04:25 18:33:02	load data.
2017:04:25 18:33:02	load context for further preprocessing.
2017:04:25 18:33:02	clean data.
2017:04:25 18:33:03	...mask and pad the sentence.
2017:04:25 18:33:03	......max len:359, median len:22.0, min len:2
2017:04:25 18:33:03	......filter sentence and bound them in the range of 25.
2017:04:25 18:33:03	build a vocabulary.
2017:04:25 18:33:03	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:33:03	...mapping from index to word.
2017:04:25 18:33:03	...mapping from word to index.
2017:04:25 18:33:03	...map word to index.
2017:04:25 18:33:03	...save processed data to file.
2017:04:25 18:33:10	use DataLoaderBBC to init data.
2017:04:25 18:33:10	reading and processing the text file.
2017:04:25 18:33:10	preprocess the dataset.
2017:04:25 18:33:10	load data.
2017:04:25 18:33:10	load context for further preprocessing.
2017:04:25 18:33:10	clean data.
2017:04:25 18:33:11	...mask and pad the sentence.
2017:04:25 18:33:11	......max len:359, median len:22.0, min len:2
2017:04:25 18:33:11	......filter sentence and bound them in the range of 25.
2017:04:25 18:33:11	build a vocabulary.
2017:04:25 18:33:11	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:33:11	...mapping from index to word.
2017:04:25 18:33:11	...mapping from word to index.
2017:04:25 18:33:11	...map word to index.
2017:04:25 18:33:11	...save processed data to file.
2017:04:25 18:33:12	get data info.
2017:04:25 18:33:12	init batch data.
2017:04:25 18:33:12	...number of batches: 402
2017:04:25 18:33:13	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 18:33:13	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493145004/
2017:04:25 18:41:36	use DataLoaderBBC to init data.
2017:04:25 18:41:36	reading and processing the text file.
2017:04:25 18:41:36	preprocess the dataset.
2017:04:25 18:41:36	load data.
2017:04:25 18:41:36	load context for further preprocessing.
2017:04:25 18:41:36	clean data.
2017:04:25 18:41:37	...mask and pad the sentence.
2017:04:25 18:41:37	......max len:359, median len:22.0, min len:2
2017:04:25 18:41:37	......filter sentence and bound them in the range of 25.
2017:04:25 18:41:37	build a vocabulary.
2017:04:25 18:41:37	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:41:37	...mapping from index to word.
2017:04:25 18:41:37	...mapping from word to index.
2017:04:25 18:41:37	...map word to index.
2017:04:25 18:41:38	...save processed data to file.
2017:04:25 18:41:38	get data info.
2017:04:25 18:41:38	init batch data.
2017:04:25 18:41:38	...number of batches: 402
2017:04:25 18:41:38	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 18:41:38	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493145004/
2017:04:25 18:47:53	use DataLoaderBBC to init data.
2017:04:25 18:47:53	reading and processing the text file.
2017:04:25 18:47:53	preprocess the dataset.
2017:04:25 18:47:53	load data.
2017:04:25 18:47:53	load context for further preprocessing.
2017:04:25 18:47:53	clean data.
2017:04:25 18:47:53	...mask and pad the sentence.
2017:04:25 18:47:53	......max len:359, median len:22.0, min len:2
2017:04:25 18:47:53	......filter sentence and bound them in the range of 25.
2017:04:25 18:47:53	build a vocabulary.
2017:04:25 18:47:53	...flatmap a list of sentence list to a list of sentence.
2017:04:25 18:47:54	...mapping from index to word.
2017:04:25 18:47:54	...mapping from word to index.
2017:04:25 18:47:54	...map word to index.
2017:04:25 18:47:54	...save processed data to file.
2017:04:25 18:47:55	get data info.
2017:04:25 18:47:55	init batch data.
2017:04:25 18:47:55	...number of batches: 402
2017:04:25 18:47:55	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 18:47:55	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493145004/
2017:04:25 19:13:47	use DataLoaderBBC to init data.
2017:04:25 19:13:47	reading and processing the text file.
2017:04:25 19:13:47	preprocess the dataset.
2017:04:25 19:13:47	load data.
2017:04:25 19:13:47	load context for further preprocessing.
2017:04:25 19:13:47	clean data.
2017:04:25 19:13:47	...mask and pad the sentence.
2017:04:25 19:13:47	......max len:359, median len:22.0, min len:2
2017:04:25 19:13:48	......filter sentence and bound them in the range of 25.
2017:04:25 19:13:48	build a vocabulary.
2017:04:25 19:13:48	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:13:48	...mapping from index to word.
2017:04:25 19:13:48	...mapping from word to index.
2017:04:25 19:13:48	...map word to index.
2017:04:25 19:13:48	...save processed data to file.
2017:04:25 19:13:49	get data info.
2017:04:25 19:13:49	init batch data.
2017:04:25 19:13:49	...number of batches: 3
2017:04:25 19:13:49	num of sentence: 150, sentence length: 25, vocab size: 25278
2017:04:25 19:13:50	enter standard seq2seq's generator mode.
2017:04:25 19:13:50	enter GAN's generator mode.
2017:04:25 19:14:05	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/checkpoints/bestmodel.

2017:04:25 19:14:05	------ pretraining ------ 

2017:04:25 19:14:05	pretrain epoch 0
2017:04:25 19:14:12	pretrain loss d: 1.80006289482, pretrain loss g: 10.1369247437, execution speed: 2.33 seconds/batch

2017:04:25 19:14:13	save 2-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/checkpoints/bestmodel.

2017:04:25 19:14:13	------ training ------ 

2017:04:25 19:14:13	train epoch 1
2017:04:25 19:14:33	train loss d: -0.0100325094536, train loss g: 0.00554863689467, execution speed: 6.33 seconds/batch
2017:04:25 19:14:35	val loss d: -0.0135871246457, val loss g: 0.00752903940156, execution speed: 0.67 seconds/batch

2017:04:25 19:14:35	train epoch 2
2017:04:25 19:15:02	use DataLoaderBBC to init data.
2017:04:25 19:15:02	reading and processing the text file.
2017:04:25 19:15:02	preprocess the dataset.
2017:04:25 19:15:02	load data.
2017:04:25 19:15:02	load context for further preprocessing.
2017:04:25 19:15:02	clean data.
2017:04:25 19:15:03	...mask and pad the sentence.
2017:04:25 19:15:03	......max len:359, median len:22.0, min len:2
2017:04:25 19:15:03	......filter sentence and bound them in the range of 25.
2017:04:25 19:15:03	build a vocabulary.
2017:04:25 19:15:03	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:15:03	...mapping from index to word.
2017:04:25 19:15:03	...mapping from word to index.
2017:04:25 19:15:03	...map word to index.
2017:04:25 19:15:04	...save processed data to file.
2017:04:25 19:15:05	get data info.
2017:04:25 19:15:05	init batch data.
2017:04:25 19:15:05	...number of batches: 402
2017:04:25 19:15:05	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:15:05	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 19:17:05	use DataLoaderBBC to init data.
2017:04:25 19:17:05	reading and processing the text file.
2017:04:25 19:17:05	preprocess the dataset.
2017:04:25 19:17:05	load data.
2017:04:25 19:17:05	load context for further preprocessing.
2017:04:25 19:17:05	clean data.
2017:04:25 19:17:06	...mask and pad the sentence.
2017:04:25 19:17:06	......max len:359, median len:22.0, min len:2
2017:04:25 19:17:06	......filter sentence and bound them in the range of 25.
2017:04:25 19:17:06	build a vocabulary.
2017:04:25 19:17:06	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:17:06	...mapping from index to word.
2017:04:25 19:17:06	...mapping from word to index.
2017:04:25 19:17:06	...map word to index.
2017:04:25 19:17:07	...save processed data to file.
2017:04:25 19:17:07	get data info.
2017:04:25 19:17:07	init batch data.
2017:04:25 19:17:07	...number of batches: 402
2017:04:25 19:17:08	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:17:08	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 19:17:14	use DataLoaderBBC to init data.
2017:04:25 19:17:14	reading and processing the text file.
2017:04:25 19:17:14	preprocess the dataset.
2017:04:25 19:17:14	load data.
2017:04:25 19:17:14	load context for further preprocessing.
2017:04:25 19:17:14	clean data.
2017:04:25 19:17:15	...mask and pad the sentence.
2017:04:25 19:17:15	......max len:359, median len:22.0, min len:2
2017:04:25 19:17:15	......filter sentence and bound them in the range of 25.
2017:04:25 19:17:15	build a vocabulary.
2017:04:25 19:17:15	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:17:15	...mapping from index to word.
2017:04:25 19:17:15	...mapping from word to index.
2017:04:25 19:17:15	...map word to index.
2017:04:25 19:17:16	...save processed data to file.
2017:04:25 19:17:17	get data info.
2017:04:25 19:17:17	init batch data.
2017:04:25 19:17:17	...number of batches: 402
2017:04:25 19:17:17	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:17:17	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 19:19:37	use DataLoaderBBC to init data.
2017:04:25 19:19:37	reading and processing the text file.
2017:04:25 19:19:37	preprocess the dataset.
2017:04:25 19:19:37	load data.
2017:04:25 19:19:37	load context for further preprocessing.
2017:04:25 19:19:37	clean data.
2017:04:25 19:19:38	...mask and pad the sentence.
2017:04:25 19:19:38	......max len:359, median len:22.0, min len:2
2017:04:25 19:19:38	......filter sentence and bound them in the range of 25.
2017:04:25 19:19:38	build a vocabulary.
2017:04:25 19:19:38	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:19:38	...mapping from index to word.
2017:04:25 19:19:38	...mapping from word to index.
2017:04:25 19:19:38	...map word to index.
2017:04:25 19:19:38	...save processed data to file.
2017:04:25 19:19:39	get data info.
2017:04:25 19:19:39	init batch data.
2017:04:25 19:19:39	...number of batches: 402
2017:04:25 19:19:39	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:19:39	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 19:19:39	generate sentence. beam search:False.
2017:04:25 19:19:39	...decide sampling type.
2017:04:25 19:19:39	...start sampling.
2017:04:25 19:20:38	use DataLoaderBBC to init data.
2017:04:25 19:20:38	reading and processing the text file.
2017:04:25 19:20:38	preprocess the dataset.
2017:04:25 19:20:38	load data.
2017:04:25 19:20:38	load context for further preprocessing.
2017:04:25 19:20:38	clean data.
2017:04:25 19:20:39	...mask and pad the sentence.
2017:04:25 19:20:39	......max len:359, median len:22.0, min len:2
2017:04:25 19:20:39	......filter sentence and bound them in the range of 25.
2017:04:25 19:20:39	build a vocabulary.
2017:04:25 19:20:39	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:20:39	...mapping from index to word.
2017:04:25 19:20:39	...mapping from word to index.
2017:04:25 19:20:39	...map word to index.
2017:04:25 19:20:39	...save processed data to file.
2017:04:25 19:20:40	get data info.
2017:04:25 19:20:40	init batch data.
2017:04:25 19:20:40	...number of batches: 402
2017:04:25 19:20:40	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:20:41	enter standard seq2seq's generator mode.
2017:04:25 19:20:41	enter GAN's generator mode.
2017:04:25 19:22:51	use DataLoaderBBC to init data.
2017:04:25 19:22:51	reading and processing the text file.
2017:04:25 19:22:51	preprocess the dataset.
2017:04:25 19:22:51	load data.
2017:04:25 19:22:51	load context for further preprocessing.
2017:04:25 19:22:51	clean data.
2017:04:25 19:22:52	...mask and pad the sentence.
2017:04:25 19:22:52	......max len:359, median len:22.0, min len:2
2017:04:25 19:22:52	......filter sentence and bound them in the range of 25.
2017:04:25 19:22:52	build a vocabulary.
2017:04:25 19:22:52	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:22:52	...mapping from index to word.
2017:04:25 19:22:52	...mapping from word to index.
2017:04:25 19:22:52	...map word to index.
2017:04:25 19:22:53	...save processed data to file.
2017:04:25 19:22:54	get data info.
2017:04:25 19:22:54	init batch data.
2017:04:25 19:22:54	...number of batches: 402
2017:04:25 19:22:54	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:23:12	use DataLoaderBBC to init data.
2017:04:25 19:23:12	reading and processing the text file.
2017:04:25 19:23:12	preprocess the dataset.
2017:04:25 19:23:12	load data.
2017:04:25 19:23:12	load context for further preprocessing.
2017:04:25 19:23:12	clean data.
2017:04:25 19:23:13	...mask and pad the sentence.
2017:04:25 19:23:13	......max len:359, median len:22.0, min len:2
2017:04:25 19:23:13	......filter sentence and bound them in the range of 25.
2017:04:25 19:23:13	build a vocabulary.
2017:04:25 19:23:13	...flatmap a list of sentence list to a list of sentence.
2017:04:25 19:23:13	...mapping from index to word.
2017:04:25 19:23:13	...mapping from word to index.
2017:04:25 19:23:13	...map word to index.
2017:04:25 19:23:13	...save processed data to file.
2017:04:25 19:23:14	get data info.
2017:04:25 19:23:14	init batch data.
2017:04:25 19:23:14	...number of batches: 402
2017:04:25 19:23:14	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 19:23:15	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 19:23:16	generate sentence. beam search:False.
2017:04:25 19:23:16	...decide sampling type.
2017:04:25 19:23:16	...start sampling.
2017:04:25 20:15:36	use DataLoaderBBC to init data.
2017:04:25 20:15:37	reading and processing the text file.
2017:04:25 20:15:37	preprocess the dataset.
2017:04:25 20:15:37	load data.
2017:04:25 20:15:37	load context for further preprocessing.
2017:04:25 20:15:37	clean data.
2017:04:25 20:15:37	...mask and pad the sentence.
2017:04:25 20:15:37	......max len:359, median len:22.0, min len:2
2017:04:25 20:15:37	......filter sentence and bound them in the range of 25.
2017:04:25 20:15:37	build a vocabulary.
2017:04:25 20:15:37	...flatmap a list of sentence list to a list of sentence.
2017:04:25 20:15:38	...mapping from index to word.
2017:04:25 20:15:38	...mapping from word to index.
2017:04:25 20:15:38	...map word to index.
2017:04:25 20:15:38	...save processed data to file.
2017:04:25 20:15:39	get data info.
2017:04:25 20:15:39	init batch data.
2017:04:25 20:15:39	...number of batches: 402
2017:04:25 20:15:39	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 20:15:40	enter standard seq2seq's generator mode.
2017:04:25 20:15:40	enter GAN's generator mode.
2017:04:25 20:15:40	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 20:15:40	generate sentence. beam search:False.
2017:04:25 20:15:40	...decide sampling type.
2017:04:25 20:15:40	...start sampling.
2017:04:25 20:17:31	use DataLoaderBBC to init data.
2017:04:25 20:17:31	reading and processing the text file.
2017:04:25 20:17:31	preprocess the dataset.
2017:04:25 20:17:31	load data.
2017:04:25 20:17:31	load context for further preprocessing.
2017:04:25 20:17:31	clean data.
2017:04:25 20:17:32	...mask and pad the sentence.
2017:04:25 20:17:32	......max len:359, median len:22.0, min len:2
2017:04:25 20:17:32	......filter sentence and bound them in the range of 25.
2017:04:25 20:17:32	build a vocabulary.
2017:04:25 20:17:32	...flatmap a list of sentence list to a list of sentence.
2017:04:25 20:17:32	...mapping from index to word.
2017:04:25 20:17:33	...mapping from word to index.
2017:04:25 20:17:33	...map word to index.
2017:04:25 20:17:33	...save processed data to file.
2017:04:25 20:17:34	get data info.
2017:04:25 20:17:34	init batch data.
2017:04:25 20:17:34	...number of batches: 402
2017:04:25 20:17:34	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 20:17:35	enter standard seq2seq's generator mode.
2017:04:25 20:17:35	enter GAN's generator mode.
2017:04:25 20:17:35	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 20:17:36	generate sentence. beam search:False.
2017:04:25 20:17:36	...decide sampling type.
2017:04:25 20:17:36	...start sampling.
2017:04:25 20:37:16	use DataLoaderBBC to init data.
2017:04:25 20:37:16	reading and processing the text file.
2017:04:25 20:37:16	preprocess the dataset.
2017:04:25 20:37:16	load data.
2017:04:25 20:37:16	load context for further preprocessing.
2017:04:25 20:37:16	clean data.
2017:04:25 20:37:17	...mask and pad the sentence.
2017:04:25 20:37:17	......max len:359, median len:22.0, min len:2
2017:04:25 20:37:17	......filter sentence and bound them in the range of 25.
2017:04:25 20:37:17	build a vocabulary.
2017:04:25 20:37:17	...flatmap a list of sentence list to a list of sentence.
2017:04:25 20:37:17	...mapping from index to word.
2017:04:25 20:37:17	...mapping from word to index.
2017:04:25 20:37:17	...map word to index.
2017:04:25 20:37:17	...save processed data to file.
2017:04:25 20:37:18	get data info.
2017:04:25 20:37:18	init batch data.
2017:04:25 20:37:18	...number of batches: 402
2017:04:25 20:37:18	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 20:37:19	enter standard seq2seq's generator mode.
2017:04:25 20:46:23	use DataLoaderBBC to init data.
2017:04:25 20:46:23	reading and processing the text file.
2017:04:25 20:46:23	preprocess the dataset.
2017:04:25 20:46:23	load data.
2017:04:25 20:46:23	load context for further preprocessing.
2017:04:25 20:46:23	clean data.
2017:04:25 20:46:24	...mask and pad the sentence.
2017:04:25 20:46:24	......max len:359, median len:22.0, min len:2
2017:04:25 20:46:24	......filter sentence and bound them in the range of 25.
2017:04:25 20:46:24	build a vocabulary.
2017:04:25 20:46:24	...flatmap a list of sentence list to a list of sentence.
2017:04:25 20:46:24	...mapping from index to word.
2017:04:25 20:46:24	...mapping from word to index.
2017:04:25 20:46:24	...map word to index.
2017:04:25 20:46:24	...save processed data to file.
2017:04:25 20:46:25	get data info.
2017:04:25 20:46:25	init batch data.
2017:04:25 20:46:25	...number of batches: 402
2017:04:25 20:46:25	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 20:46:26	enter standard seq2seq's generator mode.
2017:04:25 20:46:26	enter GAN's generator mode.
2017:04:25 20:46:26	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 20:46:27	generate sentence. beam search:False.
2017:04:25 20:46:27	...decide sampling type.
2017:04:25 20:46:27	...start sampling.
2017:04:25 21:00:07	use DataLoaderBBC to init data.
2017:04:25 21:00:07	reading and processing the text file.
2017:04:25 21:00:07	preprocess the dataset.
2017:04:25 21:00:07	load data.
2017:04:25 21:00:07	load context for further preprocessing.
2017:04:25 21:00:07	clean data.
2017:04:25 21:00:07	...mask and pad the sentence.
2017:04:25 21:00:08	......max len:359, median len:22.0, min len:2
2017:04:25 21:00:08	......filter sentence and bound them in the range of 25.
2017:04:25 21:00:08	build a vocabulary.
2017:04:25 21:00:08	...flatmap a list of sentence list to a list of sentence.
2017:04:25 21:00:08	...mapping from index to word.
2017:04:25 21:00:08	...mapping from word to index.
2017:04:25 21:00:08	...map word to index.
2017:04:25 21:00:08	...save processed data to file.
2017:04:25 21:00:09	get data info.
2017:04:25 21:00:09	init batch data.
2017:04:25 21:00:09	...number of batches: 402
2017:04:25 21:00:09	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 21:00:10	enter standard seq2seq's generator mode.
2017:04:25 21:00:10	enter GAN's generator mode.
2017:04:25 21:00:10	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 21:00:10	generate sentence. beam search:False.
2017:04:25 21:00:10	...decide sampling type.
2017:04:25 21:00:10	...start sampling.
2017:04:25 21:01:54	use DataLoaderBBC to init data.
2017:04:25 21:01:54	reading and processing the text file.
2017:04:25 21:01:54	preprocess the dataset.
2017:04:25 21:01:54	load data.
2017:04:25 21:01:54	load context for further preprocessing.
2017:04:25 21:01:54	clean data.
2017:04:25 21:01:54	...mask and pad the sentence.
2017:04:25 21:01:54	......max len:359, median len:22.0, min len:2
2017:04:25 21:01:54	......filter sentence and bound them in the range of 25.
2017:04:25 21:01:54	build a vocabulary.
2017:04:25 21:01:54	...flatmap a list of sentence list to a list of sentence.
2017:04:25 21:01:55	...mapping from index to word.
2017:04:25 21:01:55	...mapping from word to index.
2017:04:25 21:01:55	...map word to index.
2017:04:25 21:01:55	...save processed data to file.
2017:04:25 21:01:56	get data info.
2017:04:25 21:01:56	init batch data.
2017:04:25 21:01:56	...number of batches: 402
2017:04:25 21:01:56	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 21:01:57	enter standard seq2seq's generator mode.
2017:04:25 21:01:57	enter GAN's generator mode.
2017:04:25 21:01:57	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 21:01:57	generate sentence. beam search:False.
2017:04:25 21:01:57	...decide sampling type.
2017:04:25 21:01:57	...start sampling.
2017:04:25 21:01:58	above content is generated from lstm.
2017:04:25 21:01:58	total execution time: 4
2017:04:25 21:07:29	use DataLoaderBBC to init data.
2017:04:25 21:07:29	reading and processing the text file.
2017:04:25 21:07:29	preprocess the dataset.
2017:04:25 21:07:29	load data.
2017:04:25 21:07:29	load context for further preprocessing.
2017:04:25 21:07:29	clean data.
2017:04:25 21:07:30	...mask and pad the sentence.
2017:04:25 21:07:30	......max len:359, median len:22.0, min len:2
2017:04:25 21:07:30	......filter sentence and bound them in the range of 25.
2017:04:25 21:07:30	build a vocabulary.
2017:04:25 21:07:30	...flatmap a list of sentence list to a list of sentence.
2017:04:25 21:07:30	...mapping from index to word.
2017:04:25 21:07:30	...mapping from word to index.
2017:04:25 21:07:30	...map word to index.
2017:04:25 21:07:31	...save processed data to file.
2017:04:25 21:07:32	get data info.
2017:04:25 21:07:32	init batch data.
2017:04:25 21:07:32	...number of batches: 402
2017:04:25 21:07:32	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 21:07:32	enter standard seq2seq's generator mode.
2017:04:25 21:10:09	use DataLoaderBBC to init data.
2017:04:25 21:10:09	reading and processing the text file.
2017:04:25 21:10:09	preprocess the dataset.
2017:04:25 21:10:09	load data.
2017:04:25 21:10:09	load context for further preprocessing.
2017:04:25 21:10:09	clean data.
2017:04:25 21:10:10	...mask and pad the sentence.
2017:04:25 21:10:10	......max len:359, median len:22.0, min len:2
2017:04:25 21:10:10	......filter sentence and bound them in the range of 25.
2017:04:25 21:10:10	build a vocabulary.
2017:04:25 21:10:10	...flatmap a list of sentence list to a list of sentence.
2017:04:25 21:10:10	...mapping from index to word.
2017:04:25 21:10:10	...mapping from word to index.
2017:04:25 21:10:10	...map word to index.
2017:04:25 21:10:10	...save processed data to file.
2017:04:25 21:10:11	get data info.
2017:04:25 21:10:11	init batch data.
2017:04:25 21:10:11	...number of batches: 402
2017:04:25 21:10:11	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 21:10:12	enter standard seq2seq's generator mode.
2017:04:25 21:18:36	use DataLoaderBBC to init data.
2017:04:25 21:18:36	reading and processing the text file.
2017:04:25 21:18:36	preprocess the dataset.
2017:04:25 21:18:36	load data.
2017:04:25 21:18:36	load context for further preprocessing.
2017:04:25 21:18:36	clean data.
2017:04:25 21:18:37	...mask and pad the sentence.
2017:04:25 21:18:37	......max len:359, median len:22.0, min len:2
2017:04:25 21:18:37	......filter sentence and bound them in the range of 25.
2017:04:25 21:18:37	build a vocabulary.
2017:04:25 21:18:37	...flatmap a list of sentence list to a list of sentence.
2017:04:25 21:18:37	...mapping from index to word.
2017:04:25 21:18:37	...mapping from word to index.
2017:04:25 21:18:37	...map word to index.
2017:04:25 21:18:38	...save processed data to file.
2017:04:25 21:18:39	get data info.
2017:04:25 21:18:39	init batch data.
2017:04:25 21:18:39	...number of batches: 402
2017:04:25 21:18:39	num of sentence: 20100, sentence length: 25, vocab size: 25278
2017:04:25 21:18:39	enter GAN's generator mode.
2017:04:25 21:18:39	init from the path data/training/runs/DataLoaderBBC/code.model.textGANV3.TextGANV3/1493147637/
2017:04:25 21:18:40	generate sentence. beam search:False.
2017:04:25 21:18:40	...decide sampling type.
2017:04:25 21:18:40	...start sampling.
2017:04:25 21:18:40	above content is generated from lstm.
2017:04:25 21:18:40	total execution time: 4
2017:05:12 10:28:42	use DataLoaderBBT to init data.
2017:05:12 10:28:42	reading and processing the text file.
2017:05:12 10:28:42	preprocess the dataset.
2017:05:12 10:28:42	load data.
2017:05:12 10:28:42	init content from raw.
2017:05:12 10:28:42	init data from the raw dataset.
2017:05:12 10:30:25	use DataLoaderBBT to init data.
2017:05:12 10:30:25	reading and processing the text file.
2017:05:12 10:30:25	preprocess the dataset.
2017:05:12 10:30:25	load data.
2017:05:12 10:30:25	init content from raw.
2017:05:12 10:30:25	init data from the raw dataset.
2017:05:12 10:36:58	use DataLoaderBBT to init data.
2017:05:12 10:36:58	reading and processing the text file.
2017:05:12 10:36:58	preprocess the dataset.
2017:05:12 10:36:58	load data.
2017:05:12 10:36:58	init content from raw.
2017:05:12 10:36:58	init data from the raw dataset.
2017:05:12 10:46:07	use DataLoaderBBT to init data.
2017:05:12 10:46:07	reading and processing the text file.
2017:05:12 10:46:07	preprocess the dataset.
2017:05:12 10:46:07	load data.
2017:05:12 10:46:07	init content from raw.
2017:05:12 10:46:07	init data from the raw dataset.
2017:05:12 10:46:07	...basic initialization
2017:05:12 10:46:07	...load the mapping dictionary.
2017:05:12 10:46:30	use DataLoaderBBT to init data.
2017:05:12 10:46:30	reading and processing the text file.
2017:05:12 10:46:30	preprocess the dataset.
2017:05:12 10:46:30	load data.
2017:05:12 10:46:30	init content from raw.
2017:05:12 10:46:30	init data from the raw dataset.
2017:05:12 10:46:30	...basic initialization
2017:05:12 10:46:30	...load the mapping dictionary.
2017:05:12 10:49:15	use DataLoaderBBT to init data.
2017:05:12 10:49:15	reading and processing the text file.
2017:05:12 10:49:15	preprocess the dataset.
2017:05:12 10:49:15	load data.
2017:05:12 10:49:15	init content from raw.
2017:05:12 10:49:15	init data from the raw dataset.
2017:05:12 10:49:15	...basic initialization
2017:05:12 10:49:15	...load the mapping dictionary.
2017:05:12 10:50:53	use DataLoaderBBT to init data.
2017:05:12 10:50:53	reading and processing the text file.
2017:05:12 10:50:53	preprocess the dataset.
2017:05:12 10:50:53	load data.
2017:05:12 10:50:53	init content from raw.
2017:05:12 10:50:53	init data from the raw dataset.
2017:05:12 10:50:53	...basic initialization
2017:05:12 10:50:53	...load the mapping dictionary.
2017:05:12 10:51:50	use DataLoaderBBT to init data.
2017:05:12 10:51:50	reading and processing the text file.
2017:05:12 10:51:50	preprocess the dataset.
2017:05:12 10:51:50	load data.
2017:05:12 10:51:50	init content from raw.
2017:05:12 10:51:50	init data from the raw dataset.
2017:05:12 10:51:50	...basic initialization
2017:05:12 10:51:50	...load the mapping dictionary.
2017:05:12 10:51:50	...load data and do mapping.
2017:05:12 10:53:11	use DataLoaderBBT to init data.
2017:05:12 10:53:11	reading and processing the text file.
2017:05:12 10:53:11	preprocess the dataset.
2017:05:12 10:53:11	load data.
2017:05:12 10:53:11	init content from raw.
2017:05:12 10:53:11	init data from the raw dataset.
2017:05:12 10:53:11	...basic initialization
2017:05:12 10:53:11	...load the mapping dictionary.
2017:05:12 10:53:11	...load data and do mapping.
2017:05:12 10:53:12	...mask and pad the sentence.
2017:05:12 10:53:12	......max len:28, median len:24.0, min len:10
2017:05:12 10:53:12	......filter sentence and bound them in the range of 25.
2017:05:12 10:53:12	build a vocabulary.
2017:05:12 10:53:12	...flatmap a list of sentence list to a list of sentence.
2017:05:12 10:53:12	...mapping from index to word.
2017:05:12 10:53:12	...keep frequent words.
2017:05:12 10:53:12	...mapping from word to index.
2017:05:12 10:53:12	...map word to index.
2017:05:12 10:53:12	...save processed data to file.
2017:05:12 10:53:12	get data info.
2017:05:12 10:53:12	init batch data.
2017:05:12 10:53:12	...number of batches: 0
2017:05:12 10:53:12	num of sentence: 0, sentence length: 25, vocab size: 36
2017:05:12 10:53:13	enter standard seq2seq's generator mode.
2017:05:12 10:53:14	enter GAN's generator mode.
2017:05:12 10:54:28	use DataLoaderBBT to init data.
2017:05:12 10:54:28	reading and processing the text file.
2017:05:12 10:54:28	preprocess the dataset.
2017:05:12 10:54:28	load data.
2017:05:12 10:54:28	init content from raw.
2017:05:12 10:54:28	init data from the raw dataset.
2017:05:12 10:54:28	...basic initialization
2017:05:12 10:54:28	...load the mapping dictionary.
2017:05:12 10:54:28	...load data and do mapping.
2017:05:12 10:55:46	use DataLoaderBBT to init data.
2017:05:12 10:55:46	reading and processing the text file.
2017:05:12 10:55:46	preprocess the dataset.
2017:05:12 10:55:46	load data.
2017:05:12 10:55:46	init content from raw.
2017:05:12 10:55:46	init data from the raw dataset.
2017:05:12 10:55:46	...basic initialization
2017:05:12 10:55:46	...load the mapping dictionary.
2017:05:12 10:55:46	...load data and do mapping.
2017:05:12 10:55:47	...mask and pad the sentence.
2017:05:12 10:55:47	......max len:50, median len:42.0, min len:14
2017:05:12 10:55:47	......filter sentence and bound them in the range of 25.
2017:05:12 10:55:47	build a vocabulary.
2017:05:12 10:55:47	...flatmap a list of sentence list to a list of sentence.
2017:05:12 10:56:25	use DataLoaderBBT to init data.
2017:05:12 10:56:25	reading and processing the text file.
2017:05:12 10:56:25	preprocess the dataset.
2017:05:12 10:56:25	load data.
2017:05:12 10:56:25	init content from raw.
2017:05:12 10:56:25	init data from the raw dataset.
2017:05:12 10:56:25	...basic initialization
2017:05:12 10:56:25	...load the mapping dictionary.
2017:05:12 10:56:25	...load data and do mapping.
2017:05:12 10:56:29	...mask and pad the sentence.
2017:05:12 10:56:29	......max len:62, median len:25.0, min len:7
2017:05:12 10:56:29	......filter sentence and bound them in the range of 25.
2017:05:12 10:56:29	build a vocabulary.
2017:05:12 10:56:29	...flatmap a list of sentence list to a list of sentence.
2017:05:12 10:56:29	...mapping from index to word.
2017:05:12 10:56:29	...keep frequent words.
2017:05:12 10:56:29	...mapping from word to index.
2017:05:12 10:56:29	...map word to index.
2017:05:12 10:56:29	...save processed data to file.
2017:05:12 10:56:30	get data info.
2017:05:12 10:56:30	init batch data.
2017:05:12 10:56:30	...number of batches: 277
2017:05:12 10:56:30	num of sentence: 13850, sentence length: 25, vocab size: 9253
2017:05:12 10:56:31	enter standard seq2seq's generator mode.
2017:05:12 10:56:32	enter GAN's generator mode.
2017:05:12 10:56:52	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV3.TextGANV3/1494586602/checkpoints/bestmodel.

2017:05:12 10:56:52	------ pretraining ------ 

2017:05:12 10:56:52	pretrain epoch 0
2017:05:14 18:23:02	use DataLoaderBBT to init data.
2017:05:14 18:23:02	reading and processing the text file.
2017:05:14 18:23:02	preprocess the dataset.
2017:05:14 18:23:02	load data.
2017:05:14 18:23:02	init content from raw.
2017:05:14 18:23:02	init data from the raw dataset.
2017:05:14 18:23:02	...basic initialization
2017:05:14 18:23:02	...load the mapping dictionary.
2017:05:14 18:23:02	...load data and do mapping.
2017:05:14 18:23:03	...mask and pad the sentence.
2017:05:14 18:23:03	......max len:62, median len:25.0, min len:7
2017:05:14 18:23:03	......filter sentence and bound them in the range of 25.
2017:05:14 18:23:03	build a vocabulary.
2017:05:14 18:23:03	...flatmap a list of sentence list to a list of sentence.
2017:05:14 18:23:03	...mapping from index to word.
2017:05:14 18:23:03	...keep frequent words.
2017:05:14 18:23:03	...mapping from word to index.
2017:05:14 18:23:03	...map word to index.
2017:05:14 18:23:04	...save processed data to file.
2017:05:14 18:23:04	get data info.
2017:05:14 18:23:04	init batch data.
2017:05:14 18:23:04	...number of batches: 277
2017:05:14 18:23:04	num of sentence: 13850, sentence length: 25, vocab size: 9253
2017:05:14 18:23:05	enter standard seq2seq's generator mode.
2017:05:14 18:23:06	enter GAN's generator mode.
2017:05:14 18:23:30	use DataLoaderBBT to init data.
2017:05:14 18:23:30	loading preprocessed files.
2017:05:14 18:23:31	get data info.
2017:05:14 18:23:31	init batch data.
2017:05:14 18:23:31	...number of batches: 277
2017:05:14 18:23:31	num of sentence: 13850, sentence length: 25, vocab size: 9253
2017:05:14 18:23:32	enter standard seq2seq's generator mode.
2017:05:14 18:23:33	enter GAN's generator mode.
2017:05:14 18:24:06	use DataLoaderBBT to init data.
2017:05:14 18:24:06	reading and processing the text file.
2017:05:14 18:24:06	preprocess the dataset.
2017:05:14 18:24:06	load data.
2017:05:14 18:24:06	init content from raw.
2017:05:14 18:24:06	init data from the raw dataset.
2017:05:14 18:24:06	...basic initialization
2017:05:14 18:24:06	...load the mapping dictionary.
2017:05:14 18:24:06	...load data and do mapping.
2017:05:14 18:24:08	...mask and pad the sentence.
2017:05:14 18:24:08	......max len:62, median len:25.0, min len:7
2017:05:14 18:24:08	......filter sentence and bound them in the range of 25.
2017:05:14 18:24:08	build a vocabulary.
2017:05:14 18:24:08	...flatmap a list of sentence list to a list of sentence.
2017:05:14 18:24:08	...mapping from index to word.
2017:05:14 18:24:08	...keep frequent words.
2017:05:14 18:24:08	...mapping from word to index.
2017:05:14 18:24:08	...map word to index.
2017:05:14 18:24:08	...save processed data to file.
2017:05:14 18:24:09	get data info.
2017:05:14 18:24:09	init batch data.
2017:05:14 18:24:09	...number of batches: 277
2017:05:14 18:24:09	num of sentence: 13850, sentence length: 25, vocab size: 9253
2017:05:14 18:24:09	enter standard seq2seq's generator mode.
2017:05:14 18:24:10	enter GAN's generator mode.
2017:05:14 18:27:29	use DataLoaderBBT to init data.
2017:05:14 18:27:29	reading and processing the text file.
2017:05:14 18:27:29	preprocess the dataset.
2017:05:14 18:27:29	load data.
2017:05:14 18:27:29	init content from raw.
2017:05:14 18:27:29	init data from the raw dataset.
2017:05:14 18:27:29	...basic initialization
2017:05:14 18:27:29	...load the mapping dictionary.
2017:05:14 18:27:29	...load data and do mapping.
2017:05:14 18:27:30	...mask and pad the sentence.
2017:05:14 18:27:30	......max len:33, median len:12.0, min len:3
2017:05:14 18:27:30	......filter sentence and bound them in the range of 25.
2017:05:14 18:27:30	build a vocabulary.
2017:05:14 18:27:30	...flatmap a list of sentence list to a list of sentence.
2017:05:14 18:27:30	...mapping from index to word.
2017:05:14 18:27:30	...keep frequent words.
2017:05:14 18:27:30	...mapping from word to index.
2017:05:14 18:27:30	...map word to index.
2017:05:14 18:27:30	...save processed data to file.
2017:05:14 18:27:31	get data info.
2017:05:14 18:27:31	init batch data.
2017:05:14 18:27:31	...number of batches: 415
2017:05:14 18:27:31	num of sentence: 20750, sentence length: 25, vocab size: 10001
2017:05:14 18:27:32	enter standard seq2seq's generator mode.
2017:05:14 18:27:32	enter GAN's generator mode.
2017:05:14 18:32:42	use DataLoaderBBT to init data.
2017:05:14 18:32:42	reading and processing the text file.
2017:05:14 18:32:42	preprocess the dataset.
2017:05:14 18:32:42	load data.
2017:05:14 18:32:42	init content from raw.
2017:05:14 18:32:42	init data from the raw dataset.
2017:05:14 18:32:42	...basic initialization
2017:05:14 18:32:42	...load the mapping dictionary.
2017:05:14 18:32:42	...load data and do mapping.
2017:05:14 18:32:43	...mask and pad the sentence.
2017:05:14 18:32:43	...statistics.
2017:05:14 18:32:43	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 18:32:43	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 18:41:31	use DataLoaderBBT to init data.
2017:05:14 18:41:31	reading and processing the text file.
2017:05:14 18:41:31	preprocess the dataset.
2017:05:14 18:41:31	load data.
2017:05:14 18:41:31	init content from raw.
2017:05:14 18:41:31	init data from the raw dataset.
2017:05:14 18:41:31	...basic initialization
2017:05:14 18:41:31	...load the mapping dictionary.
2017:05:14 18:41:31	...load data and do mapping.
2017:05:14 18:41:32	...mask and pad the sentence.
2017:05:14 18:41:32	...statistics.
2017:05:14 18:41:32	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 18:41:32	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 18:41:32	...get valid sentence.
2017:05:14 18:41:33	build a vocabulary.
2017:05:14 18:41:33	...flatmap a list of sentence list to a list of sentence.
2017:05:14 18:54:52	use DataLoaderBBT to init data.
2017:05:14 18:54:52	reading and processing the text file.
2017:05:14 18:54:52	preprocess the dataset.
2017:05:14 18:54:52	load data.
2017:05:14 18:54:52	init content from raw.
2017:05:14 18:54:52	init data from the raw dataset.
2017:05:14 18:54:52	...basic initialization
2017:05:14 18:54:52	...load the mapping dictionary.
2017:05:14 18:54:52	...load data and do mapping.
2017:05:14 18:54:53	...mask and pad the sentence.
2017:05:14 18:54:53	...statistics.
2017:05:14 18:54:53	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 18:54:53	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 18:54:53	...build valid sentence.
2017:05:14 18:54:53	build a vocabulary.
2017:05:14 18:54:53	...flatmap a list of sentence list to a list of sentence.
2017:05:14 18:54:54	...mapping from index to word.
2017:05:14 18:54:54	...keep frequent words.
2017:05:14 18:54:54	...mapping from word to index.
2017:05:14 18:54:54	...map word to index.
2017:05:14 18:54:54	...save processed data to file.
2017:05:14 19:40:35	use DataLoaderBBT to init data.
2017:05:14 19:40:35	reading and processing the text file.
2017:05:14 19:40:35	preprocess the dataset.
2017:05:14 19:40:35	load data.
2017:05:14 19:40:35	init content from raw.
2017:05:14 19:40:35	init data from the raw dataset.
2017:05:14 19:40:35	...basic initialization
2017:05:14 19:40:35	...load the mapping dictionary.
2017:05:14 19:40:35	...load data and do mapping.
2017:05:14 19:40:36	...mask and pad the sentence.
2017:05:14 19:40:36	...statistics.
2017:05:14 19:40:36	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 19:40:36	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 19:40:36	...build valid sentence and mask.
2017:05:14 19:40:37	build a vocabulary.
2017:05:14 19:40:37	...flatmap a list of sentence list to a list of sentence.
2017:05:14 19:40:37	...mapping from index to word.
2017:05:14 19:40:38	...keep frequent words.
2017:05:14 19:40:38	...mapping from word to index.
2017:05:14 19:40:38	...map word to index.
2017:05:14 19:40:38	...save processed data to file.
2017:05:14 19:40:41	get data info.
2017:05:14 19:40:41	init batch data.
2017:05:14 19:40:41	...number of batches: 708
2017:05:14 19:42:32	use DataLoaderBBT to init data.
2017:05:14 19:42:32	reading and processing the text file.
2017:05:14 19:42:32	preprocess the dataset.
2017:05:14 19:42:32	load data.
2017:05:14 19:42:32	init content from raw.
2017:05:14 19:42:32	init data from the raw dataset.
2017:05:14 19:42:32	...basic initialization
2017:05:14 19:42:32	...load the mapping dictionary.
2017:05:14 19:42:32	...load data and do mapping.
2017:05:14 19:42:34	...mask and pad the sentence.
2017:05:14 19:42:34	...statistics.
2017:05:14 19:42:34	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 19:42:34	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 19:42:34	...build valid sentence and mask.
2017:05:14 19:42:34	build a vocabulary.
2017:05:14 19:42:34	...flatmap a list of sentence list to a list of sentence.
2017:05:14 19:42:35	...mapping from index to word.
2017:05:14 19:42:35	...keep frequent words.
2017:05:14 19:42:35	...mapping from word to index.
2017:05:14 19:42:35	...map word to index.
2017:05:14 19:42:36	...save processed data to file.
2017:05:14 19:42:39	get data info.
2017:05:14 19:42:39	init batch data.
2017:05:14 19:42:39	...number of batches: 708
2017:05:14 20:28:32	use DataLoaderBBT to init data.
2017:05:14 20:28:32	reading and processing the text file.
2017:05:14 20:28:32	preprocess the dataset.
2017:05:14 20:28:32	load data.
2017:05:14 20:28:32	init content from raw.
2017:05:14 20:28:32	init data from the raw dataset.
2017:05:14 20:28:32	...basic initialization
2017:05:14 20:28:32	...load the mapping dictionary.
2017:05:14 20:28:32	...load data and do mapping.
2017:05:14 20:28:33	...mask and pad the sentence.
2017:05:14 20:28:33	...statistics.
2017:05:14 20:28:33	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 20:28:33	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 20:28:33	...build valid sentence and mask.
2017:05:14 20:28:34	build a vocabulary.
2017:05:14 20:28:34	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:28:34	...mapping from index to word.
2017:05:14 20:28:34	...keep frequent words.
2017:05:14 20:28:34	...mapping from word to index.
2017:05:14 20:28:34	...map word to index.
2017:05:14 20:28:35	...save processed data to file.
2017:05:14 20:28:37	get data info.
2017:05:14 20:28:37	init batch data.
2017:05:14 20:28:37	...number of batches: 708
2017:05:14 20:30:08	use DataLoaderBBT to init data.
2017:05:14 20:30:08	reading and processing the text file.
2017:05:14 20:30:08	preprocess the dataset.
2017:05:14 20:30:08	load data.
2017:05:14 20:30:08	init content from raw.
2017:05:14 20:30:08	init data from the raw dataset.
2017:05:14 20:30:08	...basic initialization
2017:05:14 20:30:08	...load the mapping dictionary.
2017:05:14 20:30:08	...load data and do mapping.
2017:05:14 20:30:09	...mask and pad the sentence.
2017:05:14 20:30:09	...statistics.
2017:05:14 20:30:09	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:14 20:30:09	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:14 20:30:09	...build valid sentence and mask.
2017:05:14 20:30:09	build a vocabulary.
2017:05:14 20:30:09	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:30:10	...mapping from index to word.
2017:05:14 20:30:10	...keep frequent words.
2017:05:14 20:30:10	...mapping from word to index.
2017:05:14 20:30:10	...map word to index.
2017:05:14 20:30:11	...save processed data to file.
2017:05:14 20:30:13	get data info.
2017:05:14 20:30:13	init batch data.
2017:05:14 20:30:13	...number of batches: 708
2017:05:14 20:33:32	use DataLoaderBBT to init data.
2017:05:14 20:33:32	reading and processing the text file.
2017:05:14 20:33:32	preprocess the dataset.
2017:05:14 20:33:32	load data.
2017:05:14 20:33:32	init content from raw.
2017:05:14 20:33:32	init data from the raw dataset.
2017:05:14 20:33:32	...basic initialization
2017:05:14 20:33:32	...load the mapping dictionary.
2017:05:14 20:33:32	...load data and do mapping.
2017:05:14 20:33:33	...mask and pad the sentence.
2017:05:14 20:33:33	...statistics.
2017:05:14 20:33:33	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:33:33	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:33:33	...build valid sentence and mask.
2017:05:14 20:33:34	build a vocabulary.
2017:05:14 20:33:34	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:33:36	...mapping from index to word.
2017:05:14 20:33:36	...keep frequent words.
2017:05:14 20:33:36	...mapping from word to index.
2017:05:14 20:33:36	...map word to index.
2017:05:14 20:33:37	...save processed data to file.
2017:05:14 20:33:42	get data info.
2017:05:14 20:33:42	init batch data.
2017:05:14 20:33:42	...number of batches: 1417
2017:05:14 20:33:42	# sent: 2, left_sent_len: 33, right_sent_len: 33, vocab size: 10001
2017:05:14 20:33:43	enter standard seq2seq's generator mode.
2017:05:14 20:33:44	enter GAN's generator mode.
2017:05:14 20:34:14	use DataLoaderBBT to init data.
2017:05:14 20:34:14	reading and processing the text file.
2017:05:14 20:34:14	preprocess the dataset.
2017:05:14 20:34:14	load data.
2017:05:14 20:34:14	init content from raw.
2017:05:14 20:34:14	init data from the raw dataset.
2017:05:14 20:34:14	...basic initialization
2017:05:14 20:34:14	...load the mapping dictionary.
2017:05:14 20:34:14	...load data and do mapping.
2017:05:14 20:34:15	...mask and pad the sentence.
2017:05:14 20:34:15	...statistics.
2017:05:14 20:34:15	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:34:15	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:34:15	...build valid sentence and mask.
2017:05:14 20:34:16	build a vocabulary.
2017:05:14 20:34:16	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:34:18	...mapping from index to word.
2017:05:14 20:34:18	...keep frequent words.
2017:05:14 20:34:18	...mapping from word to index.
2017:05:14 20:34:18	...map word to index.
2017:05:14 20:34:19	...save processed data to file.
2017:05:14 20:34:24	get data info.
2017:05:14 20:34:24	init batch data.
2017:05:14 20:34:24	...number of batches: 1417
2017:05:14 20:34:49	use DataLoaderBBT to init data.
2017:05:14 20:34:49	reading and processing the text file.
2017:05:14 20:34:49	preprocess the dataset.
2017:05:14 20:34:49	load data.
2017:05:14 20:34:49	init content from raw.
2017:05:14 20:34:49	init data from the raw dataset.
2017:05:14 20:34:49	...basic initialization
2017:05:14 20:34:49	...load the mapping dictionary.
2017:05:14 20:34:49	...load data and do mapping.
2017:05:14 20:34:50	...mask and pad the sentence.
2017:05:14 20:34:50	...statistics.
2017:05:14 20:34:50	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:34:50	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:34:50	...build valid sentence and mask.
2017:05:14 20:34:51	build a vocabulary.
2017:05:14 20:34:51	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:34:53	...mapping from index to word.
2017:05:14 20:34:53	...keep frequent words.
2017:05:14 20:34:53	...mapping from word to index.
2017:05:14 20:34:53	...map word to index.
2017:05:14 20:34:54	...save processed data to file.
2017:05:14 20:35:00	get data info.
2017:05:14 20:35:00	init batch data.
2017:05:14 20:35:00	...number of batches: 1417
2017:05:14 20:35:00	# sent: 2, sentence length: 33, vocab size: 10001
2017:05:14 20:35:01	enter standard seq2seq's generator mode.
2017:05:14 20:35:01	enter GAN's generator mode.
2017:05:14 20:35:27	use DataLoaderBBT to init data.
2017:05:14 20:35:27	reading and processing the text file.
2017:05:14 20:35:27	preprocess the dataset.
2017:05:14 20:35:27	load data.
2017:05:14 20:35:27	init content from raw.
2017:05:14 20:35:27	init data from the raw dataset.
2017:05:14 20:35:27	...basic initialization
2017:05:14 20:35:27	...load the mapping dictionary.
2017:05:14 20:35:27	...load data and do mapping.
2017:05:14 20:35:28	...mask and pad the sentence.
2017:05:14 20:35:28	...statistics.
2017:05:14 20:35:28	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:35:28	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:35:28	...build valid sentence and mask.
2017:05:14 20:35:29	build a vocabulary.
2017:05:14 20:35:29	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:35:31	...mapping from index to word.
2017:05:14 20:35:31	...keep frequent words.
2017:05:14 20:35:31	...mapping from word to index.
2017:05:14 20:35:31	...map word to index.
2017:05:14 20:35:32	...save processed data to file.
2017:05:14 20:35:37	get data info.
2017:05:14 20:35:37	init batch data.
2017:05:14 20:35:37	...number of batches: 1417
2017:05:14 20:35:37	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 20:35:38	enter standard seq2seq's generator mode.
2017:05:14 20:35:38	enter GAN's generator mode.
2017:05:14 20:58:57	use DataLoaderBBT to init data.
2017:05:14 20:58:57	reading and processing the text file.
2017:05:14 20:58:57	preprocess the dataset.
2017:05:14 20:58:57	load data.
2017:05:14 20:58:57	init content from raw.
2017:05:14 20:58:57	init data from the raw dataset.
2017:05:14 20:58:57	...basic initialization
2017:05:14 20:58:57	...load the mapping dictionary.
2017:05:14 20:58:57	...load data and do mapping.
2017:05:14 20:58:58	...mask and pad the sentence.
2017:05:14 20:58:58	...statistics.
2017:05:14 20:58:58	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:58:58	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:58:58	...build valid sentence and mask.
2017:05:14 20:58:59	build a vocabulary.
2017:05:14 20:58:59	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:59:01	...mapping from index to word.
2017:05:14 20:59:01	...keep frequent words.
2017:05:14 20:59:01	...mapping from word to index.
2017:05:14 20:59:01	...map word to index.
2017:05:14 20:59:02	...save processed data to file.
2017:05:14 20:59:08	get data info.
2017:05:14 20:59:08	init batch data.
2017:05:14 20:59:08	...number of batches: 1417
2017:05:14 20:59:09	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 20:59:19	use DataLoaderBBT to init data.
2017:05:14 20:59:19	reading and processing the text file.
2017:05:14 20:59:19	preprocess the dataset.
2017:05:14 20:59:19	load data.
2017:05:14 20:59:19	init content from raw.
2017:05:14 20:59:19	init data from the raw dataset.
2017:05:14 20:59:19	...basic initialization
2017:05:14 20:59:19	...load the mapping dictionary.
2017:05:14 20:59:19	...load data and do mapping.
2017:05:14 20:59:20	...mask and pad the sentence.
2017:05:14 20:59:20	...statistics.
2017:05:14 20:59:20	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:59:20	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:59:20	...build valid sentence and mask.
2017:05:14 20:59:21	build a vocabulary.
2017:05:14 20:59:21	...flatmap a list of sentence list to a list of sentence.
2017:05:14 20:59:23	...mapping from index to word.
2017:05:14 20:59:24	...keep frequent words.
2017:05:14 20:59:24	...mapping from word to index.
2017:05:14 20:59:24	...map word to index.
2017:05:14 20:59:25	...save processed data to file.
2017:05:14 20:59:31	get data info.
2017:05:14 20:59:31	init batch data.
2017:05:14 20:59:31	...number of batches: 1417
2017:05:14 20:59:32	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 20:59:57	use DataLoaderBBT to init data.
2017:05:14 20:59:57	reading and processing the text file.
2017:05:14 20:59:57	preprocess the dataset.
2017:05:14 20:59:57	load data.
2017:05:14 20:59:57	init content from raw.
2017:05:14 20:59:57	init data from the raw dataset.
2017:05:14 20:59:57	...basic initialization
2017:05:14 20:59:57	...load the mapping dictionary.
2017:05:14 20:59:57	...load data and do mapping.
2017:05:14 20:59:58	...mask and pad the sentence.
2017:05:14 20:59:58	...statistics.
2017:05:14 20:59:58	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:59:58	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 20:59:58	...build valid sentence and mask.
2017:05:14 20:59:59	build a vocabulary.
2017:05:14 20:59:59	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:00:01	...mapping from index to word.
2017:05:14 21:00:01	...keep frequent words.
2017:05:14 21:00:01	...mapping from word to index.
2017:05:14 21:00:01	...map word to index.
2017:05:14 21:00:02	...save processed data to file.
2017:05:14 21:00:07	get data info.
2017:05:14 21:00:07	init batch data.
2017:05:14 21:00:07	...number of batches: 1417
2017:05:14 21:00:07	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:00:37	use DataLoaderBBT to init data.
2017:05:14 21:00:37	reading and processing the text file.
2017:05:14 21:00:37	preprocess the dataset.
2017:05:14 21:00:37	load data.
2017:05:14 21:00:37	init content from raw.
2017:05:14 21:00:37	init data from the raw dataset.
2017:05:14 21:00:37	...basic initialization
2017:05:14 21:00:37	...load the mapping dictionary.
2017:05:14 21:00:37	...load data and do mapping.
2017:05:14 21:00:38	...mask and pad the sentence.
2017:05:14 21:00:38	...statistics.
2017:05:14 21:00:38	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:00:38	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:00:38	...build valid sentence and mask.
2017:05:14 21:00:39	build a vocabulary.
2017:05:14 21:00:39	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:00:40	...mapping from index to word.
2017:05:14 21:00:40	...keep frequent words.
2017:05:14 21:00:40	...mapping from word to index.
2017:05:14 21:00:41	...map word to index.
2017:05:14 21:00:42	...save processed data to file.
2017:05:14 21:00:46	get data info.
2017:05:14 21:00:46	init batch data.
2017:05:14 21:00:46	...number of batches: 1417
2017:05:14 21:00:47	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:04:04	use DataLoaderBBT to init data.
2017:05:14 21:04:04	reading and processing the text file.
2017:05:14 21:04:04	preprocess the dataset.
2017:05:14 21:04:04	load data.
2017:05:14 21:04:04	init content from raw.
2017:05:14 21:04:04	init data from the raw dataset.
2017:05:14 21:04:04	...basic initialization
2017:05:14 21:04:04	...load the mapping dictionary.
2017:05:14 21:04:04	...load data and do mapping.
2017:05:14 21:04:06	...mask and pad the sentence.
2017:05:14 21:04:06	...statistics.
2017:05:14 21:04:06	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:04:06	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:04:06	...build valid sentence and mask.
2017:05:14 21:04:07	build a vocabulary.
2017:05:14 21:04:07	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:04:09	...mapping from index to word.
2017:05:14 21:04:09	...keep frequent words.
2017:05:14 21:04:09	...mapping from word to index.
2017:05:14 21:04:09	...map word to index.
2017:05:14 21:04:10	...save processed data to file.
2017:05:14 21:04:16	get data info.
2017:05:14 21:04:16	init batch data.
2017:05:14 21:04:16	...number of batches: 1417
2017:05:14 21:04:16	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:09:38	use DataLoaderBBT to init data.
2017:05:14 21:09:38	reading and processing the text file.
2017:05:14 21:09:38	preprocess the dataset.
2017:05:14 21:09:38	load data.
2017:05:14 21:09:38	init content from raw.
2017:05:14 21:09:38	init data from the raw dataset.
2017:05:14 21:09:38	...basic initialization
2017:05:14 21:09:38	...load the mapping dictionary.
2017:05:14 21:09:38	...load data and do mapping.
2017:05:14 21:09:39	...mask and pad the sentence.
2017:05:14 21:09:39	...statistics.
2017:05:14 21:09:39	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:09:39	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:09:39	...build valid sentence and mask.
2017:05:14 21:09:43	use DataLoaderBBT to init data.
2017:05:14 21:09:43	loading preprocessed files.
2017:05:14 21:09:52	get data info.
2017:05:14 21:09:52	init batch data.
2017:05:14 21:09:52	...number of batches: 1417
2017:05:14 21:09:54	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:11:24	use DataLoaderBBT to init data.
2017:05:14 21:11:24	loading preprocessed files.
2017:05:14 21:11:32	get data info.
2017:05:14 21:11:32	init batch data.
2017:05:14 21:11:32	...number of batches: 1417
2017:05:14 21:11:33	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:13:18	use DataLoaderBBT to init data.
2017:05:14 21:13:18	loading preprocessed files.
2017:05:14 21:13:25	get data info.
2017:05:14 21:13:25	init batch data.
2017:05:14 21:13:25	...number of batches: 1417
2017:05:14 21:13:26	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:14:52	use DataLoaderBBT to init data.
2017:05:14 21:14:52	loading preprocessed files.
2017:05:14 21:14:59	get data info.
2017:05:14 21:14:59	init batch data.
2017:05:14 21:14:59	...number of batches: 1417
2017:05:14 21:15:00	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:15:16	use DataLoaderBBT to init data.
2017:05:14 21:15:16	loading preprocessed files.
2017:05:14 21:15:23	get data info.
2017:05:14 21:15:23	init batch data.
2017:05:14 21:15:23	...number of batches: 1417
2017:05:14 21:15:24	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:16:08	use DataLoaderBBT to init data.
2017:05:14 21:16:08	loading preprocessed files.
2017:05:14 21:16:14	get data info.
2017:05:14 21:16:14	init batch data.
2017:05:14 21:16:14	...number of batches: 1417
2017:05:14 21:16:16	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:16:39	use DataLoaderBBT to init data.
2017:05:14 21:16:39	loading preprocessed files.
2017:05:14 21:16:46	get data info.
2017:05:14 21:16:46	init batch data.
2017:05:14 21:16:46	...number of batches: 1417
2017:05:14 21:16:47	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:17:20	use DataLoaderBBT to init data.
2017:05:14 21:17:20	loading preprocessed files.
2017:05:14 21:17:28	get data info.
2017:05:14 21:17:28	init batch data.
2017:05:14 21:17:28	...number of batches: 1417
2017:05:14 21:17:30	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:18:13	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494796674/checkpoints/bestmodel.

2017:05:14 21:18:13	------ pretraining ------ 

2017:05:14 21:18:14	pretrain epoch 0
2017:05:14 21:20:15	use DataLoaderBBT to init data.
2017:05:14 21:20:15	loading preprocessed files.
2017:05:14 21:20:22	get data info.
2017:05:14 21:20:22	init batch data.
2017:05:14 21:20:22	...number of batches: 1417
2017:05:14 21:20:23	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:20:57	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494796841/checkpoints/bestmodel.

2017:05:14 21:20:57	------ pretraining ------ 

2017:05:14 21:20:58	pretrain epoch 0
2017:05:14 21:23:46	use DataLoaderBBT to init data.
2017:05:14 21:23:46	loading preprocessed files.
2017:05:14 21:23:53	get data info.
2017:05:14 21:23:53	init batch data.
2017:05:14 21:23:53	...number of batches: 1417
2017:05:14 21:23:55	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:24:30	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494797053/checkpoints/bestmodel.

2017:05:14 21:24:30	------ pretraining ------ 

2017:05:14 21:24:30	pretrain epoch 0
2017:05:14 21:40:03	use DataLoaderBBT to init data.
2017:05:14 21:40:03	loading preprocessed files.
2017:05:14 21:40:10	get data info.
2017:05:14 21:40:10	init batch data.
2017:05:14 21:40:10	...number of batches: 1417
2017:05:14 21:40:11	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:40:56	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494798033/checkpoints/bestmodel.

2017:05:14 21:40:56	------ pretraining ------ 

2017:05:14 21:40:56	pretrain epoch 0
2017:05:14 21:41:49	use DataLoaderBBT to init data.
2017:05:14 21:41:49	loading preprocessed files.
2017:05:14 21:41:57	get data info.
2017:05:14 21:41:57	init batch data.
2017:05:14 21:41:57	...number of batches: 1417
2017:05:14 21:41:59	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:42:46	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494798145/checkpoints/bestmodel.

2017:05:14 21:42:46	------ pretraining ------ 

2017:05:14 21:42:46	pretrain epoch 0
2017:05:14 21:43:20	use DataLoaderBBT to init data.
2017:05:14 21:43:20	loading preprocessed files.
2017:05:14 21:43:27	get data info.
2017:05:14 21:43:27	init batch data.
2017:05:14 21:43:27	...number of batches: 1417
2017:05:14 21:43:29	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:44:13	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494798232/checkpoints/bestmodel.

2017:05:14 21:44:13	------ pretraining ------ 

2017:05:14 21:44:13	pretrain epoch 0
2017:05:14 21:48:19	use DataLoaderBBT to init data.
2017:05:14 21:48:19	loading preprocessed files.
2017:05:14 21:48:27	get data info.
2017:05:14 21:48:27	init batch data.
2017:05:14 21:48:27	...number of batches: 1417
2017:05:14 21:48:29	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:49:12	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494798532/checkpoints/bestmodel.

2017:05:14 21:49:12	------ pretraining ------ 

2017:05:14 21:49:13	pretrain epoch 0
2017:05:14 21:51:32	use DataLoaderBBT to init data.
2017:05:14 21:51:32	reading and processing the text file.
2017:05:14 21:51:32	preprocess the dataset.
2017:05:14 21:51:32	load data.
2017:05:14 21:51:32	init content from raw.
2017:05:14 21:51:32	init data from the raw dataset.
2017:05:14 21:51:32	...basic initialization
2017:05:14 21:51:32	...load the mapping dictionary.
2017:05:14 21:51:32	...load data and do mapping.
2017:05:14 21:51:34	...mask and pad the sentence.
2017:05:14 21:51:34	...statistics.
2017:05:14 21:51:34	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:51:34	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:51:34	...build valid sentence and mask.
2017:05:14 21:51:35	build a vocabulary.
2017:05:14 21:51:35	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:51:37	...mapping from index to word.
2017:05:14 21:51:37	...keep frequent words.
2017:05:14 21:51:37	...mapping from word to index.
2017:05:14 21:51:37	...map word to index.
2017:05:14 21:51:39	...save processed data to file.
2017:05:14 21:52:46	use DataLoaderBBT to init data.
2017:05:14 21:52:46	reading and processing the text file.
2017:05:14 21:52:46	preprocess the dataset.
2017:05:14 21:52:46	load data.
2017:05:14 21:52:46	init content from raw.
2017:05:14 21:52:46	init data from the raw dataset.
2017:05:14 21:52:46	...basic initialization
2017:05:14 21:52:46	...load the mapping dictionary.
2017:05:14 21:52:46	...load data and do mapping.
2017:05:14 21:52:48	...mask and pad the sentence.
2017:05:14 21:52:48	...statistics.
2017:05:14 21:52:48	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:52:48	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:52:48	...build valid sentence and mask.
2017:05:14 21:52:50	build a vocabulary.
2017:05:14 21:52:50	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:52:52	...mapping from index to word.
2017:05:14 21:52:52	...keep frequent words.
2017:05:14 21:52:52	...mapping from word to index.
2017:05:14 21:52:52	...map word to index.
2017:05:14 21:52:56	...save processed data to file.
2017:05:14 21:53:03	get data info.
2017:05:14 21:53:03	init batch data.
2017:05:14 21:53:03	...number of batches: 1417
2017:05:14 21:53:04	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:54:00	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494798818/checkpoints/bestmodel.

2017:05:14 21:54:01	------ pretraining ------ 

2017:05:14 21:54:01	pretrain epoch 0
2017:05:14 21:55:16	use DataLoaderBBT to init data.
2017:05:14 21:55:16	reading and processing the text file.
2017:05:14 21:55:16	preprocess the dataset.
2017:05:14 21:55:16	load data.
2017:05:14 21:55:16	init content from raw.
2017:05:14 21:55:16	init data from the raw dataset.
2017:05:14 21:55:16	...basic initialization
2017:05:14 21:55:16	...load the mapping dictionary.
2017:05:14 21:55:16	...load data and do mapping.
2017:05:14 21:55:17	...mask and pad the sentence.
2017:05:14 21:55:17	...statistics.
2017:05:14 21:55:17	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:55:17	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:55:17	...build valid sentence and mask.
2017:05:14 21:55:19	build a vocabulary.
2017:05:14 21:55:19	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:55:20	...mapping from index to word.
2017:05:14 21:55:21	...keep frequent words.
2017:05:14 21:55:21	...mapping from word to index.
2017:05:14 21:55:21	...map word to index.
2017:05:14 21:55:23	...save processed data to file.
2017:05:14 21:55:29	get data info.
2017:05:14 21:55:29	init batch data.
2017:05:14 21:55:29	...number of batches: 1417
2017:05:14 21:55:30	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:56:14	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494798954/checkpoints/bestmodel.

2017:05:14 21:56:14	------ pretraining ------ 

2017:05:14 21:56:14	pretrain epoch 0
2017:05:14 21:57:03	use DataLoaderBBT to init data.
2017:05:14 21:57:03	reading and processing the text file.
2017:05:14 21:57:03	preprocess the dataset.
2017:05:14 21:57:03	load data.
2017:05:14 21:57:03	init content from raw.
2017:05:14 21:57:03	init data from the raw dataset.
2017:05:14 21:57:03	...basic initialization
2017:05:14 21:57:03	...load the mapping dictionary.
2017:05:14 21:57:03	...load data and do mapping.
2017:05:14 21:57:04	...mask and pad the sentence.
2017:05:14 21:57:04	...statistics.
2017:05:14 21:57:04	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:57:04	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 21:57:04	...build valid sentence and mask.
2017:05:14 21:57:06	build a vocabulary.
2017:05:14 21:57:06	...flatmap a list of sentence list to a list of sentence.
2017:05:14 21:57:08	...mapping from index to word.
2017:05:14 21:57:08	...keep frequent words.
2017:05:14 21:57:08	...mapping from word to index.
2017:05:14 21:57:08	...map word to index.
2017:05:14 21:57:10	...save processed data to file.
2017:05:14 21:57:15	get data info.
2017:05:14 21:57:15	init batch data.
2017:05:14 21:57:15	...number of batches: 1417
2017:05:14 21:57:16	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 21:58:01	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494799060/checkpoints/bestmodel.

2017:05:14 21:58:01	------ pretraining ------ 

2017:05:14 21:58:01	pretrain epoch 0
2017:05:14 22:00:47	use DataLoaderBBT to init data.
2017:05:14 22:00:47	reading and processing the text file.
2017:05:14 22:00:47	preprocess the dataset.
2017:05:14 22:00:47	load data.
2017:05:14 22:00:47	init content from raw.
2017:05:14 22:00:47	init data from the raw dataset.
2017:05:14 22:00:47	...basic initialization
2017:05:14 22:00:47	...load the mapping dictionary.
2017:05:14 22:00:47	...load data and do mapping.
2017:05:14 22:00:49	...mask and pad the sentence.
2017:05:14 22:00:49	...statistics.
2017:05:14 22:00:49	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 22:00:49	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 22:00:49	...build valid sentence and mask.
2017:05:14 22:00:50	build a vocabulary.
2017:05:14 22:00:50	...flatmap a list of sentence list to a list of sentence.
2017:05:14 22:00:52	...mapping from index to word.
2017:05:14 22:00:52	...keep frequent words.
2017:05:14 22:00:52	...mapping from word to index.
2017:05:14 22:00:52	...map word to index.
2017:05:14 22:00:54	...save processed data to file.
2017:05:14 22:01:01	get data info.
2017:05:14 22:01:01	init batch data.
2017:05:14 22:01:01	...number of batches: 1417
2017:05:14 22:01:01	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:01:45	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494799285/checkpoints/bestmodel.

2017:05:14 22:01:45	------ pretraining ------ 

2017:05:14 22:01:45	pretrain epoch 0
2017:05:14 22:02:22	use DataLoaderBBT to init data.
2017:05:14 22:02:22	reading and processing the text file.
2017:05:14 22:02:22	preprocess the dataset.
2017:05:14 22:02:22	load data.
2017:05:14 22:02:22	init content from raw.
2017:05:14 22:02:22	init data from the raw dataset.
2017:05:14 22:02:22	...basic initialization
2017:05:14 22:02:22	...load the mapping dictionary.
2017:05:14 22:02:22	...load data and do mapping.
2017:05:14 22:02:23	...mask and pad the sentence.
2017:05:14 22:02:23	...statistics.
2017:05:14 22:02:23	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 22:02:23	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 22:02:23	...build valid sentence and mask.
2017:05:14 22:02:24	build a vocabulary.
2017:05:14 22:02:24	...flatmap a list of sentence list to a list of sentence.
2017:05:14 22:02:26	...mapping from index to word.
2017:05:14 22:02:26	...keep frequent words.
2017:05:14 22:02:26	...mapping from word to index.
2017:05:14 22:02:26	...map word to index.
2017:05:14 22:02:28	...save processed data to file.
2017:05:14 22:02:34	get data info.
2017:05:14 22:02:34	init batch data.
2017:05:14 22:02:34	...number of batches: 1417
2017:05:14 22:02:35	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:03:21	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494799380/checkpoints/bestmodel.

2017:05:14 22:03:21	------ pretraining ------ 

2017:05:14 22:03:21	pretrain epoch 0
2017:05:14 22:04:20	use DataLoaderBBT to init data.
2017:05:14 22:04:20	reading and processing the text file.
2017:05:14 22:04:20	preprocess the dataset.
2017:05:14 22:04:20	load data.
2017:05:14 22:04:20	init content from raw.
2017:05:14 22:04:20	init data from the raw dataset.
2017:05:14 22:04:20	...basic initialization
2017:05:14 22:04:20	...load the mapping dictionary.
2017:05:14 22:04:20	...load data and do mapping.
2017:05:14 22:04:21	...mask and pad the sentence.
2017:05:14 22:04:21	...statistics.
2017:05:14 22:04:21	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 22:04:22	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:14 22:04:22	...build valid sentence and mask.
2017:05:14 22:04:23	build a vocabulary.
2017:05:14 22:04:23	...flatmap a list of sentence list to a list of sentence.
2017:05:14 22:04:25	...mapping from index to word.
2017:05:14 22:04:25	...keep frequent words.
2017:05:14 22:04:25	...mapping from word to index.
2017:05:14 22:04:25	...map word to index.
2017:05:14 22:04:28	...save processed data to file.
2017:05:14 22:04:33	get data info.
2017:05:14 22:04:33	init batch data.
2017:05:14 22:04:33	...number of batches: 1417
2017:05:14 22:04:34	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:05:16	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494799496/checkpoints/bestmodel.

2017:05:14 22:05:16	------ pretraining ------ 

2017:05:14 22:05:16	pretrain epoch 0
2017:05:14 22:07:23	use DataLoaderBBT to init data.
2017:05:14 22:07:23	loading preprocessed files.
2017:05:14 22:07:31	get data info.
2017:05:14 22:07:31	init batch data.
2017:05:14 22:07:31	...number of batches: 1417
2017:05:14 22:07:33	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:08:17	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494799676/checkpoints/bestmodel.

2017:05:14 22:08:17	------ pretraining ------ 

2017:05:14 22:08:17	pretrain epoch 0
2017:05:14 22:09:26	use DataLoaderBBT to init data.
2017:05:14 22:09:26	loading preprocessed files.
2017:05:14 22:09:34	get data info.
2017:05:14 22:09:34	init batch data.
2017:05:14 22:09:34	...number of batches: 1417
2017:05:14 22:09:35	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:10:23	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494799802/checkpoints/bestmodel.

2017:05:14 22:10:23	------ pretraining ------ 

2017:05:14 22:10:23	pretrain epoch 0
2017:05:14 22:13:09	use DataLoaderBBT to init data.
2017:05:14 22:13:09	loading preprocessed files.
2017:05:14 22:13:16	get data info.
2017:05:14 22:13:16	init batch data.
2017:05:14 22:13:16	...number of batches: 1417
2017:05:14 22:13:18	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:14:05	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494800025/checkpoints/bestmodel.

2017:05:14 22:14:05	------ pretraining ------ 

2017:05:14 22:14:05	pretrain epoch 0
2017:05:14 22:17:35	use DataLoaderBBT to init data.
2017:05:14 22:17:35	loading preprocessed files.
2017:05:14 22:17:43	get data info.
2017:05:14 22:17:43	init batch data.
2017:05:14 22:17:43	...number of batches: 1417
2017:05:14 22:17:45	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:14 22:18:27	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494800287/checkpoints/bestmodel.

2017:05:14 22:18:27	------ pretraining ------ 

2017:05:14 22:18:27	pretrain epoch 0
2017:05:15 09:33:44	use DataLoaderBBT to init data.
2017:05:15 09:33:44	loading preprocessed files.
2017:05:15 09:33:50	get data info.
2017:05:15 09:33:50	init batch data.
2017:05:15 09:33:50	...number of batches: 3
2017:05:15 09:33:50	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:34:29	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494840852/checkpoints/bestmodel.

2017:05:15 09:34:29	------ pretraining ------ 

2017:05:15 09:34:30	pretrain epoch 0
2017:05:15 09:35:19	use DataLoaderBBT to init data.
2017:05:15 09:35:19	loading preprocessed files.
2017:05:15 09:35:27	get data info.
2017:05:15 09:35:27	init batch data.
2017:05:15 09:35:27	...number of batches: 3
2017:05:15 09:35:27	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:35:58	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494840943/checkpoints/bestmodel.

2017:05:15 09:35:58	------ pretraining ------ 

2017:05:15 09:35:58	pretrain epoch 0
2017:05:15 09:39:52	use DataLoaderBBT to init data.
2017:05:15 09:39:52	loading preprocessed files.
2017:05:15 09:39:58	get data info.
2017:05:15 09:39:58	init batch data.
2017:05:15 09:39:58	...number of batches: 3
2017:05:15 09:39:58	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:42:08	use DataLoaderBBT to init data.
2017:05:15 09:42:08	loading preprocessed files.
2017:05:15 09:42:14	get data info.
2017:05:15 09:42:14	init batch data.
2017:05:15 09:42:14	...number of batches: 2
2017:05:15 09:42:14	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:42:46	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494841350/checkpoints/bestmodel.

2017:05:15 09:42:46	------ pretraining ------ 

2017:05:15 09:42:47	pretrain epoch 0
2017:05:15 09:47:48	use DataLoaderBBT to init data.
2017:05:15 09:47:48	loading preprocessed files.
2017:05:15 09:47:54	get data info.
2017:05:15 09:47:54	init batch data.
2017:05:15 09:47:54	...number of batches: 2
2017:05:15 09:47:54	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:48:27	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494841689/checkpoints/bestmodel.

2017:05:15 09:48:27	------ pretraining ------ 

2017:05:15 09:48:27	pretrain epoch 0
2017:05:15 09:49:50	use DataLoaderBBT to init data.
2017:05:15 09:49:50	loading preprocessed files.
2017:05:15 09:49:56	get data info.
2017:05:15 09:49:56	init batch data.
2017:05:15 09:49:56	...number of batches: 2
2017:05:15 09:49:56	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:50:26	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494841811/checkpoints/bestmodel.

2017:05:15 09:50:26	------ pretraining ------ 

2017:05:15 09:50:26	pretrain epoch 0
2017:05:15 09:51:34	use DataLoaderBBT to init data.
2017:05:15 09:51:34	loading preprocessed files.
2017:05:15 09:51:40	get data info.
2017:05:15 09:51:40	init batch data.
2017:05:15 09:51:40	...number of batches: 2
2017:05:15 09:51:40	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:51:59	use DataLoaderBBT to init data.
2017:05:15 09:51:59	loading preprocessed files.
2017:05:15 09:52:06	get data info.
2017:05:15 09:52:06	init batch data.
2017:05:15 09:52:06	...number of batches: 2
2017:05:15 09:52:06	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:55:06	use DataLoaderBBT to init data.
2017:05:15 09:55:06	loading preprocessed files.
2017:05:15 09:55:12	get data info.
2017:05:15 09:55:12	init batch data.
2017:05:15 09:55:12	...number of batches: 2
2017:05:15 09:55:12	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:55:42	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842128/checkpoints/bestmodel.

2017:05:15 09:55:42	------ pretraining ------ 

2017:05:15 09:55:42	pretrain epoch 0
2017:05:15 09:56:12	use DataLoaderBBT to init data.
2017:05:15 09:56:12	loading preprocessed files.
2017:05:15 09:56:18	get data info.
2017:05:15 09:56:18	init batch data.
2017:05:15 09:56:18	...number of batches: 2
2017:05:15 09:56:18	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:56:49	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842194/checkpoints/bestmodel.

2017:05:15 09:56:49	------ pretraining ------ 

2017:05:15 09:56:50	pretrain epoch 0
2017:05:15 09:58:46	use DataLoaderBBT to init data.
2017:05:15 09:58:46	loading preprocessed files.
2017:05:15 09:58:52	get data info.
2017:05:15 09:58:52	init batch data.
2017:05:15 09:58:52	...number of batches: 2
2017:05:15 09:58:52	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 09:59:23	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842348/checkpoints/bestmodel.

2017:05:15 09:59:23	------ pretraining ------ 

2017:05:15 09:59:24	pretrain epoch 0
2017:05:15 10:02:48	use DataLoaderBBT to init data.
2017:05:15 10:02:48	loading preprocessed files.
2017:05:15 10:02:55	get data info.
2017:05:15 10:02:55	init batch data.
2017:05:15 10:02:55	...number of batches: 2
2017:05:15 10:02:55	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:03:28	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842592/checkpoints/bestmodel.

2017:05:15 10:03:28	------ pretraining ------ 

2017:05:15 10:03:28	pretrain epoch 0
2017:05:15 10:04:55	use DataLoaderBBT to init data.
2017:05:15 10:04:55	loading preprocessed files.
2017:05:15 10:05:02	get data info.
2017:05:15 10:05:02	init batch data.
2017:05:15 10:05:02	...number of batches: 2
2017:05:15 10:05:02	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:05:39	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842722/checkpoints/bestmodel.

2017:05:15 10:05:39	------ pretraining ------ 

2017:05:15 10:05:39	pretrain epoch 0
2017:05:15 10:05:53	use DataLoaderBBT to init data.
2017:05:15 10:05:53	loading preprocessed files.
2017:05:15 10:05:59	get data info.
2017:05:15 10:05:59	init batch data.
2017:05:15 10:05:59	...number of batches: 2
2017:05:15 10:05:59	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:06:31	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842775/checkpoints/bestmodel.

2017:05:15 10:06:31	------ pretraining ------ 

2017:05:15 10:06:31	pretrain epoch 0
2017:05:15 10:07:35	use DataLoaderBBT to init data.
2017:05:15 10:07:35	loading preprocessed files.
2017:05:15 10:07:41	get data info.
2017:05:15 10:07:41	init batch data.
2017:05:15 10:07:41	...number of batches: 2
2017:05:15 10:07:41	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:08:11	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494842877/checkpoints/bestmodel.

2017:05:15 10:08:11	------ pretraining ------ 

2017:05:15 10:08:11	pretrain epoch 0
2017:05:15 10:11:36	use DataLoaderBBT to init data.
2017:05:15 10:11:36	loading preprocessed files.
2017:05:15 10:11:42	get data info.
2017:05:15 10:11:42	init batch data.
2017:05:15 10:11:42	...number of batches: 2
2017:05:15 10:11:42	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:12:12	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494843118/checkpoints/bestmodel.

2017:05:15 10:12:12	------ pretraining ------ 

2017:05:15 10:12:12	pretrain epoch 0
2017:05:15 10:14:04	use DataLoaderBBT to init data.
2017:05:15 10:14:04	loading preprocessed files.
2017:05:15 10:14:10	get data info.
2017:05:15 10:14:11	init batch data.
2017:05:15 10:14:11	...number of batches: 2
2017:05:15 10:14:11	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:14:41	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494843266/checkpoints/bestmodel.

2017:05:15 10:14:41	------ pretraining ------ 

2017:05:15 10:14:41	pretrain epoch 0
2017:05:15 10:16:13	use DataLoaderBBT to init data.
2017:05:15 10:16:13	loading preprocessed files.
2017:05:15 10:16:20	get data info.
2017:05:15 10:16:20	init batch data.
2017:05:15 10:16:20	...number of batches: 2
2017:05:15 10:16:20	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:16:50	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494843395/checkpoints/bestmodel.

2017:05:15 10:16:50	------ pretraining ------ 

2017:05:15 10:16:50	pretrain epoch 0
2017:05:15 10:24:20	use DataLoaderBBT to init data.
2017:05:15 10:24:20	loading preprocessed files.
2017:05:15 10:24:26	get data info.
2017:05:15 10:24:26	init batch data.
2017:05:15 10:24:26	...number of batches: 2
2017:05:15 10:24:26	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:24:58	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494843881/checkpoints/bestmodel.

2017:05:15 10:24:58	------ pretraining ------ 

2017:05:15 10:24:58	pretrain epoch 0
2017:05:15 10:26:20	use DataLoaderBBT to init data.
2017:05:15 10:26:20	loading preprocessed files.
2017:05:15 10:26:26	get data info.
2017:05:15 10:26:26	init batch data.
2017:05:15 10:26:26	...number of batches: 2
2017:05:15 10:26:26	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:27:02	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844005/checkpoints/bestmodel.

2017:05:15 10:27:02	------ pretraining ------ 

2017:05:15 10:27:02	pretrain epoch 0
2017:05:15 10:27:06	pretrain loss d: 1.44197034836, pretrain loss g: 9.20996952057, execution speed: 2.00 seconds/batch

2017:05:15 10:27:09	save 2-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844005/checkpoints/bestmodel.

2017:05:15 10:27:09	pretrain epoch 1
2017:05:15 10:30:06	use DataLoaderBBT to init data.
2017:05:15 10:30:06	loading preprocessed files.
2017:05:15 10:30:12	get data info.
2017:05:15 10:30:12	init batch data.
2017:05:15 10:30:12	...number of batches: 2
2017:05:15 10:30:12	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:30:47	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844230/checkpoints/bestmodel.

2017:05:15 10:30:47	------ pretraining ------ 

2017:05:15 10:30:48	pretrain epoch 0
2017:05:15 10:30:52	pretrain loss d: 1.58792197704, pretrain loss g: 9.21171283722, execution speed: 2.00 seconds/batch

2017:05:15 10:30:54	save 2-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844230/checkpoints/bestmodel.

2017:05:15 10:30:54	------ training ------ 

2017:05:15 10:30:54	train epoch 1
2017:05:15 10:31:35	use DataLoaderBBT to init data.
2017:05:15 10:31:35	loading preprocessed files.
2017:05:15 10:31:41	get data info.
2017:05:15 10:31:42	init batch data.
2017:05:15 10:31:42	...number of batches: 2
2017:05:15 10:31:42	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:32:16	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844320/checkpoints/bestmodel.

2017:05:15 10:32:16	------ pretraining ------ 

2017:05:15 10:32:17	pretrain epoch 0
2017:05:15 10:32:21	pretrain loss d: 1.63139784336, pretrain loss g: 9.21169281006, execution speed: 2.00 seconds/batch

2017:05:15 10:32:23	save 2-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844320/checkpoints/bestmodel.

2017:05:15 10:32:23	------ training ------ 

2017:05:15 10:32:23	train epoch 1
2017:05:15 10:35:45	use DataLoaderBBT to init data.
2017:05:15 10:35:45	loading preprocessed files.
2017:05:15 10:35:53	get data info.
2017:05:15 10:35:53	init batch data.
2017:05:15 10:35:53	...number of batches: 2
2017:05:15 10:35:53	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 10:36:30	save 1-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844574/checkpoints/bestmodel.

2017:05:15 10:36:30	------ pretraining ------ 

2017:05:15 10:36:30	------ training ------ 

2017:05:15 10:36:30	------ save the final model ------ 

2017:05:15 10:36:32	save 2-th bestmodel to path: /home/lin/notebooks/code/demo4_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494844574/checkpoints/bestmodel.

2017:05:15 10:36:32	total execution time: 47
2017:05:15 13:52:28	use DataLoaderBBT to init data.
2017:05:15 13:52:29	loading preprocessed files.
2017:05:15 13:52:30	get data info.
2017:05:15 13:52:42	use DataLoaderBBT to init data.
2017:05:15 13:52:42	reading and processing the text file.
2017:05:15 13:52:42	preprocess the dataset.
2017:05:15 13:52:42	load data.
2017:05:15 13:52:42	init content from raw.
2017:05:15 13:52:42	init data from the raw dataset.
2017:05:15 13:52:42	...basic initialization
2017:05:15 13:52:42	...load the mapping dictionary.
2017:05:15 13:52:42	...load data and do mapping.
2017:05:15 13:52:43	...mask and pad the sentence.
2017:05:15 13:52:43	...statistics.
2017:05:15 13:52:43	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:15 13:52:43	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:15 13:52:43	...build valid sentence and mask.
2017:05:15 13:52:44	build a vocabulary.
2017:05:15 13:52:44	...flatmap a list of sentence list to a list of sentence.
2017:05:15 13:52:45	...mapping from index to word.
2017:05:15 13:52:45	...keep frequent words.
2017:05:15 13:52:45	...mapping from word to index.
2017:05:15 13:52:45	...map word to index.
2017:05:15 13:52:47	...save processed data to file.
2017:05:15 13:52:52	get data info.
2017:05:15 13:52:52	init batch data.
2017:05:15 13:52:52	...number of batches: 1107
2017:05:15 13:52:52	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 13:53:27	save 1-th bestmodel to path: /home/lin/notebooks/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494856389/checkpoints/bestmodel.

2017:05:15 13:53:27	------ pretraining ------ 

2017:05:15 13:53:27	------ training ------ 

2017:05:15 13:53:27	train epoch 1
2017:05:15 13:54:03	use DataLoaderBBT to init data.
2017:05:15 13:54:03	reading and processing the text file.
2017:05:15 13:54:03	preprocess the dataset.
2017:05:15 13:54:03	load data.
2017:05:15 13:54:03	init content from raw.
2017:05:15 13:54:03	init data from the raw dataset.
2017:05:15 13:54:03	...basic initialization
2017:05:15 13:54:03	...load the mapping dictionary.
2017:05:15 13:54:03	...load data and do mapping.
2017:05:15 13:54:04	...mask and pad the sentence.
2017:05:15 13:54:04	...statistics.
2017:05:15 13:54:04	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:15 13:54:04	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:15 13:54:04	...build valid sentence and mask.
2017:05:15 13:54:05	build a vocabulary.
2017:05:15 13:54:05	...flatmap a list of sentence list to a list of sentence.
2017:05:15 13:54:07	...mapping from index to word.
2017:05:15 13:54:07	...keep frequent words.
2017:05:15 13:54:07	...mapping from word to index.
2017:05:15 13:54:07	...map word to index.
2017:05:15 13:54:08	...save processed data to file.
2017:05:15 13:54:14	get data info.
2017:05:15 13:54:14	init batch data.
2017:05:15 13:54:14	...number of batches: 2
2017:05:15 13:54:14	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 13:54:48	save 1-th bestmodel to path: /home/lin/notebooks/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494856470/checkpoints/bestmodel.

2017:05:15 13:54:48	------ pretraining ------ 

2017:05:15 13:54:48	------ training ------ 

2017:05:15 13:54:48	train epoch 1
2017:05:15 13:56:30	use DataLoaderBBT to init data.
2017:05:15 13:56:30	reading and processing the text file.
2017:05:15 13:56:30	preprocess the dataset.
2017:05:15 13:56:30	load data.
2017:05:15 13:56:30	init content from raw.
2017:05:15 13:56:30	init data from the raw dataset.
2017:05:15 13:56:30	...basic initialization
2017:05:15 13:56:30	...load the mapping dictionary.
2017:05:15 13:56:30	...load data and do mapping.
2017:05:15 13:56:31	...mask and pad the sentence.
2017:05:15 13:56:31	...statistics.
2017:05:15 13:56:31	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:15 13:56:31	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:15 13:56:31	...build valid sentence and mask.
2017:05:15 13:56:32	build a vocabulary.
2017:05:15 13:56:32	...flatmap a list of sentence list to a list of sentence.
2017:05:15 13:56:37	use DataLoaderBBT to init data.
2017:05:15 13:56:37	loading preprocessed files.
2017:05:15 13:56:43	get data info.
2017:05:15 13:56:43	init batch data.
2017:05:15 13:56:43	...number of batches: 2
2017:05:15 13:56:43	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 13:57:25	save 1-th bestmodel to path: /home/lin/notebooks/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494856624/checkpoints/bestmodel.

2017:05:15 13:57:25	------ pretraining ------ 

2017:05:15 13:57:25	------ training ------ 

2017:05:15 13:57:25	train epoch 1
2017:05:15 13:58:35	use DataLoaderBBT to init data.
2017:05:15 13:58:35	loading preprocessed files.
2017:05:15 13:58:41	get data info.
2017:05:15 13:58:41	init batch data.
2017:05:15 13:58:41	...number of batches: 2
2017:05:15 13:58:41	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 13:59:12	save 1-th bestmodel to path: /home/lin/notebooks/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494856737/checkpoints/bestmodel.

2017:05:15 13:59:12	------ pretraining ------ 

2017:05:15 13:59:12	------ training ------ 

2017:05:15 13:59:12	train epoch 1
2017:05:15 13:59:22	train loss d: -0.0223626606166, train loss g: 0.0151278208941, execution speed: 4.50 seconds/batch
2017:05:15 13:59:25	val loss d: -0.0257744193077, val loss g: 0.0132428677753, execution speed: 1.00 seconds/batch

2017:05:15 13:59:25	train epoch 2
2017:05:15 13:59:31	use DataLoaderBBT to init data.
2017:05:15 13:59:31	loading preprocessed files.
2017:05:15 13:59:38	get data info.
2017:05:15 13:59:38	init batch data.
2017:05:15 13:59:38	...number of batches: 1107
2017:05:15 13:59:39	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:15 14:00:16	save 1-th bestmodel to path: /home/lin/notebooks/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494856798/checkpoints/bestmodel.

2017:05:15 14:00:16	------ pretraining ------ 

2017:05:15 14:00:16	------ training ------ 

2017:05:15 14:00:16	train epoch 1
2017:05:16 19:51:00	use DataLoaderBBT to init data.
2017:05:16 19:51:00	reading and processing the text file.
2017:05:16 19:51:00	preprocess the dataset.
2017:05:16 19:51:00	load data.
2017:05:16 19:51:00	init content from raw.
2017:05:16 19:51:00	init data from the raw dataset.
2017:05:16 19:51:00	...basic initialization
2017:05:16 19:51:00	...load the mapping dictionary.
2017:05:16 19:51:12	use DataLoaderBBT to init data.
2017:05:16 19:51:12	reading and processing the text file.
2017:05:16 19:51:12	preprocess the dataset.
2017:05:16 19:51:12	load data.
2017:05:16 19:51:12	init content from raw.
2017:05:16 19:51:12	init data from the raw dataset.
2017:05:16 19:51:12	...basic initialization
2017:05:16 19:51:12	...load the mapping dictionary.
2017:05:16 19:51:22	use DataLoaderBBT to init data.
2017:05:16 19:51:22	reading and processing the text file.
2017:05:16 19:51:22	preprocess the dataset.
2017:05:16 19:51:22	load data.
2017:05:16 19:51:22	init content from raw.
2017:05:16 19:51:22	init data from the raw dataset.
2017:05:16 19:51:22	...basic initialization
2017:05:16 19:51:22	...load the mapping dictionary.
2017:05:16 19:51:22	...load data and do mapping.
2017:05:16 19:51:24	...mask and pad the sentence.
2017:05:16 19:51:24	...statistics.
2017:05:16 19:51:24	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:16 19:51:24	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:16 19:51:24	...build valid sentence and mask.
2017:05:16 19:51:25	build a vocabulary.
2017:05:16 19:51:25	...flatmap a list of sentence list to a list of sentence.
2017:05:16 19:51:26	...mapping from index to word.
2017:05:16 19:51:26	...keep frequent words.
2017:05:16 19:51:26	...mapping from word to index.
2017:05:16 19:51:26	...map word to index.
2017:05:16 19:51:28	...save processed data to file.
2017:05:16 19:51:33	get data info.
2017:05:16 19:51:33	init batch data.
2017:05:16 19:51:33	...number of batches: 1107
2017:05:16 19:51:33	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 19:52:08	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964310/checkpoints/bestmodel.

2017:05:16 19:52:08	------ pretraining ------ 

2017:05:16 19:52:08	pretrain epoch 0
2017:05:16 19:53:00	use DataLoaderBBT to init data.
2017:05:16 19:53:00	reading and processing the text file.
2017:05:16 19:53:00	preprocess the dataset.
2017:05:16 19:53:00	load data.
2017:05:16 19:53:00	init content from raw.
2017:05:16 19:53:00	init data from the raw dataset.
2017:05:16 19:53:00	...basic initialization
2017:05:16 19:53:00	...load the mapping dictionary.
2017:05:16 19:53:00	...load data and do mapping.
2017:05:16 19:53:01	...mask and pad the sentence.
2017:05:16 19:53:01	...statistics.
2017:05:16 19:53:01	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:16 19:53:01	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:16 19:53:01	...build valid sentence and mask.
2017:05:16 19:53:02	build a vocabulary.
2017:05:16 19:53:02	...flatmap a list of sentence list to a list of sentence.
2017:05:16 19:53:03	...mapping from index to word.
2017:05:16 19:53:03	...keep frequent words.
2017:05:16 19:53:03	...mapping from word to index.
2017:05:16 19:53:03	...map word to index.
2017:05:16 19:53:05	...save processed data to file.
2017:05:16 19:53:09	get data info.
2017:05:16 19:53:09	init batch data.
2017:05:16 19:53:09	...number of batches: 1107
2017:05:16 19:53:10	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 19:53:44	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408/checkpoints/bestmodel.

2017:05:16 19:53:44	------ pretraining ------ 

2017:05:16 19:53:44	pretrain epoch 0
2017:05:16 19:54:28	use DataLoaderBBC to init data.
2017:05:16 19:54:28	loading preprocessed files.
2017:05:16 19:54:30	get data info.
2017:05:16 19:54:30	init batch data.
2017:05:16 19:54:30	...number of batches: 314
2017:05:16 19:54:30	num of sentence: 20096, sentence length: 25, vocab size: 25278
2017:05:16 19:54:32	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 19:54:43	use DataLoaderBBT to init data.
2017:05:16 19:54:43	loading preprocessed files.
2017:05:16 19:54:50	get data info.
2017:05:16 19:54:50	init batch data.
2017:05:16 19:54:50	...number of batches: 1107
2017:05:16 19:54:51	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 19:54:53	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:12:59	use DataLoaderBBT to init data.
2017:05:16 20:12:59	loading preprocessed files.
2017:05:16 20:13:05	get data info.
2017:05:16 20:13:05	init batch data.
2017:05:16 20:13:05	...number of batches: 1107
2017:05:16 20:13:06	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:13:08	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:20:06	use DataLoaderBBT to init data.
2017:05:16 20:20:06	loading preprocessed files.
2017:05:16 20:20:13	get data info.
2017:05:16 20:20:13	init batch data.
2017:05:16 20:20:13	...number of batches: 1107
2017:05:16 20:20:14	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:20:16	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:20:51	use DataLoaderBBT to init data.
2017:05:16 20:20:51	loading preprocessed files.
2017:05:16 20:20:57	get data info.
2017:05:16 20:20:57	init batch data.
2017:05:16 20:20:57	...number of batches: 1107
2017:05:16 20:20:58	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:21:00	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:30:42	use DataLoaderBBT to init data.
2017:05:16 20:30:42	loading preprocessed files.
2017:05:16 20:30:48	get data info.
2017:05:16 20:30:48	init batch data.
2017:05:16 20:30:48	...number of batches: 1107
2017:05:16 20:30:49	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:30:51	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:30:52	generate sentence. beam search:False.
2017:05:16 20:30:52	...decide sampling type.
2017:05:16 20:30:52	...start sampling.
2017:05:16 20:31:25	use DataLoaderBBT to init data.
2017:05:16 20:31:25	loading preprocessed files.
2017:05:16 20:31:31	get data info.
2017:05:16 20:31:31	init batch data.
2017:05:16 20:31:31	...number of batches: 1107
2017:05:16 20:31:32	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:31:34	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:31:34	generate sentence. beam search:False.
2017:05:16 20:31:34	...decide sampling type.
2017:05:16 20:31:34	...start sampling.
2017:05:16 20:39:49	use DataLoaderBBT to init data.
2017:05:16 20:39:49	loading preprocessed files.
2017:05:16 20:39:55	get data info.
2017:05:16 20:39:55	init batch data.
2017:05:16 20:39:55	...number of batches: 1107
2017:05:16 20:39:57	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:39:59	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:40:00	generate sentence. beam search:False.
2017:05:16 20:40:00	...decide sampling type.
2017:05:16 20:40:00	...start sampling.
2017:05:16 20:47:04	use DataLoaderBBT to init data.
2017:05:16 20:47:04	loading preprocessed files.
2017:05:16 20:47:11	get data info.
2017:05:16 20:47:11	init batch data.
2017:05:16 20:47:11	...number of batches: 1107
2017:05:16 20:47:13	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:47:14	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:47:15	generate sentence. beam search:False.
2017:05:16 20:47:15	...decide sampling type.
2017:05:16 20:47:15	...start sampling.
2017:05:16 20:48:49	use DataLoaderBBT to init data.
2017:05:16 20:48:49	loading preprocessed files.
2017:05:16 20:48:56	get data info.
2017:05:16 20:48:56	init batch data.
2017:05:16 20:48:56	...number of batches: 1107
2017:05:16 20:48:57	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:48:59	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:48:59	generate sentence. beam search:False.
2017:05:16 20:48:59	...decide sampling type.
2017:05:16 20:48:59	...start sampling.
2017:05:16 20:49:38	use DataLoaderBBT to init data.
2017:05:16 20:49:38	loading preprocessed files.
2017:05:16 20:49:44	get data info.
2017:05:16 20:49:44	init batch data.
2017:05:16 20:49:44	...number of batches: 1107
2017:05:16 20:49:46	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:49:47	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:49:48	generate sentence. beam search:False.
2017:05:16 20:49:48	...decide sampling type.
2017:05:16 20:49:48	...start sampling.
2017:05:16 20:49:48	true question: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:49:48	true answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:49:48	faked answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:49:48	total execution time: 9
2017:05:16 20:50:21	use DataLoaderBBT to init data.
2017:05:16 20:50:21	loading preprocessed files.
2017:05:16 20:50:28	get data info.
2017:05:16 20:50:28	init batch data.
2017:05:16 20:50:28	...number of batches: 1107
2017:05:16 20:50:30	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:50:32	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:50:48	use DataLoaderBBT to init data.
2017:05:16 20:50:48	loading preprocessed files.
2017:05:16 20:50:55	get data info.
2017:05:16 20:50:55	init batch data.
2017:05:16 20:50:55	...number of batches: 1107
2017:05:16 20:50:56	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:50:57	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:50:58	generate sentence. beam search:False.
2017:05:16 20:50:58	...decide sampling type.
2017:05:16 20:50:58	...start sampling.
2017:05:16 20:50:58	true question: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:50:58	true answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:50:58	faked answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:50:58	total execution time: 9
2017:05:16 20:51:23	use DataLoaderBBT to init data.
2017:05:16 20:51:23	loading preprocessed files.
2017:05:16 20:51:30	get data info.
2017:05:16 20:51:30	init batch data.
2017:05:16 20:51:30	...number of batches: 1107
2017:05:16 20:51:31	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:51:33	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:51:33	generate sentence. beam search:False.
2017:05:16 20:51:33	...decide sampling type.
2017:05:16 20:51:33	...start sampling.
2017:05:16 20:51:33	true question: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:51:33	true answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:51:33	faked answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:51:33	total execution time: 9
2017:05:16 20:51:58	use DataLoaderBBT to init data.
2017:05:16 20:51:58	loading preprocessed files.
2017:05:16 20:52:04	get data info.
2017:05:16 20:52:04	init batch data.
2017:05:16 20:52:04	...number of batches: 1107
2017:05:16 20:52:06	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:52:07	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:52:07	generate sentence. beam search:False.
2017:05:16 20:52:07	...decide sampling type.
2017:05:16 20:52:07	...start sampling.
2017:05:16 20:52:07	true question: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:52:07	true answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:52:07	faked answer: None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None
2017:05:16 20:52:07	total execution time: 9
2017:05:16 20:52:50	use DataLoaderBBT to init data.
2017:05:16 20:52:50	loading preprocessed files.
2017:05:16 20:52:57	get data info.
2017:05:16 20:52:57	init batch data.
2017:05:16 20:52:57	...number of batches: 1107
2017:05:16 20:52:58	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:53:00	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494964408
2017:05:16 20:53:00	generate sentence. beam search:False.
2017:05:16 20:53:00	...decide sampling type.
2017:05:16 20:53:00	...start sampling.
2017:05:16 20:53:00	true question: go uh unk balloons yes latex balloons no water balloons i will jump off the roof and unk for your car eos pad pad pad pad pad pad pad pad pad pad pad
2017:05:16 20:53:00	true answer: go [Penny] all right , what about music ? eos pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad
2017:05:16 20:53:00	faked answer: willy grisham cern fault fewer non varmints spine illusion scratched walking obviously ornament chirps hulking parched noticing region mathematics indicate virginity secondly yells scientists exaggeratedly prison necessarily kryptonite ashamed collar ant
2017:05:16 20:53:00	total execution time: 9
2017:05:16 20:53:20	use DataLoaderBBT to init data.
2017:05:16 20:53:20	loading preprocessed files.
2017:05:16 20:53:27	get data info.
2017:05:16 20:53:27	init batch data.
2017:05:16 20:53:27	...number of batches: 1107
2017:05:16 20:53:28	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:54:41	use DataLoaderBBT to init data.
2017:05:16 20:54:41	loading preprocessed files.
2017:05:16 20:54:48	get data info.
2017:05:16 20:54:48	init batch data.
2017:05:16 20:54:48	...number of batches: 1107
2017:05:16 20:54:49	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 20:55:24	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494968106/checkpoints/bestmodel.

2017:05:16 20:55:24	------ pretraining ------ 

2017:05:16 20:55:24	pretrain epoch 0
2017:05:16 21:01:36	use DataLoaderBBT to init data.
2017:05:16 21:01:36	loading preprocessed files.
2017:05:16 21:01:44	get data info.
2017:05:16 21:01:44	init batch data.
2017:05:16 21:01:44	...number of batches: 2
2017:05:16 21:01:44	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 21:01:48	use DataLoaderBBT to init data.
2017:05:16 21:01:48	loading preprocessed files.
2017:05:16 21:01:55	get data info.
2017:05:16 21:01:55	init batch data.
2017:05:16 21:01:55	...number of batches: 2
2017:05:16 21:01:55	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 21:02:31	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV1.TextGANV1/1494968535/checkpoints/bestmodel.

2017:05:16 21:02:31	------ pretraining ------ 

2017:05:16 21:02:32	pretrain epoch 0
2017:05:16 21:02:36	pretrain loss d: 1.56254172325, pretrain loss g: 9.20998001099, execution speed: 2.00 seconds/batch

2017:05:16 21:02:38	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV1.TextGANV1/1494968535/checkpoints/bestmodel.

2017:05:16 21:02:38	pretrain epoch 1
2017:05:16 21:02:42	pretrain loss d: 1.54337954521, pretrain loss g: 9.20468902588, execution speed: 1.50 seconds/batch

2017:05:16 21:02:42	pretrain epoch 2
2017:05:16 21:03:13	use DataLoaderBBT to init data.
2017:05:16 21:03:13	loading preprocessed files.
2017:05:16 21:03:20	get data info.
2017:05:16 21:03:20	init batch data.
2017:05:16 21:03:20	...number of batches: 2
2017:05:16 21:03:20	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 21:03:56	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV1.TextGANV1/1494968618/checkpoints/bestmodel.

2017:05:16 21:03:56	------ pretraining ------ 

2017:05:16 21:03:56	------ training ------ 

2017:05:16 21:03:56	train epoch 1
2017:05:16 21:04:06	train loss d: 9.78216171265, train loss g: -0.0118994247168, execution speed: 5.00 seconds/batch
2017:05:16 21:04:08	val loss d: 9.77755832672, val loss g: -0.0140985110775, execution speed: 0.50 seconds/batch

2017:05:16 21:04:08	train epoch 2
2017:05:16 21:27:32	use DataLoaderBBT to init data.
2017:05:16 21:27:32	loading preprocessed files.
2017:05:16 21:27:39	get data info.
2017:05:16 21:27:39	init batch data.
2017:05:16 21:27:39	...number of batches: 1107
2017:05:16 21:27:40	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 21:27:50	use DataLoaderBBT to init data.
2017:05:16 21:27:50	loading preprocessed files.
2017:05:16 21:27:57	get data info.
2017:05:16 21:27:57	init batch data.
2017:05:16 21:27:57	...number of batches: 2
2017:05:16 21:27:57	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:16 21:28:31	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494970094/checkpoints/bestmodel.

2017:05:16 21:28:31	------ pretraining ------ 

2017:05:16 21:28:32	pretrain epoch 0
2017:05:16 21:28:36	pretrain loss d: 1.97779619694, pretrain loss g: 9.21008396149, execution speed: 2.00 seconds/batch

2017:05:16 21:28:39	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1494970094/checkpoints/bestmodel.

2017:05:16 21:28:39	pretrain epoch 1
2017:05:16 21:28:42	pretrain loss d: 1.94815063477, pretrain loss g: 9.20442199707, execution speed: 1.50 seconds/batch

2017:05:16 21:28:42	pretrain epoch 2
2017:05:16 21:28:45	pretrain loss d: 1.92449378967, pretrain loss g: 9.19874477386, execution speed: 1.00 seconds/batch

2017:05:16 21:28:45	pretrain epoch 3
2017:05:25 13:33:19	use DataLoaderBBT to init data.
2017:05:25 13:33:19	reading and processing the text file.
2017:05:25 13:33:19	preprocess the dataset.
2017:05:25 13:33:19	load data.
2017:05:25 13:33:19	init content from raw.
2017:05:25 13:33:19	init data from the raw dataset.
2017:05:25 13:33:19	...basic initialization
2017:05:25 13:33:19	...load the mapping dictionary.
2017:05:25 13:33:19	...load data and do mapping.
2017:05:25 13:33:20	...mask and pad the sentence.
2017:05:25 13:33:20	...statistics.
2017:05:25 13:33:20	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:25 13:33:20	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:25 13:33:20	...build valid sentence and mask.
2017:05:25 13:33:22	build a vocabulary.
2017:05:25 13:33:22	...flatmap a list of sentence list to a list of sentence.
2017:05:25 13:33:23	...mapping from index to word.
2017:05:25 13:33:23	...keep frequent words.
2017:05:25 13:33:23	...mapping from word to index.
2017:05:25 13:33:23	...map word to index.
2017:05:25 13:33:25	...save processed data to file.
2017:05:25 13:33:31	get data info.
2017:05:25 13:33:31	init batch data.
2017:05:25 13:33:31	...number of batches: 1107
2017:05:25 13:33:32	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:25 13:34:08	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1495719231/checkpoints/bestmodel.

2017:05:25 13:34:08	------ pretraining ------ 

2017:05:25 13:34:08	pretrain epoch 0
2017:05:25 13:35:12	use DataLoaderBBT to init data.
2017:05:25 13:35:12	loading preprocessed files.
2017:05:25 13:35:18	get data info.
2017:05:25 13:35:18	init batch data.
2017:05:25 13:35:18	...number of batches: 1107
2017:05:25 13:35:19	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:25 13:35:55	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1495719338/checkpoints/bestmodel.

2017:05:25 13:35:55	------ pretraining ------ 

2017:05:25 13:35:55	pretrain epoch 0
2017:05:25 13:36:51	use DataLoaderBBT to init data.
2017:05:25 13:36:51	loading preprocessed files.
2017:05:25 13:36:57	get data info.
2017:05:25 13:36:57	init batch data.
2017:05:25 13:36:57	...number of batches: 1107
2017:05:25 13:36:58	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:25 13:37:46	use DataLoaderBBT to init data.
2017:05:25 13:37:46	reading and processing the text file.
2017:05:25 13:37:46	preprocess the dataset.
2017:05:25 13:37:46	load data.
2017:05:25 13:37:46	init content from raw.
2017:05:25 13:37:46	init data from the raw dataset.
2017:05:25 13:37:46	...basic initialization
2017:05:25 13:37:46	...load the mapping dictionary.
2017:05:25 13:37:46	...load data and do mapping.
2017:05:25 13:37:47	...mask and pad the sentence.
2017:05:25 13:37:47	...statistics.
2017:05:25 13:37:47	......left sentence stat: max len:33, median len:12.0, min len:3
2017:05:25 13:37:47	......right sentence stat: max len:33, median len:12.0, min len:3
2017:05:25 13:37:47	...build valid sentence and mask.
2017:05:25 13:37:48	build a vocabulary.
2017:05:25 13:37:48	...flatmap a list of sentence list to a list of sentence.
2017:05:25 13:37:49	...mapping from index to word.
2017:05:25 13:37:49	...keep frequent words.
2017:05:25 13:37:49	...mapping from word to index.
2017:05:25 13:37:49	...map word to index.
2017:05:25 13:37:51	...save processed data to file.
2017:05:25 13:37:55	get data info.
2017:05:25 13:37:55	init batch data.
2017:05:25 13:37:55	...number of batches: 1107
2017:05:25 13:37:55	# sent: 70857, sentence length: 33, vocab size: 10001
2017:05:25 13:40:12	use DataLoaderBBT to init data.
2017:05:25 13:40:12	reading and processing the text file.
2017:05:25 13:40:12	preprocess the dataset.
2017:05:25 13:40:12	load data.
2017:05:25 13:40:12	init content from raw.
2017:05:25 13:40:12	init data from the raw dataset.
2017:05:25 13:40:12	...basic initialization
2017:05:25 13:40:12	...load the mapping dictionary.
2017:05:25 13:40:12	...load data and do mapping.
2017:05:25 13:40:13	...mask and pad the sentence.
2017:05:25 13:40:13	...statistics.
2017:05:25 13:40:13	......left sentence stat: max len:30, median len:10.0, min len:3
2017:05:25 13:40:13	......right sentence stat: max len:33, median len:13.0, min len:4
2017:05:25 13:40:13	...build valid sentence and mask.
2017:05:25 13:40:13	build a vocabulary.
2017:05:25 13:40:13	...flatmap a list of sentence list to a list of sentence.
2017:05:25 13:40:14	...mapping from index to word.
2017:05:25 13:40:14	...keep frequent words.
2017:05:25 13:40:14	...mapping from word to index.
2017:05:25 13:40:14	...map word to index.
2017:05:25 13:40:15	...save processed data to file.
2017:05:25 13:40:16	get data info.
2017:05:25 13:40:16	init batch data.
2017:05:25 13:40:16	...number of batches: 553
2017:05:25 13:40:17	# sent: 35429, sentence length: 30, vocab size: 10001
2017:06:03 13:06:00	use DataLoaderBBT to init data.
2017:06:03 13:06:00	loading preprocessed files.
2017:06:03 13:57:37	use DataLoaderBBT to init data.
2017:06:03 13:57:37	loading preprocessed files.
2017:06:03 13:57:43	use DataLoaderBBT to init data.
2017:06:03 13:57:43	reading and processing the text file.
2017:06:03 13:57:43	preprocess.
2017:06:03 13:57:43	...init bucket.
2017:06:03 13:58:21	use DataLoaderBBT to init data.
2017:06:03 13:58:21	reading and processing the text file.
2017:06:03 13:58:21	preprocess.
2017:06:03 13:58:21	...init bucket.
2017:06:03 13:58:21	...load data.
2017:06:03 13:58:21	init content from raw.
2017:06:03 13:58:21	init data from the raw dataset.
2017:06:03 13:58:21	...basic initialization
2017:06:03 13:59:19	use DataLoaderBBT to init data.
2017:06:03 13:59:19	reading and processing the text file.
2017:06:03 13:59:19	preprocess.
2017:06:03 13:59:19	...init bucket.
2017:06:03 13:59:19	...load data.
2017:06:03 13:59:19	init content from raw.
2017:06:03 13:59:19	init data from the raw dataset.
2017:06:03 13:59:19	...basic initialization
2017:06:03 14:02:26	use DataLoaderBBT to init data.
2017:06:03 14:02:26	reading and processing the text file.
2017:06:03 14:02:26	preprocess.
2017:06:03 14:02:26	...init bucket.
2017:06:03 14:02:26	...load data.
2017:06:03 14:02:26	init content from raw.
2017:06:03 14:02:26	init data from the raw dataset.
2017:06:03 14:02:26	...basic initialization
2017:06:03 14:04:48	use DataLoaderBBT to init data.
2017:06:03 14:04:48	reading and processing the text file.
2017:06:03 14:04:48	preprocess.
2017:06:03 14:04:48	...init bucket.
2017:06:03 14:04:48	...load data.
2017:06:03 14:04:48	init content from raw.
2017:06:03 14:04:48	init data from the raw dataset.
2017:06:03 14:04:48	...basic initialization
2017:06:03 14:11:31	use DataLoaderBBT to init data.
2017:06:03 14:11:31	preprocess.
2017:06:03 14:11:31	...init bucket.
2017:06:03 14:11:31	...load data.
2017:06:03 14:11:31	init content from raw.
2017:06:03 14:11:31	init data from the raw dataset.
2017:06:03 14:11:31	...basic initialization
2017:06:03 14:14:01	use DataLoaderBBT to init data.
2017:06:03 14:14:01	preprocess.
2017:06:03 14:14:01	...init bucket.
2017:06:03 14:14:01	...load data.
2017:06:03 14:14:01	init content from raw.
2017:06:03 14:14:01	init data from the raw dataset.
2017:06:03 14:14:01	...basic initialization
2017:06:03 14:31:53	use DataLoaderBBT to init data.
2017:06:03 14:31:53	preprocess.
2017:06:03 14:31:53	...init bucket.
2017:06:03 14:31:53	...load data.
2017:06:03 14:31:53	init content from raw.
2017:06:03 14:31:53	init data from the raw dataset.
2017:06:03 14:31:53	...basic initialization
2017:06:03 15:42:52	use DataLoaderBBT to init data.
2017:06:03 15:42:52	preprocess.
2017:06:03 15:42:52	...init bucket.
2017:06:03 15:42:52	...load data.
2017:06:03 15:42:52	init content from raw.
2017:06:03 15:42:52	init data from the raw dataset.
2017:06:03 15:42:52	...basic initialization
2017:06:03 16:43:06	use DataLoaderBBT to init data.
2017:06:03 16:43:06	preprocess.
2017:06:03 16:43:06	...init bucket.
2017:06:03 16:43:06	...load data.
2017:06:03 16:43:06	init content from raw.
2017:06:03 16:43:06	init data from the raw dataset.
2017:06:03 16:43:06	...basic initialization
2017:06:03 16:47:59	use DataLoaderBBT to init data.
2017:06:03 16:47:59	preprocess.
2017:06:03 16:47:59	...init bucket.
2017:06:03 16:47:59	...load data.
2017:06:03 16:47:59	init content from raw.
2017:06:03 16:47:59	init data from the raw dataset.
2017:06:03 16:47:59	...basic initialization
2017:06:03 16:48:24	use DataLoaderBBT to init data.
2017:06:03 16:48:24	preprocess.
2017:06:03 16:48:24	...init bucket.
2017:06:03 16:48:24	...load data.
2017:06:03 16:48:24	init content from raw.
2017:06:03 16:48:24	init data from the raw dataset.
2017:06:03 16:48:24	...basic initialization
2017:06:03 16:49:36	use DataLoaderBBT to init data.
2017:06:03 16:49:36	preprocess.
2017:06:03 16:49:36	...init bucket.
2017:06:03 16:49:36	...load data.
2017:06:03 16:49:36	init content from raw.
2017:06:03 16:49:36	init data from the raw dataset.
2017:06:03 16:49:36	...basic initialization
2017:06:03 16:49:50	use DataLoaderBBT to init data.
2017:06:03 16:49:50	preprocess.
2017:06:03 16:49:50	...init bucket.
2017:06:03 16:49:50	...load data.
2017:06:03 16:49:50	init content from raw.
2017:06:03 16:49:50	init data from the raw dataset.
2017:06:03 16:49:50	...basic initialization
2017:06:03 16:50:04	use DataLoaderBBT to init data.
2017:06:03 16:50:04	preprocess.
2017:06:03 16:50:04	...init bucket.
2017:06:03 16:50:04	...load data.
2017:06:03 16:50:04	init content from raw.
2017:06:03 16:50:04	init data from the raw dataset.
2017:06:03 16:50:04	...basic initialization
2017:06:03 16:52:01	use DataLoaderBBT to init data.
2017:06:03 16:52:01	preprocess.
2017:06:03 16:52:01	...init bucket.
2017:06:03 16:52:01	...load data.
2017:06:03 16:52:01	init content from raw.
2017:06:03 16:52:01	init data from the raw dataset.
2017:06:03 16:52:01	...basic initialization
2017:06:03 16:52:15	use DataLoaderBBT to init data.
2017:06:03 16:52:15	preprocess.
2017:06:03 16:52:15	...init bucket.
2017:06:03 16:52:15	...load data.
2017:06:03 16:52:15	init content from raw.
2017:06:03 16:52:15	init data from the raw dataset.
2017:06:03 16:52:15	...basic initialization
2017:06:03 16:53:43	use DataLoaderBBT to init data.
2017:06:03 16:53:43	preprocess.
2017:06:03 16:53:43	...init bucket.
2017:06:03 16:53:43	...load data.
2017:06:03 16:53:43	init content from raw.
2017:06:03 16:53:43	init data from the raw dataset.
2017:06:03 16:53:43	...basic initialization
2017:06:03 16:53:53	use DataLoaderBBT to init data.
2017:06:03 16:53:53	preprocess.
2017:06:03 16:53:53	...init bucket.
2017:06:03 16:53:53	...load data.
2017:06:03 16:53:53	init content from raw.
2017:06:03 16:53:53	init data from the raw dataset.
2017:06:03 16:53:53	...basic initialization
2017:06:03 16:54:29	use DataLoaderBBT to init data.
2017:06:03 16:54:29	preprocess.
2017:06:03 16:54:29	...init bucket.
2017:06:03 16:54:29	...load data.
2017:06:03 16:54:29	init content from raw.
2017:06:03 16:54:29	init data from the raw dataset.
2017:06:03 16:54:29	...basic initialization
2017:06:03 16:55:43	use DataLoaderBBT to init data.
2017:06:03 16:55:43	preprocess.
2017:06:03 16:55:43	...init bucket.
2017:06:03 16:55:43	...load data.
2017:06:03 16:55:43	init content from raw.
2017:06:03 16:55:43	init data from the raw dataset.
2017:06:03 16:55:43	...basic initialization
2017:06:03 16:55:44	rnn type is lstm
2017:06:03 16:57:13	use DataLoaderBBT to init data.
2017:06:03 16:57:13	preprocess.
2017:06:03 16:57:13	...init bucket.
2017:06:03 16:57:13	...load data.
2017:06:03 16:57:13	init content from raw.
2017:06:03 16:57:13	init data from the raw dataset.
2017:06:03 16:57:13	...basic initialization
2017:06:03 16:57:13	rnn type is lstm
2017:06:03 16:57:57	use DataLoaderBBT to init data.
2017:06:03 16:57:57	preprocess.
2017:06:03 16:57:57	...init bucket.
2017:06:03 16:57:57	...load data.
2017:06:03 16:57:57	init content from raw.
2017:06:03 16:57:57	init data from the raw dataset.
2017:06:03 16:57:57	...basic initialization
2017:06:03 16:57:57	rnn type is lstm
2017:06:03 16:57:57	rnn type is lstm
2017:06:03 17:00:09	use DataLoaderBBT to init data.
2017:06:03 17:00:09	preprocess.
2017:06:03 17:00:09	...init bucket.
2017:06:03 17:00:09	...load data.
2017:06:03 17:00:09	init content from raw.
2017:06:03 17:00:09	init data from the raw dataset.
2017:06:03 17:00:09	...basic initialization
2017:06:03 17:00:09	rnn type is lstm
2017:06:03 17:00:09	rnn type is lstm
2017:06:03 17:00:25	use DataLoaderBBT to init data.
2017:06:03 17:00:25	preprocess.
2017:06:03 17:00:25	...init bucket.
2017:06:03 17:00:25	...load data.
2017:06:03 17:00:25	init content from raw.
2017:06:03 17:00:25	init data from the raw dataset.
2017:06:03 17:00:25	...basic initialization
2017:06:03 17:00:25	rnn type is lstm
2017:06:03 17:00:25	rnn type is lstm
2017:06:03 17:00:50	use DataLoaderBBT to init data.
2017:06:03 17:00:50	preprocess.
2017:06:03 17:00:50	...init bucket.
2017:06:03 17:00:50	...load data.
2017:06:03 17:00:50	init content from raw.
2017:06:03 17:00:50	init data from the raw dataset.
2017:06:03 17:00:50	...basic initialization
2017:06:03 17:00:51	rnn type is lstm
2017:06:03 17:00:51	rnn type is lstm
2017:06:03 17:02:58	use DataLoaderBBT to init data.
2017:06:03 17:02:58	preprocess.
2017:06:03 17:02:58	...init bucket.
2017:06:03 17:02:58	...load data.
2017:06:03 17:02:58	init content from raw.
2017:06:03 17:02:58	init data from the raw dataset.
2017:06:03 17:02:58	...basic initialization
2017:06:03 17:02:59	rnn type is lstm
2017:06:03 17:02:59	rnn type is lstm
2017:06:03 17:03:37	use DataLoaderBBT to init data.
2017:06:03 17:03:37	preprocess.
2017:06:03 17:03:37	...init bucket.
2017:06:03 17:03:37	...load data.
2017:06:03 17:03:37	init content from raw.
2017:06:03 17:03:37	init data from the raw dataset.
2017:06:03 17:03:37	...basic initialization
2017:06:03 17:03:38	rnn type is lstm
2017:06:03 17:03:38	rnn type is lstm
2017:06:03 17:03:44	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509419/checkpoints/bestmodel.

2017:06:03 17:03:44	------ save the final model ------ 

2017:06:03 17:03:46	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509419/checkpoints/bestmodel.

2017:06:03 17:03:46	total execution time: 8
2017:06:03 17:08:59	use DataLoaderBBT to init data.
2017:06:03 17:08:59	preprocess.
2017:06:03 17:08:59	...init bucket.
2017:06:03 17:08:59	...load data.
2017:06:03 17:08:59	init content from raw.
2017:06:03 17:08:59	init data from the raw dataset.
2017:06:03 17:08:59	...basic initialization
2017:06:03 17:09:00	rnn type is lstm
2017:06:03 17:09:00	rnn type is lstm
2017:06:03 17:09:04	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509741/checkpoints/bestmodel.

2017:06:03 17:09:04	------ pretraining ------ 

2017:06:03 17:09:38	use DataLoaderBBT to init data.
2017:06:03 17:09:38	preprocess.
2017:06:03 17:09:38	...init bucket.
2017:06:03 17:09:38	...load data.
2017:06:03 17:09:38	init content from raw.
2017:06:03 17:09:38	init data from the raw dataset.
2017:06:03 17:09:38	...basic initialization
2017:06:03 17:09:38	rnn type is lstm
2017:06:03 17:09:38	rnn type is lstm
2017:06:03 17:09:42	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509779/checkpoints/bestmodel.

2017:06:03 17:09:42	------ pretraining ------ 

2017:06:03 17:09:42	------ save the final model ------ 

2017:06:03 17:09:43	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509779/checkpoints/bestmodel.

2017:06:03 17:09:43	total execution time: 5
2017:06:03 17:10:26	use DataLoaderBBT to init data.
2017:06:03 17:10:26	preprocess.
2017:06:03 17:10:26	...init bucket.
2017:06:03 17:10:26	...load data.
2017:06:03 17:10:26	init content from raw.
2017:06:03 17:10:26	init data from the raw dataset.
2017:06:03 17:10:26	...basic initialization
2017:06:03 17:10:26	rnn type is lstm
2017:06:03 17:10:26	rnn type is lstm
2017:06:03 17:10:30	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509828/checkpoints/bestmodel.

2017:06:03 17:10:30	------ pretraining ------ 

2017:06:03 17:10:30	------ save the final model ------ 

2017:06:03 17:10:32	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496509828/checkpoints/bestmodel.

2017:06:03 17:10:32	total execution time: 5
2017:06:03 17:14:30	use DataLoaderBBT to init data.
2017:06:03 17:14:30	preprocess.
2017:06:03 17:14:30	...init bucket.
2017:06:03 17:14:30	...load data.
2017:06:03 17:14:30	init content from raw.
2017:06:03 17:14:30	init data from the raw dataset.
2017:06:03 17:14:30	...basic initialization
2017:06:03 17:14:30	rnn type is lstm
2017:06:03 17:14:30	rnn type is lstm
2017:06:03 17:14:34	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496510071/checkpoints/bestmodel.

2017:06:03 17:14:34	------ pretraining ------ 

2017:06:03 17:14:34	------ save the final model ------ 

2017:06:03 17:14:35	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496510071/checkpoints/bestmodel.

2017:06:03 17:14:35	total execution time: 4
2017:06:03 17:15:29	use DataLoaderBBT to init data.
2017:06:03 17:15:29	preprocess.
2017:06:03 17:15:29	...init bucket.
2017:06:03 17:15:29	...load data.
2017:06:03 17:15:29	init content from raw.
2017:06:03 17:15:29	init data from the raw dataset.
2017:06:03 17:15:29	...basic initialization
2017:06:03 17:15:30	rnn type is lstm
2017:06:03 17:15:30	rnn type is lstm
2017:06:03 17:15:33	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496510131/checkpoints/bestmodel.

2017:06:03 17:15:33	------ pretraining ------ 

2017:06:03 17:15:33	------ save the final model ------ 

2017:06:03 17:15:34	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496510131/checkpoints/bestmodel.

2017:06:03 17:15:34	total execution time: 4
2017:06:03 17:16:57	use DataLoaderBBT to init data.
2017:06:03 17:16:57	preprocess.
2017:06:03 17:16:57	...init bucket.
2017:06:03 17:16:57	...load data.
2017:06:03 17:16:57	init content from raw.
2017:06:03 17:16:57	init data from the raw dataset.
2017:06:03 17:16:57	...basic initialization
2017:06:03 17:16:58	rnn type is lstm
2017:06:03 17:16:58	rnn type is lstm
2017:06:03 17:17:01	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496510219/checkpoints/bestmodel.

2017:06:03 17:17:01	------ pretraining ------ 

2017:06:03 17:17:01	------ save the final model ------ 

2017:06:03 17:17:02	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496510219/checkpoints/bestmodel.

2017:06:03 17:17:02	total execution time: 4
2017:06:03 17:30:12	use DataLoaderBBT to init data.
2017:06:03 17:30:12	preprocess.
2017:06:03 17:30:12	...init bucket.
2017:06:03 17:30:12	...load data.
2017:06:03 17:30:12	init content from raw.
2017:06:03 17:30:12	init data from the raw dataset.
2017:06:03 17:30:12	...basic initialization
2017:06:03 17:30:13	rnn type is lstm
2017:06:03 17:30:13	rnn type is lstm
2017:06:03 17:30:18	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496511014/checkpoints/bestmodel.

2017:06:03 17:30:18	------ pretraining ------ 

2017:06:03 17:30:31	use DataLoaderBBT to init data.
2017:06:03 17:30:31	preprocess.
2017:06:03 17:30:31	...init bucket.
2017:06:03 17:30:31	...load data.
2017:06:03 17:30:31	init content from raw.
2017:06:03 17:30:31	init data from the raw dataset.
2017:06:03 17:30:31	...basic initialization
2017:06:03 17:30:31	rnn type is lstm
2017:06:03 17:30:31	rnn type is lstm
2017:06:03 17:30:37	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496511033/checkpoints/bestmodel.

2017:06:03 17:30:37	------ pretraining ------ 

2017:06:03 17:31:10	use DataLoaderBBT to init data.
2017:06:03 17:31:10	preprocess.
2017:06:03 17:31:10	...init bucket.
2017:06:03 17:31:10	...load data.
2017:06:03 17:31:10	init content from raw.
2017:06:03 17:31:10	init data from the raw dataset.
2017:06:03 17:31:10	...basic initialization
2017:06:03 17:31:11	rnn type is lstm
2017:06:03 17:31:11	rnn type is lstm
2017:06:03 17:31:15	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496511072/checkpoints/bestmodel.

2017:06:03 17:31:15	------ pretraining ------ 

2017:06:03 17:31:46	use DataLoaderBBT to init data.
2017:06:03 17:31:46	preprocess.
2017:06:03 17:31:46	...init bucket.
2017:06:03 17:31:46	...load data.
2017:06:03 17:31:46	init content from raw.
2017:06:03 17:31:46	init data from the raw dataset.
2017:06:03 17:31:46	...basic initialization
2017:06:03 17:31:47	rnn type is lstm
2017:06:03 17:31:47	rnn type is lstm
2017:06:03 17:31:53	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496511109/checkpoints/bestmodel.

2017:06:03 17:31:53	------ pretraining ------ 

2017:06:03 18:01:32	use DataLoaderBBT to init data.
2017:06:03 18:01:32	preprocess.
2017:06:03 18:01:32	...init bucket.
2017:06:03 18:01:32	...load data.
2017:06:03 18:01:32	init content from raw.
2017:06:03 18:01:32	init data from the raw dataset.
2017:06:03 18:01:32	...basic initialization
2017:06:03 18:01:32	rnn type is lstm
2017:06:03 18:01:32	rnn type is lstm
2017:06:03 18:01:57	use DataLoaderBBT to init data.
2017:06:03 18:01:57	preprocess.
2017:06:03 18:01:57	...init bucket.
2017:06:03 18:01:57	...load data.
2017:06:03 18:01:57	init content from raw.
2017:06:03 18:01:57	init data from the raw dataset.
2017:06:03 18:01:57	...basic initialization
2017:06:03 18:01:58	rnn type is lstm
2017:06:03 18:01:58	rnn type is lstm
2017:06:03 18:02:08	use DataLoaderBBT to init data.
2017:06:03 18:02:08	preprocess.
2017:06:03 18:02:08	...init bucket.
2017:06:03 18:02:08	...load data.
2017:06:03 18:02:08	init content from raw.
2017:06:03 18:02:08	init data from the raw dataset.
2017:06:03 18:02:08	...basic initialization
2017:06:03 18:02:08	rnn type is lstm
2017:06:03 18:02:08	rnn type is lstm
2017:06:03 18:03:34	use DataLoaderBBT to init data.
2017:06:03 18:03:34	preprocess.
2017:06:03 18:03:34	...init bucket.
2017:06:03 18:03:34	...load data.
2017:06:03 18:03:34	init content from raw.
2017:06:03 18:03:34	init data from the raw dataset.
2017:06:03 18:03:34	...basic initialization
2017:06:03 18:03:34	rnn type is lstm
2017:06:03 18:03:34	rnn type is lstm
2017:06:03 18:03:38	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513015/checkpoints/bestmodel.

2017:06:03 18:03:38	------ pretraining ------ 

2017:06:03 18:04:35	use DataLoaderBBT to init data.
2017:06:03 18:04:35	preprocess.
2017:06:03 18:04:35	...init bucket.
2017:06:03 18:04:35	...load data.
2017:06:03 18:04:35	init content from raw.
2017:06:03 18:04:35	init data from the raw dataset.
2017:06:03 18:04:35	...basic initialization
2017:06:03 18:04:35	rnn type is lstm
2017:06:03 18:04:35	rnn type is lstm
2017:06:03 18:04:40	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513076/checkpoints/bestmodel.

2017:06:03 18:04:40	------ pretraining ------ 

2017:06:03 18:05:10	use DataLoaderBBT to init data.
2017:06:03 18:05:10	preprocess.
2017:06:03 18:05:10	...init bucket.
2017:06:03 18:05:10	...load data.
2017:06:03 18:05:10	init content from raw.
2017:06:03 18:05:10	init data from the raw dataset.
2017:06:03 18:05:10	...basic initialization
2017:06:03 18:05:11	rnn type is lstm
2017:06:03 18:05:11	rnn type is lstm
2017:06:03 18:05:15	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513112/checkpoints/bestmodel.

2017:06:03 18:05:15	------ pretraining ------ 

2017:06:03 18:05:27	use DataLoaderBBT to init data.
2017:06:03 18:05:27	preprocess.
2017:06:03 18:05:27	...init bucket.
2017:06:03 18:05:27	...load data.
2017:06:03 18:05:27	init content from raw.
2017:06:03 18:05:27	init data from the raw dataset.
2017:06:03 18:05:27	...basic initialization
2017:06:03 18:05:28	rnn type is lstm
2017:06:03 18:05:28	rnn type is lstm
2017:06:03 18:05:33	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513129/checkpoints/bestmodel.

2017:06:03 18:05:33	------ pretraining ------ 

2017:06:03 18:08:14	use DataLoaderBBT to init data.
2017:06:03 18:08:14	preprocess.
2017:06:03 18:08:14	...init bucket.
2017:06:03 18:08:14	...load data.
2017:06:03 18:08:14	init content from raw.
2017:06:03 18:08:14	init data from the raw dataset.
2017:06:03 18:08:14	...basic initialization
2017:06:03 18:08:14	rnn type is lstm
2017:06:03 18:08:14	rnn type is lstm
2017:06:03 18:08:20	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo5_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513296/checkpoints/bestmodel.

2017:06:03 18:08:20	------ pretraining ------ 

2017:06:03 18:08:47	use DataLoaderBBT to init data.
2017:06:03 18:08:47	preprocess.
2017:06:03 18:08:47	...init bucket.
2017:06:03 18:08:47	...load data.
2017:06:03 18:08:47	init content from raw.
2017:06:03 18:08:47	init data from the raw dataset.
2017:06:03 18:08:47	...basic initialization
2017:06:03 18:08:48	rnn type is lstm
2017:06:03 18:08:48	rnn type is lstm
2017:06:03 18:08:53	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513329/checkpoints/bestmodel.

2017:06:03 18:08:53	------ pretraining ------ 

2017:06:03 18:10:12	use DataLoaderBBT to init data.
2017:06:03 18:10:12	preprocess.
2017:06:03 18:10:12	...init bucket.
2017:06:03 18:10:12	...load data.
2017:06:03 18:10:12	init content from raw.
2017:06:03 18:10:12	init data from the raw dataset.
2017:06:03 18:10:12	...basic initialization
2017:06:03 18:10:13	rnn type is lstm
2017:06:03 18:10:13	rnn type is lstm
2017:06:03 18:10:18	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513414/checkpoints/bestmodel.

2017:06:03 18:10:18	------ pretraining ------ 

2017:06:03 18:11:18	use DataLoaderBBT to init data.
2017:06:03 18:11:18	preprocess.
2017:06:03 18:11:18	...init bucket.
2017:06:03 18:11:18	...load data.
2017:06:03 18:11:18	init content from raw.
2017:06:03 18:11:18	init data from the raw dataset.
2017:06:03 18:11:18	...basic initialization
2017:06:03 18:11:19	rnn type is lstm
2017:06:03 18:11:19	rnn type is lstm
2017:06:03 18:11:23	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513480/checkpoints/bestmodel.

2017:06:03 18:11:23	------ pretraining ------ 

2017:06:03 18:12:02	use DataLoaderBBT to init data.
2017:06:03 18:12:02	preprocess.
2017:06:03 18:12:02	...init bucket.
2017:06:03 18:12:02	...load data.
2017:06:03 18:12:02	init content from raw.
2017:06:03 18:12:02	init data from the raw dataset.
2017:06:03 18:12:02	...basic initialization
2017:06:03 18:12:03	rnn type is lstm
2017:06:03 18:12:03	rnn type is lstm
2017:06:03 18:12:06	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513524/checkpoints/bestmodel.

2017:06:03 18:12:06	------ pretraining ------ 

2017:06:03 18:12:31	use DataLoaderBBT to init data.
2017:06:03 18:12:31	preprocess.
2017:06:03 18:12:31	...init bucket.
2017:06:03 18:12:31	...load data.
2017:06:03 18:12:31	init content from raw.
2017:06:03 18:12:31	init data from the raw dataset.
2017:06:03 18:12:31	...basic initialization
2017:06:03 18:12:32	rnn type is lstm
2017:06:03 18:12:32	rnn type is lstm
2017:06:03 18:12:36	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513553/checkpoints/bestmodel.

2017:06:03 18:12:36	------ pretraining ------ 

2017:06:03 18:13:45	use DataLoaderBBT to init data.
2017:06:03 18:13:45	preprocess.
2017:06:03 18:13:45	...init bucket.
2017:06:03 18:13:45	...load data.
2017:06:03 18:13:45	init content from raw.
2017:06:03 18:13:45	init data from the raw dataset.
2017:06:03 18:13:45	...basic initialization
2017:06:03 18:13:46	rnn type is lstm
2017:06:03 18:13:46	rnn type is lstm
2017:06:03 18:13:49	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513627/checkpoints/bestmodel.

2017:06:03 18:13:49	------ pretraining ------ 

2017:06:03 18:15:59	use DataLoaderBBT to init data.
2017:06:03 18:15:59	preprocess.
2017:06:03 18:15:59	...init bucket.
2017:06:03 18:15:59	...load data.
2017:06:03 18:15:59	init content from raw.
2017:06:03 18:15:59	init data from the raw dataset.
2017:06:03 18:15:59	...basic initialization
2017:06:03 18:16:00	rnn type is lstm
2017:06:03 18:16:00	rnn type is lstm
2017:06:03 18:16:04	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496513761/checkpoints/bestmodel.

2017:06:03 18:16:04	------ pretraining ------ 

2017:06:03 18:20:37	use DataLoaderBBT to init data.
2017:06:03 18:20:37	preprocess.
2017:06:03 18:20:37	...init bucket.
2017:06:03 18:20:37	...load data.
2017:06:03 18:20:37	init content from raw.
2017:06:03 18:20:37	init data from the raw dataset.
2017:06:03 18:20:37	...basic initialization
2017:06:03 18:20:38	rnn type is lstm
2017:06:03 18:20:38	rnn type is lstm
2017:06:03 18:20:41	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496514039/checkpoints/bestmodel.

2017:06:03 18:20:41	------ pretraining ------ 

2017:06:03 18:22:07	use DataLoaderBBT to init data.
2017:06:03 18:22:07	preprocess.
2017:06:03 18:22:07	...init bucket.
2017:06:03 18:22:07	...load data.
2017:06:03 18:22:07	init content from raw.
2017:06:03 18:22:07	init data from the raw dataset.
2017:06:03 18:22:07	...basic initialization
2017:06:03 18:22:08	rnn type is lstm
2017:06:03 18:22:08	rnn type is lstm
2017:06:03 18:22:11	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496514129/checkpoints/bestmodel.

2017:06:03 18:22:11	------ pretraining ------ 

2017:06:05 14:11:23	use DataLoaderBBT to init data.
2017:06:05 14:11:23	preprocess.
2017:06:05 14:11:23	...init bucket.
2017:06:05 14:11:23	...load data.
2017:06:05 14:11:23	init content from raw.
2017:06:05 14:11:23	init data from the raw dataset.
2017:06:05 14:11:23	...basic initialization
2017:06:05 14:11:23	rnn type is lstm
2017:06:05 14:11:23	rnn type is lstm
2017:06:05 14:13:08	use DataLoaderBBT to init data.
2017:06:05 14:13:08	preprocess.
2017:06:05 14:13:08	...init bucket.
2017:06:05 14:13:08	...load data.
2017:06:05 14:13:08	init content from raw.
2017:06:05 14:13:08	init data from the raw dataset.
2017:06:05 14:13:08	...basic initialization
2017:06:05 14:13:08	rnn type is lstm
2017:06:05 14:13:08	rnn type is lstm
2017:06:05 19:17:33	use DataLoaderBBT to init data.
2017:06:05 19:17:33	preprocess.
2017:06:05 19:17:33	...init bucket.
2017:06:05 19:17:54	use DataLoaderBBT to init data.
2017:06:05 19:17:54	preprocess.
2017:06:05 19:17:54	...init bucket.
2017:06:05 19:18:08	use DataLoaderBBT to init data.
2017:06:05 19:18:08	preprocess.
2017:06:05 19:18:08	...init bucket.
2017:06:05 19:18:08	...load data.
2017:06:05 19:18:08	init content from raw.
2017:06:05 19:18:08	init data from the raw dataset.
2017:06:05 19:18:08	...basic initialization
2017:06:05 19:18:09	rnn type is lstm
2017:06:05 19:18:09	rnn type is lstm
2017:06:05 19:18:14	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496690290/checkpoints/bestmodel.

2017:06:05 19:18:14	------ pretraining ------ 

2017:06:05 19:19:33	use DataLoaderBBT to init data.
2017:06:05 19:19:33	preprocess.
2017:06:05 19:19:33	...init bucket.
2017:06:05 19:19:33	...load data.
2017:06:05 19:19:33	init content from raw.
2017:06:05 19:19:33	init data from the raw dataset.
2017:06:05 19:19:33	...basic initialization
2017:06:05 19:19:34	rnn type is lstm
2017:06:05 19:19:34	rnn type is lstm
2017:06:05 19:19:37	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496690375/checkpoints/bestmodel.

2017:06:05 19:19:37	------ pretraining ------ 

2017:06:05 19:19:50	use DataLoaderBBT to init data.
2017:06:05 19:19:50	preprocess.
2017:06:05 19:19:50	...init bucket.
2017:06:05 19:19:50	...load data.
2017:06:05 19:19:50	init content from raw.
2017:06:05 19:19:50	init data from the raw dataset.
2017:06:05 19:19:50	...basic initialization
2017:06:05 19:19:50	rnn type is lstm
2017:06:05 19:19:50	rnn type is lstm
2017:06:05 19:19:55	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496690392/checkpoints/bestmodel.

2017:06:05 19:19:55	------ pretraining ------ 

2017:06:05 19:23:54	use DataLoaderBBT to init data.
2017:06:05 19:23:54	preprocess.
2017:06:05 19:23:54	...init bucket.
2017:06:05 19:23:54	...load data.
2017:06:05 19:23:54	init content from raw.
2017:06:05 19:23:54	init data from the raw dataset.
2017:06:05 19:23:54	...basic initialization
2017:06:05 19:23:54	rnn type is lstm
2017:06:05 19:23:54	rnn type is lstm
2017:06:05 19:23:58	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496690635/checkpoints/bestmodel.

2017:06:05 19:23:58	------ pretraining ------ 

2017:06:05 19:35:08	use DataLoaderBBT to init data.
2017:06:05 19:35:08	preprocess.
2017:06:05 19:35:08	...init bucket.
2017:06:05 19:35:08	...load data.
2017:06:05 19:35:08	init content from raw.
2017:06:05 19:35:08	...init data from the raw dataset.
2017:06:05 19:35:08	...read dialogues from file.
2017:06:05 19:35:39	use DataLoaderBBT to init data.
2017:06:05 19:35:39	preprocess.
2017:06:05 19:35:39	...init bucket.
2017:06:05 19:35:39	...load data.
2017:06:05 19:35:40	init content from raw.
2017:06:05 19:35:40	...init data from the raw dataset.
2017:06:05 19:35:40	...read dialogues from file.
2017:06:05 19:35:41	......number of instances: 35429
2017:06:05 19:35:41	rnn type is lstm
2017:06:05 19:35:41	rnn type is lstm
2017:06:05 19:35:46	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496691343/checkpoints/bestmodel.

2017:06:05 19:35:46	------ pretraining ------ 

2017:06:05 19:36:25	use DataLoaderBBT to init data.
2017:06:05 19:36:25	preprocess.
2017:06:05 19:36:25	...init bucket.
2017:06:05 19:36:25	...load data.
2017:06:05 19:36:25	init content from raw.
2017:06:05 19:36:25	...init data from the raw dataset.
2017:06:05 19:36:25	...read dialogues from file.
2017:06:05 19:36:26	......number of instances: 35429
2017:06:05 19:36:26	rnn type is lstm
2017:06:05 19:36:26	rnn type is lstm
2017:06:05 19:36:30	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496691387/checkpoints/bestmodel.

2017:06:05 19:36:30	------ pretraining ------ 

2017:06:05 19:37:23	use DataLoaderBBT to init data.
2017:06:05 19:37:23	preprocess.
2017:06:05 19:37:23	...init bucket.
2017:06:05 19:37:23	...load data.
2017:06:05 19:37:23	init content from raw.
2017:06:05 19:37:23	...init data from the raw dataset.
2017:06:05 19:37:23	...read dialogues from file.
2017:06:05 19:37:24	......number of instances: 35429
2017:06:05 19:37:25	rnn type is lstm
2017:06:05 19:37:25	rnn type is lstm
2017:06:05 19:37:28	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496691446/checkpoints/bestmodel.

2017:06:05 19:37:28	------ pretraining ------ 

2017:06:05 19:53:36	use DataLoaderBBT to init data.
2017:06:05 19:53:36	preprocess.
2017:06:05 19:53:36	...init bucket.
2017:06:05 19:53:36	...load data.
2017:06:05 19:53:36	init content from raw.
2017:06:05 19:53:36	...init data from the raw dataset.
2017:06:05 19:53:36	...read dialogues from file.
2017:06:05 19:53:37	......number of instances: 35429
2017:06:05 19:53:38	rnn type is lstm
2017:06:05 19:53:38	rnn type is lstm
2017:06:05 19:53:40	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496692419/checkpoints/bestmodel.

2017:06:05 19:53:40	------ pretraining ------ 

2017:06:05 19:54:02	use DataLoaderBBT to init data.
2017:06:05 19:54:02	preprocess.
2017:06:05 19:54:02	...init bucket.
2017:06:05 19:54:02	...load data.
2017:06:05 19:54:02	init content from raw.
2017:06:05 19:54:02	...init data from the raw dataset.
2017:06:05 19:54:02	...read dialogues from file.
2017:06:05 19:54:03	......number of instances: 35429
2017:06:05 19:54:03	rnn type is lstm
2017:06:05 19:54:03	rnn type is lstm
2017:06:05 19:54:09	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496692445/checkpoints/bestmodel.

2017:06:05 19:54:09	------ pretraining ------ 

2017:06:05 20:13:38	use DataLoaderBBT to init data.
2017:06:05 20:13:38	preprocess.
2017:06:05 20:13:38	...init bucket.
2017:06:05 20:13:38	...load data.
2017:06:05 20:13:38	init content from raw.
2017:06:05 20:13:38	...init data from the raw dataset.
2017:06:05 20:13:38	...read dialogues from file.
2017:06:05 20:13:39	......number of instances: 35429
2017:06:05 20:13:40	rnn type is lstm
2017:06:05 20:13:40	rnn type is lstm
2017:06:05 20:13:44	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496693621/checkpoints/bestmodel.

2017:06:05 20:13:44	------ pretraining ------ 

2017:06:05 20:15:17	use DataLoaderBBT to init data.
2017:06:05 20:15:17	preprocess.
2017:06:05 20:15:17	...init bucket.
2017:06:05 20:15:17	...load data.
2017:06:05 20:15:17	init content from raw.
2017:06:05 20:15:17	...init data from the raw dataset.
2017:06:05 20:15:17	...read dialogues from file.
2017:06:05 20:15:18	......number of instances: 35429
2017:06:05 20:15:18	rnn type is lstm
2017:06:05 20:15:18	rnn type is lstm
2017:06:05 20:15:21	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496693719/checkpoints/bestmodel.

2017:06:05 20:15:21	------ training ------ 

2017:06:05 20:15:21	train epoch 0
2017:06:05 20:21:04	use DataLoaderBBT to init data.
2017:06:05 20:21:04	preprocess.
2017:06:05 20:21:04	...init bucket.
2017:06:05 20:21:04	...load data.
2017:06:05 20:21:04	init content from raw.
2017:06:05 20:21:04	...init data from the raw dataset.
2017:06:05 20:21:04	...read dialogues from file.
2017:06:05 20:21:04	......number of instances: 35429
2017:06:05 20:21:05	rnn type is lstm
2017:06:05 20:21:05	rnn type is lstm
2017:06:05 20:21:08	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694066/checkpoints/bestmodel.

2017:06:05 20:21:08	------ training ------ 

2017:06:05 20:21:08	train epoch 0
2017:06:05 20:29:21	use DataLoaderBBT to init data.
2017:06:05 20:29:21	...init bucket.
2017:06:05 20:29:21	...load data.
2017:06:05 20:29:21	init content from raw.
2017:06:05 20:29:21	...init data from the raw dataset.
2017:06:05 20:29:21	...read dialogues from file.
2017:06:05 20:29:22	......number of instances: 35429
2017:06:05 20:29:22	rnn type is lstm
2017:06:05 20:29:22	rnn type is lstm
2017:06:05 20:29:27	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel.

2017:06:05 20:29:27	------ training ------ 

2017:06:05 20:29:27	train epoch 0
2017:06:05 21:05:43	use DataLoaderBBT to init data.
2017:06:05 21:05:43	...init bucket.
2017:06:05 21:05:43	...load data.
2017:06:05 21:05:43	init content from raw.
2017:06:05 21:05:43	...init data from the raw dataset.
2017:06:05 21:05:43	...read dialogues from file.
2017:06:05 21:05:43	......number of instances: 35429
2017:06:05 21:06:16	use DataLoaderBBT to init data.
2017:06:05 21:06:16	...init bucket.
2017:06:05 21:06:16	...load data.
2017:06:05 21:06:16	init content from raw.
2017:06:05 21:06:16	...init data from the raw dataset.
2017:06:05 21:06:16	...read dialogues from file.
2017:06:05 21:06:17	......number of instances: 35429
2017:06:05 21:06:17	rnn type is lstm
2017:06:05 21:06:17	rnn type is lstm
2017:06:05 21:06:18	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:06:18	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:08:06	use DataLoaderBBT to init data.
2017:06:05 21:08:06	...init bucket.
2017:06:05 21:08:06	...load data.
2017:06:05 21:08:06	init content from raw.
2017:06:05 21:08:06	...init data from the raw dataset.
2017:06:05 21:08:06	...read dialogues from file.
2017:06:05 21:08:07	......number of instances: 35429
2017:06:05 21:08:08	rnn type is lstm
2017:06:05 21:08:08	rnn type is lstm
2017:06:05 21:08:08	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:08:08	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:09:17	use DataLoaderBBT to init data.
2017:06:05 21:09:17	...init bucket.
2017:06:05 21:09:17	...load data.
2017:06:05 21:09:17	init content from raw.
2017:06:05 21:09:17	...init data from the raw dataset.
2017:06:05 21:09:17	...read dialogues from file.
2017:06:05 21:09:17	......number of instances: 35429
2017:06:05 21:09:18	rnn type is lstm
2017:06:05 21:09:18	rnn type is lstm
2017:06:05 21:09:18	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:09:18	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:09:58	use DataLoaderBBT to init data.
2017:06:05 21:09:58	...init bucket.
2017:06:05 21:09:58	...load data.
2017:06:05 21:09:58	init content from raw.
2017:06:05 21:09:58	...init data from the raw dataset.
2017:06:05 21:09:58	...read dialogues from file.
2017:06:05 21:09:59	......number of instances: 35429
2017:06:05 21:09:59	rnn type is lstm
2017:06:05 21:09:59	rnn type is lstm
2017:06:05 21:10:00	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:10:00	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:10:32	use DataLoaderBBT to init data.
2017:06:05 21:10:32	...init bucket.
2017:06:05 21:10:32	...load data.
2017:06:05 21:10:32	init content from raw.
2017:06:05 21:10:32	...init data from the raw dataset.
2017:06:05 21:10:32	...read dialogues from file.
2017:06:05 21:10:33	......number of instances: 35429
2017:06:05 21:10:33	rnn type is lstm
2017:06:05 21:10:33	rnn type is lstm
2017:06:05 21:10:34	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:10:34	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:12:05	use DataLoaderBBT to init data.
2017:06:05 21:12:05	...init bucket.
2017:06:05 21:12:05	...load data.
2017:06:05 21:12:05	init content from raw.
2017:06:05 21:12:05	...init data from the raw dataset.
2017:06:05 21:12:05	...read dialogues from file.
2017:06:05 21:12:06	......number of instances: 35429
2017:06:05 21:12:06	rnn type is lstm
2017:06:05 21:12:06	rnn type is lstm
2017:06:05 21:12:06	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:12:06	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:12:27	use DataLoaderBBT to init data.
2017:06:05 21:12:27	...init bucket.
2017:06:05 21:12:27	...load data.
2017:06:05 21:12:27	init content from raw.
2017:06:05 21:12:27	...init data from the raw dataset.
2017:06:05 21:12:27	...read dialogues from file.
2017:06:05 21:12:27	......number of instances: 35429
2017:06:05 21:12:28	rnn type is lstm
2017:06:05 21:12:28	rnn type is lstm
2017:06:05 21:12:28	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:12:28	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:13:08	use DataLoaderBBT to init data.
2017:06:05 21:13:08	...init bucket.
2017:06:05 21:13:08	...load data.
2017:06:05 21:13:08	init content from raw.
2017:06:05 21:13:08	...init data from the raw dataset.
2017:06:05 21:13:08	...read dialogues from file.
2017:06:05 21:13:09	......number of instances: 35429
2017:06:05 21:13:09	rnn type is lstm
2017:06:05 21:13:09	rnn type is lstm
2017:06:05 21:13:09	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:13:09	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:14:24	use DataLoaderBBT to init data.
2017:06:05 21:14:24	...init bucket.
2017:06:05 21:14:24	...load data.
2017:06:05 21:14:24	init content from raw.
2017:06:05 21:14:24	...init data from the raw dataset.
2017:06:05 21:14:24	...read dialogues from file.
2017:06:05 21:14:25	......number of instances: 35429
2017:06:05 21:14:26	rnn type is lstm
2017:06:05 21:14:26	rnn type is lstm
2017:06:05 21:14:26	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:14:26	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:15:06	use DataLoaderBBT to init data.
2017:06:05 21:15:06	...init bucket.
2017:06:05 21:15:06	...load data.
2017:06:05 21:15:06	init content from raw.
2017:06:05 21:15:06	...init data from the raw dataset.
2017:06:05 21:15:06	...read dialogues from file.
2017:06:05 21:15:06	......number of instances: 35429
2017:06:05 21:15:07	rnn type is lstm
2017:06:05 21:15:07	rnn type is lstm
2017:06:05 21:15:07	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:15:07	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:15:07	generate sentence from latent space.
2017:06:05 21:16:18	use DataLoaderBBT to init data.
2017:06:05 21:16:18	...init bucket.
2017:06:05 21:16:18	...load data.
2017:06:05 21:16:18	init content from raw.
2017:06:05 21:16:18	...init data from the raw dataset.
2017:06:05 21:16:18	...read dialogues from file.
2017:06:05 21:16:19	......number of instances: 35429
2017:06:05 21:16:20	rnn type is lstm
2017:06:05 21:16:20	rnn type is lstm
2017:06:05 21:16:20	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:16:20	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:16:20	generate sentence from latent space.
2017:06:05 21:17:03	use DataLoaderBBT to init data.
2017:06:05 21:17:03	...init bucket.
2017:06:05 21:17:03	...load data.
2017:06:05 21:17:03	init content from raw.
2017:06:05 21:17:03	...init data from the raw dataset.
2017:06:05 21:17:03	...read dialogues from file.
2017:06:05 21:17:03	......number of instances: 35429
2017:06:05 21:17:04	rnn type is lstm
2017:06:05 21:17:04	rnn type is lstm
2017:06:05 21:17:04	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:17:04	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:18:27	use DataLoaderBBT to init data.
2017:06:05 21:18:27	...init bucket.
2017:06:05 21:18:27	...load data.
2017:06:05 21:18:27	init content from raw.
2017:06:05 21:18:27	...init data from the raw dataset.
2017:06:05 21:18:27	...read dialogues from file.
2017:06:05 21:18:28	......number of instances: 35429
2017:06:05 21:18:28	rnn type is lstm
2017:06:05 21:18:28	rnn type is lstm
2017:06:05 21:18:29	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:18:29	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:19:00	use DataLoaderBBT to init data.
2017:06:05 21:19:00	...init bucket.
2017:06:05 21:19:00	...load data.
2017:06:05 21:19:00	init content from raw.
2017:06:05 21:19:00	...init data from the raw dataset.
2017:06:05 21:19:00	...read dialogues from file.
2017:06:05 21:19:00	......number of instances: 35429
2017:06:05 21:19:01	rnn type is lstm
2017:06:05 21:19:01	rnn type is lstm
2017:06:05 21:19:01	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:19:01	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:19:01	true question: [non] [non] [non] [non] room living the in be 'd we know you did how preparedness admire i much how know you but would it
2017:06:05 21:19:01	true answer: [Amy] who says this is the only one i hid ? [end] [non] [non] [non] [non]
2017:06:05 21:20:52	use DataLoaderBBT to init data.
2017:06:05 21:20:52	...init bucket.
2017:06:05 21:20:52	...load data.
2017:06:05 21:20:52	init content from raw.
2017:06:05 21:20:52	...init data from the raw dataset.
2017:06:05 21:20:52	...read dialogues from file.
2017:06:05 21:20:53	......number of instances: 35429
2017:06:05 21:20:53	rnn type is lstm
2017:06:05 21:20:53	rnn type is lstm
2017:06:05 21:20:53	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:20:53	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:20:54	generate sentence from latent space.
2017:06:05 21:21:09	true question: scientist a really 're you
2017:06:05 21:21:09	true answer: [Raj] well , astrophysicist . [end]
2017:06:05 21:21:09	faked answer: drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn
2017:06:05 21:21:09	total execution time: 16
2017:06:05 21:24:16	use DataLoaderBBT to init data.
2017:06:05 21:24:16	...init bucket.
2017:06:05 21:24:16	...load data.
2017:06:05 21:24:16	init content from raw.
2017:06:05 21:24:16	...init data from the raw dataset.
2017:06:05 21:24:16	...read dialogues from file.
2017:06:05 21:24:17	......number of instances: 35429
2017:06:05 21:24:17	rnn type is lstm
2017:06:05 21:24:17	rnn type is lstm
2017:06:05 21:24:18	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:24:18	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:24:19	generate sentence from latent space.
2017:06:05 21:24:34	true question: what
2017:06:05 21:24:34	true answer: [Howard] gimme .
2017:06:05 21:24:34	faked answer: drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn
2017:06:05 21:24:34	total execution time: 18 s
2017:06:05 21:25:10	use DataLoaderBBT to init data.
2017:06:05 21:25:10	...init bucket.
2017:06:05 21:25:10	...load data.
2017:06:05 21:25:10	init content from raw.
2017:06:05 21:25:10	...init data from the raw dataset.
2017:06:05 21:25:10	...read dialogues from file.
2017:06:05 21:25:11	......number of instances: 35429
2017:06:05 21:25:11	rnn type is lstm
2017:06:05 21:25:11	rnn type is lstm
2017:06:05 21:25:11	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/
2017:06:05 21:25:11	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496694564/checkpoints/bestmodel-0
2017:06:05 21:25:12	generate sentence from latent space.
2017:06:05 21:25:26	true question: well of course you are who else would you take
2017:06:05 21:25:26	true answer: [Leonard] penny .
2017:06:05 21:25:26	faked answer: drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn drawn
2017:06:05 21:25:26	total execution time: 15 s
2017:06:05 21:28:46	use DataLoaderBBT to init data.
2017:06:05 21:28:46	...init bucket.
2017:06:05 21:28:46	...load data.
2017:06:05 21:28:46	init content from raw.
2017:06:05 21:28:46	...init data from the raw dataset.
2017:06:05 21:28:46	...read dialogues from file.
2017:06:05 21:28:47	......number of instances: 35429
2017:06:05 21:28:47	rnn type is lstm
2017:06:05 21:28:47	rnn type is lstm
2017:06:05 21:28:50	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496698128/checkpoints/bestmodel.

2017:06:05 21:28:50	------ training ------ 

2017:06:05 21:28:50	train epoch 0
2017:06:05 21:39:36	use DataLoaderBBT to init data.
2017:06:05 21:39:36	...init bucket.
2017:06:05 21:39:36	...load data.
2017:06:05 21:39:36	init content from raw.
2017:06:05 21:39:36	...init data from the raw dataset.
2017:06:05 21:39:36	...read dialogues from file.
2017:06:05 21:39:37	......number of instances: 35429
2017:06:05 21:39:37	rnn type is lstm
2017:06:05 21:39:37	rnn type is lstm
2017:06:05 21:39:40	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496698778/checkpoints/bestmodel.

2017:06:05 21:39:40	------ training ------ 

2017:06:05 21:39:40	train epoch 0
2017:06:05 21:42:11	use DataLoaderBBT to init data.
2017:06:05 21:42:11	...init bucket.
2017:06:05 21:42:11	...load data.
2017:06:05 21:42:11	init content from raw.
2017:06:05 21:42:11	...init data from the raw dataset.
2017:06:05 21:42:11	...read dialogues from file.
2017:06:05 21:42:12	......number of instances: 35429
2017:06:05 21:42:12	rnn type is lstm
2017:06:05 21:42:12	rnn type is lstm
2017:06:05 21:42:12	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496698778
2017:06:05 21:42:12	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496698778/checkpoints/bestmodel-0
2017:06:05 21:42:14	generate sentence from latent space.
2017:06:05 21:42:29	true question: really maybe sleep has met you before
2017:06:05 21:42:29	true answer: [Sheldon] mockery ? that 's all you have to offer ?
2017:06:05 21:42:29	faked answer: diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego diego
2017:06:05 21:42:29	total execution time: 18 s
2017:06:06 09:03:57	use DataLoaderBBTV1 to init data.
2017:06:06 09:03:57	...init bucket.
2017:06:06 09:03:57	...load data.
2017:06:06 09:03:57	init content from raw.
2017:06:06 09:03:57	...init data from the raw dataset.
2017:06:06 09:03:57	...read dialogues from file.
2017:06:06 09:05:43	use DataLoaderBBTV1 to init data.
2017:06:06 09:05:43	...init bucket.
2017:06:06 09:05:43	...load data.
2017:06:06 09:05:43	init content from raw.
2017:06:06 09:05:43	...init data from the raw dataset.
2017:06:06 09:05:43	...read dialogues from file.
2017:06:06 09:10:21	use DataLoaderBBTV1 to init data.
2017:06:06 09:10:21	...init bucket.
2017:06:06 09:10:21	...load data.
2017:06:06 09:10:21	init content from raw.
2017:06:06 09:10:21	...init data from the raw dataset.
2017:06:06 09:10:21	...read dialogues from file.
2017:06:06 09:10:22	......number of instances: 70858
2017:06:06 09:10:23	rnn type is lstm
2017:06:06 09:10:23	rnn type is lstm
2017:06:06 09:10:46	use DataLoaderBBTV1 to init data.
2017:06:06 09:10:46	...init bucket.
2017:06:06 09:10:46	...load data.
2017:06:06 09:10:46	init content from raw.
2017:06:06 09:10:46	...init data from the raw dataset.
2017:06:06 09:10:46	...read dialogues from file.
2017:06:06 09:10:47	......number of instances: 70858
2017:06:06 09:10:47	rnn type is lstm
2017:06:06 09:10:47	rnn type is lstm
2017:06:06 09:10:50	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496740248/checkpoints/bestmodel.

2017:06:06 09:10:50	------ training ------ 

2017:06:06 09:10:50	train epoch 0
2017:06:06 09:15:22	use DataLoaderBBTV1 to init data.
2017:06:06 09:15:22	...init bucket.
2017:06:06 09:15:22	...load data.
2017:06:06 09:15:22	init content from raw.
2017:06:06 09:15:22	...init data from the raw dataset.
2017:06:06 09:15:22	...read dialogues from file.
2017:06:06 09:15:23	......number of instances: 70858
2017:06:06 09:15:23	rnn type is lstm
2017:06:06 09:15:23	rnn type is lstm
2017:06:06 09:15:26	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496740524/checkpoints/bestmodel.

2017:06:06 09:15:26	------ training ------ 

2017:06:06 09:15:26	train epoch 0
2017:06:06 09:30:51	use DataLoaderBBTV1 to init data.
2017:06:06 09:30:51	...init bucket.
2017:06:06 09:30:51	...load data.
2017:06:06 09:30:51	init content from raw.
2017:06:06 09:30:51	...init data from the raw dataset.
2017:06:06 09:30:51	...read dialogues from file.
2017:06:06 09:30:52	......number of instances: 70858
2017:06:06 09:30:52	rnn type is lstm
2017:06:06 09:30:52	rnn type is lstm
2017:06:06 09:30:56	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496741453/checkpoints/bestmodel.

2017:06:06 09:30:56	------ training ------ 

2017:06:06 09:30:56	train epoch 0
2017:06:06 09:42:07	use DataLoaderBBT to init data.
2017:06:06 09:42:07	...init bucket.
2017:06:06 09:42:07	...load data.
2017:06:06 09:42:07	init content from raw.
2017:06:06 09:42:07	...init data from the raw dataset.
2017:06:06 09:42:07	...read dialogues from file.
2017:06:06 09:42:08	......number of instances: 35429
2017:06:06 09:42:08	rnn type is lstm
2017:06:06 09:42:08	rnn type is lstm
2017:06:06 09:42:11	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496742129/checkpoints/bestmodel.

2017:06:06 09:42:11	------ training ------ 

2017:06:06 09:42:11	train epoch 0
2017:06:06 13:17:05	use DataLoaderBBTV1 to init data.
2017:06:06 13:17:05	...init bucket.
2017:06:06 13:17:05	...load data.
2017:06:06 13:17:05	init content from raw.
2017:06:06 13:17:05	...init data from the raw dataset.
2017:06:06 13:17:05	...read dialogues from file.
2017:06:06 13:17:06	......number of instances: 70858
2017:06:06 13:17:06	rnn type is lstmn
2017:06:06 13:17:06	rnn type is lstmn
2017:06:06 13:18:40	use DataLoaderBBTV1 to init data.
2017:06:06 13:18:40	...init bucket.
2017:06:06 13:18:40	...load data.
2017:06:06 13:18:40	init content from raw.
2017:06:06 13:18:40	...init data from the raw dataset.
2017:06:06 13:18:40	...read dialogues from file.
2017:06:06 13:18:41	......number of instances: 70858
2017:06:06 13:18:41	rnn type is lstmn
2017:06:06 13:18:41	rnn type is lstmn
2017:06:06 13:18:49	use DataLoaderBBT to init data.
2017:06:06 13:18:49	...init bucket.
2017:06:06 13:18:49	...load data.
2017:06:06 13:18:49	init content from raw.
2017:06:06 13:18:49	...init data from the raw dataset.
2017:06:06 13:18:49	...read dialogues from file.
2017:06:06 13:18:50	......number of instances: 35429
2017:06:06 13:18:50	rnn type is lstm
2017:06:06 13:18:50	rnn type is lstm
2017:06:06 13:18:53	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496755131/checkpoints/bestmodel.

2017:06:06 13:18:53	------ training ------ 

2017:06:06 13:18:53	train epoch 0
2017:06:06 13:21:05	use DataLoaderBBTV1 to init data.
2017:06:06 13:21:05	...init bucket.
2017:06:06 13:21:05	...load data.
2017:06:06 13:21:05	init content from raw.
2017:06:06 13:21:05	...init data from the raw dataset.
2017:06:06 13:21:05	...read dialogues from file.
2017:06:06 13:21:05	......number of instances: 70858
2017:06:06 13:21:05	rnn type is lstmn
2017:06:06 13:21:05	rnn type is lstmn
2017:06:06 13:22:59	use DataLoaderBBTV1 to init data.
2017:06:06 13:22:59	...init bucket.
2017:06:06 13:22:59	...load data.
2017:06:06 13:22:59	init content from raw.
2017:06:06 13:22:59	...init data from the raw dataset.
2017:06:06 13:22:59	...read dialogues from file.
2017:06:06 13:22:59	......number of instances: 70858
2017:06:06 13:25:00	use DataLoaderBBTV1 to init data.
2017:06:06 13:25:00	...init bucket.
2017:06:06 13:25:00	...load data.
2017:06:06 13:25:00	init content from raw.
2017:06:06 13:25:00	...init data from the raw dataset.
2017:06:06 13:25:00	...read dialogues from file.
2017:06:06 13:25:01	......number of instances: 70858
2017:06:06 13:25:55	use DataLoaderBBTV1 to init data.
2017:06:06 13:25:55	...init bucket.
2017:06:06 13:25:55	...load data.
2017:06:06 13:25:55	init content from raw.
2017:06:06 13:25:55	...init data from the raw dataset.
2017:06:06 13:25:55	...read dialogues from file.
2017:06:06 13:25:56	......number of instances: 70858
2017:06:06 13:25:56	rnn type is lstmn
2017:06:06 13:26:12	use DataLoaderBBTV1 to init data.
2017:06:06 13:26:12	...init bucket.
2017:06:06 13:26:12	...load data.
2017:06:06 13:26:12	init content from raw.
2017:06:06 13:26:12	...init data from the raw dataset.
2017:06:06 13:26:12	...read dialogues from file.
2017:06:06 13:26:13	......number of instances: 70858
2017:06:06 13:26:13	rnn type is lstm
2017:06:06 13:27:21	use DataLoaderBBTV1 to init data.
2017:06:06 13:27:21	...init bucket.
2017:06:06 13:27:21	...load data.
2017:06:06 13:27:21	init content from raw.
2017:06:06 13:27:21	...init data from the raw dataset.
2017:06:06 13:27:21	...read dialogues from file.
2017:06:06 13:27:21	......number of instances: 70858
2017:06:06 13:27:21	rnn type is lstmn
2017:06:06 17:08:17	use DataLoaderBBT to init data.
2017:06:06 17:08:17	...init bucket.
2017:06:06 17:08:17	...load data.
2017:06:06 17:08:17	init content from raw.
2017:06:06 17:08:17	...init data from the raw dataset.
2017:06:06 17:08:17	...read dialogues from file.
2017:06:06 17:08:18	......number of instances: 35429
2017:06:06 17:08:18	rnn type is lstm
2017:06:06 17:08:18	rnn type is lstm
2017:06:06 17:08:49	use DataLoaderBBT to init data.
2017:06:06 17:08:49	...init bucket.
2017:06:06 17:08:49	...load data.
2017:06:06 17:08:49	init content from raw.
2017:06:06 17:08:49	...init data from the raw dataset.
2017:06:06 17:08:49	...read dialogues from file.
2017:06:06 17:08:50	......number of instances: 35429
2017:06:06 17:08:51	rnn type is lstm
2017:06:06 17:08:51	rnn type is lstm
2017:06:06 17:08:55	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496768932/checkpoints/bestmodel.

2017:06:06 17:08:55	------ training ------ 

2017:06:06 17:08:55	------ pretraining ------ 

2017:06:06 17:08:55	train epoch 0
2017:06:06 17:09:12	use DataLoaderBBT to init data.
2017:06:06 17:09:12	...init bucket.
2017:06:06 17:09:12	...load data.
2017:06:06 17:09:12	init content from raw.
2017:06:06 17:09:12	...init data from the raw dataset.
2017:06:06 17:09:12	...read dialogues from file.
2017:06:06 17:09:13	......number of instances: 35429
2017:06:06 17:09:13	rnn type is lstm
2017:06:06 17:09:13	rnn type is lstm
2017:06:06 17:09:17	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496768954/checkpoints/bestmodel.

2017:06:06 17:09:17	------ pretraining ------ 

2017:06:06 17:09:17	train epoch 0
2017:06:06 17:13:00	use DataLoaderBBTV1 to init data.
2017:06:06 17:13:00	...init bucket.
2017:06:06 17:13:00	...load data.
2017:06:06 17:13:00	init content from raw.
2017:06:06 17:13:00	...init data from the raw dataset.
2017:06:06 17:13:00	...read dialogues from file.
2017:06:06 17:13:00	......number of instances: 70858
2017:06:06 17:13:18	use DataLoaderBBTV1 to init data.
2017:06:06 17:13:18	...init bucket.
2017:06:06 17:13:18	...load data.
2017:06:06 17:13:18	init content from raw.
2017:06:06 17:13:18	...init data from the raw dataset.
2017:06:06 17:13:18	...read dialogues from file.
2017:06:06 17:13:19	......number of instances: 70858
2017:06:06 17:13:19	rnn type is lstm
2017:06:06 17:13:45	use DataLoaderBBTV1 to init data.
2017:06:06 17:13:45	...init bucket.
2017:06:06 17:13:45	...load data.
2017:06:06 17:13:45	init content from raw.
2017:06:06 17:13:45	...init data from the raw dataset.
2017:06:06 17:13:45	...read dialogues from file.
2017:06:06 17:13:46	......number of instances: 70858
2017:06:06 17:13:46	rnn type is lstm
2017:06:06 17:16:59	use DataLoaderBBTV1 to init data.
2017:06:06 17:16:59	...init bucket.
2017:06:06 17:16:59	...load data.
2017:06:06 17:16:59	init content from raw.
2017:06:06 17:16:59	...init data from the raw dataset.
2017:06:06 17:16:59	...read dialogues from file.
2017:06:06 17:17:00	......number of instances: 70858
2017:06:06 17:17:00	rnn type is lstm
2017:06:06 17:18:15	use DataLoaderBBTV1 to init data.
2017:06:06 17:18:15	...init bucket.
2017:06:06 17:18:15	...load data.
2017:06:06 17:18:15	init content from raw.
2017:06:06 17:18:15	...init data from the raw dataset.
2017:06:06 17:18:15	...read dialogues from file.
2017:06:06 17:18:15	......number of instances: 70858
2017:06:06 17:18:16	rnn type is lstm
2017:06:06 17:19:23	use DataLoaderBBTV1 to init data.
2017:06:06 17:19:23	...init bucket.
2017:06:06 17:19:23	...load data.
2017:06:06 17:19:23	init content from raw.
2017:06:06 17:19:23	...init data from the raw dataset.
2017:06:06 17:19:23	...read dialogues from file.
2017:06:06 17:19:23	......number of instances: 70858
2017:06:06 17:19:24	rnn type is lstm
2017:06:06 17:19:49	use DataLoaderBBTV1 to init data.
2017:06:06 17:19:49	...init bucket.
2017:06:06 17:19:49	...load data.
2017:06:06 17:19:49	init content from raw.
2017:06:06 17:19:49	...init data from the raw dataset.
2017:06:06 17:19:49	...read dialogues from file.
2017:06:06 17:19:50	......number of instances: 70858
2017:06:06 17:19:50	rnn type is lstm
2017:06:06 17:25:50	use DataLoaderBBTV1 to init data.
2017:06:06 17:25:50	...init bucket.
2017:06:06 17:25:50	...load data.
2017:06:06 17:25:50	init content from raw.
2017:06:06 17:25:50	...init data from the raw dataset.
2017:06:06 17:25:50	...read dialogues from file.
2017:06:06 17:25:50	......number of instances: 70858
2017:06:06 17:25:51	rnn type is lstm
2017:06:06 17:25:58	use DataLoaderBBTV1 to init data.
2017:06:06 17:25:58	...init bucket.
2017:06:06 17:25:58	...load data.
2017:06:06 17:25:58	init content from raw.
2017:06:06 17:25:58	...init data from the raw dataset.
2017:06:06 17:25:58	...read dialogues from file.
2017:06:06 17:25:59	......number of instances: 70858
2017:06:06 17:25:59	rnn type is lstm
2017:06:06 17:27:32	use DataLoaderBBTV1 to init data.
2017:06:06 17:27:32	...init bucket.
2017:06:06 17:27:32	...load data.
2017:06:06 17:27:32	init content from raw.
2017:06:06 17:27:32	...init data from the raw dataset.
2017:06:06 17:27:32	...read dialogues from file.
2017:06:06 17:27:33	......number of instances: 70858
2017:06:06 17:27:33	rnn type is lstm
2017:06:06 17:37:01	use DataLoaderBBTV1 to init data.
2017:06:06 17:37:01	...init bucket.
2017:06:06 17:37:01	...load data.
2017:06:06 17:37:01	init content from raw.
2017:06:06 17:37:01	...init data from the raw dataset.
2017:06:06 17:37:01	...read dialogues from file.
2017:06:06 17:37:02	......number of instances: 70858
2017:06:06 17:37:03	rnn type is lstm
2017:06:06 18:16:46	use DataLoaderBBTV1 to init data.
2017:06:06 18:16:46	...init bucket.
2017:06:06 18:16:46	...load data.
2017:06:06 18:16:46	init content from raw.
2017:06:06 18:16:46	...init data from the raw dataset.
2017:06:06 18:16:46	...read dialogues from file.
2017:06:06 18:16:47	......number of instances: 70858
2017:06:06 18:16:48	rnn type is lstm
2017:06:06 18:18:42	use DataLoaderBBTV1 to init data.
2017:06:06 18:18:42	...init bucket.
2017:06:06 18:18:42	...load data.
2017:06:06 18:18:42	init content from raw.
2017:06:06 18:18:42	...init data from the raw dataset.
2017:06:06 18:18:42	...read dialogues from file.
2017:06:06 18:18:43	......number of instances: 70858
2017:06:06 18:18:44	rnn type is lstm
2017:06:06 18:19:20	use DataLoaderBBTV1 to init data.
2017:06:06 18:19:20	...init bucket.
2017:06:06 18:19:20	...load data.
2017:06:06 18:19:20	init content from raw.
2017:06:06 18:19:20	...init data from the raw dataset.
2017:06:06 18:19:20	...read dialogues from file.
2017:06:06 18:19:22	......number of instances: 70858
2017:06:06 18:19:22	rnn type is lstm
2017:06:06 18:37:13	use DataLoaderBBTV1 to init data.
2017:06:06 18:37:13	...init bucket.
2017:06:06 18:37:13	...load data.
2017:06:06 18:37:13	init content from raw.
2017:06:06 18:37:13	...init data from the raw dataset.
2017:06:06 18:37:13	...read dialogues from file.
2017:06:06 18:37:14	......number of instances: 70858
2017:06:06 18:37:15	rnn type is lstm
2017:06:06 18:37:27	use DataLoaderBBTV1 to init data.
2017:06:06 18:37:27	...init bucket.
2017:06:06 18:37:27	...load data.
2017:06:06 18:37:27	init content from raw.
2017:06:06 18:37:27	...init data from the raw dataset.
2017:06:06 18:37:27	...read dialogues from file.
2017:06:06 18:37:28	......number of instances: 70858
2017:06:06 18:37:28	rnn type is lstm
2017:06:06 18:43:22	use DataLoaderBBTV1 to init data.
2017:06:06 18:43:22	...init bucket.
2017:06:06 18:43:22	...load data.
2017:06:06 18:43:22	init content from raw.
2017:06:06 18:43:22	...init data from the raw dataset.
2017:06:06 18:43:22	...read dialogues from file.
2017:06:06 18:43:23	......number of instances: 70858
2017:06:06 18:43:24	rnn type is lstm
2017:06:06 18:48:09	use DataLoaderBBTV1 to init data.
2017:06:06 18:48:09	...init bucket.
2017:06:06 18:48:09	...load data.
2017:06:06 18:48:09	init content from raw.
2017:06:06 18:48:09	...init data from the raw dataset.
2017:06:06 18:48:09	...read dialogues from file.
2017:06:06 18:48:10	......number of instances: 70858
2017:06:06 18:48:10	rnn type is lstm
2017:06:06 18:49:04	use DataLoaderBBT to init data.
2017:06:06 18:49:04	...init bucket.
2017:06:06 18:49:04	...load data.
2017:06:06 18:49:04	init content from raw.
2017:06:06 18:49:04	...init data from the raw dataset.
2017:06:06 18:49:04	...read dialogues from file.
2017:06:06 18:49:05	......number of instances: 35429
2017:06:06 18:49:06	rnn type is lstm
2017:06:06 18:49:06	rnn type is lstm
2017:06:06 18:49:12	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496774947/checkpoints/bestmodel.

2017:06:06 18:49:12	------ pretraining ------ 

2017:06:06 18:49:12	train epoch 0
2017:06:06 18:50:08	use DataLoaderBBT to init data.
2017:06:06 18:50:08	...init bucket.
2017:06:06 18:50:08	...load data.
2017:06:06 18:50:08	init content from raw.
2017:06:06 18:50:08	...init data from the raw dataset.
2017:06:06 18:50:08	...read dialogues from file.
2017:06:06 18:50:10	use DataLoaderBBTV1 to init data.
2017:06:06 18:50:10	...init bucket.
2017:06:06 18:50:10	...load data.
2017:06:06 18:50:10	init content from raw.
2017:06:06 18:50:10	...init data from the raw dataset.
2017:06:06 18:50:10	...read dialogues from file.
2017:06:06 18:50:11	......number of instances: 70858
2017:06:06 18:50:12	rnn type is lstm
2017:06:06 18:57:19	use DataLoaderBBTV1 to init data.
2017:06:06 18:57:19	...init bucket.
2017:06:06 18:57:19	...load data.
2017:06:06 18:57:19	init content from raw.
2017:06:06 18:57:19	...init data from the raw dataset.
2017:06:06 18:57:19	...read dialogues from file.
2017:06:06 18:57:20	......number of instances: 70858
2017:06:06 18:57:20	rnn type is lstm
2017:06:06 18:57:45	use DataLoaderBBTV1 to init data.
2017:06:06 18:57:45	...init bucket.
2017:06:06 18:57:45	...load data.
2017:06:06 18:57:45	init content from raw.
2017:06:06 18:57:45	...init data from the raw dataset.
2017:06:06 18:57:45	...read dialogues from file.
2017:06:06 18:57:45	......number of instances: 70858
2017:06:06 18:57:46	rnn type is lstm
2017:06:06 18:57:46	rnn type is lstm
2017:06:06 18:57:58	use DataLoaderBBTV1 to init data.
2017:06:06 18:57:58	...init bucket.
2017:06:06 18:57:58	...load data.
2017:06:06 18:57:58	init content from raw.
2017:06:06 18:57:58	...init data from the raw dataset.
2017:06:06 18:57:58	...read dialogues from file.
2017:06:06 18:57:58	......number of instances: 70858
2017:06:06 18:57:59	rnn type is lstm
2017:06:06 18:57:59	rnn type is lstm
2017:06:06 18:58:47	use DataLoaderBBTV1 to init data.
2017:06:06 18:58:47	...init bucket.
2017:06:06 18:58:47	...load data.
2017:06:06 18:58:47	init content from raw.
2017:06:06 18:58:47	...init data from the raw dataset.
2017:06:06 18:58:47	...read dialogues from file.
2017:06:06 18:58:48	......number of instances: 70858
2017:06:06 18:58:48	rnn type is lstm
2017:06:06 18:58:49	rnn type is lstm
2017:06:06 18:59:16	use DataLoaderBBTV1 to init data.
2017:06:06 18:59:16	...init bucket.
2017:06:06 18:59:16	...load data.
2017:06:06 18:59:16	init content from raw.
2017:06:06 18:59:16	...init data from the raw dataset.
2017:06:06 18:59:16	...read dialogues from file.
2017:06:06 18:59:17	......number of instances: 70858
2017:06:06 18:59:18	rnn type is lstm
2017:06:06 18:59:18	rnn type is lstm
2017:06:06 19:11:22	use DataLoaderBBTV1 to init data.
2017:06:06 19:11:22	...init bucket.
2017:06:06 19:11:22	...load data.
2017:06:06 19:11:22	init content from raw.
2017:06:06 19:11:22	...init data from the raw dataset.
2017:06:06 19:11:22	...read dialogues from file.
2017:06:06 19:11:23	......number of instances: 70858
2017:06:06 19:11:23	rnn type is lstm
2017:06:06 19:11:33	use DataLoaderBBTV1 to init data.
2017:06:06 19:11:33	...init bucket.
2017:06:06 19:11:33	...load data.
2017:06:06 19:11:33	init content from raw.
2017:06:06 19:11:33	...init data from the raw dataset.
2017:06:06 19:11:33	...read dialogues from file.
2017:06:06 19:11:34	......number of instances: 70858
2017:06:06 19:11:34	rnn type is lstm
2017:06:06 19:26:14	use DataLoaderBBTV1 to init data.
2017:06:06 19:26:14	...init bucket.
2017:06:06 19:26:14	...load data.
2017:06:06 19:26:14	init content from raw.
2017:06:06 19:26:14	...init data from the raw dataset.
2017:06:06 19:26:14	...read dialogues from file.
2017:06:06 19:26:15	......number of instances: 70858
2017:06:06 19:26:15	rnn type is lstm
2017:06:06 19:26:15	rnn type is lstm
2017:06:06 19:26:25	use DataLoaderBBTV1 to init data.
2017:06:06 19:26:25	...init bucket.
2017:06:06 19:26:25	...load data.
2017:06:06 19:26:26	init content from raw.
2017:06:06 19:26:26	...init data from the raw dataset.
2017:06:06 19:26:26	...read dialogues from file.
2017:06:06 19:26:26	......number of instances: 70858
2017:06:06 19:26:27	rnn type is lstm
2017:06:06 19:26:27	rnn type is lstm
2017:06:06 19:27:37	use DataLoaderBBTV1 to init data.
2017:06:06 19:27:37	...init bucket.
2017:06:06 19:27:37	...load data.
2017:06:06 19:27:37	init content from raw.
2017:06:06 19:27:37	...init data from the raw dataset.
2017:06:06 19:27:37	...read dialogues from file.
2017:06:06 19:27:38	......number of instances: 70858
2017:06:06 19:27:38	rnn type is lstm
2017:06:06 19:27:52	use DataLoaderBBTV1 to init data.
2017:06:06 19:27:52	...init bucket.
2017:06:06 19:27:52	...load data.
2017:06:06 19:27:52	init content from raw.
2017:06:06 19:27:52	...init data from the raw dataset.
2017:06:06 19:27:52	...read dialogues from file.
2017:06:06 19:27:53	......number of instances: 70858
2017:06:06 19:27:53	rnn type is lstm
2017:06:06 19:28:09	use DataLoaderBBTV1 to init data.
2017:06:06 19:28:09	...init bucket.
2017:06:06 19:28:09	...load data.
2017:06:06 19:28:09	init content from raw.
2017:06:06 19:28:09	...init data from the raw dataset.
2017:06:06 19:28:09	...read dialogues from file.
2017:06:06 19:28:10	......number of instances: 70858
2017:06:06 19:28:11	rnn type is lstm
2017:06:06 19:29:29	use DataLoaderBBTV1 to init data.
2017:06:06 19:29:29	...init bucket.
2017:06:06 19:29:29	...load data.
2017:06:06 19:29:29	init content from raw.
2017:06:06 19:29:29	...init data from the raw dataset.
2017:06:06 19:29:29	...read dialogues from file.
2017:06:06 19:29:30	......number of instances: 70858
2017:06:06 19:29:30	rnn type is lstm
2017:06:06 19:31:18	use DataLoaderBBTV1 to init data.
2017:06:06 19:31:18	...init bucket.
2017:06:06 19:31:18	...load data.
2017:06:06 19:31:18	init content from raw.
2017:06:06 19:31:18	...init data from the raw dataset.
2017:06:06 19:31:18	...read dialogues from file.
2017:06:06 19:31:19	......number of instances: 70858
2017:06:06 19:31:20	rnn type is lstm
2017:06:06 19:31:43	use DataLoaderBBTV1 to init data.
2017:06:06 19:31:43	...init bucket.
2017:06:06 19:31:43	...load data.
2017:06:06 19:31:43	init content from raw.
2017:06:06 19:31:43	...init data from the raw dataset.
2017:06:06 19:31:43	...read dialogues from file.
2017:06:06 19:31:43	......number of instances: 70858
2017:06:06 19:31:44	rnn type is lstm
2017:06:06 19:34:30	use DataLoaderBBTV1 to init data.
2017:06:06 19:34:30	...init bucket.
2017:06:06 19:34:30	...load data.
2017:06:06 19:34:30	init content from raw.
2017:06:06 19:34:30	...init data from the raw dataset.
2017:06:06 19:34:30	...read dialogues from file.
2017:06:06 19:34:31	......number of instances: 70858
2017:06:06 19:34:31	rnn type is lstm
2017:06:06 19:35:07	use DataLoaderBBTV1 to init data.
2017:06:06 19:35:07	...init bucket.
2017:06:06 19:35:07	...load data.
2017:06:06 19:35:07	init content from raw.
2017:06:06 19:35:07	...init data from the raw dataset.
2017:06:06 19:35:07	...read dialogues from file.
2017:06:06 19:35:08	......number of instances: 70858
2017:06:06 19:35:08	rnn type is lstm
2017:06:06 19:35:21	use DataLoaderBBTV1 to init data.
2017:06:06 19:35:21	...init bucket.
2017:06:06 19:35:21	...load data.
2017:06:06 19:35:21	init content from raw.
2017:06:06 19:35:21	...init data from the raw dataset.
2017:06:06 19:35:21	...read dialogues from file.
2017:06:06 19:35:22	......number of instances: 70858
2017:06:06 19:35:22	rnn type is lstm
2017:06:06 19:36:45	use DataLoaderBBTV1 to init data.
2017:06:06 19:36:45	...init bucket.
2017:06:06 19:36:45	...load data.
2017:06:06 19:36:45	init content from raw.
2017:06:06 19:36:45	...init data from the raw dataset.
2017:06:06 19:36:45	...read dialogues from file.
2017:06:06 19:36:47	......number of instances: 70858
2017:06:06 19:36:47	rnn type is lstm
2017:06:06 19:36:50	use DataLoaderBBTV1 to init data.
2017:06:06 19:36:50	...init bucket.
2017:06:06 19:36:50	...load data.
2017:06:06 19:36:50	init content from raw.
2017:06:06 19:36:50	...init data from the raw dataset.
2017:06:06 19:36:50	...read dialogues from file.
2017:06:06 19:36:51	......number of instances: 70858
2017:06:06 19:36:51	rnn type is lstm
2017:06:06 19:38:49	use DataLoaderBBTV1 to init data.
2017:06:06 19:38:49	...init bucket.
2017:06:06 19:38:49	...load data.
2017:06:06 19:38:49	init content from raw.
2017:06:06 19:38:49	...init data from the raw dataset.
2017:06:06 19:38:49	...read dialogues from file.
2017:06:06 19:38:50	......number of instances: 70858
2017:06:06 19:38:51	rnn type is lstm
2017:06:06 19:39:40	use DataLoaderBBTV1 to init data.
2017:06:06 19:39:40	...init bucket.
2017:06:06 19:39:40	...load data.
2017:06:06 19:39:40	init content from raw.
2017:06:06 19:39:40	...init data from the raw dataset.
2017:06:06 19:39:40	...read dialogues from file.
2017:06:06 19:39:41	......number of instances: 70858
2017:06:06 19:39:41	rnn type is lstm
2017:06:06 19:39:56	use DataLoaderBBTV1 to init data.
2017:06:06 19:39:56	...init bucket.
2017:06:06 19:39:56	...load data.
2017:06:06 19:39:56	init content from raw.
2017:06:06 19:39:56	...init data from the raw dataset.
2017:06:06 19:39:56	...read dialogues from file.
2017:06:06 19:39:57	......number of instances: 70858
2017:06:06 19:39:57	rnn type is lstm
2017:06:06 19:41:13	use DataLoaderBBTV1 to init data.
2017:06:06 19:41:13	...init bucket.
2017:06:06 19:41:13	...load data.
2017:06:06 19:41:13	init content from raw.
2017:06:06 19:41:13	...init data from the raw dataset.
2017:06:06 19:41:13	...read dialogues from file.
2017:06:06 19:41:14	......number of instances: 70858
2017:06:06 19:41:14	rnn type is lstm
2017:06:06 19:41:54	use DataLoaderBBTV1 to init data.
2017:06:06 19:41:54	...init bucket.
2017:06:06 19:41:54	...load data.
2017:06:06 19:41:54	init content from raw.
2017:06:06 19:41:54	...init data from the raw dataset.
2017:06:06 19:41:54	...read dialogues from file.
2017:06:06 19:41:55	......number of instances: 70858
2017:06:06 19:41:56	rnn type is lstm
2017:06:06 19:42:31	use DataLoaderBBTV1 to init data.
2017:06:06 19:42:31	...init bucket.
2017:06:06 19:42:31	...load data.
2017:06:06 19:42:31	init content from raw.
2017:06:06 19:42:31	...init data from the raw dataset.
2017:06:06 19:42:31	...read dialogues from file.
2017:06:06 19:42:32	......number of instances: 70858
2017:06:06 19:42:32	rnn type is lstm
2017:06:06 19:44:13	use DataLoaderBBTV1 to init data.
2017:06:06 19:44:13	...init bucket.
2017:06:06 19:44:13	...load data.
2017:06:06 19:44:13	init content from raw.
2017:06:06 19:44:13	...init data from the raw dataset.
2017:06:06 19:44:13	...read dialogues from file.
2017:06:06 19:44:14	......number of instances: 70858
2017:06:06 19:44:14	rnn type is lstm
2017:06:06 19:45:46	use DataLoaderBBTV1 to init data.
2017:06:06 19:45:46	...init bucket.
2017:06:06 19:45:46	...load data.
2017:06:06 19:45:47	init content from raw.
2017:06:06 19:45:47	...init data from the raw dataset.
2017:06:06 19:45:47	...read dialogues from file.
2017:06:06 19:45:47	......number of instances: 70858
2017:06:06 19:45:48	rnn type is lstm
2017:06:06 19:45:58	use DataLoaderBBTV1 to init data.
2017:06:06 19:45:58	...init bucket.
2017:06:06 19:45:58	...load data.
2017:06:06 19:45:58	init content from raw.
2017:06:06 19:45:58	...init data from the raw dataset.
2017:06:06 19:45:58	...read dialogues from file.
2017:06:06 19:45:58	......number of instances: 70858
2017:06:06 19:45:59	rnn type is lstm
2017:06:06 19:46:43	use DataLoaderBBTV1 to init data.
2017:06:06 19:46:43	...init bucket.
2017:06:06 19:46:43	...load data.
2017:06:06 19:46:43	init content from raw.
2017:06:06 19:46:43	...init data from the raw dataset.
2017:06:06 19:46:43	...read dialogues from file.
2017:06:06 19:46:44	......number of instances: 70858
2017:06:06 19:46:44	rnn type is lstm
2017:06:06 19:46:55	use DataLoaderBBTV1 to init data.
2017:06:06 19:46:55	...init bucket.
2017:06:06 19:46:55	...load data.
2017:06:06 19:46:55	init content from raw.
2017:06:06 19:46:55	...init data from the raw dataset.
2017:06:06 19:46:55	...read dialogues from file.
2017:06:06 19:46:56	......number of instances: 70858
2017:06:06 19:46:56	rnn type is lstm
2017:06:06 19:47:15	use DataLoaderBBTV1 to init data.
2017:06:06 19:47:15	...init bucket.
2017:06:06 19:47:15	...load data.
2017:06:06 19:47:15	init content from raw.
2017:06:06 19:47:15	...init data from the raw dataset.
2017:06:06 19:47:15	...read dialogues from file.
2017:06:06 19:47:16	......number of instances: 70858
2017:06:06 19:47:16	rnn type is lstm
2017:06:06 19:47:28	use DataLoaderBBTV1 to init data.
2017:06:06 19:47:28	...init bucket.
2017:06:06 19:47:28	...load data.
2017:06:06 19:47:28	init content from raw.
2017:06:06 19:47:28	...init data from the raw dataset.
2017:06:06 19:47:28	...read dialogues from file.
2017:06:06 19:47:29	......number of instances: 70858
2017:06:06 19:47:30	rnn type is lstm
2017:06:06 19:47:54	use DataLoaderBBTV1 to init data.
2017:06:06 19:47:54	...init bucket.
2017:06:06 19:47:54	...load data.
2017:06:06 19:47:54	init content from raw.
2017:06:06 19:47:54	...init data from the raw dataset.
2017:06:06 19:47:54	...read dialogues from file.
2017:06:06 19:47:55	......number of instances: 70858
2017:06:06 19:47:55	rnn type is lstm
2017:06:06 19:49:07	use DataLoaderBBTV1 to init data.
2017:06:06 19:49:07	...init bucket.
2017:06:06 19:49:07	...load data.
2017:06:06 19:49:07	init content from raw.
2017:06:06 19:49:07	...init data from the raw dataset.
2017:06:06 19:49:07	...read dialogues from file.
2017:06:06 19:49:08	......number of instances: 70858
2017:06:06 19:49:08	rnn type is lstm
2017:06:06 19:50:33	use DataLoaderBBTV1 to init data.
2017:06:06 19:50:33	...init bucket.
2017:06:06 19:50:33	...load data.
2017:06:06 19:50:33	init content from raw.
2017:06:06 19:50:33	...init data from the raw dataset.
2017:06:06 19:50:33	...read dialogues from file.
2017:06:06 19:50:34	......number of instances: 70858
2017:06:06 19:50:35	rnn type is lstm
2017:06:06 19:50:43	use DataLoaderBBTV1 to init data.
2017:06:06 19:50:43	...init bucket.
2017:06:06 19:50:43	...load data.
2017:06:06 19:50:43	init content from raw.
2017:06:06 19:50:43	...init data from the raw dataset.
2017:06:06 19:50:43	...read dialogues from file.
2017:06:06 19:50:44	......number of instances: 70858
2017:06:06 19:50:44	rnn type is lstm
2017:06:06 19:51:07	use DataLoaderBBTV1 to init data.
2017:06:06 19:51:07	...init bucket.
2017:06:06 19:51:07	...load data.
2017:06:06 19:51:07	init content from raw.
2017:06:06 19:51:07	...init data from the raw dataset.
2017:06:06 19:51:07	...read dialogues from file.
2017:06:06 19:51:08	......number of instances: 70858
2017:06:06 19:51:09	rnn type is lstm
2017:06:06 19:51:42	use DataLoaderBBTV1 to init data.
2017:06:06 19:51:42	...init bucket.
2017:06:06 19:51:42	...load data.
2017:06:06 19:51:42	init content from raw.
2017:06:06 19:51:42	...init data from the raw dataset.
2017:06:06 19:51:42	...read dialogues from file.
2017:06:06 19:51:43	......number of instances: 70858
2017:06:06 19:51:43	rnn type is lstm
2017:06:06 19:51:58	use DataLoaderBBTV1 to init data.
2017:06:06 19:51:58	...init bucket.
2017:06:06 19:51:58	...load data.
2017:06:06 19:51:58	init content from raw.
2017:06:06 19:51:58	...init data from the raw dataset.
2017:06:06 19:51:58	...read dialogues from file.
2017:06:06 19:51:59	......number of instances: 70858
2017:06:06 19:51:59	rnn type is lstm
2017:06:06 19:53:12	use DataLoaderBBTV1 to init data.
2017:06:06 19:53:12	...init bucket.
2017:06:06 19:53:12	...load data.
2017:06:06 19:53:12	init content from raw.
2017:06:06 19:53:12	...init data from the raw dataset.
2017:06:06 19:53:12	...read dialogues from file.
2017:06:06 19:53:13	......number of instances: 70858
2017:06:06 19:53:13	rnn type is lstm
2017:06:06 19:58:40	use DataLoaderBBTV1 to init data.
2017:06:06 19:58:40	...init bucket.
2017:06:06 19:58:40	...load data.
2017:06:06 19:58:40	init content from raw.
2017:06:06 19:58:40	...init data from the raw dataset.
2017:06:06 19:58:40	...read dialogues from file.
2017:06:06 19:58:41	......number of instances: 70858
2017:06:06 20:00:16	use DataLoaderBBTV1 to init data.
2017:06:06 20:00:16	...init bucket.
2017:06:06 20:00:16	...load data.
2017:06:06 20:00:16	init content from raw.
2017:06:06 20:00:16	...init data from the raw dataset.
2017:06:06 20:00:16	...read dialogues from file.
2017:06:06 20:00:17	......number of instances: 70858
2017:06:06 20:00:43	use DataLoaderBBTV1 to init data.
2017:06:06 20:00:43	...init bucket.
2017:06:06 20:00:43	...load data.
2017:06:06 20:00:43	init content from raw.
2017:06:06 20:00:43	...init data from the raw dataset.
2017:06:06 20:00:43	...read dialogues from file.
2017:06:06 20:00:44	......number of instances: 70858
2017:06:06 20:00:45	rnn type is lstm
2017:06:06 20:01:42	use DataLoaderBBTV1 to init data.
2017:06:06 20:01:42	...init bucket.
2017:06:06 20:01:42	...load data.
2017:06:06 20:01:42	init content from raw.
2017:06:06 20:01:42	...init data from the raw dataset.
2017:06:06 20:01:42	...read dialogues from file.
2017:06:06 20:01:43	......number of instances: 70858
2017:06:06 20:01:43	rnn type is lstm
2017:06:06 20:04:08	use DataLoaderBBTV1 to init data.
2017:06:06 20:04:08	...init bucket.
2017:06:06 20:04:08	...load data.
2017:06:06 20:04:08	init content from raw.
2017:06:06 20:04:08	...init data from the raw dataset.
2017:06:06 20:04:08	...read dialogues from file.
2017:06:06 20:04:10	......number of instances: 70858
2017:06:06 20:04:10	rnn type is lstm
2017:06:06 20:12:31	use DataLoaderBBTV1 to init data.
2017:06:06 20:12:31	...init bucket.
2017:06:06 20:12:31	...load data.
2017:06:06 20:12:31	init content from raw.
2017:06:06 20:12:31	...init data from the raw dataset.
2017:06:06 20:12:31	...read dialogues from file.
2017:06:06 20:12:31	......number of instances: 70858
2017:06:06 20:12:32	rnn type is lstm
2017:06:06 20:13:39	use DataLoaderBBTV1 to init data.
2017:06:06 20:13:39	...init bucket.
2017:06:06 20:13:39	...load data.
2017:06:06 20:13:39	init content from raw.
2017:06:06 20:13:39	...init data from the raw dataset.
2017:06:06 20:13:39	...read dialogues from file.
2017:06:06 20:13:39	......number of instances: 70858
2017:06:06 20:13:40	rnn type is lstm
2017:06:06 20:14:18	use DataLoaderBBTV1 to init data.
2017:06:06 20:14:18	...init bucket.
2017:06:06 20:14:18	...load data.
2017:06:06 20:14:18	init content from raw.
2017:06:06 20:14:18	...init data from the raw dataset.
2017:06:06 20:14:18	...read dialogues from file.
2017:06:06 20:14:19	......number of instances: 70858
2017:06:06 20:14:20	rnn type is lstm
2017:06:06 20:15:37	use DataLoaderBBTV1 to init data.
2017:06:06 20:15:37	...init bucket.
2017:06:06 20:15:37	...load data.
2017:06:06 20:15:37	init content from raw.
2017:06:06 20:15:37	...init data from the raw dataset.
2017:06:06 20:15:37	...read dialogues from file.
2017:06:06 20:15:38	......number of instances: 70858
2017:06:06 20:15:38	rnn type is lstm
2017:06:06 20:16:00	use DataLoaderBBTV1 to init data.
2017:06:06 20:16:00	...init bucket.
2017:06:06 20:16:00	...load data.
2017:06:06 20:16:00	init content from raw.
2017:06:06 20:16:00	...init data from the raw dataset.
2017:06:06 20:16:00	...read dialogues from file.
2017:06:06 20:16:01	......number of instances: 70858
2017:06:06 20:16:01	rnn type is lstm
2017:06:06 20:17:10	use DataLoaderBBTV1 to init data.
2017:06:06 20:17:10	...init bucket.
2017:06:06 20:17:10	...load data.
2017:06:06 20:17:10	init content from raw.
2017:06:06 20:17:10	...init data from the raw dataset.
2017:06:06 20:17:10	...read dialogues from file.
2017:06:06 20:17:11	......number of instances: 70858
2017:06:06 20:17:11	rnn type is lstm
2017:06:06 20:19:25	use DataLoaderBBTV1 to init data.
2017:06:06 20:19:25	...init bucket.
2017:06:06 20:19:25	...load data.
2017:06:06 20:19:25	init content from raw.
2017:06:06 20:19:25	...init data from the raw dataset.
2017:06:06 20:19:25	...read dialogues from file.
2017:06:06 20:19:26	......number of instances: 70858
2017:06:06 20:19:26	rnn type is lstm
2017:06:06 20:19:34	use DataLoaderBBTV1 to init data.
2017:06:06 20:19:34	...init bucket.
2017:06:06 20:19:34	...load data.
2017:06:06 20:19:34	init content from raw.
2017:06:06 20:19:34	...init data from the raw dataset.
2017:06:06 20:19:34	...read dialogues from file.
2017:06:06 20:19:35	......number of instances: 70858
2017:06:06 20:19:35	rnn type is lstm
2017:06:06 20:19:35	rnn type is lstm
2017:06:06 20:22:01	use DataLoaderBBTV1 to init data.
2017:06:06 20:22:01	...init bucket.
2017:06:06 20:22:01	...load data.
2017:06:06 20:22:01	init content from raw.
2017:06:06 20:22:01	...init data from the raw dataset.
2017:06:06 20:22:01	...read dialogues from file.
2017:06:06 20:22:02	......number of instances: 70858
2017:06:06 20:22:02	rnn type is lstm
2017:06:06 20:22:03	rnn type is lstm
2017:06:06 20:22:20	use DataLoaderBBTV1 to init data.
2017:06:06 20:22:20	...init bucket.
2017:06:06 20:22:20	...load data.
2017:06:06 20:22:20	init content from raw.
2017:06:06 20:22:20	...init data from the raw dataset.
2017:06:06 20:22:20	...read dialogues from file.
2017:06:06 20:22:21	......number of instances: 70858
2017:06:06 20:22:21	rnn type is lstm
2017:06:06 20:22:22	rnn type is lstm
2017:06:06 20:22:50	use DataLoaderBBTV1 to init data.
2017:06:06 20:22:50	...init bucket.
2017:06:06 20:22:50	...load data.
2017:06:06 20:22:50	init content from raw.
2017:06:06 20:22:50	...init data from the raw dataset.
2017:06:06 20:22:50	...read dialogues from file.
2017:06:06 20:22:51	......number of instances: 70858
2017:06:06 20:22:51	rnn type is lstm
2017:06:06 20:22:51	rnn type is lstm
2017:06:06 20:23:03	use DataLoaderBBTV1 to init data.
2017:06:06 20:23:03	...init bucket.
2017:06:06 20:23:03	...load data.
2017:06:06 20:23:03	init content from raw.
2017:06:06 20:23:03	...init data from the raw dataset.
2017:06:06 20:23:03	...read dialogues from file.
2017:06:06 20:23:04	......number of instances: 70858
2017:06:06 20:23:04	rnn type is lstm
2017:06:06 20:23:04	rnn type is lstm
2017:06:06 20:23:23	use DataLoaderBBTV1 to init data.
2017:06:06 20:23:23	...init bucket.
2017:06:06 20:23:23	...load data.
2017:06:06 20:23:23	init content from raw.
2017:06:06 20:23:23	...init data from the raw dataset.
2017:06:06 20:23:23	...read dialogues from file.
2017:06:06 20:23:24	......number of instances: 70858
2017:06:06 20:23:25	rnn type is lstm
2017:06:06 20:23:25	rnn type is lstm
2017:06:06 20:23:51	use DataLoaderBBTV1 to init data.
2017:06:06 20:23:51	...init bucket.
2017:06:06 20:23:51	...load data.
2017:06:06 20:23:51	init content from raw.
2017:06:06 20:23:51	...init data from the raw dataset.
2017:06:06 20:23:51	...read dialogues from file.
2017:06:06 20:23:52	......number of instances: 70858
2017:06:06 20:23:52	rnn type is lstm
2017:06:06 20:23:53	rnn type is lstm
2017:06:06 20:24:26	use DataLoaderBBTV1 to init data.
2017:06:06 20:24:26	...init bucket.
2017:06:06 20:24:26	...load data.
2017:06:06 20:24:26	init content from raw.
2017:06:06 20:24:26	...init data from the raw dataset.
2017:06:06 20:24:26	...read dialogues from file.
2017:06:06 20:24:27	......number of instances: 70858
2017:06:06 20:24:27	rnn type is lstm
2017:06:06 20:24:27	rnn type is lstm
2017:06:06 20:33:57	use DataLoaderBBTV1 to init data.
2017:06:06 20:33:57	...init bucket.
2017:06:06 20:33:57	...load data.
2017:06:06 20:33:57	init content from raw.
2017:06:06 20:33:57	...init data from the raw dataset.
2017:06:06 20:33:57	...read dialogues from file.
2017:06:06 20:33:58	......number of instances: 70858
2017:06:06 20:33:59	rnn type is lstm
2017:06:06 20:35:06	use DataLoaderBBTV1 to init data.
2017:06:06 20:35:06	...init bucket.
2017:06:06 20:35:06	...load data.
2017:06:06 20:35:06	init content from raw.
2017:06:06 20:35:06	...init data from the raw dataset.
2017:06:06 20:35:06	...read dialogues from file.
2017:06:06 20:35:07	......number of instances: 70858
2017:06:06 20:35:07	rnn type is lstm
2017:06:06 20:36:01	use DataLoaderBBTV1 to init data.
2017:06:06 20:36:01	...init bucket.
2017:06:06 20:36:01	...load data.
2017:06:06 20:36:01	init content from raw.
2017:06:06 20:36:01	...init data from the raw dataset.
2017:06:06 20:36:01	...read dialogues from file.
2017:06:06 20:36:02	......number of instances: 70858
2017:06:06 20:36:03	rnn type is lstm
2017:06:06 20:36:11	use DataLoaderBBTV1 to init data.
2017:06:06 20:36:11	...init bucket.
2017:06:06 20:36:11	...load data.
2017:06:06 20:36:11	init content from raw.
2017:06:06 20:36:11	...init data from the raw dataset.
2017:06:06 20:36:11	...read dialogues from file.
2017:06:06 20:36:12	......number of instances: 70858
2017:06:06 20:36:12	rnn type is lstm
2017:06:06 20:36:12	rnn type is lstm
2017:06:06 20:37:28	use DataLoaderBBTV1 to init data.
2017:06:06 20:37:28	...init bucket.
2017:06:06 20:37:28	...load data.
2017:06:06 20:37:28	init content from raw.
2017:06:06 20:37:28	...init data from the raw dataset.
2017:06:06 20:37:28	...read dialogues from file.
2017:06:06 20:37:29	......number of instances: 70858
2017:06:06 20:37:29	rnn type is lstm
2017:06:06 20:37:30	rnn type is lstm
2017:06:06 20:38:59	use DataLoaderBBTV1 to init data.
2017:06:06 20:38:59	...init bucket.
2017:06:06 20:38:59	...load data.
2017:06:06 20:38:59	init content from raw.
2017:06:06 20:38:59	...init data from the raw dataset.
2017:06:06 20:38:59	...read dialogues from file.
2017:06:06 20:39:00	......number of instances: 70858
2017:06:06 20:39:00	rnn type is lstm
2017:06:06 20:39:00	rnn type is lstm
2017:06:06 20:41:15	use DataLoaderBBTV1 to init data.
2017:06:06 20:41:15	...init bucket.
2017:06:06 20:41:15	...load data.
2017:06:06 20:41:15	init content from raw.
2017:06:06 20:41:15	...init data from the raw dataset.
2017:06:06 20:41:15	...read dialogues from file.
2017:06:06 20:41:16	......number of instances: 70858
2017:06:06 20:41:16	rnn type is lstm
2017:06:06 20:41:16	rnn type is lstm
2017:06:06 20:44:18	use DataLoaderBBTV1 to init data.
2017:06:06 20:44:18	...init bucket.
2017:06:06 20:44:18	...load data.
2017:06:06 20:44:18	init content from raw.
2017:06:06 20:44:18	...init data from the raw dataset.
2017:06:06 20:44:18	...read dialogues from file.
2017:06:06 20:44:19	......number of instances: 70858
2017:06:06 20:44:19	rnn type is lstm
2017:06:06 20:44:19	rnn type is lstm
2017:06:06 20:50:02	use DataLoaderBBTV1 to init data.
2017:06:06 20:50:02	...init bucket.
2017:06:06 20:50:02	...load data.
2017:06:06 20:50:02	init content from raw.
2017:06:06 20:50:02	...init data from the raw dataset.
2017:06:06 20:50:02	...read dialogues from file.
2017:06:06 20:50:03	......number of instances: 70858
2017:06:06 20:50:03	rnn type is lstm
2017:06:06 20:50:03	rnn type is lstm
2017:06:06 20:52:55	use DataLoaderBBTV1 to init data.
2017:06:06 20:52:55	...init bucket.
2017:06:06 20:52:55	...load data.
2017:06:06 20:52:55	init content from raw.
2017:06:06 20:52:55	...init data from the raw dataset.
2017:06:06 20:52:55	...read dialogues from file.
2017:06:06 20:52:56	......number of instances: 70858
2017:06:06 20:52:56	rnn type is lstm
2017:06:06 20:52:56	rnn type is lstm
2017:06:06 20:53:18	use DataLoaderBBTV1 to init data.
2017:06:06 20:53:18	...init bucket.
2017:06:06 20:53:18	...load data.
2017:06:06 20:53:18	init content from raw.
2017:06:06 20:53:18	...init data from the raw dataset.
2017:06:06 20:53:18	...read dialogues from file.
2017:06:06 20:53:18	......number of instances: 70858
2017:06:06 20:53:19	rnn type is lstm
2017:06:06 20:53:19	rnn type is lstm
2017:06:06 20:58:53	use DataLoaderBBTV1 to init data.
2017:06:06 20:58:53	...init bucket.
2017:06:06 20:58:53	...load data.
2017:06:06 20:58:53	init content from raw.
2017:06:06 20:58:53	...init data from the raw dataset.
2017:06:06 20:58:53	...read dialogues from file.
2017:06:06 20:58:54	......number of instances: 70858
2017:06:06 20:58:54	rnn type is lstm
2017:06:06 20:58:55	rnn type is lstm
2017:06:06 20:59:25	use DataLoaderBBTV1 to init data.
2017:06:06 20:59:25	...init bucket.
2017:06:06 20:59:25	...load data.
2017:06:06 20:59:25	init content from raw.
2017:06:06 20:59:25	...init data from the raw dataset.
2017:06:06 20:59:25	...read dialogues from file.
2017:06:06 20:59:26	......number of instances: 70858
2017:06:06 20:59:26	rnn type is lstm
2017:06:06 20:59:27	rnn type is lstm
2017:06:06 21:00:23	use DataLoaderBBTV1 to init data.
2017:06:06 21:00:23	...init bucket.
2017:06:06 21:00:23	...load data.
2017:06:06 21:00:23	init content from raw.
2017:06:06 21:00:23	...init data from the raw dataset.
2017:06:06 21:00:23	...read dialogues from file.
2017:06:06 21:00:24	......number of instances: 70858
2017:06:06 21:00:24	rnn type is lstm
2017:06:06 21:00:24	rnn type is lstm
2017:06:06 21:01:33	use DataLoaderBBTV1 to init data.
2017:06:06 21:01:33	...init bucket.
2017:06:06 21:01:33	...load data.
2017:06:06 21:01:33	init content from raw.
2017:06:06 21:01:33	...init data from the raw dataset.
2017:06:06 21:01:33	...read dialogues from file.
2017:06:06 21:01:34	......number of instances: 70858
2017:06:06 21:01:35	rnn type is lstm
2017:06:06 21:01:35	rnn type is lstm
2017:06:06 21:02:08	use DataLoaderBBTV1 to init data.
2017:06:06 21:02:08	...init bucket.
2017:06:06 21:02:08	...load data.
2017:06:06 21:02:08	init content from raw.
2017:06:06 21:02:08	...init data from the raw dataset.
2017:06:06 21:02:08	...read dialogues from file.
2017:06:06 21:02:08	......number of instances: 70858
2017:06:06 21:02:09	rnn type is lstm
2017:06:06 21:02:09	rnn type is lstm
2017:06:06 21:03:45	use DataLoaderBBTV1 to init data.
2017:06:06 21:03:45	...init bucket.
2017:06:06 21:03:45	...load data.
2017:06:06 21:03:45	init content from raw.
2017:06:06 21:03:45	...init data from the raw dataset.
2017:06:06 21:03:45	...read dialogues from file.
2017:06:06 21:03:46	......number of instances: 70858
2017:06:06 21:03:47	rnn type is lstm
2017:06:06 21:03:47	rnn type is lstm
2017:06:06 21:04:27	use DataLoaderBBTV1 to init data.
2017:06:06 21:04:27	...init bucket.
2017:06:06 21:04:27	...load data.
2017:06:06 21:04:27	init content from raw.
2017:06:06 21:04:27	...init data from the raw dataset.
2017:06:06 21:04:27	...read dialogues from file.
2017:06:06 21:04:28	......number of instances: 70858
2017:06:06 21:04:28	rnn type is lstm
2017:06:06 21:04:29	rnn type is lstm
2017:06:06 21:07:47	use DataLoaderBBTV1 to init data.
2017:06:06 21:07:47	...init bucket.
2017:06:06 21:07:47	...load data.
2017:06:06 21:07:47	init content from raw.
2017:06:06 21:07:47	...init data from the raw dataset.
2017:06:06 21:07:47	...read dialogues from file.
2017:06:06 21:07:48	......number of instances: 70858
2017:06:06 21:07:48	rnn type is lstm
2017:06:06 21:07:49	rnn type is lstm
2017:06:06 21:08:34	use DataLoaderBBTV1 to init data.
2017:06:06 21:08:34	...init bucket.
2017:06:06 21:08:34	...load data.
2017:06:06 21:08:34	init content from raw.
2017:06:06 21:08:34	...init data from the raw dataset.
2017:06:06 21:08:34	...read dialogues from file.
2017:06:06 21:08:34	......number of instances: 70858
2017:06:06 21:08:35	rnn type is lstm
2017:06:06 21:08:35	rnn type is lstm
2017:06:06 21:10:27	use DataLoaderBBTV1 to init data.
2017:06:06 21:10:27	...init bucket.
2017:06:06 21:10:27	...load data.
2017:06:06 21:10:27	init content from raw.
2017:06:06 21:10:27	...init data from the raw dataset.
2017:06:06 21:10:27	...read dialogues from file.
2017:06:06 21:10:28	......number of instances: 70858
2017:06:06 21:10:29	rnn type is lstm
2017:06:06 21:10:29	rnn type is lstm
2017:06:06 21:14:01	use DataLoaderBBTV1 to init data.
2017:06:06 21:14:01	...init bucket.
2017:06:06 21:14:01	...load data.
2017:06:06 21:14:01	init content from raw.
2017:06:06 21:14:01	...init data from the raw dataset.
2017:06:06 21:14:01	...read dialogues from file.
2017:06:06 21:14:02	......number of instances: 70858
2017:06:06 21:14:03	rnn type is lstm
2017:06:06 21:14:03	rnn type is lstm
2017:06:06 21:18:41	use DataLoaderBBTV1 to init data.
2017:06:06 21:18:41	...init bucket.
2017:06:06 21:18:41	...load data.
2017:06:06 21:18:41	init content from raw.
2017:06:06 21:18:41	...init data from the raw dataset.
2017:06:06 21:18:41	...read dialogues from file.
2017:06:06 21:18:42	......number of instances: 70858
2017:06:06 21:18:43	rnn type is lstm
2017:06:06 21:19:02	use DataLoaderBBTV1 to init data.
2017:06:06 21:19:02	...init bucket.
2017:06:06 21:19:02	...load data.
2017:06:06 21:19:02	init content from raw.
2017:06:06 21:19:02	...init data from the raw dataset.
2017:06:06 21:19:02	...read dialogues from file.
2017:06:06 21:19:02	......number of instances: 70858
2017:06:06 21:19:03	rnn type is lstm
2017:06:06 21:19:03	rnn type is lstm
2017:06:06 21:20:05	use DataLoaderBBTV1 to init data.
2017:06:06 21:20:05	...init bucket.
2017:06:06 21:20:05	...load data.
2017:06:06 21:20:05	init content from raw.
2017:06:06 21:20:05	...init data from the raw dataset.
2017:06:06 21:20:05	...read dialogues from file.
2017:06:06 21:20:05	......number of instances: 70858
2017:06:06 21:20:06	rnn type is lstm
2017:06:06 21:20:06	rnn type is lstm
2017:06:06 21:21:05	use DataLoaderBBTV1 to init data.
2017:06:06 21:21:05	...init bucket.
2017:06:06 21:21:05	...load data.
2017:06:06 21:21:05	init content from raw.
2017:06:06 21:21:05	...init data from the raw dataset.
2017:06:06 21:21:05	...read dialogues from file.
2017:06:06 21:21:06	......number of instances: 70858
2017:06:06 21:21:07	rnn type is lstm
2017:06:06 21:21:07	rnn type is lstm
2017:06:06 21:21:25	use DataLoaderBBTV1 to init data.
2017:06:06 21:21:25	...init bucket.
2017:06:06 21:21:25	...load data.
2017:06:06 21:21:25	init content from raw.
2017:06:06 21:21:25	...init data from the raw dataset.
2017:06:06 21:21:25	...read dialogues from file.
2017:06:06 21:21:26	......number of instances: 70858
2017:06:06 21:21:26	rnn type is lstm
2017:06:06 21:21:26	rnn type is lstm
2017:06:06 22:31:14	use DataLoaderBBTV1 to init data.
2017:06:06 22:31:14	...init bucket.
2017:06:06 22:31:14	...load data.
2017:06:06 22:31:14	init content from raw.
2017:06:06 22:31:14	...init data from the raw dataset.
2017:06:06 22:31:14	...read dialogues from file.
2017:06:06 22:31:15	......number of instances: 70858
2017:06:06 22:31:16	rnn type is lstm
2017:06:06 22:31:16	rnn type is lstm
2017:06:06 22:33:12	use DataLoaderBBTV1 to init data.
2017:06:06 22:33:12	...init bucket.
2017:06:06 22:33:12	...load data.
2017:06:06 22:33:12	init content from raw.
2017:06:06 22:33:12	...init data from the raw dataset.
2017:06:06 22:33:12	...read dialogues from file.
2017:06:06 22:33:13	......number of instances: 70858
2017:06:06 22:33:13	rnn type is lstm
2017:06:06 22:33:13	rnn type is lstm
2017:06:06 22:35:01	use DataLoaderBBTV1 to init data.
2017:06:06 22:35:01	...init bucket.
2017:06:06 22:35:01	...load data.
2017:06:06 22:35:01	init content from raw.
2017:06:06 22:35:01	...init data from the raw dataset.
2017:06:06 22:35:01	...read dialogues from file.
2017:06:06 22:35:02	......number of instances: 70858
2017:06:06 22:35:02	rnn type is lstm
2017:06:06 22:35:03	rnn type is lstm
2017:06:06 22:40:30	use DataLoaderBBTV1 to init data.
2017:06:06 22:40:30	...init bucket.
2017:06:06 22:40:30	...load data.
2017:06:06 22:40:30	init content from raw.
2017:06:06 22:40:30	...init data from the raw dataset.
2017:06:06 22:40:30	...read dialogues from file.
2017:06:06 22:40:31	......number of instances: 70858
2017:06:06 22:40:31	rnn type is lstm
2017:06:06 22:40:32	rnn type is lstm
2017:06:06 22:58:51	use DataLoaderBBTV1 to init data.
2017:06:06 22:58:51	...init bucket.
2017:06:06 22:58:51	...load data.
2017:06:06 22:58:51	init content from raw.
2017:06:06 22:58:51	...init data from the raw dataset.
2017:06:06 22:58:51	...read dialogues from file.
2017:06:06 22:58:52	......number of instances: 70858
2017:06:06 22:58:53	rnn type is lstm
2017:06:06 22:58:53	rnn type is lstm
2017:06:06 23:00:30	use DataLoaderBBTV1 to init data.
2017:06:06 23:00:30	...init bucket.
2017:06:06 23:00:30	...load data.
2017:06:06 23:00:30	init content from raw.
2017:06:06 23:00:30	...init data from the raw dataset.
2017:06:06 23:00:30	...read dialogues from file.
2017:06:06 23:00:31	......number of instances: 70858
2017:06:06 23:00:32	rnn type is lstm
2017:06:06 23:00:32	rnn type is lstm
2017:06:06 23:10:02	use DataLoaderBBTV1 to init data.
2017:06:06 23:10:02	...init bucket.
2017:06:06 23:10:02	...load data.
2017:06:06 23:10:02	init content from raw.
2017:06:06 23:10:02	...init data from the raw dataset.
2017:06:06 23:10:02	...read dialogues from file.
2017:06:06 23:10:02	......number of instances: 70858
2017:06:06 23:10:03	rnn type is lstm
2017:06:06 23:10:03	rnn type is lstm
2017:06:06 23:12:51	use DataLoaderBBTV1 to init data.
2017:06:06 23:12:51	...init bucket.
2017:06:06 23:12:51	...load data.
2017:06:06 23:12:51	init content from raw.
2017:06:06 23:12:51	...init data from the raw dataset.
2017:06:06 23:12:51	...read dialogues from file.
2017:06:06 23:12:51	......number of instances: 70858
2017:06:06 23:12:52	rnn type is lstm
2017:06:06 23:12:52	rnn type is lstm
2017:06:06 23:14:12	use DataLoaderBBTV1 to init data.
2017:06:06 23:14:12	...init bucket.
2017:06:06 23:14:12	...load data.
2017:06:06 23:14:12	init content from raw.
2017:06:06 23:14:12	...init data from the raw dataset.
2017:06:06 23:14:12	...read dialogues from file.
2017:06:06 23:14:13	......number of instances: 70858
2017:06:06 23:14:14	rnn type is lstm
2017:06:06 23:14:14	rnn type is lstm
2017:06:06 23:15:00	use DataLoaderBBTV1 to init data.
2017:06:06 23:15:00	...init bucket.
2017:06:06 23:15:00	...load data.
2017:06:06 23:15:00	init content from raw.
2017:06:06 23:15:00	...init data from the raw dataset.
2017:06:06 23:15:00	...read dialogues from file.
2017:06:06 23:15:01	......number of instances: 70858
2017:06:06 23:15:01	rnn type is lstm
2017:06:06 23:15:09	use DataLoaderBBTV1 to init data.
2017:06:06 23:15:09	...init bucket.
2017:06:06 23:15:09	...load data.
2017:06:06 23:15:09	init content from raw.
2017:06:06 23:15:09	...init data from the raw dataset.
2017:06:06 23:15:09	...read dialogues from file.
2017:06:06 23:15:10	......number of instances: 70858
2017:06:06 23:15:10	rnn type is lstm
2017:06:06 23:15:10	rnn type is lstm
2017:06:06 23:15:25	use DataLoaderBBTV1 to init data.
2017:06:06 23:15:25	...init bucket.
2017:06:06 23:15:25	...load data.
2017:06:06 23:15:25	init content from raw.
2017:06:06 23:15:25	...init data from the raw dataset.
2017:06:06 23:15:25	...read dialogues from file.
2017:06:06 23:15:25	......number of instances: 70858
2017:06:06 23:15:26	rnn type is lstm
2017:06:06 23:15:26	rnn type is lstm
2017:06:06 23:16:55	use DataLoaderBBTV1 to init data.
2017:06:06 23:16:55	...init bucket.
2017:06:06 23:16:55	...load data.
2017:06:06 23:16:55	init content from raw.
2017:06:06 23:16:55	...init data from the raw dataset.
2017:06:06 23:16:55	...read dialogues from file.
2017:06:06 23:16:56	......number of instances: 70858
2017:06:06 23:16:56	rnn type is lstm
2017:06:06 23:16:57	rnn type is lstm
2017:06:07 08:40:02	use DataLoaderBBTV1 to init data.
2017:06:07 08:40:02	...init bucket.
2017:06:07 08:40:02	...load data.
2017:06:07 08:40:02	init content from raw.
2017:06:07 08:40:02	...init data from the raw dataset.
2017:06:07 08:40:02	...read dialogues from file.
2017:06:07 08:40:03	......number of instances: 70858
2017:06:07 08:40:04	rnn type is lstm
2017:06:07 08:40:04	rnn type is lstm
2017:06:07 08:46:32	use DataLoaderBBTV1 to init data.
2017:06:07 08:46:32	...init bucket.
2017:06:07 08:46:32	...load data.
2017:06:07 08:46:32	init content from raw.
2017:06:07 08:46:32	...init data from the raw dataset.
2017:06:07 08:46:32	...read dialogues from file.
2017:06:07 08:46:33	......number of instances: 70858
2017:06:07 08:46:33	rnn type is lstm
2017:06:07 08:46:33	rnn type is lstm
2017:06:07 08:46:55	use DataLoaderBBTV1 to init data.
2017:06:07 08:46:55	...init bucket.
2017:06:07 08:46:55	...load data.
2017:06:07 08:46:55	init content from raw.
2017:06:07 08:46:55	...init data from the raw dataset.
2017:06:07 08:46:55	...read dialogues from file.
2017:06:07 08:46:55	......number of instances: 70858
2017:06:07 08:46:56	rnn type is lstm
2017:06:07 08:46:56	rnn type is lstm
2017:06:07 09:03:08	use DataLoaderBBTV1 to init data.
2017:06:07 09:03:08	...init bucket.
2017:06:07 09:03:08	...load data.
2017:06:07 09:03:08	init content from raw.
2017:06:07 09:03:08	...init data from the raw dataset.
2017:06:07 09:03:08	...read dialogues from file.
2017:06:07 09:03:09	......number of instances: 70858
2017:06:07 09:03:10	rnn type is lstm
2017:06:07 09:03:10	rnn type is lstm
2017:06:07 09:03:27	use DataLoaderBBTV1 to init data.
2017:06:07 09:03:27	...init bucket.
2017:06:07 09:03:27	...load data.
2017:06:07 09:03:27	init content from raw.
2017:06:07 09:03:27	...init data from the raw dataset.
2017:06:07 09:03:27	...read dialogues from file.
2017:06:07 09:03:28	......number of instances: 70858
2017:06:07 09:03:28	rnn type is lstm
2017:06:07 09:03:28	rnn type is lstm
2017:06:07 09:04:05	use DataLoaderBBTV1 to init data.
2017:06:07 09:04:05	...init bucket.
2017:06:07 09:04:05	...load data.
2017:06:07 09:04:05	init content from raw.
2017:06:07 09:04:05	...init data from the raw dataset.
2017:06:07 09:04:05	...read dialogues from file.
2017:06:07 09:04:06	......number of instances: 70858
2017:06:07 09:04:06	rnn type is lstm
2017:06:07 09:05:34	use DataLoaderBBTV1 to init data.
2017:06:07 09:05:34	...init bucket.
2017:06:07 09:05:34	...load data.
2017:06:07 09:05:34	init content from raw.
2017:06:07 09:05:34	...init data from the raw dataset.
2017:06:07 09:05:34	...read dialogues from file.
2017:06:07 09:05:34	......number of instances: 70858
2017:06:07 09:05:35	rnn type is lstm
2017:06:07 09:06:16	use DataLoaderBBTV1 to init data.
2017:06:07 09:06:16	...init bucket.
2017:06:07 09:06:16	...load data.
2017:06:07 09:06:16	init content from raw.
2017:06:07 09:06:16	...init data from the raw dataset.
2017:06:07 09:06:16	...read dialogues from file.
2017:06:07 09:06:17	......number of instances: 70858
2017:06:07 09:06:17	rnn type is lstm
2017:06:07 09:08:49	use DataLoaderBBTV1 to init data.
2017:06:07 09:08:49	...init bucket.
2017:06:07 09:08:49	...load data.
2017:06:07 09:08:49	init content from raw.
2017:06:07 09:08:49	...init data from the raw dataset.
2017:06:07 09:08:49	...read dialogues from file.
2017:06:07 09:08:49	......number of instances: 70858
2017:06:07 09:08:50	rnn type is lstm
2017:06:07 09:12:02	use DataLoaderBBTV1 to init data.
2017:06:07 09:12:02	...init bucket.
2017:06:07 09:12:02	...load data.
2017:06:07 09:12:02	init content from raw.
2017:06:07 09:12:02	...init data from the raw dataset.
2017:06:07 09:12:02	...read dialogues from file.
2017:06:07 09:12:02	......number of instances: 70858
2017:06:07 09:12:03	rnn type is lstm
2017:06:07 09:12:03	rnn type is lstm
2017:06:07 09:12:19	use DataLoaderBBTV1 to init data.
2017:06:07 09:12:19	...init bucket.
2017:06:07 09:12:19	...load data.
2017:06:07 09:12:19	init content from raw.
2017:06:07 09:12:19	...init data from the raw dataset.
2017:06:07 09:12:19	...read dialogues from file.
2017:06:07 09:12:20	......number of instances: 70858
2017:06:07 09:12:20	rnn type is lstm
2017:06:07 09:12:20	rnn type is lstm
2017:06:07 09:22:09	use DataLoaderBBTV1 to init data.
2017:06:07 09:22:09	...init bucket.
2017:06:07 09:22:09	...load data.
2017:06:07 09:22:09	init content from raw.
2017:06:07 09:22:09	...init data from the raw dataset.
2017:06:07 09:22:09	...read dialogues from file.
2017:06:07 09:22:10	......number of instances: 70858
2017:06:07 09:22:11	rnn type is lstm
2017:06:07 09:22:33	use DataLoaderBBTV1 to init data.
2017:06:07 09:22:33	...init bucket.
2017:06:07 09:22:33	...load data.
2017:06:07 09:22:33	init content from raw.
2017:06:07 09:22:33	...init data from the raw dataset.
2017:06:07 09:22:33	...read dialogues from file.
2017:06:07 09:22:33	......number of instances: 70858
2017:06:07 09:22:34	rnn type is lstm
2017:06:07 09:22:47	use DataLoaderBBTV1 to init data.
2017:06:07 09:22:47	...init bucket.
2017:06:07 09:22:47	...load data.
2017:06:07 09:22:47	init content from raw.
2017:06:07 09:22:47	...init data from the raw dataset.
2017:06:07 09:22:47	...read dialogues from file.
2017:06:07 09:22:48	......number of instances: 70858
2017:06:07 09:22:48	rnn type is lstm
2017:06:07 09:22:48	rnn type is lstm
2017:06:07 09:24:23	use DataLoaderBBTV1 to init data.
2017:06:07 09:24:23	...init bucket.
2017:06:07 09:24:23	...load data.
2017:06:07 09:24:23	init content from raw.
2017:06:07 09:24:23	...init data from the raw dataset.
2017:06:07 09:24:23	...read dialogues from file.
2017:06:07 09:24:24	......number of instances: 70858
2017:06:07 09:24:24	rnn type is lstm
2017:06:07 09:24:24	rnn type is lstm
2017:06:07 09:25:59	use DataLoaderBBTV1 to init data.
2017:06:07 09:25:59	...init bucket.
2017:06:07 09:25:59	...load data.
2017:06:07 09:25:59	init content from raw.
2017:06:07 09:25:59	...init data from the raw dataset.
2017:06:07 09:25:59	...read dialogues from file.
2017:06:07 09:26:00	......number of instances: 70858
2017:06:07 09:26:00	rnn type is lstm
2017:06:07 09:26:00	rnn type is lstm
2017:06:07 09:27:12	use DataLoaderBBTV1 to init data.
2017:06:07 09:27:12	...init bucket.
2017:06:07 09:27:12	...load data.
2017:06:07 09:27:12	init content from raw.
2017:06:07 09:27:12	...init data from the raw dataset.
2017:06:07 09:27:12	...read dialogues from file.
2017:06:07 09:27:13	......number of instances: 70858
2017:06:07 09:27:13	rnn type is lstm
2017:06:07 09:27:24	use DataLoaderBBTV1 to init data.
2017:06:07 09:27:24	...init bucket.
2017:06:07 09:27:24	...load data.
2017:06:07 09:27:24	init content from raw.
2017:06:07 09:27:24	...init data from the raw dataset.
2017:06:07 09:27:24	...read dialogues from file.
2017:06:07 09:27:25	......number of instances: 70858
2017:06:07 09:27:25	rnn type is lstm
2017:06:07 09:28:39	use DataLoaderBBTV1 to init data.
2017:06:07 09:28:39	...init bucket.
2017:06:07 09:28:39	...load data.
2017:06:07 09:28:39	init content from raw.
2017:06:07 09:28:39	...init data from the raw dataset.
2017:06:07 09:28:39	...read dialogues from file.
2017:06:07 09:28:40	......number of instances: 70858
2017:06:07 09:28:40	rnn type is lstm
2017:06:07 09:29:12	use DataLoaderBBTV1 to init data.
2017:06:07 09:29:12	...init bucket.
2017:06:07 09:29:12	...load data.
2017:06:07 09:29:12	init content from raw.
2017:06:07 09:29:12	...init data from the raw dataset.
2017:06:07 09:29:12	...read dialogues from file.
2017:06:07 09:29:13	......number of instances: 70858
2017:06:07 09:29:13	rnn type is lstm
2017:06:07 09:29:13	rnn type is lstm
2017:06:07 09:29:39	use DataLoaderBBTV1 to init data.
2017:06:07 09:29:39	...init bucket.
2017:06:07 09:29:39	...load data.
2017:06:07 09:29:39	init content from raw.
2017:06:07 09:29:39	...init data from the raw dataset.
2017:06:07 09:29:39	...read dialogues from file.
2017:06:07 09:29:40	......number of instances: 70858
2017:06:07 09:29:40	rnn type is lstm
2017:06:07 09:29:40	rnn type is lstm
2017:06:07 09:32:16	use DataLoaderBBTV1 to init data.
2017:06:07 09:32:16	...init bucket.
2017:06:07 09:32:16	...load data.
2017:06:07 09:32:16	init content from raw.
2017:06:07 09:32:16	...init data from the raw dataset.
2017:06:07 09:32:16	...read dialogues from file.
2017:06:07 09:32:17	......number of instances: 70858
2017:06:07 09:32:17	rnn type is lstm
2017:06:07 09:32:17	rnn type is lstm
2017:06:07 09:35:09	use DataLoaderBBTV1 to init data.
2017:06:07 09:35:09	...init bucket.
2017:06:07 09:35:09	...load data.
2017:06:07 09:35:09	init content from raw.
2017:06:07 09:35:09	...init data from the raw dataset.
2017:06:07 09:35:09	...read dialogues from file.
2017:06:07 09:35:10	......number of instances: 70858
2017:06:07 09:35:11	rnn type is lstm
2017:06:07 09:35:11	rnn type is lstm
2017:06:07 09:44:17	use DataLoaderBBTV1 to init data.
2017:06:07 09:44:17	...init bucket.
2017:06:07 09:44:17	...load data.
2017:06:07 09:44:17	init content from raw.
2017:06:07 09:44:17	...init data from the raw dataset.
2017:06:07 09:44:17	...read dialogues from file.
2017:06:07 09:44:18	......number of instances: 70858
2017:06:07 09:44:18	rnn type is lstm
2017:06:07 09:44:18	rnn type is lstm
2017:06:07 09:46:35	use DataLoaderBBTV1 to init data.
2017:06:07 09:46:35	...init bucket.
2017:06:07 09:46:35	...load data.
2017:06:07 09:46:35	init content from raw.
2017:06:07 09:46:35	...init data from the raw dataset.
2017:06:07 09:46:35	...read dialogues from file.
2017:06:07 09:46:36	......number of instances: 70858
2017:06:07 09:46:36	rnn type is lstm
2017:06:07 09:46:36	rnn type is lstm
2017:06:07 09:47:00	use DataLoaderBBTV1 to init data.
2017:06:07 09:47:00	...init bucket.
2017:06:07 09:47:00	...load data.
2017:06:07 09:47:00	init content from raw.
2017:06:07 09:47:00	...init data from the raw dataset.
2017:06:07 09:47:00	...read dialogues from file.
2017:06:07 09:47:01	......number of instances: 70858
2017:06:07 09:47:01	rnn type is lstm
2017:06:07 09:47:01	rnn type is lstm
2017:06:07 09:47:10	use DataLoaderBBTV1 to init data.
2017:06:07 09:47:10	...init bucket.
2017:06:07 09:47:10	...load data.
2017:06:07 09:47:10	init content from raw.
2017:06:07 09:47:10	...init data from the raw dataset.
2017:06:07 09:47:10	...read dialogues from file.
2017:06:07 09:47:11	......number of instances: 70858
2017:06:07 09:47:12	rnn type is lstm
2017:06:07 09:47:12	rnn type is lstm
2017:06:07 09:54:19	use DataLoaderBBTV1 to init data.
2017:06:07 09:54:19	...init bucket.
2017:06:07 09:54:19	...load data.
2017:06:07 09:54:19	init content from raw.
2017:06:07 09:54:19	...init data from the raw dataset.
2017:06:07 09:54:19	...read dialogues from file.
2017:06:07 09:54:20	......number of instances: 70858
2017:06:07 09:55:13	use DataLoaderBBTV1 to init data.
2017:06:07 09:55:13	...init bucket.
2017:06:07 09:55:13	...load data.
2017:06:07 09:55:13	init content from raw.
2017:06:07 09:55:13	...init data from the raw dataset.
2017:06:07 09:55:13	...read dialogues from file.
2017:06:07 09:55:14	......number of instances: 70858
2017:06:07 09:55:32	use DataLoaderBBTV1 to init data.
2017:06:07 09:55:32	...init bucket.
2017:06:07 09:55:32	...load data.
2017:06:07 09:55:32	init content from raw.
2017:06:07 09:55:32	...init data from the raw dataset.
2017:06:07 09:55:32	...read dialogues from file.
2017:06:07 09:55:33	......number of instances: 70858
2017:06:07 09:55:33	rnn type is lstm
2017:06:07 09:55:33	rnn type is lstm
2017:06:07 09:56:53	use DataLoaderBBTV1 to init data.
2017:06:07 09:56:53	...init bucket.
2017:06:07 09:56:53	...load data.
2017:06:07 09:56:53	init content from raw.
2017:06:07 09:56:53	...init data from the raw dataset.
2017:06:07 09:56:53	...read dialogues from file.
2017:06:07 09:56:54	......number of instances: 70858
2017:06:07 09:56:54	rnn type is lstm
2017:06:07 09:56:55	rnn type is lstm
2017:06:07 10:06:16	use DataLoaderBBTV1 to init data.
2017:06:07 10:06:16	...init bucket.
2017:06:07 10:06:16	...load data.
2017:06:07 10:06:16	init content from raw.
2017:06:07 10:06:16	...init data from the raw dataset.
2017:06:07 10:06:16	...read dialogues from file.
2017:06:07 10:06:17	......number of instances: 70858
2017:06:07 10:06:17	rnn type is lstm
2017:06:07 10:07:01	use DataLoaderBBTV1 to init data.
2017:06:07 10:07:01	...init bucket.
2017:06:07 10:07:01	...load data.
2017:06:07 10:07:01	init content from raw.
2017:06:07 10:07:01	...init data from the raw dataset.
2017:06:07 10:07:01	...read dialogues from file.
2017:06:07 10:07:02	......number of instances: 70858
2017:06:07 10:07:02	rnn type is lstm
2017:06:07 10:07:34	use DataLoaderBBTV1 to init data.
2017:06:07 10:07:34	...init bucket.
2017:06:07 10:07:34	...load data.
2017:06:07 10:07:34	init content from raw.
2017:06:07 10:07:34	...init data from the raw dataset.
2017:06:07 10:07:34	...read dialogues from file.
2017:06:07 10:07:35	......number of instances: 70858
2017:06:07 10:07:35	rnn type is lstm
2017:06:07 10:08:53	use DataLoaderBBTV1 to init data.
2017:06:07 10:08:53	...init bucket.
2017:06:07 10:08:53	...load data.
2017:06:07 10:08:53	init content from raw.
2017:06:07 10:08:53	...init data from the raw dataset.
2017:06:07 10:08:53	...read dialogues from file.
2017:06:07 10:08:53	......number of instances: 70858
2017:06:07 10:08:53	rnn type is lstm
2017:06:07 10:11:41	use DataLoaderBBTV1 to init data.
2017:06:07 10:11:41	...init bucket.
2017:06:07 10:11:41	...load data.
2017:06:07 10:11:41	init content from raw.
2017:06:07 10:11:41	...init data from the raw dataset.
2017:06:07 10:11:41	...read dialogues from file.
2017:06:07 10:11:42	......number of instances: 70858
2017:06:07 10:11:42	rnn type is lstm
2017:06:07 10:14:10	use DataLoaderBBTV1 to init data.
2017:06:07 10:14:10	...init bucket.
2017:06:07 10:14:10	...load data.
2017:06:07 10:14:10	init content from raw.
2017:06:07 10:14:10	...init data from the raw dataset.
2017:06:07 10:14:10	...read dialogues from file.
2017:06:07 10:14:11	......number of instances: 70858
2017:06:07 10:14:11	rnn type is lstm
2017:06:07 10:14:43	use DataLoaderBBTV1 to init data.
2017:06:07 10:14:43	...init bucket.
2017:06:07 10:14:43	...load data.
2017:06:07 10:14:43	init content from raw.
2017:06:07 10:14:43	...init data from the raw dataset.
2017:06:07 10:14:43	...read dialogues from file.
2017:06:07 10:14:44	......number of instances: 70858
2017:06:07 10:14:44	rnn type is lstm
2017:06:07 10:15:18	use DataLoaderBBTV1 to init data.
2017:06:07 10:15:18	...init bucket.
2017:06:07 10:15:18	...load data.
2017:06:07 10:15:18	init content from raw.
2017:06:07 10:15:18	...init data from the raw dataset.
2017:06:07 10:15:18	...read dialogues from file.
2017:06:07 10:15:19	......number of instances: 70858
2017:06:07 10:15:19	rnn type is lstm
2017:06:07 10:15:19	rnn type is lstm
2017:06:07 10:16:01	use DataLoaderBBTV1 to init data.
2017:06:07 10:16:01	...init bucket.
2017:06:07 10:16:01	...load data.
2017:06:07 10:16:01	init content from raw.
2017:06:07 10:16:01	...init data from the raw dataset.
2017:06:07 10:16:01	...read dialogues from file.
2017:06:07 10:16:02	......number of instances: 70858
2017:06:07 10:16:02	rnn type is lstm
2017:06:07 10:16:02	rnn type is lstm
2017:06:07 10:17:08	use DataLoaderBBTV1 to init data.
2017:06:07 10:17:08	...init bucket.
2017:06:07 10:17:08	...load data.
2017:06:07 10:17:08	init content from raw.
2017:06:07 10:17:08	...init data from the raw dataset.
2017:06:07 10:17:08	...read dialogues from file.
2017:06:07 10:17:09	......number of instances: 70858
2017:06:07 10:17:09	rnn type is lstm
2017:06:07 10:17:09	rnn type is lstm
2017:06:07 10:17:52	use DataLoaderBBTV1 to init data.
2017:06:07 10:17:52	...init bucket.
2017:06:07 10:17:52	...load data.
2017:06:07 10:17:52	init content from raw.
2017:06:07 10:17:52	...init data from the raw dataset.
2017:06:07 10:17:52	...read dialogues from file.
2017:06:07 10:17:53	......number of instances: 70858
2017:06:07 10:17:53	rnn type is lstm
2017:06:07 10:17:53	rnn type is lstm
2017:06:07 10:18:09	use DataLoaderBBTV1 to init data.
2017:06:07 10:18:09	...init bucket.
2017:06:07 10:18:09	...load data.
2017:06:07 10:18:09	init content from raw.
2017:06:07 10:18:09	...init data from the raw dataset.
2017:06:07 10:18:09	...read dialogues from file.
2017:06:07 10:18:10	......number of instances: 70858
2017:06:07 10:18:10	rnn type is lstm
2017:06:07 10:18:10	rnn type is lstm
2017:06:07 10:21:48	use DataLoaderBBTV1 to init data.
2017:06:07 10:21:48	...init bucket.
2017:06:07 10:21:48	...load data.
2017:06:07 10:21:48	init content from raw.
2017:06:07 10:21:48	...init data from the raw dataset.
2017:06:07 10:21:48	...read dialogues from file.
2017:06:07 10:21:49	......number of instances: 70858
2017:06:07 10:21:49	rnn type is lstm
2017:06:07 10:21:49	rnn type is lstm
2017:06:07 10:23:10	use DataLoaderBBTV1 to init data.
2017:06:07 10:23:10	...init bucket.
2017:06:07 10:23:10	...load data.
2017:06:07 10:23:10	init content from raw.
2017:06:07 10:23:10	...init data from the raw dataset.
2017:06:07 10:23:10	...read dialogues from file.
2017:06:07 10:23:10	......number of instances: 70858
2017:06:07 10:23:11	rnn type is lstm
2017:06:07 10:23:11	rnn type is lstm
2017:06:07 10:23:12	variables in the discriminator:
2017:06:07 10:23:13	variables in the generator:
2017:06:07 10:25:43	use DataLoaderBBTV1 to init data.
2017:06:07 10:25:43	...init bucket.
2017:06:07 10:25:43	...load data.
2017:06:07 10:25:43	init content from raw.
2017:06:07 10:25:43	...init data from the raw dataset.
2017:06:07 10:25:43	...read dialogues from file.
2017:06:07 10:25:44	......number of instances: 70858
2017:06:07 10:25:44	rnn type is lstm
2017:06:07 10:28:54	use DataLoaderBBTV1 to init data.
2017:06:07 10:28:54	...init bucket.
2017:06:07 10:28:54	...load data.
2017:06:07 10:28:54	init content from raw.
2017:06:07 10:28:54	...init data from the raw dataset.
2017:06:07 10:28:54	...read dialogues from file.
2017:06:07 10:28:55	......number of instances: 70858
2017:06:07 10:28:55	rnn type is lstm
2017:06:07 10:29:23	use DataLoaderBBTV1 to init data.
2017:06:07 10:29:23	...init bucket.
2017:06:07 10:29:23	...load data.
2017:06:07 10:29:23	init content from raw.
2017:06:07 10:29:23	...init data from the raw dataset.
2017:06:07 10:29:23	...read dialogues from file.
2017:06:07 10:29:23	......number of instances: 70858
2017:06:07 10:29:23	rnn type is lstm
2017:06:07 10:29:49	use DataLoaderBBTV1 to init data.
2017:06:07 10:29:49	...init bucket.
2017:06:07 10:29:49	...load data.
2017:06:07 10:29:49	init content from raw.
2017:06:07 10:29:49	...init data from the raw dataset.
2017:06:07 10:29:49	...read dialogues from file.
2017:06:07 10:29:49	......number of instances: 70858
2017:06:07 10:29:49	rnn type is lstm
2017:06:07 10:29:50	rnn type is lstm
2017:06:07 10:30:15	use DataLoaderBBTV1 to init data.
2017:06:07 10:30:15	...init bucket.
2017:06:07 10:30:15	...load data.
2017:06:07 10:30:15	init content from raw.
2017:06:07 10:30:15	...init data from the raw dataset.
2017:06:07 10:30:15	...read dialogues from file.
2017:06:07 10:30:16	......number of instances: 70858
2017:06:07 10:30:16	rnn type is lstm
2017:06:07 10:30:16	rnn type is lstm
2017:06:07 10:30:57	use DataLoaderBBTV1 to init data.
2017:06:07 10:30:57	...init bucket.
2017:06:07 10:30:57	...load data.
2017:06:07 10:30:57	init content from raw.
2017:06:07 10:30:57	...init data from the raw dataset.
2017:06:07 10:30:57	...read dialogues from file.
2017:06:07 10:30:57	......number of instances: 70858
2017:06:07 10:30:57	rnn type is lstm
2017:06:07 10:30:58	rnn type is lstm
2017:06:07 10:32:15	use DataLoaderBBTV1 to init data.
2017:06:07 10:32:15	...init bucket.
2017:06:07 10:32:15	...load data.
2017:06:07 10:32:15	init content from raw.
2017:06:07 10:32:15	...init data from the raw dataset.
2017:06:07 10:32:15	...read dialogues from file.
2017:06:07 10:32:16	......number of instances: 70858
2017:06:07 10:32:16	rnn type is lstm
2017:06:07 10:32:16	rnn type is lstm
2017:06:07 10:33:02	use DataLoaderBBTV1 to init data.
2017:06:07 10:33:02	...init bucket.
2017:06:07 10:33:02	...load data.
2017:06:07 10:33:02	init content from raw.
2017:06:07 10:33:02	...init data from the raw dataset.
2017:06:07 10:33:02	...read dialogues from file.
2017:06:07 10:33:03	......number of instances: 70858
2017:06:07 10:33:03	rnn type is lstm
2017:06:07 10:33:03	rnn type is lstm
2017:06:07 10:34:49	use DataLoaderBBTV1 to init data.
2017:06:07 10:34:49	...init bucket.
2017:06:07 10:34:49	...load data.
2017:06:07 10:34:49	init content from raw.
2017:06:07 10:34:49	...init data from the raw dataset.
2017:06:07 10:34:49	...read dialogues from file.
2017:06:07 10:34:50	......number of instances: 70858
2017:06:07 10:34:50	rnn type is lstm
2017:06:07 10:34:50	rnn type is lstm
2017:06:07 10:39:52	use DataLoaderBBTV1 to init data.
2017:06:07 10:39:52	...init bucket.
2017:06:07 10:39:52	...load data.
2017:06:07 10:39:52	init content from raw.
2017:06:07 10:39:52	...init data from the raw dataset.
2017:06:07 10:39:52	...read dialogues from file.
2017:06:07 10:39:52	......number of instances: 70858
2017:06:07 10:39:52	rnn type is lstm
2017:06:07 10:39:53	rnn type is lstm
2017:06:07 10:40:06	use DataLoaderBBTV1 to init data.
2017:06:07 10:40:06	...init bucket.
2017:06:07 10:40:06	...load data.
2017:06:07 10:40:06	init content from raw.
2017:06:07 10:40:06	...init data from the raw dataset.
2017:06:07 10:40:06	...read dialogues from file.
2017:06:07 10:40:07	......number of instances: 70858
2017:06:07 10:40:07	rnn type is lstm
2017:06:07 10:40:07	rnn type is lstm
2017:06:07 10:40:26	use DataLoaderBBTV1 to init data.
2017:06:07 10:40:26	...init bucket.
2017:06:07 10:40:26	...load data.
2017:06:07 10:40:26	init content from raw.
2017:06:07 10:40:26	...init data from the raw dataset.
2017:06:07 10:40:26	...read dialogues from file.
2017:06:07 10:40:26	......number of instances: 70858
2017:06:07 10:40:26	rnn type is lstm
2017:06:07 10:40:27	rnn type is lstm
2017:06:07 10:40:27	define train operations...
2017:06:07 10:40:28	variables in the discriminator:
2017:06:07 10:40:29	variables in the generator:
2017:06:07 10:42:01	use DataLoaderBBTV1 to init data.
2017:06:07 10:42:01	...init bucket.
2017:06:07 10:42:01	...load data.
2017:06:07 10:42:01	init content from raw.
2017:06:07 10:42:01	...init data from the raw dataset.
2017:06:07 10:42:01	...read dialogues from file.
2017:06:07 10:42:02	......number of instances: 70858
2017:06:07 10:42:02	rnn type is lstm
2017:06:07 10:42:02	rnn type is lstm
2017:06:07 10:42:03	define train operations...
2017:06:07 10:42:03	variables in the discriminator:
2017:06:07 10:42:04	variables in the generator:
2017:06:07 10:43:22	use DataLoaderBBTV1 to init data.
2017:06:07 10:43:22	...init bucket.
2017:06:07 10:43:22	...load data.
2017:06:07 10:43:22	init content from raw.
2017:06:07 10:43:22	...init data from the raw dataset.
2017:06:07 10:43:22	...read dialogues from file.
2017:06:07 10:43:23	......number of instances: 70858
2017:06:07 10:43:23	rnn type is lstm
2017:06:07 10:43:23	rnn type is lstm
2017:06:07 10:43:24	define train operations...
2017:06:07 10:43:24	variables in the discriminator:
2017:06:07 10:43:25	variables in the generator:
2017:06:07 10:43:52	use DataLoaderBBTV1 to init data.
2017:06:07 10:43:52	...init bucket.
2017:06:07 10:43:52	...load data.
2017:06:07 10:43:52	init content from raw.
2017:06:07 10:43:52	...init data from the raw dataset.
2017:06:07 10:43:52	...read dialogues from file.
2017:06:07 10:43:52	......number of instances: 70858
2017:06:07 10:43:52	rnn type is lstm
2017:06:07 10:43:53	rnn type is lstm
2017:06:07 10:43:53	define train operations...
2017:06:07 10:43:54	variables in the discriminator:
2017:06:07 10:43:55	variables in the generator:
2017:06:07 10:44:22	use DataLoaderBBTV1 to init data.
2017:06:07 10:44:22	...init bucket.
2017:06:07 10:44:22	...load data.
2017:06:07 10:44:22	init content from raw.
2017:06:07 10:44:22	...init data from the raw dataset.
2017:06:07 10:44:22	...read dialogues from file.
2017:06:07 10:44:22	......number of instances: 70858
2017:06:07 10:44:22	rnn type is lstm
2017:06:07 10:44:40	use DataLoaderBBTV1 to init data.
2017:06:07 10:44:40	...init bucket.
2017:06:07 10:44:40	...load data.
2017:06:07 10:44:40	init content from raw.
2017:06:07 10:44:40	...init data from the raw dataset.
2017:06:07 10:44:40	...read dialogues from file.
2017:06:07 10:44:41	......number of instances: 70858
2017:06:07 10:44:41	rnn type is lstm
2017:06:07 10:44:41	rnn type is lstm
2017:06:07 10:44:42	define train operations...
2017:06:07 10:44:43	variables in the discriminator:
2017:06:07 10:44:43	variables in the generator:
2017:06:07 10:45:44	use DataLoaderBBTV1 to init data.
2017:06:07 10:45:44	...init bucket.
2017:06:07 10:45:44	...load data.
2017:06:07 10:45:44	init content from raw.
2017:06:07 10:45:44	...init data from the raw dataset.
2017:06:07 10:45:44	...read dialogues from file.
2017:06:07 10:45:45	......number of instances: 70858
2017:06:07 10:45:45	rnn type is lstm
2017:06:07 10:45:45	rnn type is lstm
2017:06:07 10:45:46	define train operations...
2017:06:07 10:45:47	variables in the discriminator:
2017:06:07 10:45:48	variables in the generator:
2017:06:07 10:47:04	use DataLoaderBBTV1 to init data.
2017:06:07 10:47:04	...init bucket.
2017:06:07 10:47:04	...load data.
2017:06:07 10:47:04	init content from raw.
2017:06:07 10:47:04	...init data from the raw dataset.
2017:06:07 10:47:04	...read dialogues from file.
2017:06:07 10:47:04	......number of instances: 70858
2017:06:07 10:47:04	rnn type is lstm
2017:06:07 10:48:01	use DataLoaderBBTV1 to init data.
2017:06:07 10:48:01	...init bucket.
2017:06:07 10:48:01	...load data.
2017:06:07 10:48:01	init content from raw.
2017:06:07 10:48:01	...init data from the raw dataset.
2017:06:07 10:48:01	...read dialogues from file.
2017:06:07 10:48:02	......number of instances: 70858
2017:06:07 10:48:02	rnn type is lstm
2017:06:07 10:48:28	use DataLoaderBBTV1 to init data.
2017:06:07 10:48:28	...init bucket.
2017:06:07 10:48:28	...load data.
2017:06:07 10:48:28	init content from raw.
2017:06:07 10:48:28	...init data from the raw dataset.
2017:06:07 10:48:28	...read dialogues from file.
2017:06:07 10:48:29	......number of instances: 70858
2017:06:07 10:48:29	rnn type is lstm
2017:06:07 10:48:29	rnn type is lstm
2017:06:07 10:48:30	define train operations...
2017:06:07 10:48:30	variables in the discriminator:
2017:06:07 10:48:31	variables in the generator:
2017:06:07 11:16:54	use DataLoaderBBTV1 to init data.
2017:06:07 11:16:54	...init bucket.
2017:06:07 11:16:54	...load data.
2017:06:07 11:16:54	init content from raw.
2017:06:07 11:16:54	...init data from the raw dataset.
2017:06:07 11:16:54	...read dialogues from file.
2017:06:07 11:16:55	......number of instances: 70858
2017:06:07 11:16:55	rnn type is lstm
2017:06:07 11:17:05	use DataLoaderBBTV1 to init data.
2017:06:07 11:17:05	...init bucket.
2017:06:07 11:17:05	...load data.
2017:06:07 11:17:05	init content from raw.
2017:06:07 11:17:05	...init data from the raw dataset.
2017:06:07 11:17:05	...read dialogues from file.
2017:06:07 11:17:05	......number of instances: 70858
2017:06:07 11:17:05	rnn type is lstm
2017:06:07 11:17:06	rnn type is lstm
2017:06:07 11:17:06	define train operations...
2017:06:07 11:17:07	variables in the discriminator:
2017:06:07 11:17:08	variables in the generator:
2017:06:07 11:17:25	use DataLoaderBBTV1 to init data.
2017:06:07 11:17:25	...init bucket.
2017:06:07 11:17:25	...load data.
2017:06:07 11:17:25	init content from raw.
2017:06:07 11:17:25	...init data from the raw dataset.
2017:06:07 11:17:25	...read dialogues from file.
2017:06:07 11:17:25	......number of instances: 70858
2017:06:07 11:17:25	rnn type is lstm
2017:06:07 11:17:26	rnn type is lstm
2017:06:07 11:17:26	define train operations...
2017:06:07 11:17:27	variables in the discriminator:
2017:06:07 11:17:28	variables in the generator:
2017:06:07 11:17:56	use DataLoaderBBTV1 to init data.
2017:06:07 11:17:56	...init bucket.
2017:06:07 11:17:56	...load data.
2017:06:07 11:17:56	init content from raw.
2017:06:07 11:17:56	...init data from the raw dataset.
2017:06:07 11:17:56	...read dialogues from file.
2017:06:07 11:17:57	......number of instances: 70858
2017:06:07 11:17:57	rnn type is lstm
2017:06:07 11:17:57	rnn type is lstm
2017:06:07 11:17:58	define train operations...
2017:06:07 11:17:58	variables in the discriminator:
2017:06:07 11:17:59	variables in the generator:
2017:06:07 11:20:07	use DataLoaderBBTV1 to init data.
2017:06:07 11:20:07	...init bucket.
2017:06:07 11:20:07	...load data.
2017:06:07 11:20:07	init content from raw.
2017:06:07 11:20:07	...init data from the raw dataset.
2017:06:07 11:20:07	...read dialogues from file.
2017:06:07 11:20:08	......number of instances: 70858
2017:06:07 11:20:08	rnn type is lstm
2017:06:07 11:20:08	rnn type is lstm
2017:06:07 11:20:09	define train operations...
2017:06:07 11:20:10	variables in the discriminator:
2017:06:07 11:20:11	variables in the generator:
2017:06:07 11:21:12	use DataLoaderBBTV1 to init data.
2017:06:07 11:21:12	...init bucket.
2017:06:07 11:21:12	...load data.
2017:06:07 11:21:12	init content from raw.
2017:06:07 11:21:12	...init data from the raw dataset.
2017:06:07 11:21:12	...read dialogues from file.
2017:06:07 11:21:12	......number of instances: 70858
2017:06:07 11:21:13	rnn type is lstm
2017:06:07 11:21:22	use DataLoaderBBTV1 to init data.
2017:06:07 11:21:22	...init bucket.
2017:06:07 11:21:22	...load data.
2017:06:07 11:21:22	init content from raw.
2017:06:07 11:21:22	...init data from the raw dataset.
2017:06:07 11:21:22	...read dialogues from file.
2017:06:07 11:21:23	......number of instances: 70858
2017:06:07 11:21:23	rnn type is lstm
2017:06:07 11:21:23	rnn type is lstm
2017:06:07 11:21:23	define train operations...
2017:06:07 11:21:24	variables in the discriminator:
2017:06:07 11:21:25	variables in the generator:
2017:06:07 11:27:06	use DataLoaderBBTV1 to init data.
2017:06:07 11:27:06	...init bucket.
2017:06:07 11:27:06	...load data.
2017:06:07 11:27:06	init content from raw.
2017:06:07 11:27:06	...init data from the raw dataset.
2017:06:07 11:27:06	...read dialogues from file.
2017:06:07 11:27:07	......number of instances: 70858
2017:06:07 11:27:07	rnn type is lstm
2017:06:07 11:27:45	use DataLoaderBBTV1 to init data.
2017:06:07 11:27:45	...init bucket.
2017:06:07 11:27:45	...load data.
2017:06:07 11:27:45	init content from raw.
2017:06:07 11:27:45	...init data from the raw dataset.
2017:06:07 11:27:45	...read dialogues from file.
2017:06:07 11:27:46	......number of instances: 70858
2017:06:07 11:27:46	rnn type is lstm
2017:06:07 11:27:46	rnn type is lstm
2017:06:07 11:27:47	define train operations...
2017:06:07 11:27:48	variables in the discriminator:
2017:06:07 11:27:49	variables in the generator:
2017:06:07 11:28:06	use DataLoaderBBTV1 to init data.
2017:06:07 11:28:06	...init bucket.
2017:06:07 11:28:06	...load data.
2017:06:07 11:28:06	init content from raw.
2017:06:07 11:28:06	...init data from the raw dataset.
2017:06:07 11:28:06	...read dialogues from file.
2017:06:07 11:28:08	......number of instances: 70858
2017:06:07 11:28:08	rnn type is lstm
2017:06:07 11:28:08	rnn type is lstm
2017:06:07 11:28:09	define train operations...
2017:06:07 11:28:09	variables in the discriminator:
2017:06:07 11:28:10	variables in the generator:
2017:06:07 11:30:39	use DataLoaderBBTV1 to init data.
2017:06:07 11:30:39	...init bucket.
2017:06:07 11:30:39	...load data.
2017:06:07 11:30:39	init content from raw.
2017:06:07 11:30:39	...init data from the raw dataset.
2017:06:07 11:30:39	...read dialogues from file.
2017:06:07 11:30:40	......number of instances: 70858
2017:06:07 11:30:40	rnn type is lstm
2017:06:07 11:31:04	use DataLoaderBBTV1 to init data.
2017:06:07 11:31:04	...init bucket.
2017:06:07 11:31:04	...load data.
2017:06:07 11:31:04	init content from raw.
2017:06:07 11:31:04	...init data from the raw dataset.
2017:06:07 11:31:04	...read dialogues from file.
2017:06:07 11:31:05	......number of instances: 70858
2017:06:07 11:31:05	rnn type is lstm
2017:06:07 11:31:06	rnn type is lstm
2017:06:07 11:31:06	define train operations...
2017:06:07 11:31:07	variables in the discriminator:
2017:06:07 11:31:08	variables in the generator:
2017:06:07 11:32:14	use DataLoaderBBTV1 to init data.
2017:06:07 11:32:14	...init bucket.
2017:06:07 11:32:14	...load data.
2017:06:07 11:32:14	init content from raw.
2017:06:07 11:32:14	...init data from the raw dataset.
2017:06:07 11:32:14	...read dialogues from file.
2017:06:07 11:32:15	......number of instances: 70858
2017:06:07 11:32:15	rnn type is lstm
2017:06:07 11:32:15	rnn type is lstm
2017:06:07 11:32:16	define train operations...
2017:06:07 11:32:17	variables in the discriminator:
2017:06:07 11:32:17	variables in the generator:
2017:06:07 11:32:44	use DataLoaderBBTV1 to init data.
2017:06:07 11:32:44	...init bucket.
2017:06:07 11:32:44	...load data.
2017:06:07 11:32:44	init content from raw.
2017:06:07 11:32:44	...init data from the raw dataset.
2017:06:07 11:32:44	...read dialogues from file.
2017:06:07 11:32:45	......number of instances: 70858
2017:06:07 11:32:45	rnn type is lstm
2017:06:07 11:32:46	rnn type is lstm
2017:06:07 11:32:46	define train operations...
2017:06:07 11:32:47	variables in the discriminator:
2017:06:07 11:32:48	variables in the generator:
2017:06:07 11:32:57	use DataLoaderBBTV1 to init data.
2017:06:07 11:32:57	...init bucket.
2017:06:07 11:32:57	...load data.
2017:06:07 11:32:57	init content from raw.
2017:06:07 11:32:57	...init data from the raw dataset.
2017:06:07 11:32:57	...read dialogues from file.
2017:06:07 11:32:58	......number of instances: 70858
2017:06:07 11:32:58	rnn type is lstm
2017:06:07 11:32:58	rnn type is lstm
2017:06:07 11:32:59	define train operations...
2017:06:07 11:33:00	variables in the discriminator:
2017:06:07 11:33:01	variables in the generator:
2017:06:07 11:33:49	use DataLoaderBBTV1 to init data.
2017:06:07 11:33:49	...init bucket.
2017:06:07 11:33:49	...load data.
2017:06:07 11:33:49	init content from raw.
2017:06:07 11:33:49	...init data from the raw dataset.
2017:06:07 11:33:49	...read dialogues from file.
2017:06:07 11:33:50	......number of instances: 70858
2017:06:07 11:33:50	rnn type is lstm
2017:06:07 11:33:50	rnn type is lstm
2017:06:07 11:33:51	define train operations...
2017:06:07 11:33:52	variables in the discriminator:
2017:06:07 11:33:52	variables in the generator:
2017:06:07 11:35:06	use DataLoaderBBTV1 to init data.
2017:06:07 11:35:06	...init bucket.
2017:06:07 11:35:06	...load data.
2017:06:07 11:35:06	init content from raw.
2017:06:07 11:35:06	...init data from the raw dataset.
2017:06:07 11:35:06	...read dialogues from file.
2017:06:07 11:35:07	......number of instances: 70858
2017:06:07 11:35:07	rnn type is lstm
2017:06:07 11:35:07	rnn type is lstm
2017:06:07 11:35:08	define train operations...
2017:06:07 11:35:09	variables in the discriminator:
2017:06:07 11:35:10	variables in the generator:
2017:06:07 11:35:48	use DataLoaderBBTV1 to init data.
2017:06:07 11:35:48	...init bucket.
2017:06:07 11:35:48	...load data.
2017:06:07 11:35:48	init content from raw.
2017:06:07 11:35:48	...init data from the raw dataset.
2017:06:07 11:35:48	...read dialogues from file.
2017:06:07 11:35:49	......number of instances: 70858
2017:06:07 11:35:49	rnn type is lstm
2017:06:07 11:35:49	rnn type is lstm
2017:06:07 11:35:49	define train operations...
2017:06:07 11:35:50	variables in the discriminator:
2017:06:07 11:35:51	variables in the generator:
2017:06:07 11:43:35	use DataLoaderBBTV1 to init data.
2017:06:07 11:43:35	...init bucket.
2017:06:07 11:43:35	...load data.
2017:06:07 11:43:35	init content from raw.
2017:06:07 11:43:35	...init data from the raw dataset.
2017:06:07 11:43:35	...read dialogues from file.
2017:06:07 11:43:36	......number of instances: 70858
2017:06:07 11:43:36	rnn type is lstm
2017:06:07 11:43:53	use DataLoaderBBTV1 to init data.
2017:06:07 11:43:53	...init bucket.
2017:06:07 11:43:53	...load data.
2017:06:07 11:43:53	init content from raw.
2017:06:07 11:43:53	...init data from the raw dataset.
2017:06:07 11:43:53	...read dialogues from file.
2017:06:07 11:43:53	......number of instances: 70858
2017:06:07 11:43:53	rnn type is lstm
2017:06:07 11:43:54	rnn type is lstm
2017:06:07 11:43:54	define train operations...
2017:06:07 11:43:55	variables in the discriminator:
2017:06:07 11:43:56	variables in the generator:
2017:06:07 11:45:11	use DataLoaderBBTV1 to init data.
2017:06:07 11:45:11	...init bucket.
2017:06:07 11:45:11	...load data.
2017:06:07 11:45:11	init content from raw.
2017:06:07 11:45:11	...init data from the raw dataset.
2017:06:07 11:45:11	...read dialogues from file.
2017:06:07 11:45:12	......number of instances: 70858
2017:06:07 11:45:12	rnn type is lstm
2017:06:07 11:54:43	use DataLoaderBBTV1 to init data.
2017:06:07 11:54:43	...init bucket.
2017:06:07 11:54:43	...load data.
2017:06:07 11:54:43	init content from raw.
2017:06:07 11:54:43	...init data from the raw dataset.
2017:06:07 11:54:43	...read dialogues from file.
2017:06:07 11:54:44	......number of instances: 70858
2017:06:07 11:54:44	rnn type is lstm
2017:06:07 11:55:24	use DataLoaderBBTV1 to init data.
2017:06:07 11:55:24	...init bucket.
2017:06:07 11:55:24	...load data.
2017:06:07 11:55:24	init content from raw.
2017:06:07 11:55:24	...init data from the raw dataset.
2017:06:07 11:55:24	...read dialogues from file.
2017:06:07 11:55:25	......number of instances: 70858
2017:06:07 11:55:25	rnn type is lstm
2017:06:07 11:56:47	use DataLoaderBBTV1 to init data.
2017:06:07 11:56:47	...init bucket.
2017:06:07 11:56:47	...load data.
2017:06:07 11:56:47	init content from raw.
2017:06:07 11:56:47	...init data from the raw dataset.
2017:06:07 11:56:47	...read dialogues from file.
2017:06:07 11:56:48	......number of instances: 70858
2017:06:07 11:56:48	rnn type is lstm
2017:06:07 11:57:05	use DataLoaderBBTV1 to init data.
2017:06:07 11:57:05	...init bucket.
2017:06:07 11:57:05	...load data.
2017:06:07 11:57:05	init content from raw.
2017:06:07 11:57:05	...init data from the raw dataset.
2017:06:07 11:57:05	...read dialogues from file.
2017:06:07 11:57:06	......number of instances: 70858
2017:06:07 11:57:06	rnn type is lstm
2017:06:07 11:57:17	use DataLoaderBBTV1 to init data.
2017:06:07 11:57:17	...init bucket.
2017:06:07 11:57:17	...load data.
2017:06:07 11:57:17	init content from raw.
2017:06:07 11:57:17	...init data from the raw dataset.
2017:06:07 11:57:17	...read dialogues from file.
2017:06:07 11:57:18	......number of instances: 70858
2017:06:07 11:57:18	rnn type is lstm
2017:06:07 12:07:15	use DataLoaderBBTV1 to init data.
2017:06:07 12:07:15	...init bucket.
2017:06:07 12:07:15	...load data.
2017:06:07 12:07:15	init content from raw.
2017:06:07 12:07:15	...init data from the raw dataset.
2017:06:07 12:07:15	...read dialogues from file.
2017:06:07 12:07:16	......number of instances: 70858
2017:06:07 12:07:16	rnn type is lstm
2017:06:07 12:07:29	use DataLoaderBBTV1 to init data.
2017:06:07 12:07:29	...init bucket.
2017:06:07 12:07:29	...load data.
2017:06:07 12:07:29	init content from raw.
2017:06:07 12:07:29	...init data from the raw dataset.
2017:06:07 12:07:29	...read dialogues from file.
2017:06:07 12:07:30	......number of instances: 70858
2017:06:07 12:07:30	rnn type is lstm
2017:06:07 12:07:43	use DataLoaderBBTV1 to init data.
2017:06:07 12:07:43	...init bucket.
2017:06:07 12:07:43	...load data.
2017:06:07 12:07:43	init content from raw.
2017:06:07 12:07:43	...init data from the raw dataset.
2017:06:07 12:07:43	...read dialogues from file.
2017:06:07 12:07:44	......number of instances: 70858
2017:06:07 12:07:44	rnn type is lstm
2017:06:07 12:08:24	use DataLoaderBBTV1 to init data.
2017:06:07 12:08:24	...init bucket.
2017:06:07 12:08:24	...load data.
2017:06:07 12:08:24	init content from raw.
2017:06:07 12:08:24	...init data from the raw dataset.
2017:06:07 12:08:24	...read dialogues from file.
2017:06:07 12:08:25	......number of instances: 70858
2017:06:07 12:08:25	rnn type is lstm
2017:06:07 12:08:25	rnn type is lstm
2017:06:07 12:08:26	define train operations...
2017:06:07 12:08:27	variables in the discriminator:
2017:06:07 12:08:27	variables in the generator:
2017:06:07 12:24:59	use DataLoaderBBTV1 to init data.
2017:06:07 12:24:59	...init bucket.
2017:06:07 12:24:59	...load data.
2017:06:07 12:24:59	init content from raw.
2017:06:07 12:24:59	...init data from the raw dataset.
2017:06:07 12:24:59	...read dialogues from file.
2017:06:07 12:25:00	......number of instances: 70858
2017:06:07 12:25:00	rnn type is lstm
2017:06:07 12:25:00	rnn type is lstm
2017:06:07 12:25:01	define train operations...
2017:06:07 12:25:01	variables in the discriminator:
2017:06:07 12:25:02	variables in the generator:
2017:06:07 12:25:43	use DataLoaderBBTV1 to init data.
2017:06:07 12:25:43	...init bucket.
2017:06:07 12:25:43	...load data.
2017:06:07 12:25:43	init content from raw.
2017:06:07 12:25:43	...init data from the raw dataset.
2017:06:07 12:25:43	...read dialogues from file.
2017:06:07 12:25:44	......number of instances: 70858
2017:06:07 12:25:44	rnn type is lstm
2017:06:07 12:25:44	rnn type is lstm
2017:06:07 12:25:45	define train operations...
2017:06:07 12:25:46	variables in the discriminator:
2017:06:07 12:25:46	variables in the generator:
2017:06:07 12:26:03	use DataLoaderBBTV1 to init data.
2017:06:07 12:26:03	...init bucket.
2017:06:07 12:26:03	...load data.
2017:06:07 12:26:03	init content from raw.
2017:06:07 12:26:03	...init data from the raw dataset.
2017:06:07 12:26:03	...read dialogues from file.
2017:06:07 12:26:04	......number of instances: 70858
2017:06:07 12:26:04	rnn type is lstm
2017:06:07 12:26:04	rnn type is lstm
2017:06:07 12:26:05	define train operations...
2017:06:07 12:26:06	variables in the discriminator:
2017:06:07 12:26:07	variables in the generator:
2017:06:07 12:27:15	use DataLoaderBBTV1 to init data.
2017:06:07 12:27:15	...init bucket.
2017:06:07 12:27:15	...load data.
2017:06:07 12:27:15	init content from raw.
2017:06:07 12:27:15	...init data from the raw dataset.
2017:06:07 12:27:15	...read dialogues from file.
2017:06:07 12:27:16	......number of instances: 70858
2017:06:07 12:27:16	rnn type is lstm
2017:06:07 12:27:42	use DataLoaderBBTV1 to init data.
2017:06:07 12:27:42	...init bucket.
2017:06:07 12:27:42	...load data.
2017:06:07 12:27:42	init content from raw.
2017:06:07 12:27:42	...init data from the raw dataset.
2017:06:07 12:27:42	...read dialogues from file.
2017:06:07 12:27:43	......number of instances: 70858
2017:06:07 12:27:43	rnn type is lstm
2017:06:07 12:27:52	use DataLoaderBBTV1 to init data.
2017:06:07 12:27:52	...init bucket.
2017:06:07 12:27:52	...load data.
2017:06:07 12:27:52	init content from raw.
2017:06:07 12:27:52	...init data from the raw dataset.
2017:06:07 12:27:52	...read dialogues from file.
2017:06:07 12:27:53	......number of instances: 70858
2017:06:07 12:27:53	rnn type is lstm
2017:06:07 12:27:53	rnn type is lstm
2017:06:07 12:27:54	define train operations...
2017:06:07 12:27:54	variables in the discriminator:
2017:06:07 12:27:55	variables in the generator:
2017:06:07 12:28:21	use DataLoaderBBTV1 to init data.
2017:06:07 12:28:21	...init bucket.
2017:06:07 12:28:21	...load data.
2017:06:07 12:28:21	init content from raw.
2017:06:07 12:28:21	...init data from the raw dataset.
2017:06:07 12:28:21	...read dialogues from file.
2017:06:07 12:28:22	......number of instances: 70858
2017:06:07 12:28:22	rnn type is lstm
2017:06:07 12:29:53	use DataLoaderBBTV1 to init data.
2017:06:07 12:29:53	...init bucket.
2017:06:07 12:29:53	...load data.
2017:06:07 12:29:53	init content from raw.
2017:06:07 12:29:53	...init data from the raw dataset.
2017:06:07 12:29:53	...read dialogues from file.
2017:06:07 12:29:54	......number of instances: 70858
2017:06:07 12:29:54	rnn type is lstm
2017:06:07 12:30:06	use DataLoaderBBTV1 to init data.
2017:06:07 12:30:06	...init bucket.
2017:06:07 12:30:06	...load data.
2017:06:07 12:30:06	init content from raw.
2017:06:07 12:30:06	...init data from the raw dataset.
2017:06:07 12:30:06	...read dialogues from file.
2017:06:07 12:30:07	......number of instances: 70858
2017:06:07 12:30:07	rnn type is lstm
2017:06:07 12:30:07	rnn type is lstm
2017:06:07 12:30:08	define train operations...
2017:06:07 12:30:08	variables in the discriminator:
2017:06:07 12:30:09	variables in the generator:
2017:06:07 12:30:43	use DataLoaderBBTV1 to init data.
2017:06:07 12:30:43	...init bucket.
2017:06:07 12:30:43	...load data.
2017:06:07 12:30:43	init content from raw.
2017:06:07 12:30:43	...init data from the raw dataset.
2017:06:07 12:30:43	...read dialogues from file.
2017:06:07 12:30:44	......number of instances: 70858
2017:06:07 12:30:44	rnn type is lstm
2017:06:07 12:30:44	rnn type is lstm
2017:06:07 12:30:45	define train operations...
2017:06:07 12:30:46	variables in the discriminator:
2017:06:07 12:30:46	variables in the generator:
2017:06:07 12:32:29	use DataLoaderBBTV1 to init data.
2017:06:07 12:32:29	...init bucket.
2017:06:07 12:32:29	...load data.
2017:06:07 12:32:29	init content from raw.
2017:06:07 12:32:29	...init data from the raw dataset.
2017:06:07 12:32:29	...read dialogues from file.
2017:06:07 12:32:29	......number of instances: 70858
2017:06:07 12:32:30	rnn type is lstm
2017:06:07 12:32:30	rnn type is lstm
2017:06:07 12:32:31	define train operations...
2017:06:07 12:32:31	variables in the discriminator:
2017:06:07 12:32:32	variables in the generator:
2017:06:07 12:32:37	use DataLoaderBBTV1 to init data.
2017:06:07 12:32:37	...init bucket.
2017:06:07 12:32:37	...load data.
2017:06:07 12:32:37	init content from raw.
2017:06:07 12:32:37	...init data from the raw dataset.
2017:06:07 12:32:37	...read dialogues from file.
2017:06:07 12:32:38	......number of instances: 70858
2017:06:07 12:32:38	rnn type is lstm
2017:06:07 12:32:38	rnn type is lstm
2017:06:07 12:32:39	define train operations...
2017:06:07 12:32:40	variables in the discriminator:
2017:06:07 12:32:41	variables in the generator:
2017:06:07 12:36:12	use DataLoaderBBTV1 to init data.
2017:06:07 12:36:12	...init bucket.
2017:06:07 12:36:12	...load data.
2017:06:07 12:36:12	init content from raw.
2017:06:07 12:36:12	...init data from the raw dataset.
2017:06:07 12:36:12	...read dialogues from file.
2017:06:07 12:36:12	......number of instances: 70858
2017:06:07 12:36:12	rnn type is lstm
2017:06:07 12:36:28	use DataLoaderBBTV1 to init data.
2017:06:07 12:36:28	...init bucket.
2017:06:07 12:36:28	...load data.
2017:06:07 12:36:28	init content from raw.
2017:06:07 12:36:28	...init data from the raw dataset.
2017:06:07 12:36:28	...read dialogues from file.
2017:06:07 12:36:28	......number of instances: 70858
2017:06:07 12:36:28	rnn type is lstm
2017:06:07 12:36:44	use DataLoaderBBTV1 to init data.
2017:06:07 12:36:44	...init bucket.
2017:06:07 12:36:44	...load data.
2017:06:07 12:36:44	init content from raw.
2017:06:07 12:36:44	...init data from the raw dataset.
2017:06:07 12:36:44	...read dialogues from file.
2017:06:07 12:36:45	......number of instances: 70858
2017:06:07 12:36:45	rnn type is lstm
2017:06:07 12:36:45	rnn type is lstm
2017:06:07 12:36:46	define train operations...
2017:06:07 12:36:47	variables in the discriminator:
2017:06:07 12:36:47	variables in the generator:
2017:06:07 12:37:29	use DataLoaderBBTV1 to init data.
2017:06:07 12:37:29	...init bucket.
2017:06:07 12:37:29	...load data.
2017:06:07 12:37:29	init content from raw.
2017:06:07 12:37:29	...init data from the raw dataset.
2017:06:07 12:37:29	...read dialogues from file.
2017:06:07 12:37:29	......number of instances: 70858
2017:06:07 12:37:29	rnn type is lstm
2017:06:07 12:37:30	rnn type is lstm
2017:06:07 12:37:30	define train operations...
2017:06:07 12:37:31	variables in the discriminator:
2017:06:07 12:37:32	variables in the generator:
2017:06:07 12:37:42	use DataLoaderBBTV1 to init data.
2017:06:07 12:37:42	...init bucket.
2017:06:07 12:37:42	...load data.
2017:06:07 12:37:42	init content from raw.
2017:06:07 12:37:42	...init data from the raw dataset.
2017:06:07 12:37:42	...read dialogues from file.
2017:06:07 12:37:42	......number of instances: 70858
2017:06:07 12:37:42	rnn type is lstm
2017:06:07 12:38:12	use DataLoaderBBTV1 to init data.
2017:06:07 12:38:12	...init bucket.
2017:06:07 12:38:12	...load data.
2017:06:07 12:38:12	init content from raw.
2017:06:07 12:38:12	...init data from the raw dataset.
2017:06:07 12:38:12	...read dialogues from file.
2017:06:07 12:38:13	......number of instances: 70858
2017:06:07 12:38:13	rnn type is lstm
2017:06:07 12:38:13	rnn type is lstm
2017:06:07 12:38:14	define train operations...
2017:06:07 12:38:15	variables in the discriminator:
2017:06:07 12:38:15	variables in the generator:
2017:06:07 12:38:56	use DataLoaderBBTV1 to init data.
2017:06:07 12:38:56	...init bucket.
2017:06:07 12:38:56	...load data.
2017:06:07 12:38:56	init content from raw.
2017:06:07 12:38:56	...init data from the raw dataset.
2017:06:07 12:38:56	...read dialogues from file.
2017:06:07 12:38:56	......number of instances: 70858
2017:06:07 12:38:56	rnn type is lstm
2017:06:07 12:38:57	rnn type is lstm
2017:06:07 12:38:57	define train operations...
2017:06:07 12:38:58	variables in the discriminator:
2017:06:07 12:38:59	variables in the generator:
2017:06:07 12:39:37	use DataLoaderBBTV1 to init data.
2017:06:07 12:39:37	...init bucket.
2017:06:07 12:39:37	...load data.
2017:06:07 12:39:37	init content from raw.
2017:06:07 12:39:37	...init data from the raw dataset.
2017:06:07 12:39:37	...read dialogues from file.
2017:06:07 12:39:38	......number of instances: 70858
2017:06:07 12:39:38	rnn type is lstm
2017:06:07 12:39:38	rnn type is lstm
2017:06:07 12:39:38	define train operations...
2017:06:07 12:39:39	variables in the discriminator:
2017:06:07 12:39:40	variables in the generator:
2017:06:07 12:41:51	use DataLoaderBBTV1 to init data.
2017:06:07 12:41:51	...init bucket.
2017:06:07 12:41:51	...load data.
2017:06:07 12:41:51	init content from raw.
2017:06:07 12:41:51	...init data from the raw dataset.
2017:06:07 12:41:51	...read dialogues from file.
2017:06:07 12:41:52	......number of instances: 70858
2017:06:07 12:41:52	rnn type is lstm
2017:06:07 12:42:07	use DataLoaderBBTV1 to init data.
2017:06:07 12:42:07	...init bucket.
2017:06:07 12:42:07	...load data.
2017:06:07 12:42:07	init content from raw.
2017:06:07 12:42:07	...init data from the raw dataset.
2017:06:07 12:42:07	...read dialogues from file.
2017:06:07 12:42:08	......number of instances: 70858
2017:06:07 12:42:08	rnn type is lstm
2017:06:07 12:42:08	rnn type is lstm
2017:06:07 12:42:09	define train operations...
2017:06:07 12:42:09	variables in the discriminator:
2017:06:07 12:42:10	variables in the generator:
2017:06:07 12:42:41	use DataLoaderBBTV1 to init data.
2017:06:07 12:42:41	...init bucket.
2017:06:07 12:42:41	...load data.
2017:06:07 12:42:41	init content from raw.
2017:06:07 12:42:41	...init data from the raw dataset.
2017:06:07 12:42:41	...read dialogues from file.
2017:06:07 12:42:42	......number of instances: 70858
2017:06:07 12:42:42	rnn type is lstm
2017:06:07 12:42:43	rnn type is lstm
2017:06:07 12:42:43	define train operations...
2017:06:07 12:42:44	variables in the discriminator:
2017:06:07 12:42:45	variables in the generator:
2017:06:07 12:44:59	use DataLoaderBBTV1 to init data.
2017:06:07 12:44:59	...init bucket.
2017:06:07 12:44:59	...load data.
2017:06:07 12:44:59	init content from raw.
2017:06:07 12:44:59	...init data from the raw dataset.
2017:06:07 12:44:59	...read dialogues from file.
2017:06:07 12:44:59	......number of instances: 70858
2017:06:07 12:44:59	rnn type is lstm
2017:06:07 12:45:00	rnn type is lstm
2017:06:07 12:45:00	define train operations...
2017:06:07 12:45:01	variables in the discriminator:
2017:06:07 12:45:02	variables in the generator:
2017:06:07 12:45:10	use DataLoaderBBTV1 to init data.
2017:06:07 12:45:10	...init bucket.
2017:06:07 12:45:10	...load data.
2017:06:07 12:45:10	init content from raw.
2017:06:07 12:45:10	...init data from the raw dataset.
2017:06:07 12:45:10	...read dialogues from file.
2017:06:07 12:45:10	......number of instances: 70858
2017:06:07 12:45:10	rnn type is lstm
2017:06:07 12:45:21	use DataLoaderBBTV1 to init data.
2017:06:07 12:45:21	...init bucket.
2017:06:07 12:45:21	...load data.
2017:06:07 12:45:21	init content from raw.
2017:06:07 12:45:21	...init data from the raw dataset.
2017:06:07 12:45:21	...read dialogues from file.
2017:06:07 12:45:21	......number of instances: 70858
2017:06:07 12:45:21	rnn type is lstm
2017:06:07 12:45:34	use DataLoaderBBTV1 to init data.
2017:06:07 12:45:34	...init bucket.
2017:06:07 12:45:34	...load data.
2017:06:07 12:45:34	init content from raw.
2017:06:07 12:45:34	...init data from the raw dataset.
2017:06:07 12:45:34	...read dialogues from file.
2017:06:07 12:45:34	......number of instances: 70858
2017:06:07 12:45:35	rnn type is lstm
2017:06:07 12:48:06	use DataLoaderBBTV1 to init data.
2017:06:07 12:48:06	...init bucket.
2017:06:07 12:48:06	...load data.
2017:06:07 12:48:06	init content from raw.
2017:06:07 12:48:06	...init data from the raw dataset.
2017:06:07 12:48:06	...read dialogues from file.
2017:06:07 12:48:07	......number of instances: 70858
2017:06:07 12:48:07	rnn type is lstm
2017:06:07 12:48:07	rnn type is lstm
2017:06:07 12:48:08	define train operations...
2017:06:07 12:48:09	variables in the discriminator:
2017:06:07 12:48:09	variables in the generator:
2017:06:07 12:49:02	use DataLoaderBBTV1 to init data.
2017:06:07 12:49:02	...init bucket.
2017:06:07 12:49:02	...load data.
2017:06:07 12:49:02	init content from raw.
2017:06:07 12:49:02	...init data from the raw dataset.
2017:06:07 12:49:02	...read dialogues from file.
2017:06:07 12:49:03	......number of instances: 70858
2017:06:07 12:49:03	rnn type is lstm
2017:06:07 12:49:03	rnn type is lstm
2017:06:07 12:49:04	define train operations...
2017:06:07 12:49:05	variables in the discriminator:
2017:06:07 12:49:05	variables in the generator:
2017:06:07 13:10:20	use DataLoaderBBTV1 to init data.
2017:06:07 13:10:20	...init bucket.
2017:06:07 13:10:20	...load data.
2017:06:07 13:10:20	init content from raw.
2017:06:07 13:10:20	...init data from the raw dataset.
2017:06:07 13:10:20	...read dialogues from file.
2017:06:07 13:10:21	......number of instances: 70858
2017:06:07 13:10:21	rnn type is lstm
2017:06:07 13:10:21	rnn type is lstm
2017:06:07 13:10:22	define train operations...
2017:06:07 13:10:23	variables in the discriminator:
2017:06:07 13:10:24	variables in the generator:
2017:06:07 13:10:52	use DataLoaderBBTV1 to init data.
2017:06:07 13:10:52	...init bucket.
2017:06:07 13:10:52	...load data.
2017:06:07 13:10:52	init content from raw.
2017:06:07 13:10:52	...init data from the raw dataset.
2017:06:07 13:10:52	...read dialogues from file.
2017:06:07 13:10:53	......number of instances: 70858
2017:06:07 13:10:53	rnn type is lstm
2017:06:07 13:10:53	rnn type is lstm
2017:06:07 13:10:53	define train operations...
2017:06:07 13:10:54	variables in the discriminator:
2017:06:07 13:10:55	variables in the generator:
2017:06:07 13:11:26	use DataLoaderBBTV1 to init data.
2017:06:07 13:11:26	...init bucket.
2017:06:07 13:11:26	...load data.
2017:06:07 13:11:26	init content from raw.
2017:06:07 13:11:26	...init data from the raw dataset.
2017:06:07 13:11:26	...read dialogues from file.
2017:06:07 13:11:27	......number of instances: 70858
2017:06:07 13:11:27	rnn type is lstm
2017:06:07 13:11:27	rnn type is lstm
2017:06:07 13:11:28	define train operations...
2017:06:07 13:11:29	variables in the discriminator:
2017:06:07 13:11:30	variables in the generator:
2017:06:07 13:12:23	use DataLoaderBBTV1 to init data.
2017:06:07 13:12:23	...init bucket.
2017:06:07 13:12:23	...load data.
2017:06:07 13:12:23	init content from raw.
2017:06:07 13:12:23	...init data from the raw dataset.
2017:06:07 13:12:23	...read dialogues from file.
2017:06:07 13:12:24	......number of instances: 70858
2017:06:07 13:12:24	rnn type is lstm
2017:06:07 13:12:24	rnn type is lstm
2017:06:07 13:12:25	define train operations...
2017:06:07 13:12:25	variables in the discriminator:
2017:06:07 13:12:26	variables in the generator:
2017:06:07 13:19:17	use DataLoaderBBTV1 to init data.
2017:06:07 13:19:17	...init bucket.
2017:06:07 13:19:17	...load data.
2017:06:07 13:19:17	init content from raw.
2017:06:07 13:19:17	...init data from the raw dataset.
2017:06:07 13:19:17	...read dialogues from file.
2017:06:07 13:19:18	......number of instances: 70858
2017:06:07 13:19:18	rnn type is lstm
2017:06:07 13:19:25	use DataLoaderBBTV1 to init data.
2017:06:07 13:19:25	...init bucket.
2017:06:07 13:19:25	...load data.
2017:06:07 13:19:25	init content from raw.
2017:06:07 13:19:25	...init data from the raw dataset.
2017:06:07 13:19:25	...read dialogues from file.
2017:06:07 13:19:26	......number of instances: 70858
2017:06:07 13:19:26	rnn type is lstm
2017:06:07 13:19:39	use DataLoaderBBTV1 to init data.
2017:06:07 13:19:39	...init bucket.
2017:06:07 13:19:39	...load data.
2017:06:07 13:19:39	init content from raw.
2017:06:07 13:19:39	...init data from the raw dataset.
2017:06:07 13:19:39	...read dialogues from file.
2017:06:07 13:19:40	......number of instances: 70858
2017:06:07 13:19:40	rnn type is lstm
2017:06:07 13:19:50	use DataLoaderBBTV1 to init data.
2017:06:07 13:19:50	...init bucket.
2017:06:07 13:19:50	...load data.
2017:06:07 13:19:50	init content from raw.
2017:06:07 13:19:50	...init data from the raw dataset.
2017:06:07 13:19:50	...read dialogues from file.
2017:06:07 13:19:51	......number of instances: 70858
2017:06:07 13:19:51	rnn type is lstm
2017:06:07 13:19:51	rnn type is lstm
2017:06:07 13:19:52	define train operations...
2017:06:07 13:19:52	variables in the discriminator:
2017:06:07 13:19:53	variables in the generator:
2017:06:07 13:24:55	use DataLoaderBBTV1 to init data.
2017:06:07 13:24:55	...init bucket.
2017:06:07 13:24:55	...load data.
2017:06:07 13:24:55	init content from raw.
2017:06:07 13:24:55	...init data from the raw dataset.
2017:06:07 13:24:55	...read dialogues from file.
2017:06:07 13:24:56	......number of instances: 70858
2017:06:07 13:24:56	rnn type is lstm
2017:06:07 13:47:48	use DataLoaderBBTV1 to init data.
2017:06:07 13:47:48	...init bucket.
2017:06:07 13:47:48	...load data.
2017:06:07 13:47:48	init content from raw.
2017:06:07 13:47:48	...init data from the raw dataset.
2017:06:07 13:47:48	...read dialogues from file.
2017:06:07 13:47:49	......number of instances: 70858
2017:06:07 13:47:49	rnn type is lstm
2017:06:07 13:47:49	rnn type is lstm
2017:06:07 13:47:50	define train operations...
2017:06:07 13:47:50	variables in the discriminator:
2017:06:07 13:47:51	variables in the generator:
2017:06:07 13:48:44	use DataLoaderBBTV1 to init data.
2017:06:07 13:48:44	...init bucket.
2017:06:07 13:48:44	...load data.
2017:06:07 13:48:44	init content from raw.
2017:06:07 13:48:44	...init data from the raw dataset.
2017:06:07 13:48:44	...read dialogues from file.
2017:06:07 13:48:45	......number of instances: 70858
2017:06:07 13:48:45	rnn type is lstm
2017:06:07 13:48:45	rnn type is lstm
2017:06:07 13:48:46	define train operations...
2017:06:07 13:48:48	variables in the discriminator:
2017:06:07 13:48:49	variables in the generator:
2017:06:07 13:49:24	use DataLoaderBBTV1 to init data.
2017:06:07 13:49:24	...init bucket.
2017:06:07 13:49:24	...load data.
2017:06:07 13:49:24	init content from raw.
2017:06:07 13:49:24	...init data from the raw dataset.
2017:06:07 13:49:24	...read dialogues from file.
2017:06:07 13:49:25	......number of instances: 70858
2017:06:07 13:49:25	rnn type is lstm
2017:06:07 13:49:25	rnn type is lstm
2017:06:07 13:49:26	define train operations...
2017:06:07 13:49:27	variables in the discriminator:
2017:06:07 13:49:28	variables in the generator:
2017:06:07 14:09:39	use DataLoaderBBTV1 to init data.
2017:06:07 14:09:39	...init bucket.
2017:06:07 14:09:39	...load data.
2017:06:07 14:09:39	init content from raw.
2017:06:07 14:09:39	...init data from the raw dataset.
2017:06:07 14:09:39	...read dialogues from file.
2017:06:07 14:09:39	......number of instances: 70858
2017:06:07 14:09:40	rnn type is lstm
2017:06:07 14:09:50	use DataLoaderBBTV1 to init data.
2017:06:07 14:09:50	...init bucket.
2017:06:07 14:09:50	...load data.
2017:06:07 14:09:50	init content from raw.
2017:06:07 14:09:50	...init data from the raw dataset.
2017:06:07 14:09:50	...read dialogues from file.
2017:06:07 14:09:50	......number of instances: 70858
2017:06:07 14:09:50	rnn type is lstm
2017:06:07 14:11:11	use DataLoaderBBTV1 to init data.
2017:06:07 14:11:11	...init bucket.
2017:06:07 14:11:11	...load data.
2017:06:07 14:11:11	init content from raw.
2017:06:07 14:11:11	...init data from the raw dataset.
2017:06:07 14:11:11	...read dialogues from file.
2017:06:07 14:11:12	......number of instances: 70858
2017:06:07 14:11:12	rnn type is lstm
2017:06:07 14:11:19	use DataLoaderBBTV1 to init data.
2017:06:07 14:11:19	...init bucket.
2017:06:07 14:11:19	...load data.
2017:06:07 14:11:19	init content from raw.
2017:06:07 14:11:19	...init data from the raw dataset.
2017:06:07 14:11:19	...read dialogues from file.
2017:06:07 14:11:20	......number of instances: 70858
2017:06:07 14:11:20	rnn type is lstm
2017:06:07 14:11:39	use DataLoaderBBTV1 to init data.
2017:06:07 14:11:39	...init bucket.
2017:06:07 14:11:39	...load data.
2017:06:07 14:11:39	init content from raw.
2017:06:07 14:11:39	...init data from the raw dataset.
2017:06:07 14:11:39	...read dialogues from file.
2017:06:07 14:11:40	......number of instances: 70858
2017:06:07 14:11:40	rnn type is lstm
2017:06:07 14:14:18	use DataLoaderBBTV1 to init data.
2017:06:07 14:14:18	...init bucket.
2017:06:07 14:14:18	...load data.
2017:06:07 14:14:18	init content from raw.
2017:06:07 14:14:18	...init data from the raw dataset.
2017:06:07 14:14:18	...read dialogues from file.
2017:06:07 14:14:19	......number of instances: 70858
2017:06:07 14:14:19	rnn type is lstm
2017:06:07 14:18:21	use DataLoaderBBTV1 to init data.
2017:06:07 14:18:21	...init bucket.
2017:06:07 14:18:21	...load data.
2017:06:07 14:18:21	init content from raw.
2017:06:07 14:18:21	...init data from the raw dataset.
2017:06:07 14:18:21	...read dialogues from file.
2017:06:07 14:18:21	......number of instances: 70858
2017:06:07 14:18:22	rnn type is lstm
2017:06:07 14:19:18	use DataLoaderBBTV1 to init data.
2017:06:07 14:19:18	...init bucket.
2017:06:07 14:19:18	...load data.
2017:06:07 14:19:18	init content from raw.
2017:06:07 14:19:18	...init data from the raw dataset.
2017:06:07 14:19:18	...read dialogues from file.
2017:06:07 14:19:19	......number of instances: 70858
2017:06:07 14:19:19	rnn type is lstm
2017:06:07 14:20:01	use DataLoaderBBTV1 to init data.
2017:06:07 14:20:01	...init bucket.
2017:06:07 14:20:01	...load data.
2017:06:07 14:20:01	init content from raw.
2017:06:07 14:20:01	...init data from the raw dataset.
2017:06:07 14:20:01	...read dialogues from file.
2017:06:07 14:20:02	......number of instances: 70858
2017:06:07 14:20:02	rnn type is lstm
2017:06:07 14:22:22	use DataLoaderBBTV1 to init data.
2017:06:07 14:22:22	...init bucket.
2017:06:07 14:22:22	...load data.
2017:06:07 14:22:22	init content from raw.
2017:06:07 14:22:22	...init data from the raw dataset.
2017:06:07 14:22:22	...read dialogues from file.
2017:06:07 14:22:23	......number of instances: 70858
2017:06:07 14:22:23	rnn type is lstm
2017:06:07 14:25:46	use DataLoaderBBTV1 to init data.
2017:06:07 14:25:46	...init bucket.
2017:06:07 14:25:46	...load data.
2017:06:07 14:25:46	init content from raw.
2017:06:07 14:25:46	...init data from the raw dataset.
2017:06:07 14:25:46	...read dialogues from file.
2017:06:07 14:25:47	......number of instances: 70858
2017:06:07 14:25:47	rnn type is lstm
2017:06:07 14:30:41	use DataLoaderBBTV1 to init data.
2017:06:07 14:30:41	...init bucket.
2017:06:07 14:30:41	...load data.
2017:06:07 14:30:41	init content from raw.
2017:06:07 14:30:41	...init data from the raw dataset.
2017:06:07 14:30:41	...read dialogues from file.
2017:06:07 14:30:42	......number of instances: 70858
2017:06:07 14:30:42	rnn type is lstm
2017:06:07 14:30:53	use DataLoaderBBTV1 to init data.
2017:06:07 14:30:53	...init bucket.
2017:06:07 14:30:53	...load data.
2017:06:07 14:30:53	init content from raw.
2017:06:07 14:30:53	...init data from the raw dataset.
2017:06:07 14:30:53	...read dialogues from file.
2017:06:07 14:30:54	......number of instances: 70858
2017:06:07 14:30:54	rnn type is lstm
2017:06:07 14:36:29	use DataLoaderBBTV1 to init data.
2017:06:07 14:36:29	...init bucket.
2017:06:07 14:36:29	...load data.
2017:06:07 14:36:29	init content from raw.
2017:06:07 14:36:29	...init data from the raw dataset.
2017:06:07 14:36:29	...read dialogues from file.
2017:06:07 14:36:30	......number of instances: 70858
2017:06:07 14:36:30	rnn type is lstm
2017:06:07 14:39:43	use DataLoaderBBTV1 to init data.
2017:06:07 14:39:43	...init bucket.
2017:06:07 14:39:43	...load data.
2017:06:07 14:39:43	init content from raw.
2017:06:07 14:39:43	...init data from the raw dataset.
2017:06:07 14:39:43	...read dialogues from file.
2017:06:07 14:39:44	......number of instances: 70858
2017:06:07 14:39:44	rnn type is lstm
2017:06:07 14:39:58	use DataLoaderBBTV1 to init data.
2017:06:07 14:39:58	...init bucket.
2017:06:07 14:39:58	...load data.
2017:06:07 14:39:58	init content from raw.
2017:06:07 14:39:58	...init data from the raw dataset.
2017:06:07 14:39:58	...read dialogues from file.
2017:06:07 14:39:59	......number of instances: 70858
2017:06:07 14:39:59	rnn type is lstm
2017:06:07 14:43:03	use DataLoaderBBTV1 to init data.
2017:06:07 14:43:03	...init bucket.
2017:06:07 14:43:03	...load data.
2017:06:07 14:43:03	init content from raw.
2017:06:07 14:43:03	...init data from the raw dataset.
2017:06:07 14:43:03	...read dialogues from file.
2017:06:07 14:43:03	......number of instances: 70858
2017:06:07 14:43:04	rnn type is lstm
2017:06:07 14:44:21	use DataLoaderBBTV1 to init data.
2017:06:07 14:44:21	...init bucket.
2017:06:07 14:44:21	...load data.
2017:06:07 14:44:21	init content from raw.
2017:06:07 14:44:21	...init data from the raw dataset.
2017:06:07 14:44:21	...read dialogues from file.
2017:06:07 14:44:21	......number of instances: 70858
2017:06:07 14:44:21	rnn type is lstm
2017:06:07 14:47:00	use DataLoaderBBTV1 to init data.
2017:06:07 14:47:00	...init bucket.
2017:06:07 14:47:00	...load data.
2017:06:07 14:47:00	init content from raw.
2017:06:07 14:47:00	...init data from the raw dataset.
2017:06:07 14:47:00	...read dialogues from file.
2017:06:07 14:47:01	......number of instances: 70858
2017:06:07 14:47:01	rnn type is lstm
2017:06:07 14:47:21	use DataLoaderBBTV1 to init data.
2017:06:07 14:47:21	...init bucket.
2017:06:07 14:47:21	...load data.
2017:06:07 14:47:21	init content from raw.
2017:06:07 14:47:21	...init data from the raw dataset.
2017:06:07 14:47:21	...read dialogues from file.
2017:06:07 14:47:22	......number of instances: 70858
2017:06:07 14:47:22	rnn type is lstm
2017:06:07 14:53:33	use DataLoaderBBTV1 to init data.
2017:06:07 14:53:33	...init bucket.
2017:06:07 14:53:33	...load data.
2017:06:07 14:53:33	init content from raw.
2017:06:07 14:53:33	...init data from the raw dataset.
2017:06:07 14:53:33	...read dialogues from file.
2017:06:07 14:53:34	......number of instances: 70858
2017:06:07 14:53:34	rnn type is lstm
2017:06:07 15:00:01	use DataLoaderBBTV1 to init data.
2017:06:07 15:00:01	...init bucket.
2017:06:07 15:00:01	...load data.
2017:06:07 15:00:01	init content from raw.
2017:06:07 15:00:01	...init data from the raw dataset.
2017:06:07 15:00:01	...read dialogues from file.
2017:06:07 15:00:02	......number of instances: 70858
2017:06:07 15:00:02	rnn type is lstm
2017:06:07 15:01:28	use DataLoaderBBTV1 to init data.
2017:06:07 15:01:28	...init bucket.
2017:06:07 15:01:28	...load data.
2017:06:07 15:01:28	init content from raw.
2017:06:07 15:01:28	...init data from the raw dataset.
2017:06:07 15:01:28	...read dialogues from file.
2017:06:07 15:01:29	......number of instances: 70858
2017:06:07 15:01:29	rnn type is lstm
2017:06:07 15:25:37	use DataLoaderBBTV1 to init data.
2017:06:07 15:25:37	...init bucket.
2017:06:07 15:25:37	...load data.
2017:06:07 15:25:37	init content from raw.
2017:06:07 15:25:37	...init data from the raw dataset.
2017:06:07 15:25:37	...read dialogues from file.
2017:06:07 15:25:38	......number of instances: 70858
2017:06:07 15:25:38	rnn type is lstm
2017:06:07 15:27:53	use DataLoaderBBTV1 to init data.
2017:06:07 15:27:53	...init bucket.
2017:06:07 15:27:53	...load data.
2017:06:07 15:27:53	init content from raw.
2017:06:07 15:27:53	...init data from the raw dataset.
2017:06:07 15:27:53	...read dialogues from file.
2017:06:07 15:27:54	......number of instances: 70858
2017:06:07 15:27:54	rnn type is lstm
2017:06:07 15:37:08	use DataLoaderBBTV1 to init data.
2017:06:07 15:37:08	...init bucket.
2017:06:07 15:37:08	...load data.
2017:06:07 15:37:08	init content from raw.
2017:06:07 15:37:08	...init data from the raw dataset.
2017:06:07 15:37:08	...read dialogues from file.
2017:06:07 15:37:09	......number of instances: 70858
2017:06:07 15:37:09	rnn type is lstm
2017:06:07 15:37:36	use DataLoaderBBTV1 to init data.
2017:06:07 15:37:36	...init bucket.
2017:06:07 15:37:36	...load data.
2017:06:07 15:37:36	init content from raw.
2017:06:07 15:37:36	...init data from the raw dataset.
2017:06:07 15:37:36	...read dialogues from file.
2017:06:07 15:37:36	......number of instances: 70858
2017:06:07 15:37:37	rnn type is lstm
2017:06:07 15:38:00	use DataLoaderBBTV1 to init data.
2017:06:07 15:38:00	...init bucket.
2017:06:07 15:38:00	...load data.
2017:06:07 15:38:00	init content from raw.
2017:06:07 15:38:00	...init data from the raw dataset.
2017:06:07 15:38:00	...read dialogues from file.
2017:06:07 15:38:01	......number of instances: 70858
2017:06:07 15:38:01	rnn type is lstm
2017:06:07 15:38:49	use DataLoaderBBTV1 to init data.
2017:06:07 15:38:49	...init bucket.
2017:06:07 15:38:49	...load data.
2017:06:07 15:38:49	init content from raw.
2017:06:07 15:38:49	...init data from the raw dataset.
2017:06:07 15:38:49	...read dialogues from file.
2017:06:07 15:38:50	......number of instances: 70858
2017:06:07 15:38:50	rnn type is lstm
2017:06:07 15:39:46	use DataLoaderBBTV1 to init data.
2017:06:07 15:39:46	...init bucket.
2017:06:07 15:39:46	...load data.
2017:06:07 15:39:46	init content from raw.
2017:06:07 15:39:46	...init data from the raw dataset.
2017:06:07 15:39:46	...read dialogues from file.
2017:06:07 15:39:46	......number of instances: 70858
2017:06:07 15:39:46	rnn type is lstm
2017:06:07 15:40:09	use DataLoaderBBTV1 to init data.
2017:06:07 15:40:09	...init bucket.
2017:06:07 15:40:09	...load data.
2017:06:07 15:40:09	init content from raw.
2017:06:07 15:40:09	...init data from the raw dataset.
2017:06:07 15:40:09	...read dialogues from file.
2017:06:07 15:40:09	......number of instances: 70858
2017:06:07 15:40:10	rnn type is lstm
2017:06:07 15:40:22	use DataLoaderBBTV1 to init data.
2017:06:07 15:40:22	...init bucket.
2017:06:07 15:40:22	...load data.
2017:06:07 15:40:22	init content from raw.
2017:06:07 15:40:22	...init data from the raw dataset.
2017:06:07 15:40:22	...read dialogues from file.
2017:06:07 15:40:23	......number of instances: 70858
2017:06:07 15:40:23	rnn type is lstm
2017:06:07 15:41:02	use DataLoaderBBTV1 to init data.
2017:06:07 15:41:02	...init bucket.
2017:06:07 15:41:02	...load data.
2017:06:07 15:41:02	init content from raw.
2017:06:07 15:41:02	...init data from the raw dataset.
2017:06:07 15:41:02	...read dialogues from file.
2017:06:07 15:41:02	......number of instances: 70858
2017:06:07 15:41:03	rnn type is lstm
2017:06:07 15:41:29	use DataLoaderBBTV1 to init data.
2017:06:07 15:41:29	...init bucket.
2017:06:07 15:41:29	...load data.
2017:06:07 15:41:29	init content from raw.
2017:06:07 15:41:29	...init data from the raw dataset.
2017:06:07 15:41:29	...read dialogues from file.
2017:06:07 15:41:30	......number of instances: 70858
2017:06:07 15:41:30	rnn type is lstm
2017:06:07 15:42:22	use DataLoaderBBTV1 to init data.
2017:06:07 15:42:22	...init bucket.
2017:06:07 15:42:22	...load data.
2017:06:07 15:42:22	init content from raw.
2017:06:07 15:42:22	...init data from the raw dataset.
2017:06:07 15:42:22	...read dialogues from file.
2017:06:07 15:42:23	......number of instances: 70858
2017:06:07 15:42:23	rnn type is lstm
2017:06:07 15:43:45	use DataLoaderBBTV1 to init data.
2017:06:07 15:43:45	...init bucket.
2017:06:07 15:43:45	...load data.
2017:06:07 15:43:45	init content from raw.
2017:06:07 15:43:45	...init data from the raw dataset.
2017:06:07 15:43:45	...read dialogues from file.
2017:06:07 15:43:46	......number of instances: 70858
2017:06:07 15:43:46	rnn type is lstm
2017:06:07 15:44:03	use DataLoaderBBTV1 to init data.
2017:06:07 15:44:03	...init bucket.
2017:06:07 15:44:03	...load data.
2017:06:07 15:44:03	init content from raw.
2017:06:07 15:44:03	...init data from the raw dataset.
2017:06:07 15:44:03	...read dialogues from file.
2017:06:07 15:44:03	......number of instances: 70858
2017:06:07 15:44:03	rnn type is lstm
2017:06:07 15:44:36	use DataLoaderBBTV1 to init data.
2017:06:07 15:44:36	...init bucket.
2017:06:07 15:44:36	...load data.
2017:06:07 15:44:36	init content from raw.
2017:06:07 15:44:36	...init data from the raw dataset.
2017:06:07 15:44:36	...read dialogues from file.
2017:06:07 15:44:37	......number of instances: 70858
2017:06:07 15:44:37	rnn type is lstm
2017:06:07 15:48:56	use DataLoaderBBTV1 to init data.
2017:06:07 15:48:56	...init bucket.
2017:06:07 15:48:56	...load data.
2017:06:07 15:48:56	init content from raw.
2017:06:07 15:48:56	...init data from the raw dataset.
2017:06:07 15:48:56	...read dialogues from file.
2017:06:07 15:48:57	......number of instances: 70858
2017:06:07 15:48:57	rnn type is lstm
2017:06:07 15:51:24	use DataLoaderBBTV1 to init data.
2017:06:07 15:51:24	...init bucket.
2017:06:07 15:51:24	...load data.
2017:06:07 15:51:24	init content from raw.
2017:06:07 15:51:24	...init data from the raw dataset.
2017:06:07 15:51:24	...read dialogues from file.
2017:06:07 15:51:24	......number of instances: 70858
2017:06:07 15:51:24	rnn type is lstm
2017:06:07 15:51:34	use DataLoaderBBTV1 to init data.
2017:06:07 15:51:34	...init bucket.
2017:06:07 15:51:34	...load data.
2017:06:07 15:51:34	init content from raw.
2017:06:07 15:51:34	...init data from the raw dataset.
2017:06:07 15:51:34	...read dialogues from file.
2017:06:07 15:51:35	......number of instances: 70858
2017:06:07 15:51:35	rnn type is lstm
2017:06:07 15:52:14	use DataLoaderBBTV1 to init data.
2017:06:07 15:52:14	...init bucket.
2017:06:07 15:52:14	...load data.
2017:06:07 15:52:14	init content from raw.
2017:06:07 15:52:14	...init data from the raw dataset.
2017:06:07 15:52:14	...read dialogues from file.
2017:06:07 15:52:14	......number of instances: 70858
2017:06:07 15:52:15	rnn type is lstm
2017:06:07 15:52:24	use DataLoaderBBTV1 to init data.
2017:06:07 15:52:24	...init bucket.
2017:06:07 15:52:24	...load data.
2017:06:07 15:52:24	init content from raw.
2017:06:07 15:52:24	...init data from the raw dataset.
2017:06:07 15:52:24	...read dialogues from file.
2017:06:07 15:52:25	......number of instances: 70858
2017:06:07 15:52:25	rnn type is lstm
2017:06:07 15:52:47	use DataLoaderBBTV1 to init data.
2017:06:07 15:52:47	...init bucket.
2017:06:07 15:52:47	...load data.
2017:06:07 15:52:47	init content from raw.
2017:06:07 15:52:47	...init data from the raw dataset.
2017:06:07 15:52:47	...read dialogues from file.
2017:06:07 15:52:48	......number of instances: 70858
2017:06:07 15:52:48	rnn type is lstm
2017:06:07 15:53:08	use DataLoaderBBTV1 to init data.
2017:06:07 15:53:08	...init bucket.
2017:06:07 15:53:08	...load data.
2017:06:07 15:53:08	init content from raw.
2017:06:07 15:53:08	...init data from the raw dataset.
2017:06:07 15:53:08	...read dialogues from file.
2017:06:07 15:53:09	......number of instances: 70858
2017:06:07 15:53:09	rnn type is lstm
2017:06:07 15:53:24	use DataLoaderBBTV1 to init data.
2017:06:07 15:53:24	...init bucket.
2017:06:07 15:53:24	...load data.
2017:06:07 15:53:24	init content from raw.
2017:06:07 15:53:24	...init data from the raw dataset.
2017:06:07 15:53:24	...read dialogues from file.
2017:06:07 15:53:25	......number of instances: 70858
2017:06:07 15:53:25	rnn type is lstm
2017:06:07 15:54:28	use DataLoaderBBTV1 to init data.
2017:06:07 15:54:28	...init bucket.
2017:06:07 15:54:28	...load data.
2017:06:07 15:54:28	init content from raw.
2017:06:07 15:54:28	...init data from the raw dataset.
2017:06:07 15:54:28	...read dialogues from file.
2017:06:07 15:54:28	......number of instances: 70858
2017:06:07 15:54:28	rnn type is lstm
2017:06:07 15:55:56	use DataLoaderBBTV1 to init data.
2017:06:07 15:55:56	...init bucket.
2017:06:07 15:55:56	...load data.
2017:06:07 15:55:56	init content from raw.
2017:06:07 15:55:56	...init data from the raw dataset.
2017:06:07 15:55:56	...read dialogues from file.
2017:06:07 15:55:56	......number of instances: 70858
2017:06:07 15:55:57	rnn type is lstm
2017:06:07 15:56:33	use DataLoaderBBTV1 to init data.
2017:06:07 15:56:33	...init bucket.
2017:06:07 15:56:33	...load data.
2017:06:07 15:56:33	init content from raw.
2017:06:07 15:56:33	...init data from the raw dataset.
2017:06:07 15:56:33	...read dialogues from file.
2017:06:07 15:56:34	......number of instances: 70858
2017:06:07 15:56:34	rnn type is lstm
2017:06:07 16:04:15	use DataLoaderBBTV1 to init data.
2017:06:07 16:04:15	...init bucket.
2017:06:07 16:04:15	...load data.
2017:06:07 16:04:15	init content from raw.
2017:06:07 16:04:15	...init data from the raw dataset.
2017:06:07 16:04:15	...read dialogues from file.
2017:06:07 16:04:15	......number of instances: 70858
2017:06:07 16:04:15	rnn type is lstm
2017:06:07 16:04:16	rnn type is lstm
2017:06:07 16:04:16	define train operations...
2017:06:07 16:04:17	variables in the discriminator:
2017:06:07 16:04:18	variables in the generator:
2017:06:07 16:06:34	use DataLoaderBBTV1 to init data.
2017:06:07 16:06:34	...init bucket.
2017:06:07 16:06:34	...load data.
2017:06:07 16:06:34	init content from raw.
2017:06:07 16:06:34	...init data from the raw dataset.
2017:06:07 16:06:34	...read dialogues from file.
2017:06:07 16:06:35	......number of instances: 70858
2017:06:07 16:06:35	rnn type is lstm
2017:06:07 16:06:35	rnn type is lstm
2017:06:07 16:06:36	define train operations...
2017:06:07 16:06:37	variables in the discriminator:
2017:06:07 16:06:37	variables in the generator:
2017:06:08 12:57:42	use DataLoaderBBTV1 to init data.
2017:06:08 12:57:42	...init bucket.
2017:06:08 12:57:42	...load data.
2017:06:08 12:57:42	init content from raw.
2017:06:08 12:57:42	...init data from the raw dataset.
2017:06:08 12:57:42	...read dialogues from file.
2017:06:08 12:57:43	......number of instances: 70858
2017:06:08 12:57:43	rnn type is lstm
2017:06:08 12:57:53	use DataLoaderBBTV1 to init data.
2017:06:08 12:57:53	...init bucket.
2017:06:08 12:57:53	...load data.
2017:06:08 12:57:53	init content from raw.
2017:06:08 12:57:53	...init data from the raw dataset.
2017:06:08 12:57:53	...read dialogues from file.
2017:06:08 12:57:54	......number of instances: 70858
2017:06:08 12:57:54	rnn type is lstm
2017:06:08 12:59:02	use DataLoaderBBTV1 to init data.
2017:06:08 12:59:02	...init bucket.
2017:06:08 12:59:02	...load data.
2017:06:08 12:59:02	init content from raw.
2017:06:08 12:59:02	...init data from the raw dataset.
2017:06:08 12:59:02	...read dialogues from file.
2017:06:08 12:59:03	......number of instances: 70858
2017:06:08 12:59:03	rnn type is lstm
2017:06:08 12:59:26	use DataLoaderBBTV1 to init data.
2017:06:08 12:59:26	...init bucket.
2017:06:08 12:59:26	...load data.
2017:06:08 12:59:26	init content from raw.
2017:06:08 12:59:26	...init data from the raw dataset.
2017:06:08 12:59:26	...read dialogues from file.
2017:06:08 12:59:27	......number of instances: 70858
2017:06:08 12:59:27	rnn type is lstm
2017:06:08 12:59:49	use DataLoaderBBTV1 to init data.
2017:06:08 12:59:49	...init bucket.
2017:06:08 12:59:49	...load data.
2017:06:08 12:59:49	init content from raw.
2017:06:08 12:59:49	...init data from the raw dataset.
2017:06:08 12:59:49	...read dialogues from file.
2017:06:08 12:59:49	......number of instances: 70858
2017:06:08 12:59:50	rnn type is lstm
2017:06:08 13:00:38	use DataLoaderBBTV1 to init data.
2017:06:08 13:00:38	...init bucket.
2017:06:08 13:00:38	...load data.
2017:06:08 13:00:38	init content from raw.
2017:06:08 13:00:38	...init data from the raw dataset.
2017:06:08 13:00:38	...read dialogues from file.
2017:06:08 13:00:38	......number of instances: 70858
2017:06:08 13:00:38	rnn type is lstm
2017:06:08 13:00:39	rnn type is lstm
2017:06:08 13:00:39	define train operations...
2017:06:08 13:00:40	variables in the discriminator:
2017:06:08 13:00:40	variables in the generator:
2017:06:08 13:01:25	use DataLoaderBBTV1 to init data.
2017:06:08 13:01:25	...init bucket.
2017:06:08 13:01:25	...load data.
2017:06:08 13:01:25	init content from raw.
2017:06:08 13:01:25	...init data from the raw dataset.
2017:06:08 13:01:25	...read dialogues from file.
2017:06:08 13:01:28	use DataLoaderBBTV1 to init data.
2017:06:08 13:01:28	...init bucket.
2017:06:08 13:01:28	...load data.
2017:06:08 13:01:28	init content from raw.
2017:06:08 13:01:28	...init data from the raw dataset.
2017:06:08 13:01:28	...read dialogues from file.
2017:06:08 13:01:29	......number of instances: 70858
2017:06:08 13:01:29	rnn type is lstm
2017:06:08 13:01:29	rnn type is lstm
2017:06:08 13:01:30	define train operations...
2017:06:08 13:01:31	variables in the discriminator:
2017:06:08 13:01:31	variables in the generator:
2017:06:08 13:19:00	use DataLoaderBBTV1 to init data.
2017:06:08 13:19:00	...init bucket.
2017:06:08 13:19:00	...load data.
2017:06:08 13:19:00	init content from raw.
2017:06:08 13:19:00	...init data from the raw dataset.
2017:06:08 13:19:00	...read dialogues from file.
2017:06:08 13:19:01	......number of instances: 70858
2017:06:08 13:19:01	rnn type is lstm
2017:06:08 13:19:30	use DataLoaderBBTV1 to init data.
2017:06:08 13:19:30	...init bucket.
2017:06:08 13:19:30	...load data.
2017:06:08 13:19:30	init content from raw.
2017:06:08 13:19:30	...init data from the raw dataset.
2017:06:08 13:19:30	...read dialogues from file.
2017:06:08 13:19:31	......number of instances: 70858
2017:06:08 13:19:31	rnn type is lstm
2017:06:08 13:19:31	rnn type is lstm
2017:06:08 13:19:32	define train operations...
2017:06:08 13:19:32	variables in the discriminator:
2017:06:08 13:19:32	variables in the generator:
2017:06:08 13:20:23	use DataLoaderBBTV1 to init data.
2017:06:08 13:20:23	...init bucket.
2017:06:08 13:20:23	...load data.
2017:06:08 13:20:23	init content from raw.
2017:06:08 13:20:23	...init data from the raw dataset.
2017:06:08 13:20:23	...read dialogues from file.
2017:06:08 13:20:23	......number of instances: 70858
2017:06:08 13:20:23	rnn type is lstm
2017:06:08 13:20:24	rnn type is lstm
2017:06:08 13:20:24	define train operations...
2017:06:08 13:20:25	variables in the discriminator:
2017:06:08 13:20:25	variables in the generator:
2017:06:08 13:36:54	use DataLoaderBBTV1 to init data.
2017:06:08 13:36:54	...init bucket.
2017:06:08 13:36:54	...load data.
2017:06:08 13:36:54	init content from raw.
2017:06:08 13:36:54	...init data from the raw dataset.
2017:06:08 13:36:54	...read dialogues from file.
2017:06:08 13:36:55	......number of instances: 70858
2017:06:08 13:36:55	rnn type is lstm
2017:06:08 13:37:20	use DataLoaderBBTV1 to init data.
2017:06:08 13:37:20	...init bucket.
2017:06:08 13:37:20	...load data.
2017:06:08 13:37:20	init content from raw.
2017:06:08 13:37:20	...init data from the raw dataset.
2017:06:08 13:37:20	...read dialogues from file.
2017:06:08 13:37:21	......number of instances: 70858
2017:06:08 13:37:21	rnn type is lstm
2017:06:08 13:37:41	use DataLoaderBBTV1 to init data.
2017:06:08 13:37:41	...init bucket.
2017:06:08 13:37:41	...load data.
2017:06:08 13:37:41	init content from raw.
2017:06:08 13:37:41	...init data from the raw dataset.
2017:06:08 13:37:41	...read dialogues from file.
2017:06:08 13:37:42	......number of instances: 70858
2017:06:08 13:37:42	rnn type is lstm
2017:06:08 13:39:35	use DataLoaderBBTV1 to init data.
2017:06:08 13:39:35	...init bucket.
2017:06:08 13:39:35	...load data.
2017:06:08 13:39:35	init content from raw.
2017:06:08 13:39:35	...init data from the raw dataset.
2017:06:08 13:39:35	...read dialogues from file.
2017:06:08 13:39:36	......number of instances: 70858
2017:06:08 13:39:36	rnn type is lstm
2017:06:08 13:39:37	rnn type is lstm
2017:06:08 13:39:37	define train operations...
2017:06:08 13:39:38	variables in the discriminator:
2017:06:08 13:39:38	variables in the generator:
2017:06:08 13:40:15	use DataLoaderBBTV1 to init data.
2017:06:08 13:40:15	...init bucket.
2017:06:08 13:40:15	...load data.
2017:06:08 13:40:15	init content from raw.
2017:06:08 13:40:15	...init data from the raw dataset.
2017:06:08 13:40:15	...read dialogues from file.
2017:06:08 13:40:15	......number of instances: 70858
2017:06:08 13:40:16	rnn type is lstm
2017:06:08 13:40:16	rnn type is lstm
2017:06:08 13:40:16	define train operations...
2017:06:08 13:40:17	variables in the discriminator:
2017:06:08 13:40:17	variables in the generator:
2017:06:08 13:41:55	use DataLoaderBBTV1 to init data.
2017:06:08 13:41:55	...init bucket.
2017:06:08 13:41:55	...load data.
2017:06:08 13:41:55	init content from raw.
2017:06:08 13:41:55	...init data from the raw dataset.
2017:06:08 13:41:55	...read dialogues from file.
2017:06:08 13:41:56	......number of instances: 70858
2017:06:08 13:41:56	rnn type is lstm
2017:06:08 13:41:56	rnn type is lstm
2017:06:08 13:41:57	define train operations...
2017:06:08 13:41:58	variables in the discriminator:
2017:06:08 13:41:58	variables in the generator:
2017:06:08 13:42:55	use DataLoaderBBTV1 to init data.
2017:06:08 13:42:55	...init bucket.
2017:06:08 13:42:55	...load data.
2017:06:08 13:42:55	init content from raw.
2017:06:08 13:42:55	...init data from the raw dataset.
2017:06:08 13:42:55	...read dialogues from file.
2017:06:08 13:42:56	......number of instances: 70858
2017:06:08 13:42:56	rnn type is lstm
2017:06:08 13:42:56	rnn type is lstm
2017:06:08 13:42:57	define train operations...
2017:06:08 13:42:58	variables in the discriminator:
2017:06:08 13:42:58	variables in the generator:
2017:06:08 13:45:30	use DataLoaderBBTV1 to init data.
2017:06:08 13:45:30	...init bucket.
2017:06:08 13:45:30	...load data.
2017:06:08 13:45:30	init content from raw.
2017:06:08 13:45:30	...init data from the raw dataset.
2017:06:08 13:45:30	...read dialogues from file.
2017:06:08 13:45:31	......number of instances: 70858
2017:06:08 13:45:31	rnn type is lstm
2017:06:08 13:45:49	use DataLoaderBBTV1 to init data.
2017:06:08 13:45:49	...init bucket.
2017:06:08 13:45:49	...load data.
2017:06:08 13:45:49	init content from raw.
2017:06:08 13:45:49	...init data from the raw dataset.
2017:06:08 13:45:49	...read dialogues from file.
2017:06:08 13:45:50	......number of instances: 70858
2017:06:08 13:45:50	rnn type is lstm
2017:06:08 13:46:14	use DataLoaderBBTV1 to init data.
2017:06:08 13:46:14	...init bucket.
2017:06:08 13:46:14	...load data.
2017:06:08 13:46:14	init content from raw.
2017:06:08 13:46:14	...init data from the raw dataset.
2017:06:08 13:46:14	...read dialogues from file.
2017:06:08 13:46:15	......number of instances: 70858
2017:06:08 13:46:15	rnn type is lstm
2017:06:08 13:46:15	rnn type is lstm
2017:06:08 13:46:16	define train operations...
2017:06:08 13:46:16	variables in the discriminator:
2017:06:08 13:46:16	variables in the generator:
2017:06:08 13:48:59	use DataLoaderBBTV1 to init data.
2017:06:08 13:48:59	...init bucket.
2017:06:08 13:48:59	...load data.
2017:06:08 13:48:59	init content from raw.
2017:06:08 13:48:59	...init data from the raw dataset.
2017:06:08 13:48:59	...read dialogues from file.
2017:06:08 13:48:59	......number of instances: 70858
2017:06:08 13:48:59	rnn type is lstm
2017:06:08 13:49:00	rnn type is lstm
2017:06:08 13:49:00	define train operations...
2017:06:08 13:49:01	variables in the discriminator:
2017:06:08 13:49:01	variables in the generator:
2017:06:08 13:52:05	use DataLoaderBBTV1 to init data.
2017:06:08 13:52:05	...init bucket.
2017:06:08 13:52:05	...load data.
2017:06:08 13:52:05	init content from raw.
2017:06:08 13:52:05	...init data from the raw dataset.
2017:06:08 13:52:05	...read dialogues from file.
2017:06:08 13:52:05	......number of instances: 70858
2017:06:08 13:52:05	rnn type is lstm
2017:06:08 13:52:06	rnn type is lstm
2017:06:08 13:52:06	define train operations...
2017:06:08 13:52:07	variables in the discriminator:
2017:06:08 13:52:07	variables in the generator:
2017:06:08 13:52:45	use DataLoaderBBTV1 to init data.
2017:06:08 13:52:45	...init bucket.
2017:06:08 13:52:45	...load data.
2017:06:08 13:52:45	init content from raw.
2017:06:08 13:52:45	...init data from the raw dataset.
2017:06:08 13:52:45	...read dialogues from file.
2017:06:08 13:52:46	......number of instances: 70858
2017:06:08 14:08:15	use DataLoaderBBTV1 to init data.
2017:06:08 14:08:15	...init bucket.
2017:06:08 14:08:15	...load data.
2017:06:08 14:08:15	init content from raw.
2017:06:08 14:08:15	...init data from the raw dataset.
2017:06:08 14:08:15	...read dialogues from file.
2017:06:08 14:08:16	......number of instances: 70858
2017:06:08 14:08:16	rnn type is lstm
2017:06:08 14:08:16	rnn type is lstm
2017:06:08 14:08:17	define train operations...
2017:06:08 14:08:18	variables in the discriminator:
2017:06:08 14:08:18	variables in the generator:
2017:06:08 14:28:48	use DataLoaderBBTV1 to init data.
2017:06:08 14:28:48	...init bucket.
2017:06:08 14:28:48	...load data.
2017:06:08 14:28:48	init content from raw.
2017:06:08 14:28:48	...init data from the raw dataset.
2017:06:08 14:28:48	...read dialogues from file.
2017:06:08 14:28:49	......number of instances: 70858
2017:06:08 14:28:49	rnn type is lstm
2017:06:08 14:28:49	rnn type is lstm
2017:06:08 14:28:50	define train operations...
2017:06:08 14:28:51	variables in the discriminator:
2017:06:08 14:28:51	variables in the generator:
2017:06:08 14:29:21	use DataLoaderBBTV1 to init data.
2017:06:08 14:29:21	...init bucket.
2017:06:08 14:29:21	...load data.
2017:06:08 14:29:21	init content from raw.
2017:06:08 14:29:21	...init data from the raw dataset.
2017:06:08 14:29:21	...read dialogues from file.
2017:06:08 14:29:22	......number of instances: 70858
2017:06:08 14:29:22	rnn type is lstm
2017:06:08 14:29:22	rnn type is lstm
2017:06:08 14:29:23	define train operations...
2017:06:08 14:29:24	variables in the discriminator:
2017:06:08 14:29:24	variables in the generator:
2017:06:08 14:29:39	use DataLoaderBBTV1 to init data.
2017:06:08 14:29:39	...init bucket.
2017:06:08 14:29:39	...load data.
2017:06:08 14:29:39	init content from raw.
2017:06:08 14:29:39	...init data from the raw dataset.
2017:06:08 14:29:39	...read dialogues from file.
2017:06:08 14:29:40	......number of instances: 70858
2017:06:08 14:29:40	rnn type is lstm
2017:06:08 14:29:40	rnn type is lstm
2017:06:08 14:29:41	define train operations...
2017:06:08 14:29:42	variables in the discriminator:
2017:06:08 14:29:42	variables in the generator:
2017:06:08 14:30:10	use DataLoaderBBTV1 to init data.
2017:06:08 14:30:10	...init bucket.
2017:06:08 14:30:10	...load data.
2017:06:08 14:30:10	init content from raw.
2017:06:08 14:30:10	...init data from the raw dataset.
2017:06:08 14:30:10	...read dialogues from file.
2017:06:08 14:30:11	......number of instances: 70858
2017:06:08 14:30:11	rnn type is lstm
2017:06:08 14:30:11	rnn type is lstm
2017:06:08 14:30:12	define train operations...
2017:06:08 14:30:13	variables in the discriminator:
2017:06:08 14:30:13	variables in the generator:
2017:06:08 14:30:19	use DataLoaderBBTV1 to init data.
2017:06:08 14:30:19	...init bucket.
2017:06:08 14:30:19	...load data.
2017:06:08 14:30:19	init content from raw.
2017:06:08 14:30:19	...init data from the raw dataset.
2017:06:08 14:30:19	...read dialogues from file.
2017:06:08 14:30:19	......number of instances: 70858
2017:06:08 14:30:20	rnn type is lstm
2017:06:08 14:30:20	rnn type is lstm
2017:06:08 14:30:20	define train operations...
2017:06:08 14:30:21	variables in the discriminator:
2017:06:08 14:30:21	variables in the generator:
2017:06:08 14:31:41	use DataLoaderBBTV1 to init data.
2017:06:08 14:31:41	...init bucket.
2017:06:08 14:31:41	...load data.
2017:06:08 14:31:41	init content from raw.
2017:06:08 14:31:41	...init data from the raw dataset.
2017:06:08 14:31:41	...read dialogues from file.
2017:06:08 14:31:42	......number of instances: 70858
2017:06:08 14:31:42	rnn type is lstm
2017:06:08 14:31:42	rnn type is lstm
2017:06:08 14:31:43	define train operations...
2017:06:08 14:31:44	variables in the discriminator:
2017:06:08 14:31:44	variables in the generator:
2017:06:08 14:31:48	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496932305/checkpoints/bestmodel.

2017:06:08 14:31:48	------ pretraining ------ 

2017:06:08 14:31:48	train epoch 0
2017:06:08 14:35:53	use DataLoaderBBTV1 to init data.
2017:06:08 14:35:53	...init bucket.
2017:06:08 14:35:53	...load data.
2017:06:08 14:35:53	init content from raw.
2017:06:08 14:35:53	...init data from the raw dataset.
2017:06:08 14:35:53	...read dialogues from file.
2017:06:08 14:35:54	......number of instances: 70858
2017:06:08 14:35:54	rnn type is lstm
2017:06:08 14:35:54	rnn type is lstm
2017:06:08 14:35:55	define train operations...
2017:06:08 14:35:56	variables in the discriminator:
2017:06:08 14:35:56	variables in the generator:
2017:06:08 14:36:00	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496932557/checkpoints/bestmodel.

2017:06:08 14:36:00	------ pretraining ------ 

2017:06:08 14:36:00	pretrain epoch 0
2017:06:08 14:36:47	use DataLoaderBBTV1 to init data.
2017:06:08 14:36:47	...init bucket.
2017:06:08 14:36:47	...load data.
2017:06:08 14:36:47	init content from raw.
2017:06:08 14:36:47	...init data from the raw dataset.
2017:06:08 14:36:47	...read dialogues from file.
2017:06:08 14:36:48	......number of instances: 70858
2017:06:08 14:36:48	rnn type is lstm
2017:06:08 14:36:49	rnn type is lstm
2017:06:08 14:36:49	define train operations...
2017:06:08 14:36:50	variables in the discriminator:
2017:06:08 14:36:50	variables in the generator:
2017:06:08 14:36:54	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496932612/checkpoints/bestmodel.

2017:06:08 14:36:54	------ pretraining ------ 

2017:06:08 14:36:54	pretrain epoch 0
2017:06:08 14:39:00	use DataLoaderBBTV1 to init data.
2017:06:08 14:39:00	...init bucket.
2017:06:08 14:39:00	...load data.
2017:06:08 14:39:00	init content from raw.
2017:06:08 14:39:00	...init data from the raw dataset.
2017:06:08 14:39:00	...read dialogues from file.
2017:06:08 14:39:01	......number of instances: 70858
2017:06:08 14:39:01	rnn type is lstm
2017:06:08 14:39:01	rnn type is lstm
2017:06:08 14:39:15	use DataLoaderBBTV1 to init data.
2017:06:08 14:39:15	...init bucket.
2017:06:08 14:39:15	...load data.
2017:06:08 14:39:15	init content from raw.
2017:06:08 14:39:15	...init data from the raw dataset.
2017:06:08 14:39:15	...read dialogues from file.
2017:06:08 14:39:16	......number of instances: 70858
2017:06:08 14:39:16	rnn type is lstm
2017:06:08 14:39:17	rnn type is lstm
2017:06:08 14:39:59	use DataLoaderBBTV1 to init data.
2017:06:08 14:39:59	...init bucket.
2017:06:08 14:39:59	...load data.
2017:06:08 14:39:59	init content from raw.
2017:06:08 14:39:59	...init data from the raw dataset.
2017:06:08 14:39:59	...read dialogues from file.
2017:06:08 14:39:59	......number of instances: 70858
2017:06:08 14:39:59	rnn type is lstm
2017:06:08 14:40:00	rnn type is lstm
2017:06:08 14:40:36	use DataLoaderBBTV1 to init data.
2017:06:08 14:40:36	...init bucket.
2017:06:08 14:40:36	...load data.
2017:06:08 14:40:36	init content from raw.
2017:06:08 14:40:36	...init data from the raw dataset.
2017:06:08 14:40:36	...read dialogues from file.
2017:06:08 14:40:37	......number of instances: 70858
2017:06:08 14:40:37	rnn type is lstm
2017:06:08 14:40:37	rnn type is lstm
2017:06:08 14:40:57	use DataLoaderBBTV1 to init data.
2017:06:08 14:40:57	...init bucket.
2017:06:08 14:40:57	...load data.
2017:06:08 14:40:57	init content from raw.
2017:06:08 14:40:57	...init data from the raw dataset.
2017:06:08 14:40:57	...read dialogues from file.
2017:06:08 14:40:58	......number of instances: 70858
2017:06:08 14:40:58	rnn type is lstm
2017:06:08 14:40:59	rnn type is lstm
2017:06:08 14:41:36	use DataLoaderBBTV1 to init data.
2017:06:08 14:41:36	...init bucket.
2017:06:08 14:41:36	...load data.
2017:06:08 14:41:36	init content from raw.
2017:06:08 14:41:36	...init data from the raw dataset.
2017:06:08 14:41:36	...read dialogues from file.
2017:06:08 14:41:37	......number of instances: 70858
2017:06:08 14:41:37	rnn type is lstm
2017:06:08 14:41:38	rnn type is lstm
2017:06:08 14:41:38	define train operations...
2017:06:08 14:41:40	variables in the discriminator:
2017:06:08 14:41:40	variables in the generator:
2017:06:08 14:41:45	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496932902/checkpoints/bestmodel.

2017:06:08 14:41:45	------ pretraining ------ 

2017:06:08 14:41:45	pretrain epoch 0
2017:06:08 14:49:38	use DataLoaderBBTV1 to init data.
2017:06:08 14:49:38	...init bucket.
2017:06:08 14:49:38	...load data.
2017:06:08 14:49:38	init content from raw.
2017:06:08 14:49:38	...init data from the raw dataset.
2017:06:08 14:49:38	...read dialogues from file.
2017:06:08 14:49:38	......number of instances: 70858
2017:06:08 14:49:39	rnn type is lstm
2017:06:08 14:49:39	rnn type is lstm
2017:06:08 14:49:39	define train operations...
2017:06:08 14:49:40	variables in the discriminator:
2017:06:08 14:49:40	variables in the generator:
2017:06:08 14:49:45	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496933382/checkpoints/bestmodel.

2017:06:08 14:49:45	------ pretraining ------ 

2017:06:08 14:49:45	------ training ------ 

2017:06:08 14:49:45	train epoch 1
2017:06:08 15:04:36	use DataLoaderBBTV1 to init data.
2017:06:08 15:04:36	...init bucket.
2017:06:08 15:04:36	...load data.
2017:06:08 15:04:36	init content from raw.
2017:06:08 15:04:36	...init data from the raw dataset.
2017:06:08 15:04:36	...read dialogues from file.
2017:06:08 15:04:37	......number of instances: 70858
2017:06:08 15:04:37	rnn type is lstm
2017:06:08 15:04:37	rnn type is lstm
2017:06:08 15:04:38	define train operations...
2017:06:08 15:04:39	variables in the discriminator:
2017:06:08 15:04:39	variables in the generator:
2017:06:08 15:04:45	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496934280/checkpoints/bestmodel.

2017:06:08 15:04:45	------ pretraining ------ 

2017:06:08 15:04:45	------ training ------ 

2017:06:08 15:04:45	train epoch 1
2017:06:08 15:05:11	use DataLoaderBBTV1 to init data.
2017:06:08 15:05:11	...init bucket.
2017:06:08 15:05:11	...load data.
2017:06:08 15:05:11	init content from raw.
2017:06:08 15:05:11	...init data from the raw dataset.
2017:06:08 15:05:11	...read dialogues from file.
2017:06:08 15:05:12	......number of instances: 70858
2017:06:08 15:05:13	rnn type is lstm
2017:06:08 15:05:13	rnn type is lstm
2017:06:08 15:05:14	define train operations...
2017:06:08 15:05:14	variables in the discriminator:
2017:06:08 15:05:14	variables in the generator:
2017:06:08 15:05:19	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496934316/checkpoints/bestmodel.

2017:06:08 15:05:19	------ pretraining ------ 

2017:06:08 15:05:19	------ training ------ 

2017:06:08 15:05:19	train epoch 1
2017:06:08 15:05:44	use DataLoaderBBTV1 to init data.
2017:06:08 15:05:44	...init bucket.
2017:06:08 15:05:44	...load data.
2017:06:08 15:05:44	init content from raw.
2017:06:08 15:05:44	...init data from the raw dataset.
2017:06:08 15:05:44	...read dialogues from file.
2017:06:08 15:05:45	......number of instances: 70858
2017:06:08 15:05:45	rnn type is lstm
2017:06:08 15:05:45	rnn type is lstm
2017:06:08 15:05:46	define train operations...
2017:06:08 15:05:48	variables in the discriminator:
2017:06:08 15:05:48	variables in the generator:
2017:06:08 15:05:53	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496934350/checkpoints/bestmodel.

2017:06:08 15:05:53	------ pretraining ------ 

2017:06:08 15:05:53	------ training ------ 

2017:06:08 15:05:53	train epoch 1
2017:06:08 15:06:10	use DataLoaderBBTV1 to init data.
2017:06:08 15:06:10	...init bucket.
2017:06:08 15:06:10	...load data.
2017:06:08 15:06:10	init content from raw.
2017:06:08 15:06:10	...init data from the raw dataset.
2017:06:08 15:06:10	...read dialogues from file.
2017:06:08 15:06:11	......number of instances: 70858
2017:06:08 15:06:11	rnn type is lstm
2017:06:08 15:06:12	rnn type is lstm
2017:06:08 15:06:12	define train operations...
2017:06:08 15:06:13	variables in the discriminator:
2017:06:08 15:06:13	variables in the generator:
2017:06:08 15:06:19	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496934376/checkpoints/bestmodel.

2017:06:08 15:06:19	------ pretraining ------ 

2017:06:08 15:06:19	pretrain epoch 0
2017:06:08 15:07:30	use DataLoaderBBT to init data.
2017:06:08 15:07:30	...init bucket.
2017:06:08 15:07:30	...load data.
2017:06:08 15:07:30	init content from raw.
2017:06:08 15:07:30	...init data from the raw dataset.
2017:06:08 15:07:30	...read dialogues from file.
2017:06:08 15:07:31	......number of instances: 35429
2017:06:08 15:09:07	use DataLoaderBBT to init data.
2017:06:08 15:09:07	...init bucket.
2017:06:08 15:09:07	...load data.
2017:06:08 15:09:07	init content from raw.
2017:06:08 15:09:07	...init data from the raw dataset.
2017:06:08 15:09:07	...read dialogues from file.
2017:06:08 15:09:07	......number of instances: 35429
2017:06:08 15:09:07	rnn type is lstm
2017:06:08 15:09:07	rnn type is lstm
2017:06:08 15:10:12	use DataLoaderBBT to init data.
2017:06:08 15:10:12	...init bucket.
2017:06:08 15:10:12	...load data.
2017:06:08 15:10:12	init content from raw.
2017:06:08 15:10:12	...init data from the raw dataset.
2017:06:08 15:10:12	...read dialogues from file.
2017:06:08 15:10:13	......number of instances: 35429
2017:06:08 15:10:14	rnn type is lstm
2017:06:08 15:10:14	rnn type is lstm
2017:06:08 15:10:50	use DataLoaderBBT to init data.
2017:06:08 15:10:50	...init bucket.
2017:06:08 15:10:50	...load data.
2017:06:08 15:10:50	init content from raw.
2017:06:08 15:10:50	...init data from the raw dataset.
2017:06:08 15:10:50	...read dialogues from file.
2017:06:08 15:10:51	......number of instances: 35429
2017:06:08 15:10:51	rnn type is lstm
2017:06:08 15:10:51	rnn type is lstm
2017:06:08 15:11:11	use DataLoaderBBT to init data.
2017:06:08 15:11:11	...init bucket.
2017:06:08 15:11:11	...load data.
2017:06:08 15:11:11	init content from raw.
2017:06:08 15:11:11	...init data from the raw dataset.
2017:06:08 15:11:11	...read dialogues from file.
2017:06:08 15:11:12	......number of instances: 35429
2017:06:08 15:11:12	rnn type is lstm
2017:06:08 15:11:12	rnn type is lstm
2017:06:08 15:11:16	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496934674/checkpoints/bestmodel.

2017:06:08 15:11:16	------ pretraining ------ 

2017:06:08 15:11:16	train epoch 0
2017:06:08 15:13:01	use DataLoaderBBT to init data.
2017:06:08 15:13:01	...init bucket.
2017:06:08 15:13:01	...load data.
2017:06:08 15:13:01	init content from raw.
2017:06:08 15:13:01	...init data from the raw dataset.
2017:06:08 15:13:01	...read dialogues from file.
2017:06:08 15:13:02	......number of instances: 35429
2017:06:08 15:13:02	rnn type is lstm
2017:06:08 15:13:02	rnn type is lstm
2017:06:08 15:13:05	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496934783/checkpoints/bestmodel.

2017:06:08 15:13:05	------ pretraining ------ 

2017:06:08 15:13:05	train epoch 0
2017:06:08 15:13:13	use DataLoaderBBT to init data.
2017:06:08 15:13:13	...init bucket.
2017:06:08 15:13:13	...load data.
2017:06:08 15:13:13	init content from raw.
2017:06:08 15:13:13	...init data from the raw dataset.
2017:06:08 15:13:13	...read dialogues from file.
2017:06:08 15:13:14	......number of instances: 35429
2017:06:08 15:13:14	rnn type is lstm
2017:06:08 15:13:14	rnn type is lstm
2017:06:08 15:13:17	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496934795/checkpoints/bestmodel.

2017:06:08 15:13:17	------ pretraining ------ 

2017:06:08 15:13:17	train epoch 0
2017:06:08 15:13:36	use DataLoaderBBT to init data.
2017:06:08 15:13:36	...init bucket.
2017:06:08 15:13:36	...load data.
2017:06:08 15:13:36	init content from raw.
2017:06:08 15:13:36	...init data from the raw dataset.
2017:06:08 15:13:36	...read dialogues from file.
2017:06:08 15:13:37	......number of instances: 35429
2017:06:08 15:13:37	rnn type is lstm
2017:06:08 15:13:37	rnn type is lstm
2017:06:08 15:13:40	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496934818/checkpoints/bestmodel.

2017:06:08 15:13:40	------ pretraining ------ 

2017:06:08 15:13:40	train epoch 0
2017:06:08 15:15:41	use DataLoaderBBT to init data.
2017:06:08 15:15:41	...init bucket.
2017:06:08 15:15:41	...load data.
2017:06:08 15:15:41	init content from raw.
2017:06:08 15:15:41	...init data from the raw dataset.
2017:06:08 15:15:41	...read dialogues from file.
2017:06:08 15:15:42	......number of instances: 35429
2017:06:08 15:15:43	rnn type is lstm
2017:06:08 15:15:43	rnn type is lstm
2017:06:08 15:15:46	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496934944/checkpoints/bestmodel.

2017:06:08 15:15:46	------ pretraining ------ 

2017:06:08 15:15:46	train epoch 0
2017:06:08 15:16:31	use DataLoaderBBT to init data.
2017:06:08 15:16:31	...init bucket.
2017:06:08 15:16:31	...load data.
2017:06:08 15:16:31	init content from raw.
2017:06:08 15:16:31	...init data from the raw dataset.
2017:06:08 15:16:31	...read dialogues from file.
2017:06:08 15:16:32	......number of instances: 35429
2017:06:08 15:16:32	rnn type is lstm
2017:06:08 15:16:32	rnn type is lstm
2017:06:08 15:17:35	use DataLoaderBBT to init data.
2017:06:08 15:17:35	...init bucket.
2017:06:08 15:17:35	...load data.
2017:06:08 15:17:35	init content from raw.
2017:06:08 15:17:35	...init data from the raw dataset.
2017:06:08 15:17:35	...read dialogues from file.
2017:06:08 15:17:36	......number of instances: 35429
2017:06:08 15:17:36	rnn type is lstm
2017:06:08 15:17:36	rnn type is lstm
2017:06:08 15:17:39	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496935057/checkpoints/bestmodel.

2017:06:08 15:17:39	------ pretraining ------ 

2017:06:08 15:17:39	train epoch 0
2017:06:08 15:19:13	use DataLoaderBBT to init data.
2017:06:08 15:19:13	...init bucket.
2017:06:08 15:19:13	...load data.
2017:06:08 15:19:13	init content from raw.
2017:06:08 15:19:13	...init data from the raw dataset.
2017:06:08 15:19:13	...read dialogues from file.
2017:06:08 15:19:14	......number of instances: 35429
2017:06:08 15:19:14	rnn type is lstm
2017:06:08 15:19:14	rnn type is lstm
2017:06:08 15:19:16	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496935155/checkpoints/bestmodel.

2017:06:08 15:19:16	------ pretraining ------ 

2017:06:08 15:19:16	train epoch 0
2017:06:08 15:20:20	use DataLoaderBBT to init data.
2017:06:08 15:20:20	...init bucket.
2017:06:08 15:20:20	...load data.
2017:06:08 15:20:20	init content from raw.
2017:06:08 15:20:20	...init data from the raw dataset.
2017:06:08 15:20:20	...read dialogues from file.
2017:06:08 15:20:21	......number of instances: 35429
2017:06:08 15:20:21	rnn type is lstm
2017:06:08 15:20:21	rnn type is lstm
2017:06:08 15:20:44	use DataLoaderBBT to init data.
2017:06:08 15:20:44	...init bucket.
2017:06:08 15:20:44	...load data.
2017:06:08 15:20:44	init content from raw.
2017:06:08 15:20:44	...init data from the raw dataset.
2017:06:08 15:20:44	...read dialogues from file.
2017:06:08 15:20:45	......number of instances: 35429
2017:06:08 15:20:45	rnn type is lstm
2017:06:08 15:20:45	rnn type is lstm
2017:06:08 15:20:45	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496935221/
2017:06:08 15:20:57	use DataLoaderBBT to init data.
2017:06:08 15:20:57	...init bucket.
2017:06:08 15:20:57	...load data.
2017:06:08 15:20:57	init content from raw.
2017:06:08 15:20:57	...init data from the raw dataset.
2017:06:08 15:20:57	...read dialogues from file.
2017:06:08 15:20:58	......number of instances: 35429
2017:06:08 15:20:58	rnn type is lstm
2017:06:08 15:20:58	rnn type is lstm
2017:06:08 15:20:58	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496935155/
2017:06:08 15:20:58	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496935155/checkpoints/bestmodel-0
2017:06:08 15:20:58	generate sentence from latent space.
2017:06:08 15:21:15	true question: she and i are both a little awkward in social situations so this seemed like a good idea
2017:06:08 15:21:15	true answer: [***] people say i 'm a little awkward , too . may i join you ?
2017:06:08 15:21:15	faked answer: unnaturally honour honour honour honour honour honour honour opposed opposed opposed opposed opposed opposed opposed opposed opposed opposed opposed opposed opposed opposed crossover crossover crossover crossover crossover crossover crossover crossover crossover crossover effort effort effort scold scold scold borrow borrow borrow polite polite polite polite polite polite materials materials
2017:06:08 15:21:15	total execution time: 17 s
2017:06:08 15:23:07	use DataLoaderBBTV1 to init data.
2017:06:08 15:23:07	...init bucket.
2017:06:08 15:23:07	...load data.
2017:06:08 15:23:07	init content from raw.
2017:06:08 15:23:07	...init data from the raw dataset.
2017:06:08 15:23:07	...read dialogues from file.
2017:06:08 15:23:07	......number of instances: 70858
2017:06:08 15:23:07	rnn type is lstm
2017:06:08 15:23:08	rnn type is lstm
2017:06:08 15:23:08	define train operations...
2017:06:08 15:23:09	variables in the discriminator:
2017:06:08 15:23:09	variables in the generator:
2017:06:08 15:23:13	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496935391/checkpoints/bestmodel.

2017:06:08 15:23:13	------ pretraining ------ 

2017:06:08 15:23:13	pretrain epoch 0
2017:06:08 15:44:00	use DataLoaderBBTV1 to init data.
2017:06:08 15:44:00	...init bucket.
2017:06:08 15:44:00	...load data.
2017:06:08 15:44:00	...init data from the raw dataset.
2017:06:08 15:44:00	...read dialogues from file.
2017:06:08 15:44:01	......number of instances: 70858
2017:06:08 15:44:01	rnn type is lstm
2017:06:08 15:44:01	rnn type is lstm
2017:06:08 15:44:02	define train operations...
2017:06:08 15:44:03	variables in the discriminator:
2017:06:08 15:44:03	variables in the generator:
2017:06:08 15:44:08	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496936644/checkpoints/bestmodel.

2017:06:08 15:44:08	------ pretraining ------ 

2017:06:08 15:44:08	------ training ------ 

2017:06:08 15:44:08	train epoch 1
2017:06:08 15:44:26	use DataLoaderBBTV1 to init data.
2017:06:08 15:44:26	...init bucket.
2017:06:08 15:44:26	...load data.
2017:06:08 15:44:26	...init data from the raw dataset.
2017:06:08 15:44:26	...read dialogues from file.
2017:06:08 15:44:27	......number of instances: 70858
2017:06:08 15:44:27	rnn type is lstm
2017:06:08 15:44:28	rnn type is lstm
2017:06:08 15:44:29	define train operations...
2017:06:08 15:44:30	variables in the discriminator:
2017:06:08 15:44:30	variables in the generator:
2017:06:08 15:44:35	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496936672/checkpoints/bestmodel.

2017:06:08 15:44:35	------ pretraining ------ 

2017:06:08 15:44:35	------ training ------ 

2017:06:08 15:44:35	train epoch 1
2017:06:08 15:44:58	use DataLoaderBBTV1 to init data.
2017:06:08 15:44:58	...init bucket.
2017:06:08 15:44:58	...load data.
2017:06:08 15:44:58	...init data from the raw dataset.
2017:06:08 15:44:58	...read dialogues from file.
2017:06:08 15:44:59	......number of instances: 70858
2017:06:08 15:44:59	rnn type is lstm
2017:06:08 15:44:59	rnn type is lstm
2017:06:08 15:45:01	define train operations...
2017:06:08 15:45:02	variables in the discriminator:
2017:06:08 15:45:02	variables in the generator:
2017:06:08 15:45:07	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496936704/checkpoints/bestmodel.

2017:06:08 15:45:07	------ pretraining ------ 

2017:06:08 15:45:07	------ training ------ 

2017:06:08 15:45:07	train epoch 1
2017:06:08 15:45:31	use DataLoaderBBTV1 to init data.
2017:06:08 15:45:31	...init bucket.
2017:06:08 15:45:31	...load data.
2017:06:08 15:45:31	...init data from the raw dataset.
2017:06:08 15:45:31	...read dialogues from file.
2017:06:08 15:45:31	......number of instances: 70858
2017:06:08 15:45:32	rnn type is lstm
2017:06:08 15:45:32	rnn type is lstm
2017:06:08 15:45:33	define train operations...
2017:06:08 15:45:34	variables in the discriminator:
2017:06:08 15:45:34	variables in the generator:
2017:06:08 15:45:38	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496936735/checkpoints/bestmodel.

2017:06:08 15:45:38	------ pretraining ------ 

2017:06:08 15:45:38	------ training ------ 

2017:06:08 15:45:38	train epoch 1
2017:06:08 15:45:49	use DataLoaderBBTV1 to init data.
2017:06:08 15:45:49	...init bucket.
2017:06:08 15:45:49	...load data.
2017:06:08 15:45:49	...init data from the raw dataset.
2017:06:08 15:45:49	...read dialogues from file.
2017:06:08 15:45:51	......number of instances: 70858
2017:06:08 15:45:51	rnn type is lstm
2017:06:08 15:45:51	rnn type is lstm
2017:06:08 15:45:52	define train operations...
2017:06:08 15:45:53	variables in the discriminator:
2017:06:08 15:45:53	variables in the generator:
2017:06:08 15:45:58	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496936755/checkpoints/bestmodel.

2017:06:08 15:45:58	------ pretraining ------ 

2017:06:08 15:45:58	------ training ------ 

2017:06:08 15:45:58	train epoch 1
2017:06:08 15:46:08	use DataLoaderBBTV1 to init data.
2017:06:08 15:46:08	...init bucket.
2017:06:08 15:46:08	...load data.
2017:06:08 15:46:08	...init data from the raw dataset.
2017:06:08 15:46:08	...read dialogues from file.
2017:06:08 15:46:09	......number of instances: 70858
2017:06:08 15:46:09	rnn type is lstm
2017:06:08 15:46:09	rnn type is lstm
2017:06:08 15:46:10	define train operations...
2017:06:08 15:46:12	variables in the discriminator:
2017:06:08 15:46:12	variables in the generator:
2017:06:08 15:46:20	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496936775/checkpoints/bestmodel.

2017:06:08 15:46:20	------ pretraining ------ 

2017:06:08 15:46:20	------ training ------ 

2017:06:08 15:46:20	train epoch 1
2017:06:08 15:49:59	use DataLoaderBBTV1 to init data.
2017:06:08 15:49:59	...init bucket.
2017:06:08 15:49:59	...load data.
2017:06:08 15:49:59	...init data from the raw dataset.
2017:06:08 15:49:59	...read dialogues from file.
2017:06:08 15:50:00	......number of instances: 70858
2017:06:08 15:50:00	rnn type is lstm
2017:06:08 17:47:03	use DataLoaderBBTV1 to init data.
2017:06:08 17:47:03	...init bucket.
2017:06:08 17:47:03	...load data.
2017:06:08 17:47:03	...init data from the raw dataset.
2017:06:08 17:47:03	...read dialogues from file.
2017:06:08 17:47:04	......number of instances: 70858
2017:06:08 17:47:04	rnn type is lstm
2017:06:08 17:47:47	use DataLoaderBBTV1 to init data.
2017:06:08 17:47:47	...init bucket.
2017:06:08 17:47:47	...load data.
2017:06:08 17:47:47	...init data from the raw dataset.
2017:06:08 17:47:47	...read dialogues from file.
2017:06:08 17:47:48	......number of instances: 70858
2017:06:08 17:47:48	rnn type is lstm
2017:06:08 17:49:28	use DataLoaderBBTV1 to init data.
2017:06:08 17:49:28	...init bucket.
2017:06:08 17:49:28	...load data.
2017:06:08 17:49:28	...init data from the raw dataset.
2017:06:08 17:49:28	...read dialogues from file.
2017:06:08 17:49:29	......number of instances: 70858
2017:06:08 17:49:29	rnn type is lstm
2017:06:08 17:50:19	use DataLoaderBBTV1 to init data.
2017:06:08 17:50:19	...init bucket.
2017:06:08 17:50:19	...load data.
2017:06:08 17:50:19	...init data from the raw dataset.
2017:06:08 17:50:19	...read dialogues from file.
2017:06:08 17:50:20	......number of instances: 70858
2017:06:08 17:50:20	rnn type is lstm
2017:06:08 17:50:20	rnn type is lstm
2017:06:08 17:50:21	define train operations...
2017:06:08 17:50:22	variables in the discriminator:
2017:06:08 17:50:22	variables in the generator:
2017:06:08 17:50:26	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496944223/checkpoints/bestmodel.

2017:06:08 17:50:26	------ pretraining ------ 

2017:06:08 17:50:26	pretrain epoch 0
2017:06:08 17:50:34	use DataLoaderBBTV1 to init data.
2017:06:08 17:50:34	...init bucket.
2017:06:08 17:50:34	...load data.
2017:06:08 17:50:34	...init data from the raw dataset.
2017:06:08 17:50:34	...read dialogues from file.
2017:06:08 17:50:34	......number of instances: 70858
2017:06:08 17:50:35	rnn type is lstm
2017:06:08 17:50:35	rnn type is lstm
2017:06:08 17:50:36	define train operations...
2017:06:08 17:50:37	variables in the discriminator:
2017:06:08 17:50:37	variables in the generator:
2017:06:08 17:50:41	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496944238/checkpoints/bestmodel.

2017:06:08 17:50:41	------ pretraining ------ 

2017:06:08 17:50:41	------ training ------ 

2017:06:08 17:50:41	train epoch 1
2017:06:08 17:54:13	use DataLoaderBBTV1 to init data.
2017:06:08 17:54:13	...init bucket.
2017:06:08 17:54:13	...load data.
2017:06:08 17:54:13	...init data from the raw dataset.
2017:06:08 17:54:13	...read dialogues from file.
2017:06:08 17:54:14	......number of instances: 70858
2017:06:08 17:54:14	rnn type is lstm
2017:06:08 17:55:32	use DataLoaderBBTV1 to init data.
2017:06:08 17:55:32	...init bucket.
2017:06:08 17:55:32	...load data.
2017:06:08 17:55:32	...init data from the raw dataset.
2017:06:08 17:55:32	...read dialogues from file.
2017:06:08 17:55:33	......number of instances: 70858
2017:06:08 17:55:33	rnn type is lstm
2017:06:08 17:56:39	use DataLoaderBBTV1 to init data.
2017:06:08 17:56:39	...init bucket.
2017:06:08 17:56:39	...load data.
2017:06:08 17:56:39	...init data from the raw dataset.
2017:06:08 17:56:39	...read dialogues from file.
2017:06:08 17:56:39	......number of instances: 70858
2017:06:08 17:56:39	rnn type is lstm
2017:06:08 17:57:12	use DataLoaderBBTV1 to init data.
2017:06:08 17:57:12	...init bucket.
2017:06:08 17:57:12	...load data.
2017:06:08 17:57:12	...init data from the raw dataset.
2017:06:08 17:57:12	...read dialogues from file.
2017:06:08 17:57:13	......number of instances: 70858
2017:06:08 17:57:13	rnn type is lstm
2017:06:08 17:58:19	use DataLoaderBBTV1 to init data.
2017:06:08 17:58:19	...init bucket.
2017:06:08 17:58:19	...load data.
2017:06:08 17:58:19	...init data from the raw dataset.
2017:06:08 17:58:19	...read dialogues from file.
2017:06:08 17:58:20	......number of instances: 70858
2017:06:08 17:58:20	rnn type is lstm
2017:06:08 17:59:14	use DataLoaderBBTV1 to init data.
2017:06:08 17:59:14	...init bucket.
2017:06:08 17:59:14	...load data.
2017:06:08 17:59:14	...init data from the raw dataset.
2017:06:08 17:59:14	...read dialogues from file.
2017:06:08 17:59:15	......number of instances: 70858
2017:06:08 17:59:15	rnn type is lstm
2017:06:08 18:00:37	use DataLoaderBBTV1 to init data.
2017:06:08 18:00:37	...init bucket.
2017:06:08 18:00:37	...load data.
2017:06:08 18:00:37	...init data from the raw dataset.
2017:06:08 18:00:37	...read dialogues from file.
2017:06:08 18:00:38	......number of instances: 70858
2017:06:08 18:00:38	rnn type is lstm
2017:06:08 18:01:00	use DataLoaderBBTV1 to init data.
2017:06:08 18:01:00	...init bucket.
2017:06:08 18:01:00	...load data.
2017:06:08 18:01:00	...init data from the raw dataset.
2017:06:08 18:01:00	...read dialogues from file.
2017:06:08 18:01:00	......number of instances: 70858
2017:06:08 18:01:00	rnn type is lstm
2017:06:08 18:01:18	use DataLoaderBBTV1 to init data.
2017:06:08 18:01:18	...init bucket.
2017:06:08 18:01:18	...load data.
2017:06:08 18:01:18	...init data from the raw dataset.
2017:06:08 18:01:18	...read dialogues from file.
2017:06:08 18:01:18	......number of instances: 70858
2017:06:08 18:01:18	rnn type is lstm
2017:06:08 18:01:38	use DataLoaderBBTV1 to init data.
2017:06:08 18:01:38	...init bucket.
2017:06:08 18:01:38	...load data.
2017:06:08 18:01:38	...init data from the raw dataset.
2017:06:08 18:01:38	...read dialogues from file.
2017:06:08 18:01:39	......number of instances: 70858
2017:06:08 18:01:39	rnn type is lstm
2017:06:08 18:02:07	use DataLoaderBBTV1 to init data.
2017:06:08 18:02:07	...init bucket.
2017:06:08 18:02:07	...load data.
2017:06:08 18:02:07	...init data from the raw dataset.
2017:06:08 18:02:07	...read dialogues from file.
2017:06:08 18:02:08	......number of instances: 70858
2017:06:08 18:02:08	rnn type is lstm
2017:06:08 18:02:59	use DataLoaderBBTV1 to init data.
2017:06:08 18:02:59	...init bucket.
2017:06:08 18:02:59	...load data.
2017:06:08 18:02:59	...init data from the raw dataset.
2017:06:08 18:02:59	...read dialogues from file.
2017:06:08 18:03:00	......number of instances: 70858
2017:06:08 18:03:00	rnn type is lstm
2017:06:08 18:03:35	use DataLoaderBBTV1 to init data.
2017:06:08 18:03:35	...init bucket.
2017:06:08 18:03:35	...load data.
2017:06:08 18:03:35	...init data from the raw dataset.
2017:06:08 18:03:35	...read dialogues from file.
2017:06:08 18:03:36	......number of instances: 70858
2017:06:08 18:03:36	rnn type is lstm
2017:06:08 18:03:46	use DataLoaderBBTV1 to init data.
2017:06:08 18:03:46	...init bucket.
2017:06:08 18:03:46	...load data.
2017:06:08 18:03:46	...init data from the raw dataset.
2017:06:08 18:03:46	...read dialogues from file.
2017:06:08 18:03:47	......number of instances: 70858
2017:06:08 18:03:47	rnn type is lstm
2017:06:08 19:12:49	use DataLoaderBBTV1 to init data.
2017:06:08 19:12:49	...init bucket.
2017:06:08 19:12:49	...load data.
2017:06:08 19:12:49	...init data from the raw dataset.
2017:06:08 19:12:49	...read dialogues from file.
2017:06:08 19:12:50	......number of instances: 70858
2017:06:08 19:12:50	rnn type is lstm
2017:06:08 19:12:50	rnn type is lstm
2017:06:08 19:12:51	define train operations...
2017:06:08 19:12:52	variables in the discriminator:
2017:06:08 19:12:52	variables in the generator:
2017:06:08 19:12:58	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496949174/checkpoints/bestmodel.

2017:06:08 19:12:58	------ pretraining ------ 

2017:06:08 19:12:58	------ training ------ 

2017:06:08 19:12:58	train epoch 1
2017:06:08 19:33:12	use DataLoaderBBTV1 to init data.
2017:06:08 19:33:12	...init bucket.
2017:06:08 19:33:12	...load data.
2017:06:08 19:33:12	...init data from the raw dataset.
2017:06:08 19:33:12	...read dialogues from file.
2017:06:08 19:33:13	......number of instances: 70858
2017:06:08 19:33:13	rnn type is lstm
2017:06:08 19:33:13	rnn type is lstm
2017:06:08 19:33:14	define train operations...
2017:06:08 19:33:15	variables in the discriminator:
2017:06:08 19:33:15	variables in the generator:
2017:06:08 19:33:20	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496950396/checkpoints/bestmodel.

2017:06:08 19:33:20	------ pretraining ------ 

2017:06:08 19:33:20	------ training ------ 

2017:06:08 19:33:20	train epoch 1
2017:06:08 19:47:37	use DataLoaderBBT to init data.
2017:06:08 19:47:37	...init bucket.
2017:06:08 19:47:37	...load data.
2017:06:08 19:47:37	...init data from the raw dataset.
2017:06:08 19:47:37	...read dialogues from file.
2017:06:08 19:47:37	......number of instances: 35429
2017:06:08 19:48:17	use DataLoaderBBT to init data.
2017:06:08 19:48:17	...init bucket.
2017:06:08 19:48:17	...load data.
2017:06:08 19:48:17	...init data from the raw dataset.
2017:06:08 19:48:17	...read dialogues from file.
2017:06:08 19:48:17	......number of instances: 35429
2017:06:08 19:48:17	rnn type is lstm
2017:06:08 19:48:17	rnn type is lstm
2017:06:08 19:48:20	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951298/checkpoints/bestmodel.

2017:06:08 19:48:20	------ pretraining ------ 

2017:06:08 19:48:20	------ save the final model ------ 

2017:06:08 19:48:21	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951298/checkpoints/bestmodel.

2017:06:08 19:48:21	total execution time: 4
2017:06:08 19:49:03	use DataLoaderBBT to init data.
2017:06:08 19:49:03	...init bucket.
2017:06:08 19:49:03	...load data.
2017:06:08 19:49:03	...init data from the raw dataset.
2017:06:08 19:49:03	...read dialogues from file.
2017:06:08 19:49:04	......number of instances: 35429
2017:06:08 19:49:04	rnn type is lstm
2017:06:08 19:49:04	rnn type is lstm
2017:06:08 19:49:33	use DataLoaderBBT to init data.
2017:06:08 19:49:33	...init bucket.
2017:06:08 19:49:33	...load data.
2017:06:08 19:49:33	...init data from the raw dataset.
2017:06:08 19:49:33	...read dialogues from file.
2017:06:08 19:49:34	......number of instances: 35429
2017:06:08 19:49:34	rnn type is lstm
2017:06:08 19:49:34	rnn type is lstm
2017:06:08 19:49:38	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951376/checkpoints/bestmodel.

2017:06:08 19:49:38	------ pretraining ------ 

2017:06:08 19:49:38	------ save the final model ------ 

2017:06:08 19:49:39	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951376/checkpoints/bestmodel.

2017:06:08 19:49:39	total execution time: 5
2017:06:08 19:49:50	use DataLoaderBBTV1 to init data.
2017:06:08 19:49:50	...init bucket.
2017:06:08 19:49:51	...load data.
2017:06:08 19:49:51	...init data from the raw dataset.
2017:06:08 19:49:51	...read dialogues from file.
2017:06:08 19:49:51	......number of instances: 70858
2017:06:08 19:49:51	rnn type is lstm
2017:06:08 19:51:10	use DataLoaderBBTV1 to init data.
2017:06:08 19:51:10	...init bucket.
2017:06:08 19:51:10	...load data.
2017:06:08 19:51:10	...init data from the raw dataset.
2017:06:08 19:51:10	...read dialogues from file.
2017:06:08 19:51:11	......number of instances: 70858
2017:06:08 19:51:11	rnn type is lstm
2017:06:08 19:51:49	use DataLoaderBBTV1 to init data.
2017:06:08 19:51:49	...init bucket.
2017:06:08 19:51:49	...load data.
2017:06:08 19:51:49	...init data from the raw dataset.
2017:06:08 19:51:49	...read dialogues from file.
2017:06:08 19:51:50	......number of instances: 70858
2017:06:08 19:51:50	rnn type is lstm
2017:06:08 19:51:51	rnn type is lstm
2017:06:08 19:51:51	define train operations...
2017:06:08 19:51:52	variables in the discriminator:
2017:06:08 19:51:52	variables in the generator:
2017:06:08 19:52:28	use DataLoaderBBTV1 to init data.
2017:06:08 19:52:28	...init bucket.
2017:06:08 19:52:28	...load data.
2017:06:08 19:52:28	...init data from the raw dataset.
2017:06:08 19:52:28	...read dialogues from file.
2017:06:08 19:52:29	......number of instances: 70858
2017:06:08 19:52:29	rnn type is lstm
2017:06:08 19:52:29	rnn type is lstm
2017:06:08 19:52:30	define train operations...
2017:06:08 19:52:31	variables in the discriminator:
2017:06:08 19:52:31	variables in the generator:
2017:06:08 19:53:26	use DataLoaderBBTV1 to init data.
2017:06:08 19:53:26	...init bucket.
2017:06:08 19:53:26	...load data.
2017:06:08 19:53:26	...init data from the raw dataset.
2017:06:08 19:53:26	...read dialogues from file.
2017:06:08 19:53:27	......number of instances: 70858
2017:06:08 19:53:27	rnn type is lstm
2017:06:08 19:53:38	use DataLoaderBBTV1 to init data.
2017:06:08 19:53:38	...init bucket.
2017:06:08 19:53:38	...load data.
2017:06:08 19:53:38	...init data from the raw dataset.
2017:06:08 19:53:38	...read dialogues from file.
2017:06:08 19:53:38	......number of instances: 70858
2017:06:08 19:53:39	rnn type is lstm
2017:06:08 19:53:39	rnn type is lstm
2017:06:08 19:53:39	define train operations...
2017:06:08 19:53:40	variables in the discriminator:
2017:06:08 19:53:40	variables in the generator:
2017:06:08 19:53:44	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496951622/checkpoints/bestmodel.

2017:06:08 19:53:44	------ pretraining ------ 

2017:06:08 19:53:44	------ training ------ 

2017:06:08 19:53:44	train epoch 1
2017:06:08 19:56:00	use DataLoaderBBTV1 to init data.
2017:06:08 19:56:00	...init bucket.
2017:06:08 19:56:00	...load data.
2017:06:08 19:56:00	...init data from the raw dataset.
2017:06:08 19:56:00	...read dialogues from file.
2017:06:08 19:56:01	......number of instances: 70858
2017:06:08 19:56:01	rnn type is lstm
2017:06:08 19:56:01	rnn type is lstm
2017:06:08 19:56:01	define train operations...
2017:06:08 19:56:02	variables in the discriminator:
2017:06:08 19:56:02	variables in the generator:
2017:06:08 19:56:09	use DataLoaderBBT to init data.
2017:06:08 19:56:09	...init bucket.
2017:06:08 19:56:09	...load data.
2017:06:08 19:56:09	...init data from the raw dataset.
2017:06:08 19:56:09	...read dialogues from file.
2017:06:08 19:56:10	......number of instances: 35429
2017:06:08 19:56:10	rnn type is lstm
2017:06:08 19:56:10	rnn type is lstm
2017:06:08 19:56:25	use DataLoaderBBT to init data.
2017:06:08 19:56:25	...init bucket.
2017:06:08 19:56:25	...load data.
2017:06:08 19:56:25	...init data from the raw dataset.
2017:06:08 19:56:25	...read dialogues from file.
2017:06:08 19:56:26	......number of instances: 35429
2017:06:08 19:56:26	rnn type is lstm
2017:06:08 19:56:26	rnn type is lstm
2017:06:08 19:56:58	use DataLoaderBBT to init data.
2017:06:08 19:56:58	...init bucket.
2017:06:08 19:56:58	...load data.
2017:06:08 19:56:58	...init data from the raw dataset.
2017:06:08 19:56:58	...read dialogues from file.
2017:06:08 19:56:59	......number of instances: 35429
2017:06:08 19:56:59	rnn type is lstm
2017:06:08 19:56:59	rnn type is lstm
2017:06:08 19:57:02	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951820/checkpoints/bestmodel.

2017:06:08 19:57:02	------ pretraining ------ 

2017:06:08 19:57:02	------ save the final model ------ 

2017:06:08 19:57:03	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951820/checkpoints/bestmodel.

2017:06:08 19:57:03	total execution time: 4
2017:06:08 19:57:45	use DataLoaderBBT to init data.
2017:06:08 19:57:45	...init bucket.
2017:06:08 19:57:45	...load data.
2017:06:08 19:57:45	...init data from the raw dataset.
2017:06:08 19:57:45	...read dialogues from file.
2017:06:08 19:57:46	......number of instances: 35429
2017:06:08 19:57:46	rnn type is lstm
2017:06:08 19:57:46	rnn type is lstm
2017:06:08 19:57:52	use DataLoaderBBT to init data.
2017:06:08 19:57:52	...init bucket.
2017:06:08 19:57:52	...load data.
2017:06:08 19:57:52	...init data from the raw dataset.
2017:06:08 19:57:52	...read dialogues from file.
2017:06:08 19:57:53	......number of instances: 35429
2017:06:08 19:57:53	rnn type is lstm
2017:06:08 19:57:53	rnn type is lstm
2017:06:08 19:57:56	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/checkpoints/bestmodel.

2017:06:08 19:57:56	------ pretraining ------ 

2017:06:08 19:57:56	------ save the final model ------ 

2017:06:08 19:57:56	save 2-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/checkpoints/bestmodel.

2017:06:08 19:57:56	total execution time: 4
2017:06:08 19:59:17	use DataLoaderBBT to init data.
2017:06:08 19:59:17	...init bucket.
2017:06:08 19:59:17	...load data.
2017:06:08 19:59:17	...init data from the raw dataset.
2017:06:08 19:59:17	...read dialogues from file.
2017:06:08 19:59:18	......number of instances: 35429
2017:06:08 19:59:18	rnn type is lstm
2017:06:08 19:59:18	rnn type is lstm
2017:06:08 19:59:28	save 1-th bestmodel to path: data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/checkpoints/bestmodel.

2017:06:08 19:59:28	------ pretraining ------ 

2017:06:08 19:59:28	train epoch 0
2017:06:08 19:59:48	use DataLoaderBBT to init data.
2017:06:08 19:59:48	...init bucket.
2017:06:08 19:59:48	...load data.
2017:06:08 19:59:48	...init data from the raw dataset.
2017:06:08 19:59:48	...read dialogues from file.
2017:06:08 19:59:49	......number of instances: 35429
2017:06:08 19:59:49	rnn type is lstm
2017:06:08 19:59:49	rnn type is lstm
2017:06:08 19:59:49	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/
2017:06:08 19:59:49	restore model from data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/checkpoints/bestmodel-0
2017:06:08 19:59:50	generate sentence from latent space.
2017:06:08 20:03:54	use DataLoaderBBTV1 to init data.
2017:06:08 20:03:54	...init bucket.
2017:06:08 20:03:54	...load data.
2017:06:08 20:03:54	...init data from the raw dataset.
2017:06:08 20:03:54	...read dialogues from file.
2017:06:08 20:03:58	use DataLoaderBBTV1 to init data.
2017:06:08 20:03:58	...init bucket.
2017:06:08 20:03:58	...load data.
2017:06:08 20:03:58	...init data from the raw dataset.
2017:06:08 20:03:58	...read dialogues from file.
2017:06:08 20:03:59	......number of instances: 70858
2017:06:08 20:03:59	rnn type is lstm
2017:06:08 20:03:59	rnn type is lstm
2017:06:08 20:04:00	define train operations...
2017:06:08 20:04:01	variables in the discriminator:
2017:06:08 20:04:01	variables in the generator:
2017:06:08 20:04:05	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952242/checkpoints/bestmodel.

2017:06:08 20:04:05	------ pretraining ------ 

2017:06:08 20:04:05	------ training ------ 

2017:06:08 20:04:05	train epoch 1
2017:06:08 20:05:33	use DataLoaderBBTV1 to init data.
2017:06:08 20:05:33	...init bucket.
2017:06:08 20:05:33	...load data.
2017:06:08 20:05:33	...init data from the raw dataset.
2017:06:08 20:05:33	...read dialogues from file.
2017:06:08 20:05:34	......number of instances: 70858
2017:06:08 20:05:34	rnn type is lstm
2017:06:08 20:05:35	rnn type is lstm
2017:06:08 20:05:35	define train operations...
2017:06:08 20:05:36	variables in the discriminator:
2017:06:08 20:05:36	variables in the generator:
2017:06:08 20:06:02	use DataLoaderBBTV1 to init data.
2017:06:08 20:06:02	...init bucket.
2017:06:08 20:06:02	...load data.
2017:06:08 20:06:02	...init data from the raw dataset.
2017:06:08 20:06:02	...read dialogues from file.
2017:06:08 20:06:03	......number of instances: 70858
2017:06:08 20:06:03	rnn type is lstm
2017:06:08 20:06:03	rnn type is lstm
2017:06:08 20:06:04	define train operations...
2017:06:08 20:06:05	variables in the discriminator:
2017:06:08 20:06:05	variables in the generator:
2017:06:08 20:06:09	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel.

2017:06:08 20:06:09	------ pretraining ------ 

2017:06:08 20:06:09	------ training ------ 

2017:06:08 20:06:09	train epoch 1
2017:06:08 20:06:35	use DataLoaderBBTV1 to init data.
2017:06:08 20:06:35	...init bucket.
2017:06:08 20:06:35	...load data.
2017:06:08 20:06:35	...init data from the raw dataset.
2017:06:08 20:06:35	...read dialogues from file.
2017:06:08 20:06:36	......number of instances: 70858
2017:06:08 20:06:36	rnn type is lstm
2017:06:08 20:06:36	rnn type is lstm
2017:06:08 20:06:37	define train operations...
2017:06:08 20:06:38	variables in the discriminator:
2017:06:08 20:06:38	variables in the generator:
2017:06:08 20:07:44	use DataLoaderBBTV1 to init data.
2017:06:08 20:07:44	...init bucket.
2017:06:08 20:07:44	...load data.
2017:06:08 20:07:44	...init data from the raw dataset.
2017:06:08 20:07:44	...read dialogues from file.
2017:06:08 20:07:45	......number of instances: 70858
2017:06:08 20:07:45	rnn type is lstm
2017:06:08 20:07:45	rnn type is lstm
2017:06:08 20:07:46	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:07:46	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:10:04	use DataLoaderBBTV1 to init data.
2017:06:08 20:10:04	...init bucket.
2017:06:08 20:10:04	...load data.
2017:06:08 20:10:04	...init data from the raw dataset.
2017:06:08 20:10:04	...read dialogues from file.
2017:06:08 20:10:05	......number of instances: 70858
2017:06:08 20:10:05	rnn type is lstm
2017:06:08 20:10:06	rnn type is lstm
2017:06:08 20:10:06	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:10:06	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:11:16	use DataLoaderBBTV1 to init data.
2017:06:08 20:11:16	...init bucket.
2017:06:08 20:11:16	...load data.
2017:06:08 20:11:16	...init data from the raw dataset.
2017:06:08 20:11:16	...read dialogues from file.
2017:06:08 20:11:17	......number of instances: 70858
2017:06:08 20:11:17	rnn type is lstm
2017:06:08 20:11:18	rnn type is lstm
2017:06:08 20:11:18	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:11:18	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:11:19	generate sentence from latent space.
2017:06:08 20:11:33	use DataLoaderBBTV1 to init data.
2017:06:08 20:11:33	...init bucket.
2017:06:08 20:11:33	...load data.
2017:06:08 20:11:33	...init data from the raw dataset.
2017:06:08 20:11:33	...read dialogues from file.
2017:06:08 20:11:34	......number of instances: 70858
2017:06:08 20:11:34	rnn type is lstm
2017:06:08 20:11:35	rnn type is lstm
2017:06:08 20:11:35	define train operations...
2017:06:08 20:11:36	variables in the discriminator:
2017:06:08 20:11:36	variables in the generator:
2017:06:08 20:11:41	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952698/checkpoints/bestmodel.

2017:06:08 20:11:41	------ pretraining ------ 

2017:06:08 20:11:41	------ training ------ 

2017:06:08 20:11:41	train epoch 1
2017:06:08 20:12:28	use DataLoaderBBTV1 to init data.
2017:06:08 20:12:28	...init bucket.
2017:06:08 20:12:28	...load data.
2017:06:08 20:12:28	...init data from the raw dataset.
2017:06:08 20:12:28	...read dialogues from file.
2017:06:08 20:12:29	......number of instances: 70858
2017:06:08 20:12:29	rnn type is lstm
2017:06:08 20:12:30	rnn type is lstm
2017:06:08 20:12:30	define train operations...
2017:06:08 20:12:31	variables in the discriminator:
2017:06:08 20:12:31	variables in the generator:
2017:06:08 20:12:57	use DataLoaderBBTV1 to init data.
2017:06:08 20:12:57	...init bucket.
2017:06:08 20:12:57	...load data.
2017:06:08 20:12:57	...init data from the raw dataset.
2017:06:08 20:12:57	...read dialogues from file.
2017:06:08 20:12:58	......number of instances: 70858
2017:06:08 20:12:58	rnn type is lstm
2017:06:08 20:12:58	rnn type is lstm
2017:06:08 20:12:59	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952752/
2017:06:08 20:13:10	use DataLoaderBBTV1 to init data.
2017:06:08 20:13:10	...init bucket.
2017:06:08 20:13:10	...load data.
2017:06:08 20:13:10	...init data from the raw dataset.
2017:06:08 20:13:10	...read dialogues from file.
2017:06:08 20:13:11	......number of instances: 70858
2017:06:08 20:13:11	rnn type is lstm
2017:06:08 20:13:12	rnn type is lstm
2017:06:08 20:13:12	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:13:12	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:13:14	generate sentence from latent space.
2017:06:08 20:13:27	use DataLoaderBBTV1 to init data.
2017:06:08 20:13:27	...init bucket.
2017:06:08 20:13:27	...load data.
2017:06:08 20:13:27	...init data from the raw dataset.
2017:06:08 20:13:27	...read dialogues from file.
2017:06:08 20:13:27	......number of instances: 70858
2017:06:08 20:13:27	rnn type is lstm
2017:06:08 20:13:28	rnn type is lstm
2017:06:08 20:13:28	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:13:28	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:13:29	generate sentence from latent space.
2017:06:08 20:14:04	use DataLoaderBBTV1 to init data.
2017:06:08 20:14:04	...init bucket.
2017:06:08 20:14:04	...load data.
2017:06:08 20:14:04	...init data from the raw dataset.
2017:06:08 20:14:04	...read dialogues from file.
2017:06:08 20:14:05	......number of instances: 70858
2017:06:08 20:14:05	rnn type is lstm
2017:06:08 20:14:05	rnn type is lstm
2017:06:08 20:14:05	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:14:05	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:14:06	generate sentence from latent space.
2017:06:08 20:14:25	use DataLoaderBBTV1 to init data.
2017:06:08 20:14:25	...init bucket.
2017:06:08 20:14:25	...load data.
2017:06:08 20:14:25	...init data from the raw dataset.
2017:06:08 20:14:25	...read dialogues from file.
2017:06:08 20:14:26	......number of instances: 70858
2017:06:08 20:14:26	rnn type is lstm
2017:06:08 20:14:26	rnn type is lstm
2017:06:08 20:14:27	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:14:27	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:14:27	generate sentence from latent space.
2017:06:08 20:18:45	use DataLoaderBBTV1 to init data.
2017:06:08 20:18:45	...init bucket.
2017:06:08 20:18:45	...load data.
2017:06:08 20:18:45	...init data from the raw dataset.
2017:06:08 20:18:45	...read dialogues from file.
2017:06:08 20:18:46	......number of instances: 70858
2017:06:08 20:18:46	rnn type is lstm
2017:06:08 20:18:46	rnn type is lstm
2017:06:08 20:18:47	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:19:08	use DataLoaderBBTV1 to init data.
2017:06:08 20:19:08	...init bucket.
2017:06:08 20:19:08	...load data.
2017:06:08 20:19:08	...init data from the raw dataset.
2017:06:08 20:19:08	...read dialogues from file.
2017:06:08 20:19:08	......number of instances: 70858
2017:06:08 20:19:08	rnn type is lstm
2017:06:08 20:19:09	rnn type is lstm
2017:06:08 20:19:09	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:19:10	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:19:10	generate sentence from latent space.
2017:06:08 20:19:58	use DataLoaderBBTV1 to init data.
2017:06:08 20:19:58	...init bucket.
2017:06:08 20:19:58	...load data.
2017:06:08 20:19:58	...init data from the raw dataset.
2017:06:08 20:19:58	...read dialogues from file.
2017:06:08 20:19:59	......number of instances: 70858
2017:06:08 20:19:59	rnn type is lstm
2017:06:08 20:19:59	rnn type is lstm
2017:06:08 20:20:00	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:20:00	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:20:00	generate sentence from latent space.
2017:06:08 20:21:08	use DataLoaderBBTV1 to init data.
2017:06:08 20:21:08	...init bucket.
2017:06:08 20:21:08	...load data.
2017:06:08 20:21:08	...init data from the raw dataset.
2017:06:08 20:21:08	...read dialogues from file.
2017:06:08 20:21:09	......number of instances: 70858
2017:06:08 20:21:09	rnn type is lstm
2017:06:08 20:21:09	rnn type is lstm
2017:06:08 20:21:10	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:21:10	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:21:10	generate sentence from latent space.
2017:06:08 20:21:12	true question: [Raj] do you know what he 's talking about ?
2017:06:08 20:21:25	use DataLoaderBBTV1 to init data.
2017:06:08 20:21:25	...init bucket.
2017:06:08 20:21:25	...load data.
2017:06:08 20:21:25	...init data from the raw dataset.
2017:06:08 20:21:25	...read dialogues from file.
2017:06:08 20:21:26	......number of instances: 70858
2017:06:08 20:21:26	rnn type is lstm
2017:06:08 20:21:26	rnn type is lstm
2017:06:08 20:21:27	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:21:27	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:21:27	generate sentence from latent space.
2017:06:08 20:21:29	true question: [Sheldon] you mean just go someplace else and be someplace else ?
2017:06:08 20:21:29	true answer: [Sheldon] you mean just go someplace else and be someplace else ?
2017:06:08 20:21:29	faked answer: 45 splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing
2017:06:08 20:21:29	total execution time: 4 s
2017:06:08 20:21:52	use DataLoaderBBTV1 to init data.
2017:06:08 20:21:52	...init bucket.
2017:06:08 20:21:52	...load data.
2017:06:08 20:21:52	...init data from the raw dataset.
2017:06:08 20:21:52	...read dialogues from file.
2017:06:08 20:21:53	......number of instances: 70858
2017:06:08 20:21:53	rnn type is lstm
2017:06:08 20:21:53	rnn type is lstm
2017:06:08 20:21:54	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:21:55	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:21:55	generate sentence from latent space.
2017:06:08 20:21:57	true sentence: [Penny] okay , look , we don 't have to go anywhere . we can just , you know , stay here and hang out in the hot tub .
2017:06:08 20:21:57	faked sentence: 45 splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing
2017:06:08 20:21:57	total execution time: 4 s
2017:06:08 20:28:29	use DataLoaderBBTV1 to init data.
2017:06:08 20:28:30	...init bucket.
2017:06:08 20:28:30	...load data.
2017:06:08 20:28:30	...init data from the raw dataset.
2017:06:08 20:28:30	...read dialogues from file.
2017:06:08 20:28:30	......number of instances: 70858
2017:06:08 20:28:30	rnn type is lstm
2017:06:08 20:28:31	rnn type is lstm
2017:06:08 20:28:31	init from the path data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/
2017:06:08 20:28:32	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1496952367/checkpoints/bestmodel-0
2017:06:08 20:28:32	generate sentence from latent space.
2017:06:08 20:28:34	true sentence: there were only two people there
2017:06:08 20:28:34	faked sentence: 45 splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing splicing
2017:06:08 20:28:34	total execution time: 4 s
2017:06:08 20:29:00	use DataLoaderBBT to init data.
2017:06:08 20:29:00	...init bucket.
2017:06:08 20:29:00	...load data.
2017:06:08 20:29:00	...init data from the raw dataset.
2017:06:08 20:29:00	...read dialogues from file.
2017:06:08 20:29:01	......number of instances: 35429
2017:06:08 20:29:01	rnn type is lstm
2017:06:08 20:29:01	rnn type is lstm
2017:06:08 20:29:01	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951867/
2017:06:08 20:29:27	use DataLoaderBBT to init data.
2017:06:08 20:29:27	...init bucket.
2017:06:08 20:29:27	...load data.
2017:06:08 20:29:27	...init data from the raw dataset.
2017:06:08 20:29:27	...read dialogues from file.
2017:06:08 20:29:27	......number of instances: 35429
2017:06:08 20:29:27	rnn type is lstm
2017:06:08 20:29:27	rnn type is lstm
2017:06:08 20:29:28	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/
2017:06:08 20:29:29	restore model from data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/checkpoints/bestmodel-0
2017:06:08 20:30:00	use DataLoaderBBT to init data.
2017:06:08 20:30:00	...init bucket.
2017:06:08 20:30:00	...load data.
2017:06:08 20:30:00	...init data from the raw dataset.
2017:06:08 20:30:00	...read dialogues from file.
2017:06:08 20:30:01	......number of instances: 35429
2017:06:08 20:30:01	rnn type is lstm
2017:06:08 20:30:01	rnn type is lstm
2017:06:08 20:30:01	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/
2017:06:08 20:30:02	restore model from data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1496951874/checkpoints/bestmodel-0
2017:06:08 20:30:02	generate sentence from latent space.
2017:06:08 20:30:16	true question: hey penny we 're kind of in the middle of a crisis here
2017:06:08 20:30:16	true answer: [Penny] oh , i know . bernadette told me . sorry , sheldon . i know that game meant a lot to you .
2017:06:08 20:30:16	faked answer: widen widen buckles tropicana tropicana fashioned fashioned fashioned fashioned iguana iguana iguana iguana iguana iguana iguana mush mush mush mush mush mush mush oklahoma tardy tardy tardy tardy tardy tardy tardy tardy interpretation interpretation interpretation interpretation interpretation interpretation forms forms forms forms interpretation wheelchair wheelchair wheelchair wheelchair verses verses
2017:06:08 20:30:16	total execution time: 15 s
2017:06:09 10:25:49	use DataLoaderBBT to init data.
2017:06:09 10:25:49	...init bucket.
2017:06:09 10:25:49	...load data.
2017:06:09 10:25:49	...init data from the raw dataset.
2017:06:09 10:25:49	...read dialogues from file.
2017:06:09 10:25:50	......number of instances: 35429
2017:06:09 10:25:50	rnn type is lstm
2017:06:09 10:25:50	rnn type is lstm
2017:06:09 10:25:51	rnn type is lstm
2017:06:09 10:26:56	use DataLoaderBBT to init data.
2017:06:09 10:26:56	...init bucket.
2017:06:09 10:26:56	...load data.
2017:06:09 10:26:56	...init data from the raw dataset.
2017:06:09 10:26:56	...read dialogues from file.
2017:06:09 10:26:57	......number of instances: 35429
2017:06:09 10:26:57	rnn type is lstm
2017:06:09 10:26:57	rnn type is lstm
2017:06:09 10:26:57	rnn type is lstm
2017:06:09 10:30:14	use DataLoaderBBT to init data.
2017:06:09 10:30:14	...init bucket.
2017:06:09 10:30:14	...load data.
2017:06:09 10:30:14	...init data from the raw dataset.
2017:06:09 10:30:14	...read dialogues from file.
2017:06:09 10:30:15	......number of instances: 35429
2017:06:09 10:30:15	rnn type is lstm
2017:06:09 10:30:15	rnn type is lstm
2017:06:09 10:30:16	rnn type is lstm
2017:06:09 10:31:48	use DataLoaderBBT to init data.
2017:06:09 10:31:48	...init bucket.
2017:06:09 10:31:48	...load data.
2017:06:09 10:31:48	...init data from the raw dataset.
2017:06:09 10:31:48	...read dialogues from file.
2017:06:09 10:31:49	......number of instances: 35429
2017:06:09 10:31:49	rnn type is lstm
2017:06:09 10:31:49	rnn type is lstm
2017:06:09 10:31:49	rnn type is lstm
2017:06:09 10:32:19	use DataLoaderBBT to init data.
2017:06:09 10:32:19	...init bucket.
2017:06:09 10:32:19	...load data.
2017:06:09 10:32:19	...init data from the raw dataset.
2017:06:09 10:32:19	...read dialogues from file.
2017:06:09 10:32:20	......number of instances: 35429
2017:06:09 10:32:20	rnn type is lstm
2017:06:09 10:32:20	rnn type is lstm
2017:06:09 10:32:21	rnn type is lstm
2017:06:09 10:33:05	use DataLoaderBBT to init data.
2017:06:09 10:33:05	...init bucket.
2017:06:09 10:33:05	...load data.
2017:06:09 10:33:05	...init data from the raw dataset.
2017:06:09 10:33:05	...read dialogues from file.
2017:06:09 10:33:06	......number of instances: 35429
2017:06:09 10:33:06	rnn type is lstm
2017:06:09 10:33:06	rnn type is lstm
2017:06:09 10:33:06	rnn type is lstm
2017:06:09 10:33:49	use DataLoaderBBT to init data.
2017:06:09 10:33:49	...init bucket.
2017:06:09 10:33:49	...load data.
2017:06:09 10:33:49	...init data from the raw dataset.
2017:06:09 10:33:49	...read dialogues from file.
2017:06:09 10:33:50	......number of instances: 35429
2017:06:09 10:33:50	rnn type is lstm
2017:06:09 10:33:50	rnn type is lstm
2017:06:09 10:33:50	rnn type is lstm
2017:06:09 10:44:45	use DataLoaderBBT to init data.
2017:06:09 10:44:45	...init bucket.
2017:06:09 10:44:45	...load data.
2017:06:09 10:44:45	...init data from the raw dataset.
2017:06:09 10:44:45	...read dialogues from file.
2017:06:09 10:44:46	......number of instances: 35429
2017:06:09 10:44:46	rnn type is lstm
2017:06:09 10:44:46	rnn type is lstm
2017:06:09 10:44:47	rnn type is lstm
2017:06:09 10:47:26	use DataLoaderBBT to init data.
2017:06:09 10:47:26	...init bucket.
2017:06:09 10:47:26	...load data.
2017:06:09 10:47:26	...init data from the raw dataset.
2017:06:09 10:47:26	...read dialogues from file.
2017:06:09 10:47:27	......number of instances: 35429
2017:06:09 10:47:27	rnn type is lstm
2017:06:09 10:47:27	rnn type is lstm
2017:06:09 10:47:28	rnn type is lstm
2017:06:09 10:47:28	define train operations...
2017:06:09 10:47:30	variables in the discriminator:
2017:06:09 10:47:30	variables in the generator:
2017:06:09 10:50:21	use DataLoaderBBT to init data.
2017:06:09 10:50:21	...init bucket.
2017:06:09 10:50:21	...load data.
2017:06:09 10:50:21	...init data from the raw dataset.
2017:06:09 10:50:21	...read dialogues from file.
2017:06:09 10:50:22	......number of instances: 35429
2017:06:09 10:50:22	rnn type is lstm
2017:06:09 10:50:22	rnn type is lstm
2017:06:09 10:50:22	rnn type is lstm
2017:06:09 10:50:23	define train operations...
2017:06:09 10:50:24	variables in the discriminator:
2017:06:09 10:50:24	variables in the generator:
2017:06:09 10:50:57	use DataLoaderBBT to init data.
2017:06:09 10:50:57	...init bucket.
2017:06:09 10:50:57	...load data.
2017:06:09 10:50:57	...init data from the raw dataset.
2017:06:09 10:50:57	...read dialogues from file.
2017:06:09 10:50:58	......number of instances: 35429
2017:06:09 10:50:59	rnn type is lstm
2017:06:09 10:50:59	rnn type is lstm
2017:06:09 10:50:59	rnn type is lstm
2017:06:09 10:51:00	define train operations...
2017:06:09 10:51:02	variables in the discriminator:
2017:06:09 10:51:02	variables in the generator:
2017:06:09 10:51:09	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497005464/checkpoints/bestmodel.

2017:06:09 10:51:09	------ pretraining ------ 

2017:06:09 10:51:09	pretrain epoch 0
2017:06:09 10:52:54	use DataLoaderBBT to init data.
2017:06:09 10:52:54	...init bucket.
2017:06:09 10:52:54	...load data.
2017:06:09 10:52:54	...init data from the raw dataset.
2017:06:09 10:52:54	...read dialogues from file.
2017:06:09 10:52:55	......number of instances: 35429
2017:06:09 10:52:55	rnn type is lstm
2017:06:09 10:52:55	rnn type is lstm
2017:06:09 10:52:55	rnn type is lstm
2017:06:09 10:52:56	define train operations...
2017:06:09 10:52:57	variables in the discriminator:
2017:06:09 10:52:57	variables in the generator:
2017:06:09 10:53:05	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497005580/checkpoints/bestmodel.

2017:06:09 10:53:05	------ pretraining ------ 

2017:06:09 10:53:05	pretrain epoch 0
2017:06:09 10:53:15	use DataLoaderBBT to init data.
2017:06:09 10:53:15	...init bucket.
2017:06:09 10:53:15	...load data.
2017:06:09 10:53:15	...init data from the raw dataset.
2017:06:09 10:53:15	...read dialogues from file.
2017:06:09 10:53:16	......number of instances: 35429
2017:06:09 10:53:16	rnn type is lstm
2017:06:09 10:53:16	rnn type is lstm
2017:06:09 10:53:19	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV0.TextGANV0/1497005597/checkpoints/bestmodel.

2017:06:09 10:53:19	------ pretraining ------ 

2017:06:09 10:53:19	train epoch 0
2017:06:09 10:53:32	use DataLoaderBBTV1 to init data.
2017:06:09 10:53:32	...init bucket.
2017:06:09 10:53:32	...load data.
2017:06:09 10:53:32	...init data from the raw dataset.
2017:06:09 10:53:32	...read dialogues from file.
2017:06:09 10:53:34	......number of instances: 70858
2017:06:09 10:53:34	rnn type is lstm
2017:06:09 10:53:34	rnn type is lstm
2017:06:09 10:53:35	define train operations...
2017:06:09 10:53:36	variables in the discriminator:
2017:06:09 10:53:36	variables in the generator:
2017:06:09 10:55:33	use DataLoaderBBT to init data.
2017:06:09 10:55:33	...init bucket.
2017:06:09 10:55:33	...load data.
2017:06:09 10:55:33	...init data from the raw dataset.
2017:06:09 10:55:33	...read dialogues from file.
2017:06:09 10:55:34	......number of instances: 35429
2017:06:09 10:55:34	rnn type is lstm
2017:06:09 10:55:34	rnn type is lstm
2017:06:09 10:55:34	rnn type is lstm
2017:06:09 10:55:35	define train operations...
2017:06:09 10:55:36	variables in the discriminator:
2017:06:09 10:55:36	variables in the generator:
2017:06:09 10:55:43	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497005738/checkpoints/bestmodel.

2017:06:09 10:55:43	------ pretraining ------ 

2017:06:09 10:55:43	pretrain epoch 0
2017:06:09 10:55:51	use DataLoaderBBT to init data.
2017:06:09 10:55:51	...init bucket.
2017:06:09 10:55:51	...load data.
2017:06:09 10:55:51	...init data from the raw dataset.
2017:06:09 10:55:51	...read dialogues from file.
2017:06:09 10:55:51	......number of instances: 35429
2017:06:09 10:55:51	rnn type is lstm
2017:06:09 10:55:51	rnn type is lstm
2017:06:09 10:55:52	rnn type is lstm
2017:06:09 10:55:53	define train operations...
2017:06:09 10:55:54	variables in the discriminator:
2017:06:09 10:55:54	variables in the generator:
2017:06:09 10:56:01	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497005756/checkpoints/bestmodel.

2017:06:09 10:56:01	------ pretraining ------ 

2017:06:09 10:56:01	------ training ------ 

2017:06:09 10:56:01	train epoch 1
2017:06:09 10:57:06	use DataLoaderBBT to init data.
2017:06:09 10:57:06	...init bucket.
2017:06:09 10:57:06	...load data.
2017:06:09 10:57:06	...init data from the raw dataset.
2017:06:09 10:57:06	...read dialogues from file.
2017:06:09 10:57:07	......number of instances: 35429
2017:06:09 10:57:07	rnn type is lstm
2017:06:09 10:57:07	rnn type is lstm
2017:06:09 10:57:07	rnn type is lstm
2017:06:09 10:57:08	define train operations...
2017:06:09 10:57:09	variables in the discriminator:
2017:06:09 10:57:09	variables in the generator:
2017:06:09 10:57:14	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497005831/checkpoints/bestmodel.

2017:06:09 10:57:14	------ pretraining ------ 

2017:06:09 10:57:14	pretrain epoch 0
2017:06:09 10:57:46	use DataLoaderBBTV1 to init data.
2017:06:09 10:57:46	...init bucket.
2017:06:09 10:57:46	...load data.
2017:06:09 10:57:46	...init data from the raw dataset.
2017:06:09 10:57:46	...read dialogues from file.
2017:06:09 10:57:47	......number of instances: 70858
2017:06:09 10:57:47	rnn type is lstm
2017:06:09 10:57:47	rnn type is lstm
2017:06:09 10:57:48	define train operations...
2017:06:09 10:57:49	variables in the discriminator:
2017:06:09 10:57:49	variables in the generator:
2017:06:09 10:59:04	use DataLoaderBBTV1 to init data.
2017:06:09 10:59:04	...init bucket.
2017:06:09 10:59:04	...load data.
2017:06:09 10:59:04	...init data from the raw dataset.
2017:06:09 10:59:04	...read dialogues from file.
2017:06:09 10:59:05	......number of instances: 70858
2017:06:09 10:59:05	rnn type is lstm
2017:06:09 10:59:06	rnn type is lstm
2017:06:09 10:59:06	define train operations...
2017:06:09 10:59:08	variables in the discriminator:
2017:06:09 10:59:08	variables in the generator:
2017:06:09 12:26:43	use DataLoaderBBTV1 to init data.
2017:06:09 12:26:43	...init bucket.
2017:06:09 12:26:43	...load data.
2017:06:09 12:26:43	...init data from the raw dataset.
2017:06:09 12:26:43	...read dialogues from file.
2017:06:09 12:26:44	......number of instances: 70858
2017:06:09 12:26:44	rnn type is lstm
2017:06:09 12:26:44	rnn type is lstm
2017:06:09 12:26:45	define train operations...
2017:06:09 12:26:46	variables in the discriminator:
2017:06:09 12:26:46	variables in the generator:
2017:06:09 12:27:21	use DataLoaderBBTV1 to init data.
2017:06:09 12:27:21	...init bucket.
2017:06:09 12:27:21	...load data.
2017:06:09 12:27:21	...init data from the raw dataset.
2017:06:09 12:27:21	...read dialogues from file.
2017:06:09 12:27:22	......number of instances: 70858
2017:06:09 12:27:22	rnn type is lstm
2017:06:09 12:27:22	rnn type is lstm
2017:06:09 12:27:23	define train operations...
2017:06:09 12:27:24	variables in the discriminator:
2017:06:09 12:27:24	variables in the generator:
2017:06:09 12:30:16	use DataLoaderBBTV1 to init data.
2017:06:09 12:30:16	...init bucket.
2017:06:09 12:30:16	...load data.
2017:06:09 12:30:16	...init data from the raw dataset.
2017:06:09 12:30:16	...read dialogues from file.
2017:06:09 12:30:18	......number of instances: 70858
2017:06:09 12:30:18	rnn type is lstm
2017:06:09 12:30:18	rnn type is lstm
2017:06:09 12:30:19	define train operations...
2017:06:09 12:30:20	variables in the discriminator:
2017:06:09 12:30:20	variables in the generator:
2017:06:09 12:31:51	use DataLoaderBBTV1 to init data.
2017:06:09 12:31:51	...init bucket.
2017:06:09 12:31:51	...load data.
2017:06:09 12:31:51	...init data from the raw dataset.
2017:06:09 12:31:51	...read dialogues from file.
2017:06:09 12:31:51	......number of instances: 70858
2017:06:09 12:31:51	rnn type is lstm
2017:06:09 12:31:52	rnn type is lstm
2017:06:09 12:31:52	define train operations...
2017:06:09 12:31:53	variables in the discriminator:
2017:06:09 12:31:53	variables in the generator:
2017:06:09 12:32:13	use DataLoaderBBTV1 to init data.
2017:06:09 12:32:13	...init bucket.
2017:06:09 12:32:13	...load data.
2017:06:09 12:32:13	...init data from the raw dataset.
2017:06:09 12:32:13	...read dialogues from file.
2017:06:09 12:32:14	......number of instances: 70858
2017:06:09 12:32:14	rnn type is lstm
2017:06:09 12:32:14	rnn type is lstm
2017:06:09 12:32:15	define train operations...
2017:06:09 12:32:16	variables in the discriminator:
2017:06:09 12:32:16	variables in the generator:
2017:06:09 12:37:46	use DataLoaderBBT to init data.
2017:06:09 12:37:46	...init bucket.
2017:06:09 12:37:46	...load data.
2017:06:09 12:37:46	...init data from the raw dataset.
2017:06:09 12:37:46	...read dialogues from file.
2017:06:09 12:37:47	......number of instances: 35429
2017:06:09 12:37:47	rnn type is lstm
2017:06:09 12:37:47	rnn type is lstm
2017:06:09 12:37:47	rnn type is lstm
2017:06:09 12:37:48	define train operations...
2017:06:09 12:37:51	variables in the discriminator:
2017:06:09 12:37:51	variables in the generator:
2017:06:09 12:38:56	use DataLoaderBBT to init data.
2017:06:09 12:38:56	...init bucket.
2017:06:09 12:38:56	...load data.
2017:06:09 12:38:56	...init data from the raw dataset.
2017:06:09 12:38:56	...read dialogues from file.
2017:06:09 12:38:56	......number of instances: 35429
2017:06:09 12:38:56	rnn type is lstm
2017:06:09 12:38:56	rnn type is lstm
2017:06:09 12:38:57	rnn type is lstm
2017:06:09 12:38:57	define train operations...
2017:06:09 12:39:00	variables in the discriminator:
2017:06:09 12:39:00	variables in the generator:
2017:06:09 12:39:14	use DataLoaderBBT to init data.
2017:06:09 12:39:14	...init bucket.
2017:06:09 12:39:14	...load data.
2017:06:09 12:39:14	...init data from the raw dataset.
2017:06:09 12:39:14	...read dialogues from file.
2017:06:09 12:39:14	......number of instances: 35429
2017:06:09 12:39:15	rnn type is lstm
2017:06:09 12:39:15	rnn type is lstm
2017:06:09 12:39:15	rnn type is lstm
2017:06:09 12:39:15	define train operations...
2017:06:09 12:39:18	variables in the discriminator:
2017:06:09 12:39:18	variables in the generator:
2017:06:09 12:39:31	use DataLoaderBBT to init data.
2017:06:09 12:39:31	...init bucket.
2017:06:09 12:39:31	...load data.
2017:06:09 12:39:31	...init data from the raw dataset.
2017:06:09 12:39:31	...read dialogues from file.
2017:06:09 12:39:31	......number of instances: 35429
2017:06:09 12:39:31	rnn type is lstm
2017:06:09 12:39:31	rnn type is lstm
2017:06:09 12:39:32	rnn type is lstm
2017:06:09 12:39:32	define train operations...
2017:06:09 12:39:35	variables in the discriminator:
2017:06:09 12:39:35	variables in the generator:
2017:06:09 12:39:55	use DataLoaderBBT to init data.
2017:06:09 12:39:55	...init bucket.
2017:06:09 12:39:55	...load data.
2017:06:09 12:39:55	...init data from the raw dataset.
2017:06:09 12:39:55	...read dialogues from file.
2017:06:09 12:39:55	......number of instances: 35429
2017:06:09 12:39:55	rnn type is lstm
2017:06:09 12:39:55	rnn type is lstm
2017:06:09 12:39:56	rnn type is lstm
2017:06:09 12:39:56	define train operations...
2017:06:09 12:39:59	variables in the discriminator:
2017:06:09 12:39:59	variables in the generator:
2017:06:09 12:41:00	use DataLoaderBBT to init data.
2017:06:09 12:41:00	...init bucket.
2017:06:09 12:41:00	...load data.
2017:06:09 12:41:00	...init data from the raw dataset.
2017:06:09 12:41:00	...read dialogues from file.
2017:06:09 12:41:00	......number of instances: 35429
2017:06:09 12:41:00	rnn type is lstm
2017:06:09 12:41:00	rnn type is lstm
2017:06:09 12:41:01	rnn type is lstm
2017:06:09 12:41:01	define train operations...
2017:06:09 12:41:04	variables in the discriminator:
2017:06:09 12:41:04	variables in the generator:
2017:06:09 12:44:15	use DataLoaderBBT to init data.
2017:06:09 12:44:15	...init bucket.
2017:06:09 12:44:15	...load data.
2017:06:09 12:44:15	...init data from the raw dataset.
2017:06:09 12:44:15	...read dialogues from file.
2017:06:09 12:44:16	......number of instances: 35429
2017:06:09 12:44:16	rnn type is lstm
2017:06:09 12:44:16	rnn type is lstm
2017:06:09 12:44:16	rnn type is lstm
2017:06:09 12:44:17	define train operations...
2017:06:09 12:44:20	variables and gradients in the discriminator:
2017:06:09 12:44:20	variables and gradients in the generator:
2017:06:09 12:45:28	use DataLoaderBBT to init data.
2017:06:09 12:45:28	...init bucket.
2017:06:09 12:45:28	...load data.
2017:06:09 12:45:28	...init data from the raw dataset.
2017:06:09 12:45:28	...read dialogues from file.
2017:06:09 12:45:29	......number of instances: 35429
2017:06:09 12:45:29	rnn type is lstm
2017:06:09 12:45:29	rnn type is lstm
2017:06:09 12:45:29	rnn type is lstm
2017:06:09 12:45:30	define train operations...
2017:06:09 12:45:33	variables and gradients in the discriminator:
2017:06:09 12:45:33	variables and gradients in the generator:
2017:06:09 12:50:23	use DataLoaderBBT to init data.
2017:06:09 12:50:23	...init bucket.
2017:06:09 12:50:23	...load data.
2017:06:09 12:50:23	...init data from the raw dataset.
2017:06:09 12:50:23	...read dialogues from file.
2017:06:09 12:50:24	......number of instances: 35429
2017:06:09 12:50:24	rnn type is lstm
2017:06:09 12:50:24	rnn type is lstm
2017:06:09 12:50:24	rnn type is lstm
2017:06:09 12:50:44	use DataLoaderBBT to init data.
2017:06:09 12:50:44	...init bucket.
2017:06:09 12:50:44	...load data.
2017:06:09 12:50:44	...init data from the raw dataset.
2017:06:09 12:50:44	...read dialogues from file.
2017:06:09 12:50:44	......number of instances: 35429
2017:06:09 12:50:45	rnn type is lstm
2017:06:09 12:50:45	rnn type is lstm
2017:06:09 12:50:45	rnn type is lstm
2017:06:09 12:50:45	define train operations...
2017:06:09 13:19:51	use DataLoaderBBT to init data.
2017:06:09 13:19:51	...init bucket.
2017:06:09 13:19:51	...load data.
2017:06:09 13:19:51	...init data from the raw dataset.
2017:06:09 13:19:51	...read dialogues from file.
2017:06:09 13:19:52	......number of instances: 35429
2017:06:09 13:19:52	rnn type is lstm
2017:06:09 13:19:52	rnn type is lstm
2017:06:09 13:19:52	rnn type is lstm
2017:06:09 13:35:16	use DataLoaderBBT to init data.
2017:06:09 13:35:16	...init bucket.
2017:06:09 13:35:16	...load data.
2017:06:09 13:35:16	...init data from the raw dataset.
2017:06:09 13:35:16	...read dialogues from file.
2017:06:09 13:35:17	......number of instances: 35429
2017:06:09 13:35:17	rnn type is lstm
2017:06:09 13:35:17	rnn type is lstm
2017:06:09 13:36:19	use DataLoaderBBT to init data.
2017:06:09 13:36:19	...init bucket.
2017:06:09 13:36:19	...load data.
2017:06:09 13:36:19	...init data from the raw dataset.
2017:06:09 13:36:19	...read dialogues from file.
2017:06:09 13:36:20	......number of instances: 35429
2017:06:09 13:36:20	define generator.
2017:06:09 13:36:20	rnn type is lstm
2017:06:09 13:36:20	rnn type is lstm
2017:06:09 13:36:20	define discriminator.
2017:06:09 13:37:54	use DataLoaderBBT to init data.
2017:06:09 13:37:54	...init bucket.
2017:06:09 13:37:54	...load data.
2017:06:09 13:37:54	...init data from the raw dataset.
2017:06:09 13:37:54	...read dialogues from file.
2017:06:09 13:37:54	......number of instances: 35429
2017:06:09 13:37:55	define generator.
2017:06:09 13:37:55	rnn type is lstm
2017:06:09 13:37:55	rnn type is lstm
2017:06:09 13:37:55	define discriminator.
2017:06:09 13:38:22	use DataLoaderBBT to init data.
2017:06:09 13:38:22	...init bucket.
2017:06:09 13:38:22	...load data.
2017:06:09 13:38:22	...init data from the raw dataset.
2017:06:09 13:38:22	...read dialogues from file.
2017:06:09 13:38:23	......number of instances: 35429
2017:06:09 13:38:23	define generator.
2017:06:09 13:38:23	rnn type is lstm
2017:06:09 13:38:23	rnn type is lstm
2017:06:09 13:38:23	define discriminator.
2017:06:09 13:38:33	use DataLoaderBBT to init data.
2017:06:09 13:38:33	...init bucket.
2017:06:09 13:38:33	...load data.
2017:06:09 13:38:33	...init data from the raw dataset.
2017:06:09 13:38:33	...read dialogues from file.
2017:06:09 13:38:34	......number of instances: 35429
2017:06:09 13:38:34	define generator.
2017:06:09 13:38:34	rnn type is lstm
2017:06:09 13:38:34	rnn type is lstm
2017:06:09 13:38:35	define discriminator.
2017:06:09 13:39:32	use DataLoaderBBT to init data.
2017:06:09 13:39:32	...init bucket.
2017:06:09 13:39:32	...load data.
2017:06:09 13:39:32	...init data from the raw dataset.
2017:06:09 13:39:32	...read dialogues from file.
2017:06:09 13:39:32	......number of instances: 35429
2017:06:09 13:39:32	define generator.
2017:06:09 13:39:32	rnn type is lstm
2017:06:09 13:39:32	rnn type is lstm
2017:06:09 13:39:33	define discriminator.
2017:06:09 13:39:33	define train operations...
2017:06:09 13:39:36	variables and gradients in the discriminator:
2017:06:09 13:39:36	variables and gradients in the generator:
2017:06:09 13:39:40	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497015576/checkpoints/bestmodel.

2017:06:09 13:39:40	------ pretraining ------ 

2017:06:09 13:39:40	pretrain epoch 0
2017:06:09 13:40:14	use DataLoaderBBT to init data.
2017:06:09 13:40:14	...init bucket.
2017:06:09 13:40:14	...load data.
2017:06:09 13:40:14	...init data from the raw dataset.
2017:06:09 13:40:14	...read dialogues from file.
2017:06:09 13:40:15	......number of instances: 35429
2017:06:09 13:40:15	define generator.
2017:06:09 13:40:15	rnn type is lstm
2017:06:09 13:40:15	rnn type is lstm
2017:06:09 13:40:16	define discriminator.
2017:06:09 13:40:16	define train operations...
2017:06:09 13:40:19	variables and gradients in the discriminator:
2017:06:09 13:40:19	variables and gradients in the generator:
2017:06:09 13:40:22	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497015619/checkpoints/bestmodel.

2017:06:09 13:40:22	------ pretraining ------ 

2017:06:09 13:40:22	pretrain epoch 0
2017:06:09 13:40:49	use DataLoaderBBTV1 to init data.
2017:06:09 13:40:49	...init bucket.
2017:06:09 13:40:49	...load data.
2017:06:09 13:40:49	...init data from the raw dataset.
2017:06:09 13:40:49	...read dialogues from file.
2017:06:09 13:40:50	......number of instances: 70858
2017:06:09 13:40:50	rnn type is lstm
2017:06:09 13:40:51	rnn type is lstm
2017:06:09 13:40:51	define train operations...
2017:06:09 13:40:53	variables and gradients in the discriminator:
2017:06:09 13:40:53	variables and gradients in the generator:
2017:06:09 13:40:57	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1497015654/checkpoints/bestmodel.

2017:06:09 13:40:57	------ pretraining ------ 

2017:06:09 13:40:57	pretrain epoch 0
2017:06:09 13:41:49	use DataLoaderBBTV1 to init data.
2017:06:09 13:41:49	...init bucket.
2017:06:09 13:41:49	...load data.
2017:06:09 13:41:49	...init data from the raw dataset.
2017:06:09 13:41:49	...read dialogues from file.
2017:06:09 13:41:49	......number of instances: 70858
2017:06:09 13:41:49	define generator.
2017:06:09 13:41:49	rnn type is lstm
2017:06:09 13:41:50	define discriminator.
2017:06:09 13:41:50	define train operations...
2017:06:09 13:41:52	variables and gradients in the discriminator:
2017:06:09 13:41:52	variables and gradients in the generator:
2017:06:09 13:41:55	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1497015712/checkpoints/bestmodel.

2017:06:09 13:41:55	------ pretraining ------ 

2017:06:09 13:41:55	pretrain epoch 0
2017:06:09 13:42:16	use DataLoaderBBTV1 to init data.
2017:06:09 13:42:16	...init bucket.
2017:06:09 13:42:16	...load data.
2017:06:09 13:42:16	...init data from the raw dataset.
2017:06:09 13:42:16	...read dialogues from file.
2017:06:09 13:42:17	......number of instances: 70858
2017:06:09 13:42:17	define generator.
2017:06:09 13:42:17	rnn type is lstm
2017:06:09 13:42:18	define discriminator.
2017:06:09 13:42:18	define train operations...
2017:06:09 13:42:21	variables and gradients in the discriminator:
2017:06:09 13:42:21	variables and gradients in the generator:
2017:06:09 13:42:24	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV1.TextGANV1/1497015741/checkpoints/bestmodel.

2017:06:09 13:42:24	------ pretraining ------ 

2017:06:09 13:42:24	------ training ------ 

2017:06:09 13:42:24	train epoch 1
2017:06:09 14:05:29	use DataLoaderBBT to init data.
2017:06:09 14:05:29	...init bucket.
2017:06:09 14:05:29	...load data.
2017:06:09 14:05:29	...init data from the raw dataset.
2017:06:09 14:05:29	...read dialogues from file.
2017:06:09 14:05:30	......number of instances: 35429
2017:06:09 14:05:30	define generator.
2017:06:09 14:05:30	rnn type is lstm
2017:06:09 14:05:30	rnn type is lstm
2017:06:09 14:05:30	define discriminator.
2017:06:09 14:05:31	define train operations...
2017:06:09 14:05:34	variables and gradients in the discriminator:
2017:06:09 14:05:34	variables and gradients in the generator:
2017:06:09 14:05:39	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017135/checkpoints/bestmodel.

2017:06:09 14:05:39	------ pretraining ------ 

2017:06:09 14:05:39	------ training ------ 

2017:06:09 14:05:39	train epoch 1
2017:06:09 14:06:43	use DataLoaderBBT to init data.
2017:06:09 14:06:43	...init bucket.
2017:06:09 14:06:43	...load data.
2017:06:09 14:06:43	...init data from the raw dataset.
2017:06:09 14:06:43	...read dialogues from file.
2017:06:09 14:06:44	......number of instances: 35429
2017:06:09 14:06:44	rnn type is lstm
2017:06:09 14:06:44	rnn type is lstm
2017:06:09 14:06:44	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017135/
2017:06:09 14:07:15	use DataLoaderBBT to init data.
2017:06:09 14:07:15	...init bucket.
2017:06:09 14:07:15	...load data.
2017:06:09 14:07:15	...init data from the raw dataset.
2017:06:09 14:07:15	...read dialogues from file.
2017:06:09 14:07:15	......number of instances: 35429
2017:06:09 14:07:15	define generator.
2017:06:09 14:07:15	rnn type is lstm
2017:06:09 14:07:16	rnn type is lstm
2017:06:09 14:07:16	define discriminator.
2017:06:09 14:07:16	define train operations...
2017:06:09 14:07:29	use DataLoaderBBT to init data.
2017:06:09 14:07:29	...init bucket.
2017:06:09 14:07:29	...load data.
2017:06:09 14:07:29	...init data from the raw dataset.
2017:06:09 14:07:29	...read dialogues from file.
2017:06:09 14:07:30	......number of instances: 35429
2017:06:09 14:07:30	define generator.
2017:06:09 14:07:30	rnn type is lstm
2017:06:09 14:07:30	rnn type is lstm
2017:06:09 14:07:31	define discriminator.
2017:06:09 14:07:31	define train operations...
2017:06:09 14:07:34	variables and gradients in the discriminator:
2017:06:09 14:07:34	variables and gradients in the generator:
2017:06:09 14:07:37	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017254/checkpoints/bestmodel.

2017:06:09 14:07:37	------ pretraining ------ 

2017:06:09 14:07:37	------ training ------ 

2017:06:09 14:07:37	train epoch 1
2017:06:09 14:08:09	use DataLoaderBBT to init data.
2017:06:09 14:08:09	...init bucket.
2017:06:09 14:08:09	...load data.
2017:06:09 14:08:09	...init data from the raw dataset.
2017:06:09 14:08:09	...read dialogues from file.
2017:06:09 14:08:10	......number of instances: 35429
2017:06:09 14:08:10	rnn type is lstm
2017:06:09 14:08:10	rnn type is lstm
2017:06:09 14:08:10	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017254/
2017:06:09 14:10:03	use DataLoaderBBT to init data.
2017:06:09 14:10:03	...init bucket.
2017:06:09 14:10:03	...load data.
2017:06:09 14:10:03	...init data from the raw dataset.
2017:06:09 14:10:03	...read dialogues from file.
2017:06:09 14:10:04	......number of instances: 35429
2017:06:09 14:10:04	define generator.
2017:06:09 14:10:04	rnn type is lstm
2017:06:09 14:10:04	rnn type is lstm
2017:06:09 14:10:04	define discriminator.
2017:06:09 14:10:04	define train operations...
2017:06:09 14:10:07	variables and gradients in the discriminator:
2017:06:09 14:10:07	variables and gradients in the generator:
2017:06:09 14:10:11	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017407/checkpoints/bestmodel.

2017:06:09 14:10:11	------ pretraining ------ 

2017:06:09 14:10:11	------ training ------ 

2017:06:09 14:10:11	train epoch 1
2017:06:09 14:11:34	use DataLoaderBBT to init data.
2017:06:09 14:11:34	...init bucket.
2017:06:09 14:11:34	...load data.
2017:06:09 14:11:34	...init data from the raw dataset.
2017:06:09 14:11:34	...read dialogues from file.
2017:06:09 14:11:35	......number of instances: 35429
2017:06:09 14:11:35	rnn type is lstm
2017:06:09 14:11:35	rnn type is lstm
2017:06:09 14:11:35	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017407/
2017:06:09 14:12:01	use DataLoaderBBT to init data.
2017:06:09 14:12:01	...init bucket.
2017:06:09 14:12:01	...load data.
2017:06:09 14:12:01	...init data from the raw dataset.
2017:06:09 14:12:01	...read dialogues from file.
2017:06:09 14:12:02	......number of instances: 35429
2017:06:09 14:12:02	define generator.
2017:06:09 14:12:02	rnn type is lstm
2017:06:09 14:12:02	rnn type is lstm
2017:06:09 14:12:02	define discriminator.
2017:06:09 14:12:02	init from the path data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017407/
2017:06:09 14:12:03	restore model from /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBT/code.model.textGANV2.TextGANV2/1497017407/checkpoints/bestmodel-0
2017:06:09 14:12:03	generate sentence from latent space.
2017:06:09 14:12:16	true question: one star trek the next generation phaser that 's leonard 's
2017:06:09 14:12:16	true answer: [Amy] children 's toy .
2017:06:09 14:12:16	faked answer: tad tad brad brad eloquence eloquence eloquence assurance assurance assurance assurance assurance assurance assurance assurance assurance directors unresolved unresolved directors directors squirrel squirrel squirrel squirrel completing completing completing completing completing completing completing hitchhiker kryptonite hitchhiker newton newton newton newton apsparagus invention invention invention invention invention invention invention invention invention
2017:06:09 14:12:16	total execution time: 14 s
2017:06:09 15:31:14	use DataLoaderBBTV1 to init data.
2017:06:09 15:31:14	...init bucket.
2017:06:09 15:31:14	...load data.
2017:06:09 15:31:14	...init data from the raw dataset.
2017:06:09 15:31:14	...read dialogues from file.
2017:06:09 15:31:15	......number of instances: 70858
2017:06:09 15:31:15	define generator.
2017:06:09 15:31:15	rnn type is lstm
2017:06:09 15:32:14	use DataLoaderBBTV1 to init data.
2017:06:09 15:32:14	...init bucket.
2017:06:09 15:32:14	...load data.
2017:06:09 15:32:14	...init data from the raw dataset.
2017:06:09 15:32:14	...read dialogues from file.
2017:06:09 15:32:15	......number of instances: 70858
2017:06:09 15:32:15	define generator.
2017:06:09 15:32:15	rnn type is lstm
2017:06:09 15:32:15	define discriminator.
2017:06:09 15:34:10	use DataLoaderBBTV1 to init data.
2017:06:09 15:34:10	...init bucket.
2017:06:09 15:34:10	...load data.
2017:06:09 15:34:10	...init data from the raw dataset.
2017:06:09 15:34:10	...read dialogues from file.
2017:06:09 15:34:11	......number of instances: 70858
2017:06:09 15:34:11	define generator.
2017:06:09 15:34:11	rnn type is lstm
2017:06:09 15:34:12	define discriminator.
2017:06:09 15:49:00	use DataLoaderBBTV1 to init data.
2017:06:09 15:49:00	...init bucket.
2017:06:09 15:49:00	...load data.
2017:06:09 15:49:00	...init data from the raw dataset.
2017:06:09 15:49:00	...read dialogues from file.
2017:06:09 15:49:00	......number of instances: 70858
2017:06:09 15:49:01	define generator.
2017:06:09 15:49:01	rnn type is lstm
2017:06:09 15:49:01	define discriminator.
2017:06:09 15:53:58	use DataLoaderBBTV1 to init data.
2017:06:09 15:53:58	...init bucket.
2017:06:09 15:53:58	...load data.
2017:06:09 15:53:58	...init data from the raw dataset.
2017:06:09 15:53:58	...read dialogues from file.
2017:06:09 15:53:59	......number of instances: 70858
2017:06:09 15:53:59	define generator.
2017:06:09 15:53:59	rnn type is lstm
2017:06:09 15:54:00	define discriminator.
2017:06:09 15:55:20	use DataLoaderBBTV1 to init data.
2017:06:09 15:55:20	...init bucket.
2017:06:09 15:55:20	...load data.
2017:06:09 15:55:20	...init data from the raw dataset.
2017:06:09 15:55:20	...read dialogues from file.
2017:06:09 15:55:21	......number of instances: 70858
2017:06:09 15:55:21	define generator.
2017:06:09 15:55:21	rnn type is lstm
2017:06:09 15:55:21	define discriminator.
2017:06:09 15:58:47	use DataLoaderBBTV1 to init data.
2017:06:09 15:58:47	...init bucket.
2017:06:09 15:58:47	...load data.
2017:06:09 15:58:47	...init data from the raw dataset.
2017:06:09 15:58:47	...read dialogues from file.
2017:06:09 15:58:48	......number of instances: 70858
2017:06:09 15:58:48	define generator.
2017:06:09 15:58:48	rnn type is lstm
2017:06:09 15:58:48	define discriminator.
2017:06:09 16:01:56	use DataLoaderBBTV1 to init data.
2017:06:09 16:01:56	...init bucket.
2017:06:09 16:01:56	...load data.
2017:06:09 16:01:56	...init data from the raw dataset.
2017:06:09 16:01:56	...read dialogues from file.
2017:06:09 16:01:57	......number of instances: 70858
2017:06:09 16:01:57	define generator.
2017:06:09 16:01:57	rnn type is lstm
2017:06:09 16:01:57	define discriminator.
2017:06:09 16:02:56	use DataLoaderBBTV1 to init data.
2017:06:09 16:02:56	...init bucket.
2017:06:09 16:02:56	...load data.
2017:06:09 16:02:56	...init data from the raw dataset.
2017:06:09 16:02:56	...read dialogues from file.
2017:06:09 16:02:56	......number of instances: 70858
2017:06:09 16:02:56	define generator.
2017:06:09 16:02:56	rnn type is lstm
2017:06:09 16:02:57	define discriminator.
2017:06:09 16:03:45	use DataLoaderBBTV1 to init data.
2017:06:09 16:03:45	...init bucket.
2017:06:09 16:03:45	...load data.
2017:06:09 16:03:45	...init data from the raw dataset.
2017:06:09 16:03:45	...read dialogues from file.
2017:06:09 16:03:46	......number of instances: 70858
2017:06:09 16:03:46	define generator.
2017:06:09 16:03:46	rnn type is lstm
2017:06:09 16:03:47	define discriminator.
2017:06:09 16:04:08	use DataLoaderBBTV1 to init data.
2017:06:09 16:04:08	...init bucket.
2017:06:09 16:04:08	...load data.
2017:06:09 16:04:08	...init data from the raw dataset.
2017:06:09 16:04:08	...read dialogues from file.
2017:06:09 16:04:09	......number of instances: 70858
2017:06:09 16:04:09	define generator.
2017:06:09 16:04:09	rnn type is lstm
2017:06:09 16:04:09	define discriminator.
2017:06:09 16:04:26	use DataLoaderBBTV1 to init data.
2017:06:09 16:04:26	...init bucket.
2017:06:09 16:04:26	...load data.
2017:06:09 16:04:26	...init data from the raw dataset.
2017:06:09 16:04:26	...read dialogues from file.
2017:06:09 16:04:27	......number of instances: 70858
2017:06:09 16:04:27	define generator.
2017:06:09 16:04:27	rnn type is lstm
2017:06:09 16:04:27	define discriminator.
2017:06:09 16:06:44	use DataLoaderBBTV1 to init data.
2017:06:09 16:06:44	...init bucket.
2017:06:09 16:06:44	...load data.
2017:06:09 16:06:44	...init data from the raw dataset.
2017:06:09 16:06:44	...read dialogues from file.
2017:06:09 16:06:45	......number of instances: 70858
2017:06:09 16:06:45	define generator.
2017:06:09 16:06:45	rnn type is lstm
2017:06:09 16:06:45	define discriminator.
2017:06:09 16:06:46	define train operations...
2017:06:09 16:06:48	variables and gradients in the discriminator:
2017:06:09 16:06:48	variables and gradients in the generator:
2017:06:09 16:06:53	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV3.TextGANV3/1497024408/checkpoints/bestmodel.

2017:06:09 16:06:53	------ training ------ 

2017:06:09 16:06:53	train epoch 1
2017:06:09 16:44:11	use DataLoaderBBTV1 to init data.
2017:06:09 16:44:11	...init bucket.
2017:06:09 16:44:11	...load data.
2017:06:09 16:44:11	...init data from the raw dataset.
2017:06:09 16:44:11	...read dialogues from file.
2017:06:09 16:44:12	......number of instances: 70858
2017:06:09 16:44:12	define generator.
2017:06:09 16:44:12	rnn type is lstm
2017:06:09 16:44:13	define discriminator.
2017:06:09 16:44:13	rnn type is lstm
2017:06:09 16:44:13	define train operations...
2017:06:09 16:44:16	variables and gradients in the discriminator:
2017:06:09 16:44:16	variables and gradients in the generator:
2017:06:09 16:44:21	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV3.TextGANV3/1497026656/checkpoints/bestmodel.

2017:06:09 16:44:21	------ training ------ 

2017:06:09 16:44:21	train epoch 1
2017:06:09 16:46:33	use DataLoaderBBTV1 to init data.
2017:06:09 16:46:33	...init bucket.
2017:06:09 16:46:33	...load data.
2017:06:09 16:46:33	...init data from the raw dataset.
2017:06:09 16:46:33	...read dialogues from file.
2017:06:09 16:46:34	......number of instances: 70858
2017:06:09 16:46:34	define generator.
2017:06:09 16:46:34	rnn type is lstm
2017:06:09 16:46:35	define discriminator.
2017:06:09 16:46:35	rnn type is lstm
2017:06:09 16:46:35	define train operations...
2017:06:09 16:46:38	variables and gradients in the discriminator:
2017:06:09 16:46:38	variables and gradients in the generator:
2017:06:09 16:46:41	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV3.TextGANV3/1497026799/checkpoints/bestmodel.

2017:06:09 16:46:41	------ training ------ 

2017:06:09 16:46:41	train epoch 1
2017:06:09 16:47:51	use DataLoaderBBTV1 to init data.
2017:06:09 16:47:51	...init bucket.
2017:06:09 16:47:51	...load data.
2017:06:09 16:47:51	...init data from the raw dataset.
2017:06:09 16:47:51	...read dialogues from file.
2017:06:09 16:47:52	......number of instances: 70858
2017:06:09 16:47:52	define generator.
2017:06:09 16:47:52	rnn type is lstm
2017:06:09 16:47:53	define discriminator.
2017:06:09 16:47:53	rnn type is lstm
2017:06:09 16:47:53	define train operations...
2017:06:09 16:47:56	variables and gradients in the discriminator:
2017:06:09 16:47:56	variables and gradients in the generator:
2017:06:09 16:47:58	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV3.TextGANV3/1497026876/checkpoints/bestmodel.

2017:06:09 16:47:58	------ training ------ 

2017:06:09 16:47:58	train epoch 1
2017:06:09 17:09:48	use DataLoaderBBTV1 to init data.
2017:06:09 17:09:49	...init bucket.
2017:06:09 17:09:49	...load data.
2017:06:09 17:09:49	...init data from the raw dataset.
2017:06:09 17:09:49	...read dialogues from file.
2017:06:09 17:09:49	......number of instances: 70858
2017:06:09 17:09:49	define generator.
2017:06:09 17:09:49	rnn type is lstm
2017:06:09 17:09:50	define discriminator.
2017:06:09 17:09:50	rnn type is lstm
2017:06:09 17:11:37	use DataLoaderBBTV1 to init data.
2017:06:09 17:11:37	...init bucket.
2017:06:09 17:11:37	...load data.
2017:06:09 17:11:37	...init data from the raw dataset.
2017:06:09 17:11:37	...read dialogues from file.
2017:06:09 17:11:38	......number of instances: 70858
2017:06:09 17:11:38	define generator.
2017:06:09 17:11:38	rnn type is lstm
2017:06:09 17:11:38	define discriminator.
2017:06:09 17:11:38	rnn type is lstm
2017:06:09 17:11:54	use DataLoaderBBTV1 to init data.
2017:06:09 17:11:54	...init bucket.
2017:06:09 17:11:54	...load data.
2017:06:09 17:11:54	...init data from the raw dataset.
2017:06:09 17:11:54	...read dialogues from file.
2017:06:09 17:11:54	......number of instances: 70858
2017:06:09 17:11:54	define generator.
2017:06:09 17:11:54	rnn type is lstm
2017:06:09 17:11:55	define discriminator.
2017:06:09 17:11:55	rnn type is lstm
2017:06:09 17:11:55	define train operations...
2017:06:09 17:11:58	variables and gradients in the discriminator:
2017:06:09 17:11:58	variables and gradients in the generator:
2017:06:09 17:12:44	use DataLoaderBBTV1 to init data.
2017:06:09 17:12:44	...init bucket.
2017:06:09 17:12:44	...load data.
2017:06:09 17:12:44	...init data from the raw dataset.
2017:06:09 17:12:44	...read dialogues from file.
2017:06:09 17:12:45	......number of instances: 70858
2017:06:09 17:12:45	define generator.
2017:06:09 17:12:45	rnn type is lstm
2017:06:09 17:12:45	define discriminator.
2017:06:09 17:12:45	rnn type is lstm
2017:06:09 17:12:46	define train operations...
2017:06:09 17:12:48	variables and gradients in the discriminator:
2017:06:09 17:12:48	variables and gradients in the generator:
2017:06:09 17:12:52	save 1-th bestmodel to path: /home/lin/notebooks/gan/code/demo6_v_textgan/data/training/runs/DataLoaderBBTV1/code.model.textGANV3.TextGANV3/1497028368/checkpoints/bestmodel.

2017:06:09 17:12:52	------ training ------ 

2017:06:09 17:12:52	train epoch 1
